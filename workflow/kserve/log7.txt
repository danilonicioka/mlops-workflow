WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.
2024-08-02T19:36:55,742 [WARN ] main org.pytorch.serve.util.ConfigManager - Your torchserve instance can access any URL to load models. When deploying to production, make sure to limit the set of allowed_urls in config.properties
2024-08-02T19:36:55,745 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2024-08-02T19:36:55,941 [INFO ] main org.pytorch.serve.metrics.configuration.MetricConfiguration - Successfully loaded metrics configuration from /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml
2024-08-02T19:36:56,161 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.9.0
TS Home: /home/venv/lib/python3.9/site-packages
Current directory: /home/model-server
Temp directory: /home/model-server/tmp
Metrics config path: /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml
Number of GPUs: 0
Number of CPUs: 1
Max heap size: 494 M
Python executable: /home/venv/bin/python
Config file: /mnt/models/config/config.properties
Inference address: http://0.0.0.0:8085
Management address: http://0.0.0.0:8083
Metrics address: http://0.0.0.0:8082
Model Store: /mnt/models/model-store
Initial Models: N/A
Log dir: /home/model-server/logs
Metrics dir: /home/model-server/logs
Netty threads: 4
Netty client threads: 0
Default workers per model: 1
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: true
Enable metrics API: true
Metrics mode: prometheus
Disable system metrics: false
Workflow Store: /mnt/models/model-store
Model config: N/A
2024-08-02T19:36:56,170 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2024-08-02T19:36:56,251 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Started restoring models from snapshot {"name":"startup.cfg","modelCount":1,"models":{"youtubegoes5g":{"1.0":{"defaultVersion":true,"marName":"youtubegoes5g.mar","minWorkers":1,"maxWorkers":5,"batchSize":1,"maxBatchDelay":5000,"responseTimeout":120}}}}
2024-08-02T19:36:56,260 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Validating snapshot startup.cfg
2024-08-02T19:36:56,262 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Snapshot startup.cfg validated successfully
2024-08-02T19:36:56,356 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model youtubegoes5g
2024-08-02T19:36:56,356 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model youtubegoes5g
INFO:root:Wrapper : Model names ['youtubegoes5g'], inference address http://0.0.0.0:8085, management address http://0.0.0.0:8083, grpc_inference_address, 0.0.0.0:7070, model store /mnt/models/model-store
INFO:root:Predict URL set to 0.0.0.0:8085
INFO:root:Explain URL set to 0.0.0.0:8085
INFO:root:Protocol version is v2
INFO:root:Copying contents of /mnt/models/model-store to local
INFO:root:TSModelRepo is initialized
INFO:kserve:Registering model: youtubegoes5g
INFO:kserve:Setting max asyncio worker threads as 10
INFO:kserve:Starting uvicorn with 1 workers
2024-08-02 19:36:58.028 uvicorn.error INFO:     Started server process [9]
2024-08-02 19:36:58.028 uvicorn.error INFO:     Waiting for application startup.
2024-08-02 19:36:58.032 9 kserve INFO [start():62] Starting gRPC server on [::]:8081
2024-08-02 19:36:58.032 uvicorn.error INFO:     Application startup complete.
2024-08-02 19:36:58.033 uvicorn.error INFO:     Uvicorn running on http://0.0.0.0:8080 (Press CTRL+C to quit)
2024-08-02T19:37:09,977 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model youtubegoes5g
2024-08-02T19:37:09,978 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model youtubegoes5g loaded.
2024-08-02T19:37:09,978 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: youtubegoes5g, count: 1
2024-08-02T19:37:09,986 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9000, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2024-08-02T19:37:09,987 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.
2024-08-02T19:37:10,142 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://0.0.0.0:8085
2024-08-02T19:37:10,142 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: EpollServerSocketChannel.
2024-08-02T19:37:10,144 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://0.0.0.0:8083
2024-08-02T19:37:10,144 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.
2024-08-02T19:37:10,145 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://0.0.0.0:8082
Model server started.
2024-08-02T19:37:10,786 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2024-08-02T19:37:12,515 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9000, pid=52
2024-08-02T19:37:12,517 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9000
2024-08-02T19:37:12,527 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Successfully loaded /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2024-08-02T19:37:12,528 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - [PID]52
2024-08-02T19:37:12,528 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Torch worker started.
2024-08-02T19:37:12,529 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Python runtime: 3.9.18
2024-08-02T19:37:12,537 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-youtubegoes5g_1.0 State change null -> WORKER_STARTED
2024-08-02T19:37:12,542 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9000
2024-08-02T19:37:12,550 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9000.
2024-08-02T19:37:12,553 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1722627432553
2024-08-02T19:37:12,640 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - model_name: youtubegoes5g, batchSize: 1
2024-08-02T19:37:12,649 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Backend worker process died.
2024-08-02T19:37:12,649 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2024-08-02T19:37:12,650 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG -   File "/home/model-server/tmp/models/afce701209234594ab7e60fd95e2fdc6/ts/model_loader.py", line 108, in load
2024-08-02T19:37:12,650 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2024-08-02T19:37:12,650 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG -   File "/home/model-server/tmp/models/afce701209234594ab7e60fd95e2fdc6/ts/model_loader.py", line 153, in _load_handler_file
2024-08-02T19:37:12,651 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2024-08-02T19:37:12,651 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG -   File "/usr/lib/python3.9/importlib/__init__.py", line 127, in import_module
2024-08-02T19:37:12,650 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2024-08-02T19:37:12,651 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2024-08-02T19:37:12,651 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2024-08-02T19:37:12,652 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2024-08-02T19:37:12,652 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2024-08-02T19:37:12,652 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2024-08-02T19:37:12,652 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2024-08-02T19:37:12,652 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2024-08-02T19:37:12,653 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2024-08-02T19:37:12,653 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG -   File "/home/model-server/tmp/models/afce701209234594ab7e60fd95e2fdc6/handler.py", line 18, in <module>
2024-08-02T19:37:12,653 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG -     from ..utils.util import (
2024-08-02T19:37:12,653 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - ImportError: attempted relative import with no known parent package
2024-08-02T19:37:12,654 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - 
2024-08-02T19:37:12,654 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2024-08-02T19:37:12,654 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - 
2024-08-02T19:37:12,654 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2024-08-02T19:37:12,655 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG -   File "/home/venv/lib/python3.9/site-packages/ts/model_service_worker.py", line 258, in <module>
2024-08-02T19:37:12,655 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG -     worker.run_server()
2024-08-02T19:37:12,655 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG -   File "/home/venv/lib/python3.9/site-packages/ts/model_service_worker.py", line 226, in run_server
2024-08-02T19:37:12,655 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2024-08-02T19:37:12,655 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG -   File "/home/venv/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in handle_connection
2024-08-02T19:37:12,656 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2024-08-02T19:37:12,656 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG -   File "/home/venv/lib/python3.9/site-packages/ts/model_service_worker.py", line 131, in load_model
2024-08-02T19:37:12,656 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG -     service = model_loader.load(
2024-08-02T19:37:12,656 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG -   File "/home/model-server/tmp/models/afce701209234594ab7e60fd95e2fdc6/ts/model_loader.py", line 110, in load
2024-08-02T19:37:12,657 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2024-08-02T19:37:12,657 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG -   File "/home/model-server/tmp/models/afce701209234594ab7e60fd95e2fdc6/ts/model_loader.py", line 159, in _load_default_handler
2024-08-02T19:37:12,657 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, "ts.torch_handler")
2024-08-02T19:37:12,657 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG -   File "/usr/lib/python3.9/importlib/__init__.py", line 127, in import_module
2024-08-02T19:37:12,658 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2024-08-02T19:37:12,658 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2024-08-02T19:37:12,658 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2024-08-02T19:37:12,658 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 972, in _find_and_load_unlocked
2024-08-02T19:37:12,658 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2024-08-02T19:37:12,659 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2024-08-02T19:37:12,659 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2024-08-02T19:37:12,659 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 984, in _find_and_load_unlocked
2024-08-02T19:37:12,659 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.handler'
2024-08-02T19:37:12,652 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:219) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2024-08-02T19:37:12,668 [WARN ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: youtubegoes5g, error: Worker died.
2024-08-02T19:37:12,668 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-youtubegoes5g_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2024-08-02T19:37:12,669 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery start timestamp: 1722627432669
2024-08-02T19:37:12,669 [WARN ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-youtubegoes5g_1.0-stderr
2024-08-02T19:37:12,737 [WARN ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-youtubegoes5g_1.0-stdout
2024-08-02T19:37:12,738 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2024-08-02T19:37:12,748 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-youtubegoes5g_1.0-stdout
2024-08-02T19:37:12,748 [INFO ] W-9000-youtubegoes5g_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-youtubegoes5g_1.0-stderr
2024-08-02T19:37:13,738 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9000, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2024-08-02T19:37:15,555 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9000, pid=69
2024-08-02T19:37:15,556 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9000
2024-08-02T19:37:15,571 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Successfully loaded /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2024-08-02T19:37:15,571 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - [PID]69
2024-08-02T19:37:15,571 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Torch worker started.
2024-08-02T19:37:15,572 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Python runtime: 3.9.18
2024-08-02T19:37:15,572 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-youtubegoes5g_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2024-08-02T19:37:15,573 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9000
2024-08-02T19:37:15,575 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2024-08-02T19:37:15,575 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9000.
2024-08-02T19:37:15,576 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2024-08-02T19:37:15,576 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.LinkedBlockingDeque.pollFirst(LinkedBlockingDeque.java:515) ~[?:?]
	at java.util.concurrent.LinkedBlockingDeque.poll(LinkedBlockingDeque.java:677) ~[?:?]
	at org.pytorch.serve.wlm.Model.pollBatch(Model.java:367) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.BatchAggregator.getRequest(BatchAggregator.java:36) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:194) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2024-08-02T19:37:15,577 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-youtubegoes5g_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2024-08-02T19:37:15,577 [WARN ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2024-08-02T19:37:15,577 [WARN ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-youtubegoes5g_1.0-stderr
2024-08-02T19:37:15,578 [WARN ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-youtubegoes5g_1.0-stdout
2024-08-02T19:37:15,578 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2024-08-02T19:37:15,587 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-youtubegoes5g_1.0-stdout
2024-08-02T19:37:15,588 [INFO ] W-9000-youtubegoes5g_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-youtubegoes5g_1.0-stderr
2024-08-02T19:37:16,578 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9000, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2024-08-02T19:37:18,333 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9000, pid=78
2024-08-02T19:37:18,337 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9000
2024-08-02T19:37:18,345 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Successfully loaded /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2024-08-02T19:37:18,345 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - [PID]78
2024-08-02T19:37:18,345 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Torch worker started.
2024-08-02T19:37:18,345 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Python runtime: 3.9.18
2024-08-02T19:37:18,345 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-youtubegoes5g_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2024-08-02T19:37:18,346 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9000
2024-08-02T19:37:18,347 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2024-08-02T19:37:18,347 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2024-08-02T19:37:18,347 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.LinkedBlockingDeque.pollFirst(LinkedBlockingDeque.java:515) ~[?:?]
	at java.util.concurrent.LinkedBlockingDeque.poll(LinkedBlockingDeque.java:677) ~[?:?]
	at org.pytorch.serve.wlm.Model.pollBatch(Model.java:367) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.BatchAggregator.getRequest(BatchAggregator.java:36) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:194) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2024-08-02T19:37:18,348 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-youtubegoes5g_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2024-08-02T19:37:18,349 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9000.
2024-08-02T19:37:18,349 [WARN ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2024-08-02T19:37:18,350 [WARN ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-youtubegoes5g_1.0-stderr
2024-08-02T19:37:18,350 [WARN ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-youtubegoes5g_1.0-stdout
2024-08-02T19:37:18,350 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 2 seconds.
2024-08-02T19:37:18,359 [INFO ] W-9000-youtubegoes5g_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-youtubegoes5g_1.0-stderr
2024-08-02T19:37:18,360 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-youtubegoes5g_1.0-stdout
2024-08-02T19:37:20,352 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9000, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2024-08-02T19:37:22,158 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9000, pid=86
2024-08-02T19:37:22,158 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9000
2024-08-02T19:37:22,170 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Successfully loaded /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2024-08-02T19:37:22,171 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - [PID]86
2024-08-02T19:37:22,171 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Torch worker started.
2024-08-02T19:37:22,172 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-youtubegoes5g_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2024-08-02T19:37:22,172 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Python runtime: 3.9.18
2024-08-02T19:37:22,172 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9000
2024-08-02T19:37:22,173 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9000.
2024-08-02T19:37:22,173 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2024-08-02T19:37:22,173 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2024-08-02T19:37:22,173 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.LinkedBlockingDeque.pollFirst(LinkedBlockingDeque.java:515) ~[?:?]
	at java.util.concurrent.LinkedBlockingDeque.poll(LinkedBlockingDeque.java:677) ~[?:?]
	at org.pytorch.serve.wlm.Model.pollBatch(Model.java:367) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.BatchAggregator.getRequest(BatchAggregator.java:36) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:194) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2024-08-02T19:37:22,173 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-youtubegoes5g_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2024-08-02T19:37:22,174 [WARN ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2024-08-02T19:37:22,174 [WARN ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-youtubegoes5g_1.0-stderr
2024-08-02T19:37:22,174 [WARN ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-youtubegoes5g_1.0-stdout
2024-08-02T19:37:22,174 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 3 seconds.
2024-08-02T19:37:22,183 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-youtubegoes5g_1.0-stdout
2024-08-02T19:37:22,183 [INFO ] W-9000-youtubegoes5g_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-youtubegoes5g_1.0-stderr
2024-08-02T19:37:25,175 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9000, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2024-08-02T19:37:26,957 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9000, pid=94
2024-08-02T19:37:26,958 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9000
2024-08-02T19:37:26,970 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Successfully loaded /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2024-08-02T19:37:26,971 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - [PID]94
2024-08-02T19:37:26,971 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Torch worker started.
2024-08-02T19:37:26,971 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-youtubegoes5g_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2024-08-02T19:37:26,971 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Python runtime: 3.9.18
2024-08-02T19:37:26,971 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9000
2024-08-02T19:37:26,972 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2024-08-02T19:37:26,972 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9000.
2024-08-02T19:37:26,972 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2024-08-02T19:37:26,973 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.LinkedBlockingDeque.pollFirst(LinkedBlockingDeque.java:515) ~[?:?]
	at java.util.concurrent.LinkedBlockingDeque.poll(LinkedBlockingDeque.java:677) ~[?:?]
	at org.pytorch.serve.wlm.Model.pollBatch(Model.java:367) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.BatchAggregator.getRequest(BatchAggregator.java:36) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:194) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2024-08-02T19:37:26,973 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-youtubegoes5g_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2024-08-02T19:37:26,973 [WARN ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2024-08-02T19:37:26,974 [WARN ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-youtubegoes5g_1.0-stderr
2024-08-02T19:37:26,974 [WARN ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-youtubegoes5g_1.0-stdout
2024-08-02T19:37:26,974 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 5 seconds.
2024-08-02T19:37:26,983 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-youtubegoes5g_1.0-stdout
2024-08-02T19:37:26,983 [INFO ] W-9000-youtubegoes5g_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-youtubegoes5g_1.0-stderr
2024-08-02T19:37:31,975 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9000, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2024-08-02T19:37:33,759 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9000, pid=102
2024-08-02T19:37:33,760 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9000
2024-08-02T19:37:33,772 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Successfully loaded /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2024-08-02T19:37:33,773 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - [PID]102
2024-08-02T19:37:33,773 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Torch worker started.
2024-08-02T19:37:33,773 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-youtubegoes5g_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2024-08-02T19:37:33,773 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Python runtime: 3.9.18
2024-08-02T19:37:33,774 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9000
2024-08-02T19:37:33,775 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2024-08-02T19:37:33,775 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2024-08-02T19:37:33,775 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.LinkedBlockingDeque.pollFirst(LinkedBlockingDeque.java:515) ~[?:?]
	at java.util.concurrent.LinkedBlockingDeque.poll(LinkedBlockingDeque.java:677) ~[?:?]
	at org.pytorch.serve.wlm.Model.pollBatch(Model.java:367) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.BatchAggregator.getRequest(BatchAggregator.java:36) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:194) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2024-08-02T19:37:33,776 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-youtubegoes5g_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2024-08-02T19:37:33,776 [WARN ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2024-08-02T19:37:33,776 [WARN ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-youtubegoes5g_1.0-stderr
2024-08-02T19:37:33,777 [WARN ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-youtubegoes5g_1.0-stdout
2024-08-02T19:37:33,777 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 8 seconds.
2024-08-02T19:37:33,786 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-youtubegoes5g_1.0-stdout
2024-08-02T19:37:33,787 [INFO ] W-9000-youtubegoes5g_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-youtubegoes5g_1.0-stderr
2024-08-02T19:37:33,789 [ERROR] epollEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - Unknown exception
io.netty.channel.unix.Errors$NativeIoException: readAddress(..) failed: Connection reset by peer
2024-08-02T19:37:41,778 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9000, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2024-08-02T19:37:43,561 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9000, pid=110
2024-08-02T19:37:43,562 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9000
2024-08-02T19:37:43,581 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Successfully loaded /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2024-08-02T19:37:43,581 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - [PID]110
2024-08-02T19:37:43,581 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Torch worker started.
2024-08-02T19:37:43,581 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Python runtime: 3.9.18
2024-08-02T19:37:43,582 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-youtubegoes5g_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2024-08-02T19:37:43,582 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9000
2024-08-02T19:37:43,585 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9000.
2024-08-02T19:37:43,585 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2024-08-02T19:37:43,585 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2024-08-02T19:37:43,586 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.LinkedBlockingDeque.pollFirst(LinkedBlockingDeque.java:515) ~[?:?]
	at java.util.concurrent.LinkedBlockingDeque.poll(LinkedBlockingDeque.java:677) ~[?:?]
	at org.pytorch.serve.wlm.Model.pollBatch(Model.java:367) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.BatchAggregator.getRequest(BatchAggregator.java:36) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:194) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2024-08-02T19:37:43,586 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-youtubegoes5g_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2024-08-02T19:37:43,586 [WARN ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2024-08-02T19:37:43,587 [WARN ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-youtubegoes5g_1.0-stderr
2024-08-02T19:37:43,587 [WARN ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-youtubegoes5g_1.0-stdout
2024-08-02T19:37:43,587 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 13 seconds.
2024-08-02T19:37:43,597 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-youtubegoes5g_1.0-stdout
2024-08-02T19:37:43,597 [INFO ] W-9000-youtubegoes5g_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-youtubegoes5g_1.0-stderr
2024-08-02T19:37:56,588 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9000, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2024-08-02T19:37:58,320 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9000, pid=118
2024-08-02T19:37:58,321 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9000
2024-08-02T19:37:58,332 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Successfully loaded /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2024-08-02T19:37:58,332 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - [PID]118
2024-08-02T19:37:58,332 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Torch worker started.
2024-08-02T19:37:58,333 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Python runtime: 3.9.18
2024-08-02T19:37:58,333 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-youtubegoes5g_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2024-08-02T19:37:58,333 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9000
2024-08-02T19:37:58,336 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2024-08-02T19:37:58,337 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2024-08-02T19:37:58,337 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer.tryAcquireSharedNanos(AbstractQueuedSynchronizer.java:1081) ~[?:?]
	at java.util.concurrent.CountDownLatch.await(CountDownLatch.java:276) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.connect(WorkerThread.java:424) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:191) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2024-08-02T19:37:58,337 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-youtubegoes5g_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2024-08-02T19:37:58,338 [WARN ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2024-08-02T19:37:58,338 [WARN ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-youtubegoes5g_1.0-stderr
2024-08-02T19:37:58,338 [WARN ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-youtubegoes5g_1.0-stdout
2024-08-02T19:37:58,338 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 21 seconds.
2024-08-02T19:37:58,350 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-youtubegoes5g_1.0-stdout
2024-08-02T19:37:58,351 [ERROR] epollEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - Unknown exception
io.netty.channel.unix.Errors$NativeIoException: readAddress(..) failed: Connection reset by peer
2024-08-02T19:37:58,350 [INFO ] W-9000-youtubegoes5g_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-youtubegoes5g_1.0-stderr

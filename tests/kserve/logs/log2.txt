2025-01-22T18:17:16,466 [INFO ] epollEventLoopGroup-3-4 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737569836
2025-01-22T18:17:16,466 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1737569836466
2025-01-22T18:17:16,467 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Backend received inference at: 1737569836
2025-01-22T18:17:16,467 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Received data: [{'data': [13, 13, 13, 0, 13, 13, 13, 13, -76, -76, -81, -76, -78.5, -76, -76, -7, -7, -12, -7, -9.5, -7, -7, 12, 12, 7, 12, 9.5, 12, 12]}]
2025-01-22T18:17:16,468 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Input data preprocessed successfully
2025-01-22T18:17:16,468 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Inference performed successfully
2025-01-22T18:17:16,468 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Output postprocessed successfully
2025-01-22T18:17:16,469 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:1.5|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,1737569836,a69819dd-ff72-4251-a0ae-d4bcebe764c2, pattern=[METRICS]
2025-01-22T18:17:16,469 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_METRICS - PredictionTime.ms:1.5|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,requestID:a69819dd-ff72-4251-a0ae-d4bcebe764c2,timestamp:1737569836
2025-01-22T18:17:16,469 [INFO ] W-9000-youtubegoes5g_1.0 ACCESS_LOG - /127.0.0.1:60482 "POST /v1/models/youtubegoes5g:predict HTTP/1.1" 200 3
2025-01-22T18:17:16,469 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737569836
2025-01-22T18:17:16,469 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:2573.688|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737569836
2025-01-22T18:17:16,469 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:41.658|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737569836
2025-01-22T18:17:16,469 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.job.Job - Waiting time ns: 41658, Backend time ns: 3018441
2025-01-22T18:17:16,470 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737569836
2025-01-22T18:17:16,470 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2025-01-22T18:17:16,470 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2
2025-01-22T18:17:16,470 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:2.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737569836
2025-01-22 18:17:16.472 kserve.trace requestId: d830a36f-fa9a-4908-b056-5925238850c9, preprocess_ms: 0.012397766, explain_ms: 0, predict_ms: 7.484197617, postprocess_ms: 0.005960464
2025-01-22 18:17:16.472 uvicorn.access INFO:     10.233.75.99:0 9 - "POST /v1/models/youtubegoes5g%3Apredict HTTP/1.1" 200 OK
2025-01-22 18:17:16.472 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.008633852005004883
2025-01-22 18:17:16.472 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.0048659999993105885
2025-01-22T18:17:18,993 [INFO ] pool-3-thread-2 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737569838
2025-01-22T18:17:18,993 [INFO ] pool-3-thread-2 TS_METRICS - DiskAvailable.Gigabytes:263.71530532836914|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737569838
2025-01-22T18:17:18,993 [INFO ] pool-3-thread-2 TS_METRICS - DiskUsage.Gigabytes:208.28796005249023|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737569838
2025-01-22T18:17:18,993 [INFO ] pool-3-thread-2 TS_METRICS - DiskUtilization.Percent:44.1|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737569838
2025-01-22T18:17:18,993 [INFO ] pool-3-thread-2 TS_METRICS - MemoryAvailable.Megabytes:11122.54296875|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737569838
2025-01-22T18:17:18,993 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUsed.Megabytes:8517.05859375|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737569838
2025-01-22T18:17:18,993 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUtilization.Percent:44.3|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737569838
2025-01-22T18:17:28,505 [INFO ] epollEventLoopGroup-3-1 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737569848
2025-01-22T18:17:28,505 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1737569848505
2025-01-22T18:17:28,506 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Backend received inference at: 1737569848
2025-01-22T18:17:28,506 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Received data: [{'data': [13, 13, 13, 0, 13, 13, 13, 13, -76, -76, -81, -76, -78.5, -76, -76, -7, -7, -12, -7, -9.5, -7, -7, 12, 12, 7, 12, 9.5, 12, 12]}]
2025-01-22T18:17:28,506 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Input data preprocessed successfully
2025-01-22T18:17:28,509 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Inference performed successfully
2025-01-22T18:17:28,509 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Output postprocessed successfully
2025-01-22T18:17:28,509 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:2.95|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,1737569848,66d306cf-e033-47ee-9ac7-67a50692ec85, pattern=[METRICS]
2025-01-22T18:17:28,509 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_METRICS - PredictionTime.ms:2.95|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,requestID:66d306cf-e033-47ee-9ac7-67a50692ec85,timestamp:1737569848
2025-01-22T18:17:28,510 [INFO ] W-9000-youtubegoes5g_1.0 ACCESS_LOG - /127.0.0.1:59758 "POST /v1/models/youtubegoes5g:predict HTTP/1.1" 200 5
2025-01-22T18:17:28,510 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737569848
2025-01-22T18:17:28,510 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:4889.587|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737569848
2025-01-22T18:17:28,510 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:36.61|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737569848
2025-01-22T18:17:28,510 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.job.Job - Waiting time ns: 36610, Backend time ns: 5111216
2025-01-22T18:17:28,510 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737569848
2025-01-22T18:17:28,510 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2025-01-22T18:17:28,510 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 5
2025-01-22T18:17:28,510 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737569848
2025-01-22 18:17:28.512 kserve.trace requestId: 5b7e5d58-46e1-40c7-b7ca-51a01983ee5f, preprocess_ms: 0.013113022, explain_ms: 0, predict_ms: 8.891820908, postprocess_ms: 0.006437302
2025-01-22 18:17:28.512 uvicorn.access INFO:     10.233.75.99:0 9 - "POST /v1/models/youtubegoes5g%3Apredict HTTP/1.1" 200 OK
2025-01-22 18:17:28.512 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.009893417358398438
2025-01-22 18:17:28.512 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.004424000000653905
2025-01-22T18:17:40,531 [INFO ] epollEventLoopGroup-3-2 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737569860
2025-01-22T18:17:40,532 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1737569860532
2025-01-22T18:17:40,532 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Backend received inference at: 1737569860
2025-01-22T18:17:40,532 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Received data: [{'data': [13, 13, 13, 0, 13, 13, 13, 13, -76, -76, -81, -76, -78.5, -76, -76, -7, -7, -12, -7, -9.5, -7, -7, 12, 12, 7, 12, 9.5, 12, 12]}]
2025-01-22T18:17:40,533 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Input data preprocessed successfully
2025-01-22T18:17:40,534 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Inference performed successfully
2025-01-22T18:17:40,534 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Output postprocessed successfully
2025-01-22T18:17:40,534 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:1.56|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,1737569860,65e48490-245c-4b6d-b7c0-8905cf74af0e, pattern=[METRICS]
2025-01-22T18:17:40,534 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_METRICS - PredictionTime.ms:1.56|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,requestID:65e48490-245c-4b6d-b7c0-8905cf74af0e,timestamp:1737569860
2025-01-22T18:17:40,535 [INFO ] W-9000-youtubegoes5g_1.0 ACCESS_LOG - /127.0.0.1:36014 "POST /v1/models/youtubegoes5g:predict HTTP/1.1" 200 4
2025-01-22T18:17:40,535 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737569860
2025-01-22T18:17:40,535 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:3700.49|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737569860
2025-01-22T18:17:40,535 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:36.793|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737569860
2025-01-22T18:17:40,535 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.job.Job - Waiting time ns: 36793, Backend time ns: 3935319
2025-01-22T18:17:40,535 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737569860
2025-01-22T18:17:40,535 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2025-01-22T18:17:40,535 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3
2025-01-22T18:17:40,536 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737569860
2025-01-22 18:17:40.537 kserve.trace requestId: 31ccd89a-b162-48e8-8c3f-51a5219d5d54, preprocess_ms: 0.016927719, explain_ms: 0, predict_ms: 7.997751236, postprocess_ms: 0.005722046
2025-01-22 18:17:40.537 uvicorn.access INFO:     10.233.75.99:0 9 - "POST /v1/models/youtubegoes5g%3Apredict HTTP/1.1" 200 OK
2025-01-22 18:17:40.537 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.009109258651733398
2025-01-22 18:17:40.537 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.0048170000009122305
2025-01-22T18:17:52,555 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737569872
2025-01-22T18:17:52,555 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1737569872555
2025-01-22T18:17:52,555 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Backend received inference at: 1737569872
2025-01-22T18:17:52,556 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Received data: [{'data': [13, 13, 13, 0, 13, 13, 13, 13, -76, -76, -81, -76, -78.5, -76, -76, -7, -7, -12, -7, -9.5, -7, -7, 12, 12, 7, 12, 9.5, 12, 12]}]
2025-01-22T18:17:52,556 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Input data preprocessed successfully
2025-01-22T18:17:52,557 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Inference performed successfully
2025-01-22T18:17:52,557 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Output postprocessed successfully
2025-01-22T18:17:52,557 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:1.56|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,1737569872,6ee0fe92-dc15-419c-91d2-92dcb768be70, pattern=[METRICS]
2025-01-22T18:17:52,557 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_METRICS - PredictionTime.ms:1.56|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,requestID:6ee0fe92-dc15-419c-91d2-92dcb768be70,timestamp:1737569872
2025-01-22T18:17:52,557 [INFO ] W-9000-youtubegoes5g_1.0 ACCESS_LOG - /127.0.0.1:37642 "POST /v1/models/youtubegoes5g:predict HTTP/1.1" 200 2
2025-01-22T18:17:52,557 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737569872
2025-01-22T18:17:52,557 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:2598.458|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737569872
2025-01-22T18:17:52,557 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:55.807|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737569872
2025-01-22T18:17:52,558 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.job.Job - Waiting time ns: 55807, Backend time ns: 2678440
2025-01-22T18:17:52,558 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737569872
2025-01-22T18:17:52,558 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2025-01-22T18:17:52,558 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2
2025-01-22T18:17:52,558 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737569872
2025-01-22 18:17:52.559 kserve.trace requestId: ce2071fa-7b34-424e-bdc4-6e494249f9b2, preprocess_ms: 0.019788742, explain_ms: 0, predict_ms: 7.373332977, postprocess_ms: 0.004768372
2025-01-22 18:17:52.560 uvicorn.access INFO:     10.233.75.99:0 9 - "POST /v1/models/youtubegoes5g%3Apredict HTTP/1.1" 200 OK
2025-01-22 18:17:52.560 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.008464813232421875
2025-01-22 18:17:52.560 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.004621000000042841
2025-01-22T18:18:04,578 [INFO ] epollEventLoopGroup-3-4 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737569884
2025-01-22T18:18:04,579 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1737569884579
2025-01-22T18:18:04,579 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Backend received inference at: 1737569884
2025-01-22T18:18:04,579 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Received data: [{'data': [13, 13, 13, 0, 13, 13, 13, 13, -76, -76, -81, -76, -78.5, -76, -76, -7, -7, -12, -7, -9.5, -7, -7, 12, 12, 7, 12, 9.5, 12, 12]}]
2025-01-22T18:18:04,580 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Input data preprocessed successfully
2025-01-22T18:18:04,586 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Inference performed successfully
2025-01-22T18:18:04,586 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Output postprocessed successfully
2025-01-22T18:18:04,586 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:6.52|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,1737569884,752bda77-2485-49bd-89f4-77b17b17ce6f, pattern=[METRICS]
2025-01-22T18:18:04,586 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_METRICS - PredictionTime.ms:6.52|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,requestID:752bda77-2485-49bd-89f4-77b17b17ce6f,timestamp:1737569884
2025-01-22T18:18:04,586 [INFO ] W-9000-youtubegoes5g_1.0 ACCESS_LOG - /127.0.0.1:38092 "POST /v1/models/youtubegoes5g:predict HTTP/1.1" 200 8
2025-01-22T18:18:04,586 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737569884
2025-01-22T18:18:04,586 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:7608.127|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737569884
2025-01-22T18:18:04,586 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:64.235|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737569884
2025-01-22T18:18:04,586 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.job.Job - Waiting time ns: 64235, Backend time ns: 7662416
2025-01-22T18:18:04,586 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737569884
2025-01-22T18:18:04,586 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2025-01-22T18:18:04,586 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 7
2025-01-22T18:18:04,586 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737569884
2025-01-22 18:18:04.587 kserve.trace requestId: ea47a0cf-101d-4258-ac2c-1c344952a098, preprocess_ms: 0.014781952, explain_ms: 0, predict_ms: 12.342453003, postprocess_ms: 0.005245209
2025-01-22 18:18:04.588 uvicorn.access INFO:     10.233.75.99:0 9 - "POST /v1/models/youtubegoes5g%3Apredict HTTP/1.1" 200 OK
2025-01-22 18:18:04.588 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.013218402862548828
2025-01-22 18:18:04.588 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.005516999999599648
2025-01-22T18:18:16,608 [INFO ] epollEventLoopGroup-3-1 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737569896
2025-01-22T18:18:16,609 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1737569896609
2025-01-22T18:18:16,609 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Backend received inference at: 1737569896
2025-01-22T18:18:16,609 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Received data: [{'data': [13, 13, 13, 0, 13, 13, 13, 13, -76, -76, -81, -76, -78.5, -76, -76, -7, -7, -12, -7, -9.5, -7, -7, 12, 12, 7, 12, 9.5, 12, 12]}]
2025-01-22T18:18:16,610 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Input data preprocessed successfully
2025-01-22T18:18:16,612 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Inference performed successfully
2025-01-22T18:18:16,612 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Output postprocessed successfully
2025-01-22T18:18:16,613 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:3.23|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,1737569896,2cd25312-cbc6-450b-8cdb-d52c68823882, pattern=[METRICS]
2025-01-22T18:18:16,613 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_METRICS - PredictionTime.ms:3.23|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,requestID:2cd25312-cbc6-450b-8cdb-d52c68823882,timestamp:1737569896
2025-01-22T18:18:16,613 [INFO ] W-9000-youtubegoes5g_1.0 ACCESS_LOG - /127.0.0.1:39742 "POST /v1/models/youtubegoes5g:predict HTTP/1.1" 200 5
2025-01-22T18:18:16,613 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737569896
2025-01-22T18:18:16,613 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:4322.939|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737569896
2025-01-22T18:18:16,613 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:52.864|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737569896
2025-01-22T18:18:16,613 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.job.Job - Waiting time ns: 52864, Backend time ns: 4421045
2025-01-22T18:18:16,613 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737569896
2025-01-22T18:18:16,613 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2025-01-22T18:18:16,613 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 4
2025-01-22T18:18:16,613 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737569896
2025-01-22 18:18:16.614 kserve.trace requestId: 2959c52b-f7ae-4b22-a9f9-ab7bad85450c, preprocess_ms: 0.012874603, explain_ms: 0, predict_ms: 8.037805557, postprocess_ms: 0.004291534
2025-01-22 18:18:16.614 uvicorn.access INFO:     10.233.75.99:0 9 - "POST /v1/models/youtubegoes5g%3Apredict HTTP/1.1" 200 OK
2025-01-22 18:18:16.615 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.00912928581237793
2025-01-22 18:18:16.615 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.0044850000012957025
2025-01-22T18:18:18,988 [INFO ] pool-3-thread-2 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737569898
2025-01-22T18:18:18,989 [INFO ] pool-3-thread-2 TS_METRICS - DiskAvailable.Gigabytes:263.7150421142578|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737569898
2025-01-22T18:18:18,989 [INFO ] pool-3-thread-2 TS_METRICS - DiskUsage.Gigabytes:208.28822326660156|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737569898
2025-01-22T18:18:18,989 [INFO ] pool-3-thread-2 TS_METRICS - DiskUtilization.Percent:44.1|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737569898
2025-01-22T18:18:18,989 [INFO ] pool-3-thread-2 TS_METRICS - MemoryAvailable.Megabytes:11136.3984375|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737569898
2025-01-22T18:18:18,989 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUsed.Megabytes:8503.203125|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737569898
2025-01-22T18:18:18,989 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUtilization.Percent:44.3|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737569898
2025-01-22T18:18:28,632 [INFO ] epollEventLoopGroup-3-2 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737569908
2025-01-22T18:18:28,633 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1737569908633
2025-01-22T18:18:28,636 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Backend received inference at: 1737569908
2025-01-22T18:18:28,636 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Received data: [{'data': [13, 13, 13, 0, 13, 13, 13, 13, -76, -76, -81, -76, -78.5, -76, -76, -7, -7, -12, -7, -9.5, -7, -7, 12, 12, 7, 12, 9.5, 12, 12]}]
2025-01-22T18:18:28,636 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Input data preprocessed successfully
2025-01-22T18:18:28,636 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Inference performed successfully
2025-01-22T18:18:28,636 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Output postprocessed successfully
2025-01-22T18:18:28,636 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:2.99|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,1737569908,f68a67d4-a86f-4b05-b058-809f94444156, pattern=[METRICS]
2025-01-22T18:18:28,636 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_METRICS - PredictionTime.ms:2.99|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,requestID:f68a67d4-a86f-4b05-b058-809f94444156,timestamp:1737569908
2025-01-22T18:18:28,637 [INFO ] W-9000-youtubegoes5g_1.0 ACCESS_LOG - /127.0.0.1:33240 "POST /v1/models/youtubegoes5g:predict HTTP/1.1" 200 5
2025-01-22T18:18:28,637 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737569908
2025-01-22T18:18:28,637 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:4815.273|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737569908
2025-01-22T18:18:28,637 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:67.739|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737569908
2025-01-22T18:18:28,637 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.job.Job - Waiting time ns: 67739, Backend time ns: 4899063
2025-01-22T18:18:28,637 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737569908
2025-01-22T18:18:28,637 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2025-01-22T18:18:28,637 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 4
2025-01-22T18:18:28,637 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737569908
2025-01-22 18:18:28.639 kserve.trace requestId: 247dd832-15fc-4c20-914c-26346a45b7ec, preprocess_ms: 0.010967255, explain_ms: 0, predict_ms: 8.725404739, postprocess_ms: 0.005483627
2025-01-22 18:18:28.639 uvicorn.access INFO:     10.233.75.99:0 9 - "POST /v1/models/youtubegoes5g%3Apredict HTTP/1.1" 200 OK
2025-01-22 18:18:28.639 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.009629249572753906
2025-01-22 18:18:28.639 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.0045209999989310745
2025-01-22T18:18:40,657 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737569920
2025-01-22T18:18:40,657 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1737569920657
2025-01-22T18:18:40,660 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Backend received inference at: 1737569920
2025-01-22T18:18:40,660 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Received data: [{'data': [13, 13, 13, 0, 13, 13, 13, 13, -76, -76, -81, -76, -78.5, -76, -76, -7, -7, -12, -7, -9.5, -7, -7, 12, 12, 7, 12, 9.5, 12, 12]}]
2025-01-22T18:18:40,660 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Input data preprocessed successfully
2025-01-22T18:18:40,661 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Inference performed successfully
2025-01-22T18:18:40,661 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Output postprocessed successfully
2025-01-22T18:18:40,661 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:3.21|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,1737569920,94bf9ad5-7614-4074-b263-a4013b36e0e2, pattern=[METRICS]
2025-01-22T18:18:40,661 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_METRICS - PredictionTime.ms:3.21|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,requestID:94bf9ad5-7614-4074-b263-a4013b36e0e2,timestamp:1737569920
2025-01-22T18:18:40,662 [INFO ] W-9000-youtubegoes5g_1.0 ACCESS_LOG - /127.0.0.1:44680 "POST /v1/models/youtubegoes5g:predict HTTP/1.1" 200 5
2025-01-22T18:18:40,662 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737569920
2025-01-22T18:18:40,662 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:4937.695|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737569920
2025-01-22T18:18:40,662 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:107.926|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737569920
2025-01-22T18:18:40,662 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.job.Job - Waiting time ns: 107926, Backend time ns: 4945362
2025-01-22T18:18:40,662 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737569920
2025-01-22T18:18:40,662 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2025-01-22T18:18:40,662 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 4
2025-01-22T18:18:40,662 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737569920
2025-01-22 18:18:40.663 kserve.trace requestId: 1cf075ac-62c5-4ba6-a569-619837f408a8, preprocess_ms: 0.012636185, explain_ms: 0, predict_ms: 8.639335632, postprocess_ms: 0.005483627
2025-01-22 18:18:40.664 uvicorn.access INFO:     10.233.75.99:0 9 - "POST /v1/models/youtubegoes5g%3Apredict HTTP/1.1" 200 OK
2025-01-22 18:18:40.664 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.009621143341064453
2025-01-22 18:18:40.664 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.004347000001871493
2025-01-22T18:19:16,683 [INFO ] epollEventLoopGroup-3-4 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737569956
2025-01-22T18:19:16,683 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1737569956683
2025-01-22T18:19:16,685 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Backend received inference at: 1737569956
2025-01-22T18:19:16,685 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Received data: [{'data': [13, 13, 13, 0, 13, 13, 13, 13, -76, -76, -81, -76, -78.5, -76, -76, -7, -7, -12, -7, -9.5, -7, -7, 12, 12, 7, 12, 9.5, 12, 12]}]
2025-01-22T18:19:16,685 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Input data preprocessed successfully
2025-01-22T18:19:16,688 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Inference performed successfully
2025-01-22T18:19:16,688 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Output postprocessed successfully
2025-01-22T18:19:16,688 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:3.87|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,1737569956,b3584bd4-0fff-4c37-9746-8e57ad81d397, pattern=[METRICS]
2025-01-22T18:19:16,688 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_METRICS - PredictionTime.ms:3.87|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,requestID:b3584bd4-0fff-4c37-9746-8e57ad81d397,timestamp:1737569956
2025-01-22T18:19:16,688 [INFO ] W-9000-youtubegoes5g_1.0 ACCESS_LOG - /127.0.0.1:35056 "POST /v1/models/youtubegoes5g:predict HTTP/1.1" 200 5
2025-01-22T18:19:16,688 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737569956
2025-01-22T18:19:16,689 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:5154.565|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737569956
2025-01-22T18:19:16,689 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:33.452|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737569956
2025-01-22T18:19:16,689 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.job.Job - Waiting time ns: 33452, Backend time ns: 5645886
2025-01-22T18:19:16,689 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737569956
2025-01-22T18:19:16,689 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2025-01-22T18:19:16,689 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 5
2025-01-22T18:19:16,689 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737569956
2025-01-22 18:19:16.690 kserve.trace requestId: 8cd3a86e-8f66-4653-bb15-1b6617157ed1, preprocess_ms: 0.013113022, explain_ms: 0, predict_ms: 10.710716248, postprocess_ms: 0.005245209
2025-01-22 18:19:16.690 uvicorn.access INFO:     10.233.75.99:0 9 - "POST /v1/models/youtubegoes5g%3Apredict HTTP/1.1" 200 OK
2025-01-22 18:19:16.691 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.012004613876342773
2025-01-22 18:19:16.691 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.005196999998588581
2025-01-22T18:19:18,991 [INFO ] pool-3-thread-2 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737569958
2025-01-22T18:19:18,991 [INFO ] pool-3-thread-2 TS_METRICS - DiskAvailable.Gigabytes:263.7147560119629|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737569958
2025-01-22T18:19:18,991 [INFO ] pool-3-thread-2 TS_METRICS - DiskUsage.Gigabytes:208.28850936889648|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737569958
2025-01-22T18:19:18,991 [INFO ] pool-3-thread-2 TS_METRICS - DiskUtilization.Percent:44.1|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737569958
2025-01-22T18:19:18,991 [INFO ] pool-3-thread-2 TS_METRICS - MemoryAvailable.Megabytes:11236.8046875|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737569958
2025-01-22T18:19:18,992 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUsed.Megabytes:8402.796875|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737569958
2025-01-22T18:19:18,992 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUtilization.Percent:43.8|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737569958
2025-01-22T18:19:28,708 [INFO ] epollEventLoopGroup-3-1 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737569968
2025-01-22T18:19:28,708 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1737569968708
2025-01-22T18:19:28,709 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Backend received inference at: 1737569968
2025-01-22T18:19:28,709 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Received data: [{'data': [13, 13, 13, 0, 13, 13, 13, 13, -76, -76, -81, -76, -78.5, -76, -76, -7, -7, -12, -7, -9.5, -7, -7, 12, 12, 7, 12, 9.5, 12, 12]}]
2025-01-22T18:19:28,710 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Input data preprocessed successfully
2025-01-22T18:19:28,713 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Inference performed successfully
2025-01-22T18:19:28,713 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Output postprocessed successfully
2025-01-22T18:19:28,714 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:4.72|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,1737569968,4667f175-cce5-4310-8030-bd1bfb613db8, pattern=[METRICS]
2025-01-22T18:19:28,714 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_METRICS - PredictionTime.ms:4.72|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,requestID:4667f175-cce5-4310-8030-bd1bfb613db8,timestamp:1737569968
2025-01-22T18:19:28,714 [INFO ] W-9000-youtubegoes5g_1.0 ACCESS_LOG - /127.0.0.1:36348 "POST /v1/models/youtubegoes5g:predict HTTP/1.1" 200 6
2025-01-22T18:19:28,714 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737569968
2025-01-22T18:19:28,714 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:6169.07|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737569968
2025-01-22T18:19:28,715 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:65.455|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737569968
2025-01-22T18:19:28,715 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.job.Job - Waiting time ns: 65455, Backend time ns: 6512605
2025-01-22T18:19:28,715 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737569968
2025-01-22T18:19:28,715 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2025-01-22T18:19:28,715 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 6
2025-01-22T18:19:28,715 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737569968
2025-01-22 18:19:28.716 kserve.trace requestId: 54229840-11ef-449b-aa1c-b7319891b319, preprocess_ms: 0.012636185, explain_ms: 0, predict_ms: 11.748313904, postprocess_ms: 0.005722046
2025-01-22 18:19:28.717 uvicorn.access INFO:     10.233.75.99:0 9 - "POST /v1/models/youtubegoes5g%3Apredict HTTP/1.1" 200 OK
2025-01-22 18:19:28.717 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.01313638687133789
2025-01-22 18:19:28.718 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.006309000000328524
2025-01-22T18:19:40,735 [INFO ] epollEventLoopGroup-3-2 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737569980
2025-01-22T18:19:40,735 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1737569980735
2025-01-22T18:19:40,737 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Backend received inference at: 1737569980
2025-01-22T18:19:40,737 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Received data: [{'data': [13, 13, 13, 0, 13, 13, 13, 13, -76, -76, -81, -76, -78.5, -76, -76, -7, -7, -12, -7, -9.5, -7, -7, 12, 12, 7, 12, 9.5, 12, 12]}]
2025-01-22T18:19:40,737 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Input data preprocessed successfully
2025-01-22T18:19:40,737 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Inference performed successfully
2025-01-22T18:19:40,738 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Output postprocessed successfully
2025-01-22T18:19:40,738 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:1.23|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,1737569980,88af86ee-332a-45af-8520-7b7c8d52950b, pattern=[METRICS]
2025-01-22T18:19:40,738 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_METRICS - PredictionTime.ms:1.23|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,requestID:88af86ee-332a-45af-8520-7b7c8d52950b,timestamp:1737569980
2025-01-22T18:19:40,738 [INFO ] W-9000-youtubegoes5g_1.0 ACCESS_LOG - /127.0.0.1:60206 "POST /v1/models/youtubegoes5g:predict HTTP/1.1" 200 3
2025-01-22T18:19:40,738 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737569980
2025-01-22T18:19:40,738 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:3086.837|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737569980
2025-01-22T18:19:40,738 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:25.967|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737569980
2025-01-22T18:19:40,738 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.job.Job - Waiting time ns: 25967, Backend time ns: 3168994
2025-01-22T18:19:40,738 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737569980
2025-01-22T18:19:40,738 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2025-01-22T18:19:40,738 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3
2025-01-22T18:19:40,738 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737569980
2025-01-22 18:19:40.739 kserve.trace requestId: 15197270-09ee-4c8c-a385-23245a7e79df, preprocess_ms: 0.011444092, explain_ms: 0, predict_ms: 6.61277771, postprocess_ms: 0.004529953
2025-01-22 18:19:40.739 uvicorn.access INFO:     10.233.75.99:0 9 - "POST /v1/models/youtubegoes5g%3Apredict HTTP/1.1" 200 OK
2025-01-22 18:19:40.740 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.007414340972900391
2025-01-22 18:19:40.740 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.00398000000132015
2025-01-22T18:19:52,756 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737569992
2025-01-22T18:19:52,756 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1737569992756
2025-01-22T18:19:52,758 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Backend received inference at: 1737569992
2025-01-22T18:19:52,758 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Received data: [{'data': [13, 13, 13, 0, 13, 13, 13, 13, -76, -76, -81, -76, -78.5, -76, -76, -7, -7, -12, -7, -9.5, -7, -7, 12, 12, 7, 12, 9.5, 12, 12]}]
2025-01-22T18:19:52,758 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Input data preprocessed successfully
2025-01-22T18:19:52,758 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Inference performed successfully
2025-01-22T18:19:52,758 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Output postprocessed successfully
2025-01-22T18:19:52,758 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:1.31|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,1737569992,b5a242a3-74b7-4569-af25-c7e2206390eb, pattern=[METRICS]
2025-01-22T18:19:52,758 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_METRICS - PredictionTime.ms:1.31|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,requestID:b5a242a3-74b7-4569-af25-c7e2206390eb,timestamp:1737569992
2025-01-22T18:19:52,759 [INFO ] W-9000-youtubegoes5g_1.0 ACCESS_LOG - /127.0.0.1:60910 "POST /v1/models/youtubegoes5g:predict HTTP/1.1" 200 3
2025-01-22T18:19:52,759 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737569992
2025-01-22T18:19:52,759 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:3090.508|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737569992
2025-01-22T18:19:52,760 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:41.309|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737569992
2025-01-22T18:19:52,760 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.job.Job - Waiting time ns: 41309, Backend time ns: 3165238
2025-01-22T18:19:52,760 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737569992
2025-01-22T18:19:52,760 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2025-01-22T18:19:52,760 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2
2025-01-22T18:19:52,760 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:2.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737569992
2025-01-22 18:19:52.761 kserve.trace requestId: c4a0c1bb-ab41-47f0-aacc-c513a1a72270, preprocess_ms: 0.012636185, explain_ms: 0, predict_ms: 6.669998169, postprocess_ms: 0.005722046
2025-01-22 18:19:52.761 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.0074901580810546875
2025-01-22 18:19:52.761 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.004111000000193599
2025-01-22 18:19:52.761 uvicorn.access INFO:     10.233.75.99:0 9 - "POST /v1/models/youtubegoes5g%3Apredict HTTP/1.1" 200 OK
2025-01-22T18:20:04,779 [INFO ] epollEventLoopGroup-3-4 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570004
2025-01-22T18:20:04,780 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1737570004779
2025-01-22T18:20:04,780 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Backend received inference at: 1737570004
2025-01-22T18:20:04,780 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Received data: [{'data': [13, 13, 13, 0, 13, 13, 13, 13, -76, -76, -81, -76, -78.5, -76, -76, -7, -7, -12, -7, -9.5, -7, -7, 12, 12, 7, 12, 9.5, 12, 12]}]
2025-01-22T18:20:04,781 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Input data preprocessed successfully
2025-01-22T18:20:04,782 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Inference performed successfully
2025-01-22T18:20:04,782 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Output postprocessed successfully
2025-01-22T18:20:04,782 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:1.55|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,1737570004,963f801d-c523-486d-b523-4492c2d22454, pattern=[METRICS]
2025-01-22T18:20:04,782 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_METRICS - PredictionTime.ms:1.55|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,requestID:963f801d-c523-486d-b523-4492c2d22454,timestamp:1737570004
2025-01-22T18:20:04,782 [INFO ] W-9000-youtubegoes5g_1.0 ACCESS_LOG - /127.0.0.1:59828 "POST /v1/models/youtubegoes5g:predict HTTP/1.1" 200 3
2025-01-22T18:20:04,782 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570004
2025-01-22T18:20:04,782 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:2752.621|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570004
2025-01-22T18:20:04,782 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:66.377|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570004
2025-01-22T18:20:04,782 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.job.Job - Waiting time ns: 66377, Backend time ns: 2868062
2025-01-22T18:20:04,782 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570004
2025-01-22T18:20:04,782 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2025-01-22T18:20:04,782 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2
2025-01-22T18:20:04,782 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570004
2025-01-22 18:20:04.784 kserve.trace requestId: d627a75b-64fe-4c11-bd41-26d55aa27d34, preprocess_ms: 0.009775162, explain_ms: 0, predict_ms: 6.769895554, postprocess_ms: 0.001192093
2025-01-22 18:20:04.784 uvicorn.access INFO:     10.233.75.99:0 9 - "POST /v1/models/youtubegoes5g%3Apredict HTTP/1.1" 200 OK
2025-01-22 18:20:04.784 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.008073568344116211
2025-01-22 18:20:04.784 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.004621000000042841
2025-01-22T18:20:16,802 [INFO ] epollEventLoopGroup-3-1 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570016
2025-01-22T18:20:16,802 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1737570016802
2025-01-22T18:20:16,803 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Backend received inference at: 1737570016
2025-01-22T18:20:16,803 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Received data: [{'data': [13, 13, 13, 0, 13, 13, 13, 13, -76, -76, -81, -76, -78.5, -76, -76, -7, -7, -12, -7, -9.5, -7, -7, 12, 12, 7, 12, 9.5, 12, 12]}]
2025-01-22T18:20:16,803 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Input data preprocessed successfully
2025-01-22T18:20:16,804 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Inference performed successfully
2025-01-22T18:20:16,804 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Output postprocessed successfully
2025-01-22T18:20:16,804 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:1.41|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,1737570016,47a5be45-61b8-41e7-94a7-ac95dd97e22b, pattern=[METRICS]
2025-01-22T18:20:16,804 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_METRICS - PredictionTime.ms:1.41|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,requestID:47a5be45-61b8-41e7-94a7-ac95dd97e22b,timestamp:1737570016
2025-01-22T18:20:16,804 [INFO ] W-9000-youtubegoes5g_1.0 ACCESS_LOG - /127.0.0.1:52048 "POST /v1/models/youtubegoes5g:predict HTTP/1.1" 200 2
2025-01-22T18:20:16,804 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570016
2025-01-22T18:20:16,804 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:2331.329|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570016
2025-01-22T18:20:16,804 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:63.714|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570016
2025-01-22T18:20:16,804 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.job.Job - Waiting time ns: 63714, Backend time ns: 2481510
2025-01-22T18:20:16,805 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570016
2025-01-22T18:20:16,805 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2025-01-22T18:20:16,805 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1
2025-01-22T18:20:16,805 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:2.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570016
2025-01-22 18:20:16.806 kserve.trace requestId: 7f2fcac6-5b1e-4570-8c1f-3ac59692ecf9, preprocess_ms: 0.012159348, explain_ms: 0, predict_ms: 6.567239761, postprocess_ms: 0.005722046
2025-01-22 18:20:16.806 uvicorn.access INFO:     10.233.75.99:0 9 - "POST /v1/models/youtubegoes5g%3Apredict HTTP/1.1" 200 OK
2025-01-22 18:20:16.806 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.007605314254760742
2025-01-22 18:20:16.807 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.004719999998997082
2025-01-22T18:20:18,990 [INFO ] pool-3-thread-2 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570018
2025-01-22T18:20:18,991 [INFO ] pool-3-thread-2 TS_METRICS - DiskAvailable.Gigabytes:263.7144470214844|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570018
2025-01-22T18:20:18,991 [INFO ] pool-3-thread-2 TS_METRICS - DiskUsage.Gigabytes:208.288818359375|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570018
2025-01-22T18:20:18,991 [INFO ] pool-3-thread-2 TS_METRICS - DiskUtilization.Percent:44.1|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570018
2025-01-22T18:20:18,991 [INFO ] pool-3-thread-2 TS_METRICS - MemoryAvailable.Megabytes:11234.3984375|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570018
2025-01-22T18:20:18,991 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUsed.Megabytes:8405.203125|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570018
2025-01-22T18:20:18,991 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUtilization.Percent:43.8|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570018
2025-01-22T18:20:28,824 [INFO ] epollEventLoopGroup-3-2 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570028
2025-01-22T18:20:28,824 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1737570028824
2025-01-22T18:20:28,825 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Backend received inference at: 1737570028
2025-01-22T18:20:28,825 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Received data: [{'data': [13, 13, 13, 0, 13, 13, 13, 13, -76, -76, -81, -76, -78.5, -76, -76, -7, -7, -12, -7, -9.5, -7, -7, 12, 12, 7, 12, 9.5, 12, 12]}]
2025-01-22T18:20:28,826 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Input data preprocessed successfully
2025-01-22T18:20:28,827 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Inference performed successfully
2025-01-22T18:20:28,827 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Output postprocessed successfully
2025-01-22T18:20:28,827 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:1.63|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,1737570028,82d6475a-92d4-4d9a-b03d-929d3009a94f, pattern=[METRICS]
2025-01-22T18:20:28,827 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_METRICS - PredictionTime.ms:1.63|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,requestID:82d6475a-92d4-4d9a-b03d-929d3009a94f,timestamp:1737570028
2025-01-22T18:20:28,827 [INFO ] W-9000-youtubegoes5g_1.0 ACCESS_LOG - /127.0.0.1:51160 "POST /v1/models/youtubegoes5g:predict HTTP/1.1" 200 3
2025-01-22T18:20:28,827 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570028
2025-01-22T18:20:28,827 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:2812.829|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570028
2025-01-22T18:20:28,827 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:110.434|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570028
2025-01-22T18:20:28,827 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.job.Job - Waiting time ns: 110434, Backend time ns: 2856281
2025-01-22T18:20:28,827 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570028
2025-01-22T18:20:28,827 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2025-01-22T18:20:28,827 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2
2025-01-22T18:20:28,827 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570028
2025-01-22 18:20:28.829 kserve.trace requestId: fafafe2d-19c0-4cbb-81e1-c9ea895c942a, preprocess_ms: 0.01335144, explain_ms: 0, predict_ms: 7.260799408, postprocess_ms: 0.005722046
2025-01-22 18:20:28.829 uvicorn.access INFO:     10.233.75.99:0 9 - "POST /v1/models/youtubegoes5g%3Apredict HTTP/1.1" 200 OK
2025-01-22 18:20:28.830 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.009198188781738281
2025-01-22 18:20:28.830 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.005144999999174615
2025-01-22T18:20:40,847 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570040
2025-01-22T18:20:40,847 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1737570040847
2025-01-22T18:20:40,849 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Backend received inference at: 1737570040
2025-01-22T18:20:40,849 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Received data: [{'data': [13, 13, 13, 0, 13, 13, 13, 13, -76, -76, -81, -76, -78.5, -76, -76, -7, -7, -12, -7, -9.5, -7, -7, 12, 12, 7, 12, 9.5, 12, 12]}]
2025-01-22T18:20:40,849 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Input data preprocessed successfully
2025-01-22T18:20:40,850 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Inference performed successfully
2025-01-22T18:20:40,850 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Output postprocessed successfully
2025-01-22T18:20:40,850 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:1.41|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,1737570040,5f88bf16-e1b0-4e2a-9242-d33a08e1440d, pattern=[METRICS]
2025-01-22T18:20:40,850 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_METRICS - PredictionTime.ms:1.41|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,requestID:5f88bf16-e1b0-4e2a-9242-d33a08e1440d,timestamp:1737570040
2025-01-22T18:20:40,850 [INFO ] W-9000-youtubegoes5g_1.0 ACCESS_LOG - /127.0.0.1:38476 "POST /v1/models/youtubegoes5g:predict HTTP/1.1" 200 3
2025-01-22T18:20:40,850 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570040
2025-01-22T18:20:40,850 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:2772.871|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570040
2025-01-22T18:20:40,850 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:47.526|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570040
2025-01-22T18:20:40,850 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.job.Job - Waiting time ns: 47526, Backend time ns: 2845957
2025-01-22T18:20:40,850 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570040
2025-01-22T18:20:40,850 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2025-01-22T18:20:40,850 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1
2025-01-22T18:20:40,850 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:2.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570040
2025-01-22 18:20:40.852 kserve.trace requestId: 8c3257aa-26ce-422f-8091-3290c8a894e2, preprocess_ms: 0.01335144, explain_ms: 0, predict_ms: 7.489204407, postprocess_ms: 0.005483627
2025-01-22 18:20:40.853 uvicorn.access INFO:     10.233.75.99:0 9 - "POST /v1/models/youtubegoes5g%3Apredict HTTP/1.1" 200 OK
2025-01-22 18:20:40.853 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.008901119232177734
2025-01-22 18:20:40.853 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.0053829999997105915
2025-01-22T18:20:52,871 [INFO ] epollEventLoopGroup-3-4 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570052
2025-01-22T18:20:52,871 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1737570052871
2025-01-22T18:20:52,872 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Backend received inference at: 1737570052
2025-01-22T18:20:52,872 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Received data: [{'data': [13, 13, 13, 0, 13, 13, 13, 13, -76, -76, -81, -76, -78.5, -76, -76, -7, -7, -12, -7, -9.5, -7, -7, 12, 12, 7, 12, 9.5, 12, 12]}]
2025-01-22T18:20:52,873 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Input data preprocessed successfully
2025-01-22T18:20:52,874 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Inference performed successfully
2025-01-22T18:20:52,874 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Output postprocessed successfully
2025-01-22T18:20:52,874 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:1.39|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,1737570052,898d9095-58ef-4ed8-a299-abc348b24202, pattern=[METRICS]
2025-01-22T18:20:52,874 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_METRICS - PredictionTime.ms:1.39|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,requestID:898d9095-58ef-4ed8-a299-abc348b24202,timestamp:1737570052
2025-01-22T18:20:52,875 [INFO ] W-9000-youtubegoes5g_1.0 ACCESS_LOG - /127.0.0.1:52510 "POST /v1/models/youtubegoes5g:predict HTTP/1.1" 200 4
2025-01-22T18:20:52,875 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570052
2025-01-22T18:20:52,875 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:3318.352|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570052
2025-01-22T18:20:52,875 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:90.773|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570052
2025-01-22T18:20:52,875 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.job.Job - Waiting time ns: 90773, Backend time ns: 3340920
2025-01-22T18:20:52,875 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570052
2025-01-22T18:20:52,875 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2025-01-22T18:20:52,875 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3
2025-01-22T18:20:52,875 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570052
2025-01-22 18:20:52.876 kserve.trace requestId: 6d5a3b4c-ba1e-4bd6-ac94-2c17d005ae62, preprocess_ms: 0.019073486, explain_ms: 0, predict_ms: 7.044792175, postprocess_ms: 0.005960464
2025-01-22 18:20:52.876 uvicorn.access INFO:     10.233.75.99:0 9 - "POST /v1/models/youtubegoes5g%3Apredict HTTP/1.1" 200 OK
2025-01-22 18:20:52.877 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.008260965347290039
2025-01-22 18:20:52.877 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.0048170000009122305
2025-01-22T18:21:04,895 [INFO ] epollEventLoopGroup-3-1 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570064
2025-01-22T18:21:04,895 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1737570064895
2025-01-22T18:21:04,897 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Backend received inference at: 1737570064
2025-01-22T18:21:04,897 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Received data: [{'data': [13, 13, 13, 0, 13, 13, 13, 13, -76, -76, -81, -76, -78.5, -76, -76, -7, -7, -12, -7, -9.5, -7, -7, 12, 12, 7, 12, 9.5, 12, 12]}]
2025-01-22T18:21:04,897 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Input data preprocessed successfully
2025-01-22T18:21:04,897 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Inference performed successfully
2025-01-22T18:21:04,897 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Output postprocessed successfully
2025-01-22T18:21:04,897 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:1.27|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,1737570064,82a3d1a7-c1c1-4956-bf6d-6dffe29aa602, pattern=[METRICS]
2025-01-22T18:21:04,897 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_METRICS - PredictionTime.ms:1.27|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,requestID:82a3d1a7-c1c1-4956-bf6d-6dffe29aa602,timestamp:1737570064
2025-01-22T18:21:04,898 [INFO ] W-9000-youtubegoes5g_1.0 ACCESS_LOG - /127.0.0.1:42160 "POST /v1/models/youtubegoes5g:predict HTTP/1.1" 200 3
2025-01-22T18:21:04,898 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570064
2025-01-22T18:21:04,898 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:3154.37|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570064
2025-01-22T18:21:04,898 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:34.921|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570064
2025-01-22T18:21:04,898 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.job.Job - Waiting time ns: 34921, Backend time ns: 3267810
2025-01-22T18:21:04,898 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570064
2025-01-22T18:21:04,898 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2025-01-22T18:21:04,898 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3
2025-01-22T18:21:04,898 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570064
2025-01-22 18:21:04.899 kserve.trace requestId: 5c486fc6-6bc1-47b1-9921-ee8164059ee1, preprocess_ms: 0.01168251, explain_ms: 0, predict_ms: 7.272720337, postprocess_ms: 0.004053116
2025-01-22 18:21:04.900 uvicorn.access INFO:     10.233.75.99:0 9 - "POST /v1/models/youtubegoes5g%3Apredict HTTP/1.1" 200 OK
2025-01-22 18:21:04.900 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.008260250091552734
2025-01-22 18:21:04.900 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.004716999997981475
2025-01-22T18:21:18,985 [INFO ] pool-3-thread-2 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570078
2025-01-22T18:21:18,985 [INFO ] pool-3-thread-2 TS_METRICS - DiskAvailable.Gigabytes:263.71419525146484|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570078
2025-01-22T18:21:18,985 [INFO ] pool-3-thread-2 TS_METRICS - DiskUsage.Gigabytes:208.28907012939453|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570078
2025-01-22T18:21:18,985 [INFO ] pool-3-thread-2 TS_METRICS - DiskUtilization.Percent:44.1|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570078
2025-01-22T18:21:18,985 [INFO ] pool-3-thread-2 TS_METRICS - MemoryAvailable.Megabytes:11267.3125|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570078
2025-01-22T18:21:18,985 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUsed.Megabytes:8372.2890625|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570078
2025-01-22T18:21:18,986 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUtilization.Percent:43.6|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570078
2025-01-22T18:21:40,918 [INFO ] epollEventLoopGroup-3-2 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570100
2025-01-22T18:21:40,918 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1737570100918
2025-01-22T18:21:40,919 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Backend received inference at: 1737570100
2025-01-22T18:21:40,919 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Received data: [{'data': [13, 13, 13, 0, 13, 13, 13, 13, -76, -76, -81, -76, -78.5, -76, -76, -7, -7, -12, -7, -9.5, -7, -7, 12, 12, 7, 12, 9.5, 12, 12]}]
2025-01-22T18:21:40,920 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Input data preprocessed successfully
2025-01-22T18:21:40,922 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Inference performed successfully
2025-01-22T18:21:40,922 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Output postprocessed successfully
2025-01-22T18:21:40,922 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:2.9|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,1737570100,6396a3d0-f977-4cf2-9ed7-130ec36467a6, pattern=[METRICS]
2025-01-22T18:21:40,922 [INFO ] W-9000-youtubegoes5g_1.0 ACCESS_LOG - /127.0.0.1:56572 "POST /v1/models/youtubegoes5g:predict HTTP/1.1" 200 4
2025-01-22T18:21:40,923 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_METRICS - PredictionTime.ms:2.9|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,requestID:6396a3d0-f977-4cf2-9ed7-130ec36467a6,timestamp:1737570100
2025-01-22T18:21:40,923 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570100
2025-01-22T18:21:40,923 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:4041.07|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570100
2025-01-22T18:21:40,923 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:74.591|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570100
2025-01-22T18:21:40,923 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.job.Job - Waiting time ns: 74591, Backend time ns: 4200470
2025-01-22T18:21:40,923 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570100
2025-01-22T18:21:40,923 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2025-01-22T18:21:40,923 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3
2025-01-22T18:21:40,923 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:2.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570100
2025-01-22 18:21:40.924 kserve.trace requestId: beec2543-ed1b-4dbf-87bc-4efda02d8600, preprocess_ms: 0.035047531, explain_ms: 0, predict_ms: 8.876085281, postprocess_ms: 0.019311905
2025-01-22 18:21:40.924 uvicorn.access INFO:     10.233.75.99:0 9 - "POST /v1/models/youtubegoes5g%3Apredict HTTP/1.1" 200 OK
2025-01-22 18:21:40.925 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.010027408599853516
2025-01-22 18:21:40.925 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.005343999999240623
2025-01-22T18:21:52,942 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570112
2025-01-22T18:21:52,942 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1737570112942
2025-01-22T18:21:52,943 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Backend received inference at: 1737570112
2025-01-22T18:21:52,943 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Received data: [{'data': [13, 13, 13, 0, 13, 13, 13, 13, -76, -76, -81, -76, -78.5, -76, -76, -7, -7, -12, -7, -9.5, -7, -7, 12, 12, 7, 12, 9.5, 12, 12]}]
2025-01-22T18:21:52,943 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Input data preprocessed successfully
2025-01-22T18:21:52,944 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Inference performed successfully
2025-01-22T18:21:52,944 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Output postprocessed successfully
2025-01-22T18:21:52,944 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:1.24|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,1737570112,866f8ea2-d695-4c10-9fbd-f6fcead3cb43, pattern=[METRICS]
2025-01-22T18:21:52,944 [INFO ] W-9000-youtubegoes5g_1.0 ACCESS_LOG - /127.0.0.1:58706 "POST /v1/models/youtubegoes5g:predict HTTP/1.1" 200 2
2025-01-22T18:21:52,944 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570112
2025-01-22T18:21:52,944 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_METRICS - PredictionTime.ms:1.24|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,requestID:866f8ea2-d695-4c10-9fbd-f6fcead3cb43,timestamp:1737570112
2025-01-22T18:21:52,944 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:2295.821|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570112
2025-01-22T18:21:52,945 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:84.008|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570112
2025-01-22T18:21:52,945 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.job.Job - Waiting time ns: 84008, Backend time ns: 2584317
2025-01-22T18:21:52,945 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570112
2025-01-22T18:21:52,945 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2025-01-22T18:21:52,945 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2
2025-01-22T18:21:52,945 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570112
2025-01-22 18:21:52.946 kserve.trace requestId: 3ac0bfa2-839f-4ea8-b259-f3c3b2f35c3a, preprocess_ms: 0.01168251, explain_ms: 0, predict_ms: 6.333351135, postprocess_ms: 0.005483627
2025-01-22 18:21:52.946 uvicorn.access INFO:     10.233.75.99:0 9 - "POST /v1/models/youtubegoes5g%3Apredict HTTP/1.1" 200 OK
2025-01-22 18:21:52.946 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.007319450378417969
2025-01-22 18:21:52.946 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.004119999999602442
2025-01-22T18:22:04,964 [INFO ] epollEventLoopGroup-3-4 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570124
2025-01-22T18:22:04,964 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1737570124964
2025-01-22T18:22:04,967 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Backend received inference at: 1737570124
2025-01-22T18:22:04,967 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Received data: [{'data': [13, 13, 13, 0, 13, 13, 13, 13, -76, -76, -81, -76, -78.5, -76, -76, -7, -7, -12, -7, -9.5, -7, -7, 12, 12, 7, 12, 9.5, 12, 12]}]
2025-01-22T18:22:04,967 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Input data preprocessed successfully
2025-01-22T18:22:04,967 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Inference performed successfully
2025-01-22T18:22:04,967 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Output postprocessed successfully
2025-01-22T18:22:04,967 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:1.24|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,1737570124,53814539-4b52-42af-b1cc-5a26c16883af, pattern=[METRICS]
2025-01-22T18:22:04,967 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_METRICS - PredictionTime.ms:1.24|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,requestID:53814539-4b52-42af-b1cc-5a26c16883af,timestamp:1737570124
2025-01-22T18:22:04,967 [INFO ] W-9000-youtubegoes5g_1.0 ACCESS_LOG - /127.0.0.1:51658 "POST /v1/models/youtubegoes5g:predict HTTP/1.1" 200 3
2025-01-22T18:22:04,967 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570124
2025-01-22T18:22:04,967 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:2980.567|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570124
2025-01-22T18:22:04,967 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:89.078|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570124
2025-01-22T18:22:04,967 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.job.Job - Waiting time ns: 89078, Backend time ns: 3069508
2025-01-22T18:22:04,968 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570124
2025-01-22T18:22:04,968 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2025-01-22T18:22:04,968 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2
2025-01-22T18:22:04,968 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:2.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570124
2025-01-22 18:22:04.969 kserve.trace requestId: 692e53fa-7ee8-4d78-99b6-c2546eb7addf, preprocess_ms: 0.01168251, explain_ms: 0, predict_ms: 6.913661957, postprocess_ms: 0.005245209
2025-01-22 18:22:04.969 uvicorn.access INFO:     10.233.75.99:0 9 - "POST /v1/models/youtubegoes5g%3Apredict HTTP/1.1" 200 OK
2025-01-22 18:22:04.969 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.007957935333251953
2025-01-22 18:22:04.969 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.004385000000183936
2025-01-22T18:22:16,986 [INFO ] epollEventLoopGroup-3-1 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570136
2025-01-22T18:22:16,986 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1737570136986
2025-01-22T18:22:16,988 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Backend received inference at: 1737570136
2025-01-22T18:22:16,988 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Received data: [{'data': [13, 13, 13, 0, 13, 13, 13, 13, -76, -76, -81, -76, -78.5, -76, -76, -7, -7, -12, -7, -9.5, -7, -7, 12, 12, 7, 12, 9.5, 12, 12]}]
2025-01-22T18:22:16,988 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Input data preprocessed successfully
2025-01-22T18:22:16,988 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Inference performed successfully
2025-01-22T18:22:16,988 [INFO ] W-9000-youtubegoes5g_1.0 ACCESS_LOG - /127.0.0.1:37696 "POST /v1/models/youtubegoes5g:predict HTTP/1.1" 200 2
2025-01-22T18:22:16,988 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570136
2025-01-22T18:22:16,988 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Output postprocessed successfully
2025-01-22T18:22:16,988 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:1.32|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,1737570136,d2ed232e-7eb6-4e98-88a6-87bff0aabfb0, pattern=[METRICS]
2025-01-22T18:22:16,988 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:2406.894|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570136
2025-01-22T18:22:16,988 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:93.968|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570136
2025-01-22T18:22:16,988 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.job.Job - Waiting time ns: 93968, Backend time ns: 2601000
2025-01-22T18:22:16,988 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570136
2025-01-22T18:22:16,988 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2025-01-22T18:22:16,988 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0
2025-01-22T18:22:16,988 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:2.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570136
2025-01-22T18:22:16,988 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_METRICS - PredictionTime.ms:1.32|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,requestID:d2ed232e-7eb6-4e98-88a6-87bff0aabfb0,timestamp:1737570136
2025-01-22 18:22:16.990 kserve.trace requestId: a70a0b55-bf51-492c-b3ed-691ed72eadfe, preprocess_ms: 0.012397766, explain_ms: 0, predict_ms: 6.396770477, postprocess_ms: 0.004291534
2025-01-22 18:22:16.990 uvicorn.access INFO:     10.233.75.99:0 9 - "POST /v1/models/youtubegoes5g%3Apredict HTTP/1.1" 200 OK
2025-01-22 18:22:16.990 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.007383823394775391
2025-01-22 18:22:16.990 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.00429699999949662
2025-01-22T18:22:18,989 [INFO ] pool-3-thread-2 TS_METRICS - CPUUtilization.Percent:50.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570138
2025-01-22T18:22:18,990 [INFO ] pool-3-thread-2 TS_METRICS - DiskAvailable.Gigabytes:263.71393966674805|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570138
2025-01-22T18:22:18,990 [INFO ] pool-3-thread-2 TS_METRICS - DiskUsage.Gigabytes:208.28932571411133|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570138
2025-01-22T18:22:18,990 [INFO ] pool-3-thread-2 TS_METRICS - DiskUtilization.Percent:44.1|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570138
2025-01-22T18:22:18,990 [INFO ] pool-3-thread-2 TS_METRICS - MemoryAvailable.Megabytes:11264.921875|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570138
2025-01-22T18:22:18,990 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUsed.Megabytes:8374.6796875|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570138
2025-01-22T18:22:18,990 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUtilization.Percent:43.6|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570138
2025-01-22T18:22:29,017 [INFO ] epollEventLoopGroup-3-2 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570149
2025-01-22T18:22:29,017 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1737570149017
2025-01-22T18:22:29,018 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Backend received inference at: 1737570149
2025-01-22T18:22:29,018 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Received data: [{'data': [13, 13, 13, 0, 13, 13, 13, 13, -76, -76, -81, -76, -78.5, -76, -76, -7, -7, -12, -7, -9.5, -7, -7, 12, 12, 7, 12, 9.5, 12, 12]}]
2025-01-22T18:22:29,019 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Input data preprocessed successfully
2025-01-22T18:22:29,020 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Inference performed successfully
2025-01-22T18:22:29,020 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Output postprocessed successfully
2025-01-22T18:22:29,020 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:2.18|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,1737570149,d336e1a6-ebdd-43e9-bd37-29d9d389f572, pattern=[METRICS]
2025-01-22T18:22:29,020 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_METRICS - PredictionTime.ms:2.18|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,requestID:d336e1a6-ebdd-43e9-bd37-29d9d389f572,timestamp:1737570149
2025-01-22T18:22:29,021 [INFO ] W-9000-youtubegoes5g_1.0 ACCESS_LOG - /127.0.0.1:33388 "POST /v1/models/youtubegoes5g:predict HTTP/1.1" 200 4
2025-01-22T18:22:29,021 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570149
2025-01-22T18:22:29,021 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:4178.56|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570149
2025-01-22T18:22:29,022 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:88.297|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570149
2025-01-22T18:22:29,022 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.job.Job - Waiting time ns: 88297, Backend time ns: 4657679
2025-01-22T18:22:29,022 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570149
2025-01-22T18:22:29,022 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2025-01-22T18:22:29,022 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3
2025-01-22T18:22:29,022 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:2.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570149
2025-01-22 18:22:29.023 kserve.trace requestId: 909c0e9d-1415-4eec-a370-cf9292499ce3, preprocess_ms: 0.012397766, explain_ms: 0, predict_ms: 8.61954689, postprocess_ms: 0.005960464
2025-01-22 18:22:29.023 uvicorn.access INFO:     10.233.75.99:0 9 - "POST /v1/models/youtubegoes5g%3Apredict HTTP/1.1" 200 OK
2025-01-22 18:22:29.024 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.009583711624145508
2025-01-22 18:22:29.024 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.004753999997774372
2025-01-22T18:22:41,046 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570161
2025-01-22T18:22:41,046 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1737570161046
2025-01-22T18:22:41,047 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Backend received inference at: 1737570161
2025-01-22T18:22:41,047 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Received data: [{'data': [13, 13, 13, 0, 13, 13, 13, 13, -76, -76, -81, -76, -78.5, -76, -76, -7, -7, -12, -7, -9.5, -7, -7, 12, 12, 7, 12, 9.5, 12, 12]}]
2025-01-22T18:22:41,048 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Input data preprocessed successfully
2025-01-22T18:22:41,049 [INFO ] W-9000-youtubegoes5g_1.0 ACCESS_LOG - /127.0.0.1:57870 "POST /v1/models/youtubegoes5g:predict HTTP/1.1" 200 3
2025-01-22T18:22:41,049 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570161
2025-01-22T18:22:41,049 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:2535.627|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570161
2025-01-22T18:22:41,049 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:32.621|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570161
2025-01-22T18:22:41,049 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.job.Job - Waiting time ns: 32621, Backend time ns: 2685596
2025-01-22T18:22:41,049 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570161
2025-01-22T18:22:41,049 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2025-01-22T18:22:41,049 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2
2025-01-22T18:22:41,049 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570161
2025-01-22T18:22:41,049 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Inference performed successfully
2025-01-22T18:22:41,049 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Output postprocessed successfully
2025-01-22T18:22:41,050 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:1.6|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,1737570161,29d676b3-87e1-432c-8fa0-3691d22b80c1, pattern=[METRICS]
2025-01-22T18:22:41,050 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_METRICS - PredictionTime.ms:1.6|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,requestID:29d676b3-87e1-432c-8fa0-3691d22b80c1,timestamp:1737570161
2025-01-22 18:22:41.051 kserve.trace requestId: d886494a-8a4d-4e58-99ba-9af3ebe44cfa, preprocess_ms: 0.013113022, explain_ms: 0, predict_ms: 7.705926895, postprocess_ms: 0.003099442
2025-01-22 18:22:41.051 uvicorn.access INFO:     10.233.75.99:0 9 - "POST /v1/models/youtubegoes5g%3Apredict HTTP/1.1" 200 OK
2025-01-22 18:22:41.051 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.008598566055297852
2025-01-22 18:22:41.051 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.005182999999306048
2025-01-22T18:22:53,069 [INFO ] epollEventLoopGroup-3-4 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570173
2025-01-22T18:22:53,069 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1737570173069
2025-01-22T18:22:53,070 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Backend received inference at: 1737570173
2025-01-22T18:22:53,070 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Received data: [{'data': [13, 13, 13, 0, 13, 13, 13, 13, -76, -76, -81, -76, -78.5, -76, -76, -7, -7, -12, -7, -9.5, -7, -7, 12, 12, 7, 12, 9.5, 12, 12]}]
2025-01-22T18:22:53,071 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Input data preprocessed successfully
2025-01-22T18:22:53,072 [INFO ] W-9000-youtubegoes5g_1.0 ACCESS_LOG - /127.0.0.1:56852 "POST /v1/models/youtubegoes5g:predict HTTP/1.1" 200 3
2025-01-22T18:22:53,072 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570173
2025-01-22T18:22:53,072 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:2966.495|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570173
2025-01-22T18:22:53,072 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:48.063|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570173
2025-01-22T18:22:53,072 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.job.Job - Waiting time ns: 48063, Backend time ns: 3047597
2025-01-22T18:22:53,072 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570173
2025-01-22T18:22:53,072 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2025-01-22T18:22:53,072 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3
2025-01-22T18:22:53,072 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570173
2025-01-22T18:22:53,072 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Inference performed successfully
2025-01-22T18:22:53,072 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Output postprocessed successfully
2025-01-22T18:22:53,072 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:2.03|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,1737570173,e2cebd13-3de8-4461-b25d-68c2d96cba84, pattern=[METRICS]
2025-01-22T18:22:53,072 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_METRICS - PredictionTime.ms:2.03|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,requestID:e2cebd13-3de8-4461-b25d-68c2d96cba84,timestamp:1737570173
2025-01-22 18:22:53.075 kserve.trace requestId: 62f056d2-6714-4a00-9905-229edb53a5ef, preprocess_ms: 0.012397766, explain_ms: 0, predict_ms: 8.244991302, postprocess_ms: 0.005960464
2025-01-22 18:22:53.075 uvicorn.access INFO:     10.233.75.99:0 9 - "POST /v1/models/youtubegoes5g%3Apredict HTTP/1.1" 200 OK
2025-01-22 18:22:53.075 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.009319782257080078
2025-01-22 18:22:53.075 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.004827000000659609
2025-01-22T18:23:05,094 [INFO ] epollEventLoopGroup-3-1 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570185
2025-01-22T18:23:05,094 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1737570185094
2025-01-22T18:23:05,095 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Backend received inference at: 1737570185
2025-01-22T18:23:05,095 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Received data: [{'data': [13, 13, 13, 0, 13, 13, 13, 13, -76, -76, -81, -76, -78.5, -76, -76, -7, -7, -12, -7, -9.5, -7, -7, 12, 12, 7, 12, 9.5, 12, 12]}]
2025-01-22T18:23:05,095 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Input data preprocessed successfully
2025-01-22T18:23:05,099 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Inference performed successfully
2025-01-22T18:23:05,099 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Output postprocessed successfully
2025-01-22T18:23:05,099 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:4.53|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,1737570185,1cc62fb7-e8f1-4aa4-9ea0-f20fb2349be3, pattern=[METRICS]
2025-01-22T18:23:05,099 [INFO ] W-9000-youtubegoes5g_1.0 ACCESS_LOG - /127.0.0.1:36490 "POST /v1/models/youtubegoes5g:predict HTTP/1.1" 200 5
2025-01-22T18:23:05,099 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570185
2025-01-22T18:23:05,099 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_METRICS - PredictionTime.ms:4.53|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,requestID:1cc62fb7-e8f1-4aa4-9ea0-f20fb2349be3,timestamp:1737570185
2025-01-22T18:23:05,099 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:5397.076|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570185
2025-01-22T18:23:05,099 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:45.186|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570185
2025-01-22T18:23:05,099 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.job.Job - Waiting time ns: 45186, Backend time ns: 5493057
2025-01-22T18:23:05,099 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570185
2025-01-22T18:23:05,099 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2025-01-22T18:23:05,099 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 4
2025-01-22T18:23:05,099 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570185
2025-01-22 18:23:05.101 kserve.trace requestId: 19276d66-2935-4580-9022-500841999b69, preprocess_ms: 0.011920929, explain_ms: 0, predict_ms: 9.331226349, postprocess_ms: 0.006198883
2025-01-22 18:23:05.101 uvicorn.access INFO:     10.233.75.99:0 9 - "POST /v1/models/youtubegoes5g%3Apredict HTTP/1.1" 200 OK
2025-01-22 18:23:05.101 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.010386466979980469
2025-01-22 18:23:05.101 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.004453999999896041
2025-01-22T18:23:17,121 [INFO ] epollEventLoopGroup-3-2 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570197
2025-01-22T18:23:17,121 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1737570197121
2025-01-22T18:23:17,122 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Backend received inference at: 1737570197
2025-01-22T18:23:17,122 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Received data: [{'data': [13, 13, 13, 0, 13, 13, 13, 13, -76, -76, -81, -76, -78.5, -76, -76, -7, -7, -12, -7, -9.5, -7, -7, 12, 12, 7, 12, 9.5, 12, 12]}]
2025-01-22T18:23:17,122 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Input data preprocessed successfully
2025-01-22T18:23:17,126 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Inference performed successfully
2025-01-22T18:23:17,126 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Output postprocessed successfully
2025-01-22T18:23:17,126 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:4.55|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,1737570197,cb8bc260-e399-4788-8674-914fa504b527, pattern=[METRICS]
2025-01-22T18:23:17,126 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_METRICS - PredictionTime.ms:4.55|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,requestID:cb8bc260-e399-4788-8674-914fa504b527,timestamp:1737570197
2025-01-22T18:23:17,126 [INFO ] W-9000-youtubegoes5g_1.0 ACCESS_LOG - /127.0.0.1:34002 "POST /v1/models/youtubegoes5g:predict HTTP/1.1" 200 5
2025-01-22T18:23:17,127 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570197
2025-01-22T18:23:17,127 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:5579.02|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570197
2025-01-22T18:23:17,127 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:131.689|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570197
2025-01-22T18:23:17,127 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.job.Job - Waiting time ns: 131689, Backend time ns: 5779926
2025-01-22T18:23:17,127 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570197
2025-01-22T18:23:17,127 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2025-01-22T18:23:17,127 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 5
2025-01-22T18:23:17,127 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570197
2025-01-22 18:23:17.128 kserve.trace requestId: 0aa56ed5-9753-4eb6-acef-a45ce4885760, preprocess_ms: 0.011205673, explain_ms: 0, predict_ms: 9.98544693, postprocess_ms: 0.008106232
2025-01-22 18:23:17.128 uvicorn.access INFO:     10.233.75.99:0 9 - "POST /v1/models/youtubegoes5g%3Apredict HTTP/1.1" 200 OK
2025-01-22 18:23:17.129 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.011073589324951172
2025-01-22 18:23:17.129 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.005106000000523636
2025-01-22T18:23:18,990 [INFO ] pool-3-thread-2 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570198
2025-01-22T18:23:18,990 [INFO ] pool-3-thread-2 TS_METRICS - DiskAvailable.Gigabytes:263.71366119384766|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570198
2025-01-22T18:23:18,990 [INFO ] pool-3-thread-2 TS_METRICS - DiskUsage.Gigabytes:208.28960418701172|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570198
2025-01-22T18:23:18,990 [INFO ] pool-3-thread-2 TS_METRICS - DiskUtilization.Percent:44.1|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570198
2025-01-22T18:23:18,991 [INFO ] pool-3-thread-2 TS_METRICS - MemoryAvailable.Megabytes:11289.5859375|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570198
2025-01-22T18:23:18,991 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUsed.Megabytes:8350.015625|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570198
2025-01-22T18:23:18,991 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUtilization.Percent:43.5|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570198
2025-01-22T18:23:29,146 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570209
2025-01-22T18:23:29,146 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1737570209146
2025-01-22T18:23:29,147 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Backend received inference at: 1737570209
2025-01-22T18:23:29,147 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Received data: [{'data': [13, 13, 13, 0, 13, 13, 13, 13, -76, -76, -81, -76, -78.5, -76, -76, -7, -7, -12, -7, -9.5, -7, -7, 12, 12, 7, 12, 9.5, 12, 12]}]
2025-01-22T18:23:29,148 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Input data preprocessed successfully
2025-01-22T18:23:29,151 [INFO ] W-9000-youtubegoes5g_1.0 ACCESS_LOG - /127.0.0.1:50184 "POST /v1/models/youtubegoes5g:predict HTTP/1.1" 200 5
2025-01-22T18:23:29,151 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570209
2025-01-22T18:23:29,152 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:5115.977|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570209
2025-01-22T18:23:29,152 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:43.528|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570209
2025-01-22T18:23:29,152 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.job.Job - Waiting time ns: 43528, Backend time ns: 5362659
2025-01-22T18:23:29,152 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570209
2025-01-22T18:23:29,152 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2025-01-22T18:23:29,152 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 5
2025-01-22T18:23:29,152 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570209
2025-01-22T18:23:29,151 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Inference performed successfully
2025-01-22T18:23:29,152 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Output postprocessed successfully
2025-01-22T18:23:29,152 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:4.06|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,1737570209,d1a5325b-ac1e-41e4-b93b-ba33f19df5c4, pattern=[METRICS]
2025-01-22T18:23:29,152 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_METRICS - PredictionTime.ms:4.06|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,requestID:d1a5325b-ac1e-41e4-b93b-ba33f19df5c4,timestamp:1737570209
2025-01-22 18:23:29.153 kserve.trace requestId: 5802c44f-403f-4a26-af66-47335c5db702, preprocess_ms: 0.012636185, explain_ms: 0, predict_ms: 10.110139847, postprocess_ms: 0.000476837
2025-01-22 18:23:29.154 uvicorn.access INFO:     10.233.75.99:0 9 - "POST /v1/models/youtubegoes5g%3Apredict HTTP/1.1" 200 OK
2025-01-22 18:23:29.154 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.011644840240478516
2025-01-22 18:23:29.154 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.0053740000003017485
2025-01-22T18:24:05,171 [INFO ] epollEventLoopGroup-3-4 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570245
2025-01-22T18:24:05,172 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1737570245172
2025-01-22T18:24:05,172 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Backend received inference at: 1737570245
2025-01-22T18:24:05,172 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Received data: [{'data': [13, 13, 13, 0, 13, 13, 13, 13, -76, -76, -81, -76, -78.5, -76, -76, -7, -7, -12, -7, -9.5, -7, -7, 12, 12, 7, 12, 9.5, 12, 12]}]
2025-01-22T18:24:05,173 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Input data preprocessed successfully
2025-01-22T18:24:05,177 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Inference performed successfully
2025-01-22T18:24:05,177 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Output postprocessed successfully
2025-01-22T18:24:05,177 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:4.6|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,1737570245,a23d529e-c640-4a7d-bfd1-dcb9d220276b, pattern=[METRICS]
2025-01-22T18:24:05,177 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_METRICS - PredictionTime.ms:4.6|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,requestID:a23d529e-c640-4a7d-bfd1-dcb9d220276b,timestamp:1737570245
2025-01-22T18:24:05,177 [INFO ] W-9000-youtubegoes5g_1.0 ACCESS_LOG - /127.0.0.1:48374 "POST /v1/models/youtubegoes5g:predict HTTP/1.1" 200 6
2025-01-22T18:24:05,177 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570245
2025-01-22T18:24:05,177 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:5822.2|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570245
2025-01-22T18:24:05,177 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:200.11|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570245
2025-01-22T18:24:05,177 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.job.Job - Waiting time ns: 200110, Backend time ns: 5787836
2025-01-22T18:24:05,177 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570245
2025-01-22T18:24:05,177 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2025-01-22T18:24:05,177 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 5
2025-01-22T18:24:05,177 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570245
2025-01-22 18:24:05.179 kserve.trace requestId: dcbb845b-7bba-4bcb-ac98-d1403ba814ce, preprocess_ms: 0.012159348, explain_ms: 0, predict_ms: 10.362386703, postprocess_ms: 0.005483627
2025-01-22 18:24:05.179 uvicorn.access INFO:     10.233.75.99:0 9 - "POST /v1/models/youtubegoes5g%3Apredict HTTP/1.1" 200 OK
2025-01-22 18:24:05.179 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.011661529541015625
2025-01-22 18:24:05.179 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.005368000000089523
2025-01-22T18:24:17,196 [INFO ] epollEventLoopGroup-3-1 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570257
2025-01-22T18:24:17,197 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1737570257197
2025-01-22T18:24:17,197 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Backend received inference at: 1737570257
2025-01-22T18:24:17,197 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Received data: [{'data': [13, 13, 13, 0, 13, 13, 13, 13, -76, -76, -81, -76, -78.5, -76, -76, -7, -7, -12, -7, -9.5, -7, -7, 12, 12, 7, 12, 9.5, 12, 12]}]
2025-01-22T18:24:17,198 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Input data preprocessed successfully
2025-01-22T18:24:17,200 [INFO ] W-9000-youtubegoes5g_1.0 ACCESS_LOG - /127.0.0.1:37472 "POST /v1/models/youtubegoes5g:predict HTTP/1.1" 200 4
2025-01-22T18:24:17,201 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570257
2025-01-22T18:24:17,201 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Inference performed successfully
2025-01-22T18:24:17,201 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Output postprocessed successfully
2025-01-22T18:24:17,201 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:3978.422|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570257
2025-01-22T18:24:17,201 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:2.95|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,1737570257,0e38f198-8aa8-4ef5-96dc-ed8dfa76359f, pattern=[METRICS]
2025-01-22T18:24:17,201 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:116.829|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570257
2025-01-22T18:24:17,201 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.job.Job - Waiting time ns: 116829, Backend time ns: 4736320
2025-01-22T18:24:17,201 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570257
2025-01-22T18:24:17,201 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2025-01-22T18:24:17,201 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3
2025-01-22T18:24:17,201 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570257
2025-01-22T18:24:17,201 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_METRICS - PredictionTime.ms:2.95|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,requestID:0e38f198-8aa8-4ef5-96dc-ed8dfa76359f,timestamp:1737570257
2025-01-22 18:24:17.203 kserve.trace requestId: 84dc5234-cca8-494e-8463-c9de13d36773, preprocess_ms: 0.01168251, explain_ms: 0, predict_ms: 8.34274292, postprocess_ms: 0.004768372
2025-01-22 18:24:17.203 uvicorn.access INFO:     10.233.75.99:0 9 - "POST /v1/models/youtubegoes5g%3Apredict HTTP/1.1" 200 OK
2025-01-22 18:24:17.203 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.00939035415649414
2025-01-22 18:24:17.203 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.004152000001340639
2025-01-22T18:24:19,001 [INFO ] pool-3-thread-2 TS_METRICS - CPUUtilization.Percent:50.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570259
2025-01-22T18:24:19,001 [INFO ] pool-3-thread-2 TS_METRICS - DiskAvailable.Gigabytes:263.71340560913086|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570259
2025-01-22T18:24:19,001 [INFO ] pool-3-thread-2 TS_METRICS - DiskUsage.Gigabytes:208.28985977172852|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570259
2025-01-22T18:24:19,001 [INFO ] pool-3-thread-2 TS_METRICS - DiskUtilization.Percent:44.1|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570259
2025-01-22T18:24:19,001 [INFO ] pool-3-thread-2 TS_METRICS - MemoryAvailable.Megabytes:11284.23828125|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570259
2025-01-22T18:24:19,001 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUsed.Megabytes:8355.36328125|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570259
2025-01-22T18:24:19,001 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUtilization.Percent:43.5|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570259
2025-01-22T18:24:29,221 [INFO ] epollEventLoopGroup-3-2 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570269
2025-01-22T18:24:29,221 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1737570269221
2025-01-22T18:24:29,222 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Backend received inference at: 1737570269
2025-01-22T18:24:29,222 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Received data: [{'data': [13, 13, 13, 0, 13, 13, 13, 13, -76, -76, -81, -76, -78.5, -76, -76, -7, -7, -12, -7, -9.5, -7, -7, 12, 12, 7, 12, 9.5, 12, 12]}]
2025-01-22T18:24:29,223 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Input data preprocessed successfully
2025-01-22T18:24:29,223 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Inference performed successfully
2025-01-22T18:24:29,223 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Output postprocessed successfully
2025-01-22T18:24:29,224 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:1.51|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,1737570269,46916dc5-620f-40e9-9db2-0f518549f36f, pattern=[METRICS]
2025-01-22T18:24:29,224 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_METRICS - PredictionTime.ms:1.51|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,requestID:46916dc5-620f-40e9-9db2-0f518549f36f,timestamp:1737570269
2025-01-22T18:24:29,225 [INFO ] W-9000-youtubegoes5g_1.0 ACCESS_LOG - /127.0.0.1:48384 "POST /v1/models/youtubegoes5g:predict HTTP/1.1" 200 4
2025-01-22T18:24:29,225 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570269
2025-01-22T18:24:29,225 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:3309.219|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570269
2025-01-22T18:24:29,225 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:33.654|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570269
2025-01-22T18:24:29,225 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.job.Job - Waiting time ns: 33654, Backend time ns: 3764441
2025-01-22T18:24:29,225 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570269
2025-01-22T18:24:29,225 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2025-01-22T18:24:29,225 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 4
2025-01-22T18:24:29,225 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570269
2025-01-22 18:24:29.226 kserve.trace requestId: 16ab6848-ceaa-427a-94af-a9a0bdf77085, preprocess_ms: 0.010967255, explain_ms: 0, predict_ms: 7.300853729, postprocess_ms: 0.004291534
2025-01-22 18:24:29.226 uvicorn.access INFO:     10.233.75.99:0 9 - "POST /v1/models/youtubegoes5g%3Apredict HTTP/1.1" 200 OK
2025-01-22 18:24:29.227 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.008236169815063477
2025-01-22 18:24:29.227 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.0041739999996934785
2025-01-22T18:24:41,242 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570281
2025-01-22T18:24:41,242 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1737570281242
2025-01-22T18:24:41,243 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Backend received inference at: 1737570281
2025-01-22T18:24:41,243 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Received data: [{'data': [13, 13, 13, 0, 13, 13, 13, 13, -76, -76, -81, -76, -78.5, -76, -76, -7, -7, -12, -7, -9.5, -7, -7, 12, 12, 7, 12, 9.5, 12, 12]}]
2025-01-22T18:24:41,244 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Input data preprocessed successfully
2025-01-22T18:24:41,244 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Inference performed successfully
2025-01-22T18:24:41,245 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Output postprocessed successfully
2025-01-22T18:24:41,245 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:1.54|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,1737570281,b227b1bd-7953-4877-83c4-fc69ef06b532, pattern=[METRICS]
2025-01-22T18:24:41,245 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_METRICS - PredictionTime.ms:1.54|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,requestID:b227b1bd-7953-4877-83c4-fc69ef06b532,timestamp:1737570281
2025-01-22T18:24:41,245 [INFO ] W-9000-youtubegoes5g_1.0 ACCESS_LOG - /127.0.0.1:38800 "POST /v1/models/youtubegoes5g:predict HTTP/1.1" 200 3
2025-01-22T18:24:41,245 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570281
2025-01-22T18:24:41,245 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:2690.603|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570281
2025-01-22T18:24:41,245 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:123.305|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570281
2025-01-22T18:24:41,245 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.job.Job - Waiting time ns: 123305, Backend time ns: 2801828
2025-01-22T18:24:41,245 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570281
2025-01-22T18:24:41,245 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2025-01-22T18:24:41,245 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2
2025-01-22T18:24:41,245 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570281
2025-01-22 18:24:41.247 kserve.trace requestId: 979c6fde-c016-4fc5-aafb-79553a573e4e, preprocess_ms: 0.011444092, explain_ms: 0, predict_ms: 6.668806076, postprocess_ms: 0.004768372
2025-01-22 18:24:41.247 uvicorn.access INFO:     10.233.75.99:0 9 - "POST /v1/models/youtubegoes5g%3Apredict HTTP/1.1" 200 OK
2025-01-22 18:24:41.247 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.007745265960693359
2025-01-22 18:24:41.248 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.00434300000051735
2025-01-22T18:24:53,264 [INFO ] epollEventLoopGroup-3-4 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570293
2025-01-22T18:24:53,264 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1737570293264
2025-01-22T18:24:53,265 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Backend received inference at: 1737570293
2025-01-22T18:24:53,265 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Received data: [{'data': [13, 13, 13, 0, 13, 13, 13, 13, -76, -76, -81, -76, -78.5, -76, -76, -7, -7, -12, -7, -9.5, -7, -7, 12, 12, 7, 12, 9.5, 12, 12]}]
2025-01-22T18:24:53,266 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Input data preprocessed successfully
2025-01-22T18:24:53,268 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Inference performed successfully
2025-01-22T18:24:53,268 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Output postprocessed successfully
2025-01-22T18:24:53,268 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:3.09|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,1737570293,2d44d48b-3b2d-4359-ace4-10997e9f384c, pattern=[METRICS]
2025-01-22T18:24:53,268 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_METRICS - PredictionTime.ms:3.09|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,requestID:2d44d48b-3b2d-4359-ace4-10997e9f384c,timestamp:1737570293
2025-01-22T18:24:53,268 [INFO ] W-9000-youtubegoes5g_1.0 ACCESS_LOG - /127.0.0.1:34224 "POST /v1/models/youtubegoes5g:predict HTTP/1.1" 200 4
2025-01-22T18:24:53,268 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570293
2025-01-22T18:24:53,268 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:4447.471|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570293
2025-01-22T18:24:53,268 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:108.115|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570293
2025-01-22T18:24:53,268 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.job.Job - Waiting time ns: 108115, Backend time ns: 4457058
2025-01-22T18:24:53,269 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570293
2025-01-22T18:24:53,269 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2025-01-22T18:24:53,269 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 4
2025-01-22T18:24:53,269 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570293
2025-01-22 18:24:53.270 kserve.trace requestId: 9e6193fe-cc36-4121-a618-d657da8144c1, preprocess_ms: 0.011920929, explain_ms: 0, predict_ms: 8.130073547, postprocess_ms: 0.005722046
2025-01-22 18:24:53.270 uvicorn.access INFO:     10.233.75.99:0 9 - "POST /v1/models/youtubegoes5g%3Apredict HTTP/1.1" 200 OK
2025-01-22 18:24:53.271 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.009305238723754883
2025-01-22 18:24:53.271 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.004452999999557505
2025-01-22T18:25:05,293 [INFO ] epollEventLoopGroup-3-1 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570305
2025-01-22T18:25:05,293 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1737570305293
2025-01-22T18:25:05,294 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Backend received inference at: 1737570305
2025-01-22T18:25:05,294 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Received data: [{'data': [13, 13, 13, 0, 13, 13, 13, 13, -76, -76, -81, -76, -78.5, -76, -76, -7, -7, -12, -7, -9.5, -7, -7, 12, 12, 7, 12, 9.5, 12, 12]}]
2025-01-22T18:25:05,294 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Input data preprocessed successfully
2025-01-22T18:25:05,298 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Inference performed successfully
2025-01-22T18:25:05,298 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Output postprocessed successfully
2025-01-22T18:25:05,298 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:4.49|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,1737570305,d2590d91-d97f-4d6c-ae75-3611591ed160, pattern=[METRICS]
2025-01-22T18:25:05,298 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_METRICS - PredictionTime.ms:4.49|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,requestID:d2590d91-d97f-4d6c-ae75-3611591ed160,timestamp:1737570305
2025-01-22T18:25:05,298 [INFO ] W-9000-youtubegoes5g_1.0 ACCESS_LOG - /127.0.0.1:60960 "POST /v1/models/youtubegoes5g:predict HTTP/1.1" 200 5
2025-01-22T18:25:05,299 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570305
2025-01-22T18:25:05,299 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:5495.947|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570305
2025-01-22T18:25:05,299 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:110.938|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570305
2025-01-22T18:25:05,299 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.job.Job - Waiting time ns: 110938, Backend time ns: 5494280
2025-01-22T18:25:05,299 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570305
2025-01-22T18:25:05,299 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2025-01-22T18:25:05,299 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 5
2025-01-22T18:25:05,299 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570305
2025-01-22 18:25:05.301 kserve.trace requestId: 1e831611-bfd4-48c6-956f-8fff22f162cd, preprocess_ms: 0.019788742, explain_ms: 0, predict_ms: 11.020421982, postprocess_ms: 0.004768372
2025-01-22 18:25:05.301 uvicorn.access INFO:     10.233.75.99:0 9 - "POST /v1/models/youtubegoes5g%3Apredict HTTP/1.1" 200 OK
2025-01-22 18:25:05.302 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.012467384338378906
2025-01-22 18:25:05.302 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.005782999998700689
2025-01-22T18:25:17,319 [INFO ] epollEventLoopGroup-3-2 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570317
2025-01-22T18:25:17,319 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1737570317319
2025-01-22T18:25:17,320 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Backend received inference at: 1737570317
2025-01-22T18:25:17,320 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Received data: [{'data': [13, 13, 13, 0, 13, 13, 13, 13, -76, -76, -81, -76, -78.5, -76, -76, -7, -7, -12, -7, -9.5, -7, -7, 12, 12, 7, 12, 9.5, 12, 12]}]
2025-01-22T18:25:17,321 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Input data preprocessed successfully
2025-01-22T18:25:17,324 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Inference performed successfully
2025-01-22T18:25:17,324 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Output postprocessed successfully
2025-01-22T18:25:17,324 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:4.32|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,1737570317,226a2411-f0da-45c2-8159-306109857dbe, pattern=[METRICS]
2025-01-22T18:25:17,324 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_METRICS - PredictionTime.ms:4.32|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,requestID:226a2411-f0da-45c2-8159-306109857dbe,timestamp:1737570317
2025-01-22T18:25:17,325 [INFO ] W-9000-youtubegoes5g_1.0 ACCESS_LOG - /127.0.0.1:45874 "POST /v1/models/youtubegoes5g:predict HTTP/1.1" 200 6
2025-01-22T18:25:17,325 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570317
2025-01-22T18:25:17,325 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:5565.729|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570317
2025-01-22T18:25:17,325 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:124.806|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570317
2025-01-22T18:25:17,325 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.job.Job - Waiting time ns: 124806, Backend time ns: 5601138
2025-01-22T18:25:17,325 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570317
2025-01-22T18:25:17,325 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2025-01-22T18:25:17,325 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 6
2025-01-22T18:25:17,325 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570317
2025-01-22 18:25:17.326 kserve.trace requestId: 15a4ec1b-88e5-497e-aa72-72170aeaa665, preprocess_ms: 0.012397766, explain_ms: 0, predict_ms: 9.521484375, postprocess_ms: 0.005245209
2025-01-22 18:25:17.326 uvicorn.access INFO:     10.233.75.99:0 9 - "POST /v1/models/youtubegoes5g%3Apredict HTTP/1.1" 200 OK
2025-01-22 18:25:17.327 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.010608434677124023
2025-01-22 18:25:17.327 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.0045939999999973224
2025-01-22T18:25:18,991 [INFO ] pool-3-thread-2 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570318
2025-01-22T18:25:18,991 [INFO ] pool-3-thread-2 TS_METRICS - DiskAvailable.Gigabytes:263.7131004333496|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570318
2025-01-22T18:25:18,991 [INFO ] pool-3-thread-2 TS_METRICS - DiskUsage.Gigabytes:208.29016494750977|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570318
2025-01-22T18:25:18,991 [INFO ] pool-3-thread-2 TS_METRICS - DiskUtilization.Percent:44.1|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570318
2025-01-22T18:25:18,991 [INFO ] pool-3-thread-2 TS_METRICS - MemoryAvailable.Megabytes:11283.0546875|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570318
2025-01-22T18:25:18,991 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUsed.Megabytes:8356.546875|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570318
2025-01-22T18:25:18,991 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUtilization.Percent:43.5|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570318
2025-01-22T18:25:29,343 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570329
2025-01-22T18:25:29,343 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1737570329343
2025-01-22T18:25:29,344 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Backend received inference at: 1737570329
2025-01-22T18:25:29,344 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Received data: [{'data': [13, 13, 13, 0, 13, 13, 13, 13, -76, -76, -81, -76, -78.5, -76, -76, -7, -7, -12, -7, -9.5, -7, -7, 12, 12, 7, 12, 9.5, 12, 12]}]
2025-01-22T18:25:29,345 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Input data preprocessed successfully
2025-01-22T18:25:29,347 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Inference performed successfully
2025-01-22T18:25:29,347 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Output postprocessed successfully
2025-01-22T18:25:29,347 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:2.84|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,1737570329,92f2bc40-7f43-4c78-af0f-9c3a08cc3ceb, pattern=[METRICS]
2025-01-22T18:25:29,347 [INFO ] W-9000-youtubegoes5g_1.0 ACCESS_LOG - /127.0.0.1:56868 "POST /v1/models/youtubegoes5g:predict HTTP/1.1" 200 4
2025-01-22T18:25:29,347 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570329
2025-01-22T18:25:29,347 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:3922.505|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570329
2025-01-22T18:25:29,347 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_METRICS - PredictionTime.ms:2.84|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,requestID:92f2bc40-7f43-4c78-af0f-9c3a08cc3ceb,timestamp:1737570329
2025-01-22T18:25:29,347 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:64.231|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570329
2025-01-22T18:25:29,347 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.job.Job - Waiting time ns: 64231, Backend time ns: 4261458
2025-01-22T18:25:29,347 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570329
2025-01-22T18:25:29,347 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2025-01-22T18:25:29,347 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 4
2025-01-22T18:25:29,348 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570329
2025-01-22 18:25:29.348 kserve.trace requestId: fc54ac5f-89d5-4dc8-bc64-c338bb8c0341, preprocess_ms: 0.013828278, explain_ms: 0, predict_ms: 7.571220398, postprocess_ms: 0.005722046
2025-01-22 18:25:29.349 uvicorn.access INFO:     10.233.75.99:0 9 - "POST /v1/models/youtubegoes5g%3Apredict HTTP/1.1" 200 OK
2025-01-22 18:25:29.349 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.008556842803955078
2025-01-22 18:25:29.349 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.00432600000021921
2025-01-22T18:25:41,366 [INFO ] epollEventLoopGroup-3-4 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570341
2025-01-22T18:25:41,367 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1737570341367
2025-01-22T18:25:41,367 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Backend received inference at: 1737570341
2025-01-22T18:25:41,368 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Received data: [{'data': [13, 13, 13, 0, 13, 13, 13, 13, -76, -76, -81, -76, -78.5, -76, -76, -7, -7, -12, -7, -9.5, -7, -7, 12, 12, 7, 12, 9.5, 12, 12]}]
2025-01-22T18:25:41,368 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Input data preprocessed successfully
2025-01-22T18:25:41,372 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Inference performed successfully
2025-01-22T18:25:41,372 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Output postprocessed successfully
2025-01-22T18:25:41,372 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:4.7|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,1737570341,19fdd40a-e529-4110-bcfe-8158a9a153bb, pattern=[METRICS]
2025-01-22T18:25:41,372 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_METRICS - PredictionTime.ms:4.7|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,requestID:19fdd40a-e529-4110-bcfe-8158a9a153bb,timestamp:1737570341
2025-01-22T18:25:41,373 [INFO ] W-9000-youtubegoes5g_1.0 ACCESS_LOG - /127.0.0.1:60846 "POST /v1/models/youtubegoes5g:predict HTTP/1.1" 200 7
2025-01-22T18:25:41,373 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570341
2025-01-22T18:25:41,373 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:5904.031|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570341
2025-01-22T18:25:41,373 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:96.905|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570341
2025-01-22T18:25:41,373 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.job.Job - Waiting time ns: 96905, Backend time ns: 6163936
2025-01-22T18:25:41,373 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570341
2025-01-22T18:25:41,373 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2025-01-22T18:25:41,373 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 6
2025-01-22T18:25:41,373 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570341
2025-01-22 18:25:41.374 kserve.trace requestId: c9da9d46-5175-4143-a0b3-74df1190b6ed, preprocess_ms: 0.015258789, explain_ms: 0, predict_ms: 10.839700699, postprocess_ms: 0.007867813
2025-01-22 18:25:41.375 uvicorn.access INFO:     10.233.75.99:0 9 - "POST /v1/models/youtubegoes5g%3Apredict HTTP/1.1" 200 OK
2025-01-22 18:25:41.375 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.011783123016357422
2025-01-22 18:25:41.375 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.005010000000766013
2025-01-22T18:25:53,391 [INFO ] epollEventLoopGroup-3-1 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570353
2025-01-22T18:25:53,391 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1737570353391
2025-01-22T18:25:53,392 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Backend received inference at: 1737570353
2025-01-22T18:25:53,392 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Received data: [{'data': [13, 13, 13, 0, 13, 13, 13, 13, -76, -76, -81, -76, -78.5, -76, -76, -7, -7, -12, -7, -9.5, -7, -7, 12, 12, 7, 12, 9.5, 12, 12]}]
2025-01-22T18:25:53,392 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Input data preprocessed successfully
2025-01-22T18:25:53,394 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Inference performed successfully
2025-01-22T18:25:53,394 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Output postprocessed successfully
2025-01-22T18:25:53,395 [INFO ] W-9000-youtubegoes5g_1.0 ACCESS_LOG - /127.0.0.1:45914 "POST /v1/models/youtubegoes5g:predict HTTP/1.1" 200 4
2025-01-22T18:25:53,395 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570353
2025-01-22T18:25:53,395 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:3810.199|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570353
2025-01-22T18:25:53,395 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:65.185|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570353
2025-01-22T18:25:53,395 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.job.Job - Waiting time ns: 65185, Backend time ns: 3893772
2025-01-22T18:25:53,395 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570353
2025-01-22T18:25:53,395 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2025-01-22T18:25:53,395 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 4
2025-01-22T18:25:53,395 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570353
2025-01-22T18:25:53,395 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:2.82|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,1737570353,b9f4ba49-9980-493e-a3d7-a13097a55773, pattern=[METRICS]
2025-01-22T18:25:53,395 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_METRICS - PredictionTime.ms:2.82|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,requestID:b9f4ba49-9980-493e-a3d7-a13097a55773,timestamp:1737570353
2025-01-22 18:25:53.397 kserve.trace requestId: bdc12d43-a52b-48d5-a0fc-bf4cfeab178f, preprocess_ms: 0.019311905, explain_ms: 0, predict_ms: 8.024930954, postprocess_ms: 0.005722046
2025-01-22 18:25:53.397 uvicorn.access INFO:     10.233.75.99:0 9 - "POST /v1/models/youtubegoes5g%3Apredict HTTP/1.1" 200 OK
2025-01-22 18:25:53.397 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.009128808975219727
2025-01-22 18:25:53.397 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.004611000000295462
2025-01-22T18:26:18,985 [INFO ] pool-3-thread-2 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570378
2025-01-22T18:26:18,985 [INFO ] pool-3-thread-2 TS_METRICS - DiskAvailable.Gigabytes:263.7128486633301|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570378
2025-01-22T18:26:18,985 [INFO ] pool-3-thread-2 TS_METRICS - DiskUsage.Gigabytes:208.2904167175293|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570378
2025-01-22T18:26:18,985 [INFO ] pool-3-thread-2 TS_METRICS - DiskUtilization.Percent:44.1|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570378
2025-01-22T18:26:18,985 [INFO ] pool-3-thread-2 TS_METRICS - MemoryAvailable.Megabytes:11209.8671875|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570378
2025-01-22T18:26:18,985 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUsed.Megabytes:8429.734375|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570378
2025-01-22T18:26:18,985 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUtilization.Percent:43.9|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570378
2025-01-22T18:26:29,415 [INFO ] epollEventLoopGroup-3-2 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570389
2025-01-22T18:26:29,415 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1737570389415
2025-01-22T18:26:29,416 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Backend received inference at: 1737570389
2025-01-22T18:26:29,416 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Received data: [{'data': [13, 13, 13, 0, 13, 13, 13, 13, -76, -76, -81, -76, -78.5, -76, -76, -7, -7, -12, -7, -9.5, -7, -7, 12, 12, 7, 12, 9.5, 12, 12]}]
2025-01-22T18:26:29,417 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Input data preprocessed successfully
2025-01-22T18:26:29,419 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Inference performed successfully
2025-01-22T18:26:29,419 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Output postprocessed successfully
2025-01-22T18:26:29,419 [INFO ] W-9000-youtubegoes5g_1.0 ACCESS_LOG - /127.0.0.1:38442 "POST /v1/models/youtubegoes5g:predict HTTP/1.1" 200 4
2025-01-22T18:26:29,419 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:1.49|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,1737570389,47f34ee2-0445-44c0-a302-95dd1bb4f68b, pattern=[METRICS]
2025-01-22T18:26:29,419 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570389
2025-01-22T18:26:29,419 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:3719.528|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570389
2025-01-22T18:26:29,419 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:132.715|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570389
2025-01-22T18:26:29,419 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.job.Job - Waiting time ns: 132715, Backend time ns: 3809491
2025-01-22T18:26:29,419 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570389
2025-01-22T18:26:29,419 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2025-01-22T18:26:29,419 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_METRICS - PredictionTime.ms:1.49|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,requestID:47f34ee2-0445-44c0-a302-95dd1bb4f68b,timestamp:1737570389
2025-01-22T18:26:29,419 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3
2025-01-22T18:26:29,419 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570389
2025-01-22 18:26:29.420 kserve.trace requestId: 10aee79e-b91f-444e-ac8b-43745381614d, preprocess_ms: 0.011920929, explain_ms: 0, predict_ms: 7.904291153, postprocess_ms: 0.005483627
2025-01-22 18:26:29.420 uvicorn.access INFO:     10.233.75.99:0 9 - "POST /v1/models/youtubegoes5g%3Apredict HTTP/1.1" 200 OK
2025-01-22 18:26:29.421 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.008760929107666016
2025-01-22 18:26:29.421 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.004693000000770553
2025-01-22T18:26:41,439 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570401
2025-01-22T18:26:41,440 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1737570401440
2025-01-22T18:26:41,440 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Backend received inference at: 1737570401
2025-01-22T18:26:41,441 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Received data: [{'data': [13, 13, 13, 0, 13, 13, 13, 13, -76, -76, -81, -76, -78.5, -76, -76, -7, -7, -12, -7, -9.5, -7, -7, 12, 12, 7, 12, 9.5, 12, 12]}]
2025-01-22T18:26:41,442 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Input data preprocessed successfully
2025-01-22T18:26:41,443 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Inference performed successfully
2025-01-22T18:26:41,443 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Output postprocessed successfully
2025-01-22T18:26:41,443 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:2.18|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,1737570401,eb13d677-591d-4454-a043-07df01868577, pattern=[METRICS]
2025-01-22T18:26:41,443 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_METRICS - PredictionTime.ms:2.18|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,requestID:eb13d677-591d-4454-a043-07df01868577,timestamp:1737570401
2025-01-22T18:26:41,444 [INFO ] W-9000-youtubegoes5g_1.0 ACCESS_LOG - /127.0.0.1:46016 "POST /v1/models/youtubegoes5g:predict HTTP/1.1" 200 5
2025-01-22T18:26:41,444 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570401
2025-01-22T18:26:41,444 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:4335.895|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570401
2025-01-22T18:26:41,444 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:116.166|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570401
2025-01-22T18:26:41,444 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.job.Job - Waiting time ns: 116166, Backend time ns: 4868414
2025-01-22T18:26:41,445 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570401
2025-01-22T18:26:41,445 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2025-01-22T18:26:41,445 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 4
2025-01-22T18:26:41,445 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570401
2025-01-22 18:26:41.446 kserve.trace requestId: efba4543-4f1f-4b60-a4ce-cdee883b345a, preprocess_ms: 0.014066696, explain_ms: 0, predict_ms: 8.829593658, postprocess_ms: 0.008583069
2025-01-22 18:26:41.446 uvicorn.access INFO:     10.233.75.99:0 9 - "POST /v1/models/youtubegoes5g%3Apredict HTTP/1.1" 200 OK
2025-01-22 18:26:41.446 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.010126590728759766
2025-01-22 18:26:41.447 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.0048969999988912605
2025-01-22T18:26:53,463 [INFO ] epollEventLoopGroup-3-4 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570413
2025-01-22T18:26:53,463 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1737570413463
2025-01-22T18:26:53,464 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Backend received inference at: 1737570413
2025-01-22T18:26:53,464 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Received data: [{'data': [13, 13, 13, 0, 13, 13, 13, 13, -76, -76, -81, -76, -78.5, -76, -76, -7, -7, -12, -7, -9.5, -7, -7, 12, 12, 7, 12, 9.5, 12, 12]}]
2025-01-22T18:26:53,465 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Input data preprocessed successfully
2025-01-22T18:26:53,466 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Inference performed successfully
2025-01-22T18:26:53,466 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Output postprocessed successfully
2025-01-22T18:26:53,467 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:2.5|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,1737570413,53657029-76c6-4fc5-8f23-8eb8f7488c17, pattern=[METRICS]
2025-01-22T18:26:53,467 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_METRICS - PredictionTime.ms:2.5|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,requestID:53657029-76c6-4fc5-8f23-8eb8f7488c17,timestamp:1737570413
2025-01-22T18:26:53,467 [INFO ] W-9000-youtubegoes5g_1.0 ACCESS_LOG - /127.0.0.1:42684 "POST /v1/models/youtubegoes5g:predict HTTP/1.1" 200 4
2025-01-22T18:26:53,467 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570413
2025-01-22T18:26:53,467 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:3584.393|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570413
2025-01-22T18:26:53,467 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:35.624|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570413
2025-01-22T18:26:53,467 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.job.Job - Waiting time ns: 35624, Backend time ns: 3677553
2025-01-22T18:26:53,467 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570413
2025-01-22T18:26:53,467 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2025-01-22T18:26:53,467 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 4
2025-01-22T18:26:53,467 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570413
2025-01-22 18:26:53.469 kserve.trace requestId: b3c74b6d-4d61-4ea3-bfef-1fc73ad7a25a, preprocess_ms: 0.011444092, explain_ms: 0, predict_ms: 8.428096771, postprocess_ms: 0.005722046
2025-01-22 18:26:53.470 uvicorn.access INFO:     10.233.75.99:0 9 - "POST /v1/models/youtubegoes5g%3Apredict HTTP/1.1" 200 OK
2025-01-22 18:26:53.470 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.009361743927001953
2025-01-22 18:26:53.470 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.004541000000244821
2025-01-22T18:27:05,486 [INFO ] epollEventLoopGroup-3-1 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570425
2025-01-22T18:27:05,486 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1737570425486
2025-01-22T18:27:05,487 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Backend received inference at: 1737570425
2025-01-22T18:27:05,487 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Received data: [{'data': [13, 13, 13, 0, 13, 13, 13, 13, -76, -76, -81, -76, -78.5, -76, -76, -7, -7, -12, -7, -9.5, -7, -7, 12, 12, 7, 12, 9.5, 12, 12]}]
2025-01-22T18:27:05,488 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Input data preprocessed successfully
2025-01-22T18:27:05,489 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Inference performed successfully
2025-01-22T18:27:05,489 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Output postprocessed successfully
2025-01-22T18:27:05,490 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:2.12|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,1737570425,fa954c82-41a0-4b5a-9c92-9b5365382eed, pattern=[METRICS]
2025-01-22T18:27:05,490 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_METRICS - PredictionTime.ms:2.12|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,requestID:fa954c82-41a0-4b5a-9c92-9b5365382eed,timestamp:1737570425
2025-01-22T18:27:05,490 [INFO ] W-9000-youtubegoes5g_1.0 ACCESS_LOG - /127.0.0.1:46776 "POST /v1/models/youtubegoes5g:predict HTTP/1.1" 200 4
2025-01-22T18:27:05,490 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570425
2025-01-22T18:27:05,490 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:3614.598|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570425
2025-01-22T18:27:05,490 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:32.27|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570425
2025-01-22T18:27:05,490 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.job.Job - Waiting time ns: 32270, Backend time ns: 3874147
2025-01-22T18:27:05,490 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570425
2025-01-22T18:27:05,490 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2025-01-22T18:27:05,490 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3
2025-01-22T18:27:05,490 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570425
2025-01-22 18:27:05.491 kserve.trace requestId: 50985e7a-a6da-48bc-acdd-358f93a68307, preprocess_ms: 0.012159348, explain_ms: 0, predict_ms: 7.437944412, postprocess_ms: 0.00500679
2025-01-22 18:27:05.492 uvicorn.access INFO:     10.233.75.99:0 9 - "POST /v1/models/youtubegoes5g%3Apredict HTTP/1.1" 200 OK
2025-01-22 18:27:05.492 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.008272886276245117
2025-01-22 18:27:05.492 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.004077999999935855
2025-01-22T18:27:17,509 [INFO ] epollEventLoopGroup-3-2 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570437
2025-01-22T18:27:17,509 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1737570437509
2025-01-22T18:27:17,510 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Backend received inference at: 1737570437
2025-01-22T18:27:17,510 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Received data: [{'data': [13, 13, 13, 0, 13, 13, 13, 13, -76, -76, -81, -76, -78.5, -76, -76, -7, -7, -12, -7, -9.5, -7, -7, 12, 12, 7, 12, 9.5, 12, 12]}]
2025-01-22T18:27:17,512 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Input data preprocessed successfully
2025-01-22T18:27:17,514 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Inference performed successfully
2025-01-22T18:27:17,514 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Output postprocessed successfully
2025-01-22T18:27:17,515 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:4.09|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,1737570437,275acdfd-a548-4942-a642-9da9115034ae, pattern=[METRICS]
2025-01-22T18:27:17,515 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_METRICS - PredictionTime.ms:4.09|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,requestID:275acdfd-a548-4942-a642-9da9115034ae,timestamp:1737570437
2025-01-22T18:27:17,515 [INFO ] W-9000-youtubegoes5g_1.0 ACCESS_LOG - /127.0.0.1:60998 "POST /v1/models/youtubegoes5g:predict HTTP/1.1" 200 6
2025-01-22T18:27:17,515 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570437
2025-01-22T18:27:17,515 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:5853.52|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570437
2025-01-22T18:27:17,515 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:34.669|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570437
2025-01-22T18:27:17,515 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.job.Job - Waiting time ns: 34669, Backend time ns: 6096205
2025-01-22T18:27:17,515 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570437
2025-01-22T18:27:17,515 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2025-01-22T18:27:17,515 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 5
2025-01-22T18:27:17,515 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570437
2025-01-22 18:27:17.516 kserve.trace requestId: 9ba61388-1441-40a1-a0cf-14bf4a8a1a26, preprocess_ms: 0.010490417, explain_ms: 0, predict_ms: 9.628772736, postprocess_ms: 0.004768372
2025-01-22 18:27:17.516 uvicorn.access INFO:     10.233.75.99:0 9 - "POST /v1/models/youtubegoes5g%3Apredict HTTP/1.1" 200 OK
2025-01-22 18:27:17.517 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.010547637939453125
2025-01-22 18:27:17.517 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.004379999998491257
2025-01-22T18:27:18,988 [INFO ] pool-3-thread-2 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570438
2025-01-22T18:27:18,988 [INFO ] pool-3-thread-2 TS_METRICS - DiskAvailable.Gigabytes:263.7125587463379|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570438
2025-01-22T18:27:18,988 [INFO ] pool-3-thread-2 TS_METRICS - DiskUsage.Gigabytes:208.29070663452148|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570438
2025-01-22T18:27:18,988 [INFO ] pool-3-thread-2 TS_METRICS - DiskUtilization.Percent:44.1|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570438
2025-01-22T18:27:18,988 [INFO ] pool-3-thread-2 TS_METRICS - MemoryAvailable.Megabytes:11138.71484375|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570438
2025-01-22T18:27:18,988 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUsed.Megabytes:8500.88671875|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570438
2025-01-22T18:27:18,988 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUtilization.Percent:44.3|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570438
2025-01-22T18:27:29,535 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570449
2025-01-22T18:27:29,535 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1737570449535
2025-01-22T18:27:29,537 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Backend received inference at: 1737570449
2025-01-22T18:27:29,537 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Received data: [{'data': [13, 13, 13, 0, 13, 13, 13, 13, -76, -76, -81, -76, -78.5, -76, -76, -7, -7, -12, -7, -9.5, -7, -7, 12, 12, 7, 12, 9.5, 12, 12]}]
2025-01-22T18:27:29,537 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Input data preprocessed successfully
2025-01-22T18:27:29,537 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Inference performed successfully
2025-01-22T18:27:29,537 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Output postprocessed successfully
2025-01-22T18:27:29,537 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:1.79|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,1737570449,e69e86b6-2457-4aaa-a51c-3b087b3e61da, pattern=[METRICS]
2025-01-22T18:27:29,537 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_METRICS - PredictionTime.ms:1.79|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,requestID:e69e86b6-2457-4aaa-a51c-3b087b3e61da,timestamp:1737570449
2025-01-22T18:27:29,537 [INFO ] W-9000-youtubegoes5g_1.0 ACCESS_LOG - /127.0.0.1:57962 "POST /v1/models/youtubegoes5g:predict HTTP/1.1" 200 2
2025-01-22T18:27:29,537 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570449
2025-01-22T18:27:29,537 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:2645.543|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570449
2025-01-22T18:27:29,537 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:19.756|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570449
2025-01-22T18:27:29,538 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.job.Job - Waiting time ns: 19756, Backend time ns: 2783472
2025-01-22T18:27:29,538 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570449
2025-01-22T18:27:29,538 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2025-01-22T18:27:29,538 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0
2025-01-22T18:27:29,538 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:3.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570449
2025-01-22 18:27:29.539 kserve.trace requestId: dc620d68-055b-473c-a052-c706b0e2c795, preprocess_ms: 0.012159348, explain_ms: 0, predict_ms: 7.643699646, postprocess_ms: 0.006198883
2025-01-22 18:27:29.540 uvicorn.access INFO:     10.233.75.99:0 9 - "POST /v1/models/youtubegoes5g%3Apredict HTTP/1.1" 200 OK
2025-01-22 18:27:29.540 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.008729219436645508
2025-01-22 18:27:29.540 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.004873999998380896
2025-01-22T18:27:41,560 [INFO ] epollEventLoopGroup-3-4 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570461
2025-01-22T18:27:41,560 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1737570461560
2025-01-22T18:27:41,560 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Backend received inference at: 1737570461
2025-01-22T18:27:41,560 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Received data: [{'data': [13, 13, 13, 0, 13, 13, 13, 13, -76, -76, -81, -76, -78.5, -76, -76, -7, -7, -12, -7, -9.5, -7, -7, 12, 12, 7, 12, 9.5, 12, 12]}]
2025-01-22T18:27:41,561 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Input data preprocessed successfully
2025-01-22T18:27:41,565 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Inference performed successfully
2025-01-22T18:27:41,565 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Output postprocessed successfully
2025-01-22T18:27:41,565 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:4.73|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,1737570461,ad5eaa71-f322-4b94-a327-0c65099eff61, pattern=[METRICS]
2025-01-22T18:27:41,565 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_METRICS - PredictionTime.ms:4.73|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,requestID:ad5eaa71-f322-4b94-a327-0c65099eff61,timestamp:1737570461
2025-01-22T18:27:41,566 [INFO ] W-9000-youtubegoes5g_1.0 ACCESS_LOG - /127.0.0.1:55666 "POST /v1/models/youtubegoes5g:predict HTTP/1.1" 200 6
2025-01-22T18:27:41,566 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570461
2025-01-22T18:27:41,566 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:5916.828|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570461
2025-01-22T18:27:41,566 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:35.433|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570461
2025-01-22T18:27:41,566 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.job.Job - Waiting time ns: 35433, Backend time ns: 6424658
2025-01-22T18:27:41,566 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570461
2025-01-22T18:27:41,566 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2025-01-22T18:27:41,566 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 6
2025-01-22T18:27:41,566 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570461
2025-01-22 18:27:41.567 kserve.trace requestId: 2894bce9-5964-48a8-b272-f1503a25c3d3, preprocess_ms: 0.013113022, explain_ms: 0, predict_ms: 10.176420212, postprocess_ms: 0.004291534
2025-01-22 18:27:41.568 uvicorn.access INFO:     10.233.75.99:0 9 - "POST /v1/models/youtubegoes5g%3Apredict HTTP/1.1" 200 OK
2025-01-22 18:27:41.568 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.011574029922485352
2025-01-22 18:27:41.568 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.004982999998901505
2025-01-22T18:27:53,587 [INFO ] epollEventLoopGroup-3-1 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570473
2025-01-22T18:27:53,587 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1737570473587
2025-01-22T18:27:53,587 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Backend received inference at: 1737570473
2025-01-22T18:27:53,588 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Received data: [{'data': [13, 13, 13, 0, 13, 13, 13, 13, -76, -76, -81, -76, -78.5, -76, -76, -7, -7, -12, -7, -9.5, -7, -7, 12, 12, 7, 12, 9.5, 12, 12]}]
2025-01-22T18:27:53,588 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Input data preprocessed successfully
2025-01-22T18:27:53,592 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Inference performed successfully
2025-01-22T18:27:53,592 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Output postprocessed successfully
2025-01-22T18:27:53,593 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:4.88|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,1737570473,3f58c275-52ae-4229-97f3-4052b09f8819, pattern=[METRICS]
2025-01-22T18:27:53,593 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_METRICS - PredictionTime.ms:4.88|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,requestID:3f58c275-52ae-4229-97f3-4052b09f8819,timestamp:1737570473
2025-01-22T18:27:53,593 [INFO ] W-9000-youtubegoes5g_1.0 ACCESS_LOG - /127.0.0.1:48470 "POST /v1/models/youtubegoes5g:predict HTTP/1.1" 200 6
2025-01-22T18:27:53,593 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570473
2025-01-22T18:27:53,593 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:5870.893|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570473
2025-01-22T18:27:53,593 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:48.368|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570473
2025-01-22T18:27:53,593 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.job.Job - Waiting time ns: 48368, Backend time ns: 5967148
2025-01-22T18:27:53,593 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570473
2025-01-22T18:27:53,593 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2025-01-22T18:27:53,593 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 6
2025-01-22T18:27:53,593 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570473
2025-01-22 18:27:53.594 kserve.trace requestId: d352ddf7-0089-4188-958c-9a71668eb243, preprocess_ms: 0.013113022, explain_ms: 0, predict_ms: 9.411334991, postprocess_ms: 0.004768372
2025-01-22 18:27:53.594 uvicorn.access INFO:     10.233.75.99:0 9 - "POST /v1/models/youtubegoes5g%3Apredict HTTP/1.1" 200 OK
2025-01-22 18:27:53.594 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.010312795639038086
2025-01-22 18:27:53.594 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.004095999998753541
2025-01-22T18:28:05,613 [INFO ] epollEventLoopGroup-3-2 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570485
2025-01-22T18:28:05,613 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1737570485613
2025-01-22T18:28:05,614 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Backend received inference at: 1737570485
2025-01-22T18:28:05,614 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Received data: [{'data': [13, 13, 13, 0, 13, 13, 13, 13, -76, -76, -81, -76, -78.5, -76, -76, -7, -7, -12, -7, -9.5, -7, -7, 12, 12, 7, 12, 9.5, 12, 12]}]
2025-01-22T18:28:05,615 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Input data preprocessed successfully
2025-01-22T18:28:05,618 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Inference performed successfully
2025-01-22T18:28:05,618 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Output postprocessed successfully
2025-01-22T18:28:05,619 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:4.44|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,1737570485,86edaa25-f3ec-4a58-b195-e3ca7618dd84, pattern=[METRICS]
2025-01-22T18:28:05,619 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_METRICS - PredictionTime.ms:4.44|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,requestID:86edaa25-f3ec-4a58-b195-e3ca7618dd84,timestamp:1737570485
2025-01-22T18:28:05,619 [INFO ] W-9000-youtubegoes5g_1.0 ACCESS_LOG - /127.0.0.1:58518 "POST /v1/models/youtubegoes5g:predict HTTP/1.1" 200 6
2025-01-22T18:28:05,619 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570485
2025-01-22T18:28:05,619 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:5401.151|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570485
2025-01-22T18:28:05,619 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:43.506|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570485
2025-01-22T18:28:05,619 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.job.Job - Waiting time ns: 43506, Backend time ns: 5491456
2025-01-22T18:28:05,619 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570485
2025-01-22T18:28:05,619 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2025-01-22T18:28:05,619 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 5
2025-01-22T18:28:05,619 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570485
2025-01-22 18:28:05.620 kserve.trace requestId: aff053a7-f113-4ef7-936c-6ab609783f0e, preprocess_ms: 0.026226044, explain_ms: 0, predict_ms: 10.47873497, postprocess_ms: 0.006437302
2025-01-22 18:28:05.620 uvicorn.access INFO:     10.233.75.99:0 9 - "POST /v1/models/youtubegoes5g%3Apredict HTTP/1.1" 200 OK
2025-01-22 18:28:05.621 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.011508703231811523
2025-01-22 18:28:05.621 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.005997000000206754
2025-01-22T18:28:17,639 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570497
2025-01-22T18:28:17,639 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1737570497639
2025-01-22T18:28:17,640 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Backend received inference at: 1737570497
2025-01-22T18:28:17,640 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Received data: [{'data': [13, 13, 13, 0, 13, 13, 13, 13, -76, -76, -81, -76, -78.5, -76, -76, -7, -7, -12, -7, -9.5, -7, -7, 12, 12, 7, 12, 9.5, 12, 12]}]
2025-01-22T18:28:17,640 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Input data preprocessed successfully
2025-01-22T18:28:17,642 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Inference performed successfully
2025-01-22T18:28:17,642 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Output postprocessed successfully
2025-01-22T18:28:17,643 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:2.68|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,1737570497,0fa24ee7-e29e-420c-91b9-869edf8e5601, pattern=[METRICS]
2025-01-22T18:28:17,643 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_METRICS - PredictionTime.ms:2.68|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,requestID:0fa24ee7-e29e-420c-91b9-869edf8e5601,timestamp:1737570497
2025-01-22T18:28:17,643 [INFO ] W-9000-youtubegoes5g_1.0 ACCESS_LOG - /127.0.0.1:44362 "POST /v1/models/youtubegoes5g:predict HTTP/1.1" 200 4
2025-01-22T18:28:17,643 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570497
2025-01-22T18:28:17,643 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:3544.775|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570497
2025-01-22T18:28:17,643 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:69.739|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570497
2025-01-22T18:28:17,643 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.job.Job - Waiting time ns: 69739, Backend time ns: 3612250
2025-01-22T18:28:17,643 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570497
2025-01-22T18:28:17,643 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2025-01-22T18:28:17,643 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 4
2025-01-22T18:28:17,643 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570497
2025-01-22 18:28:17.645 kserve.trace requestId: 7b59578f-983e-4f2a-9b6e-90822d801c6c, preprocess_ms: 0.014781952, explain_ms: 0, predict_ms: 8.543968201, postprocess_ms: 0.005245209
2025-01-22 18:28:17.645 uvicorn.access INFO:     10.233.75.99:0 9 - "POST /v1/models/youtubegoes5g%3Apredict HTTP/1.1" 200 OK
2025-01-22 18:28:17.646 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.009459733963012695
2025-01-22 18:28:17.646 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.004434000000401284
2025-01-22T18:28:18,987 [INFO ] pool-3-thread-2 TS_METRICS - CPUUtilization.Percent:50.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570498
2025-01-22T18:28:18,987 [INFO ] pool-3-thread-2 TS_METRICS - DiskAvailable.Gigabytes:263.7122993469238|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570498
2025-01-22T18:28:18,987 [INFO ] pool-3-thread-2 TS_METRICS - DiskUsage.Gigabytes:208.29096603393555|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570498
2025-01-22T18:28:18,987 [INFO ] pool-3-thread-2 TS_METRICS - DiskUtilization.Percent:44.1|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570498
2025-01-22T18:28:18,987 [INFO ] pool-3-thread-2 TS_METRICS - MemoryAvailable.Megabytes:11215.41015625|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570498
2025-01-22T18:28:18,987 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUsed.Megabytes:8424.19140625|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570498
2025-01-22T18:28:18,987 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUtilization.Percent:43.9|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570498
2025-01-22T18:28:53,664 [INFO ] epollEventLoopGroup-3-4 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570533
2025-01-22T18:28:53,664 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1737570533664
2025-01-22T18:28:53,665 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Backend received inference at: 1737570533
2025-01-22T18:28:53,665 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Received data: [{'data': [13, 13, 13, 0, 13, 13, 13, 13, -76, -76, -81, -76, -78.5, -76, -76, -7, -7, -12, -7, -9.5, -7, -7, 12, 12, 7, 12, 9.5, 12, 12]}]
2025-01-22T18:28:53,665 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Input data preprocessed successfully
2025-01-22T18:28:53,667 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Inference performed successfully
2025-01-22T18:28:53,667 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Output postprocessed successfully
2025-01-22T18:28:53,669 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:4.25|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,1737570533,fb73356e-c2b6-4390-b0ba-f536499e01c3, pattern=[METRICS]
2025-01-22T18:28:53,669 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_METRICS - PredictionTime.ms:4.25|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,requestID:fb73356e-c2b6-4390-b0ba-f536499e01c3,timestamp:1737570533
2025-01-22T18:28:53,669 [INFO ] W-9000-youtubegoes5g_1.0 ACCESS_LOG - /127.0.0.1:56526 "POST /v1/models/youtubegoes5g:predict HTTP/1.1" 200 5
2025-01-22T18:28:53,669 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570533
2025-01-22T18:28:53,669 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:5280.086|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570533
2025-01-22T18:28:53,669 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:35.381|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570533
2025-01-22T18:28:53,669 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.job.Job - Waiting time ns: 35381, Backend time ns: 5437647
2025-01-22T18:28:53,670 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570533
2025-01-22T18:28:53,670 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2025-01-22T18:28:53,670 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 5
2025-01-22T18:28:53,670 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570533
2025-01-22 18:28:53.670 kserve.trace requestId: d396ee27-feaa-46fa-85be-118d3dd0bbdd, preprocess_ms: 0.011920929, explain_ms: 0, predict_ms: 9.245634079, postprocess_ms: 0.004291534
2025-01-22 18:28:53.671 uvicorn.access INFO:     10.233.75.99:0 9 - "POST /v1/models/youtubegoes5g%3Apredict HTTP/1.1" 200 OK
2025-01-22 18:28:53.671 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.010219335556030273
2025-01-22 18:28:53.671 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.004670000000260188
2025-01-22T18:29:05,690 [INFO ] epollEventLoopGroup-3-1 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570545
2025-01-22T18:29:05,690 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1737570545690
2025-01-22T18:29:05,691 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Backend received inference at: 1737570545
2025-01-22T18:29:05,691 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Received data: [{'data': [13, 13, 13, 0, 13, 13, 13, 13, -76, -76, -81, -76, -78.5, -76, -76, -7, -7, -12, -7, -9.5, -7, -7, 12, 12, 7, 12, 9.5, 12, 12]}]
2025-01-22T18:29:05,692 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Input data preprocessed successfully
2025-01-22T18:29:05,696 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Inference performed successfully
2025-01-22T18:29:05,696 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Output postprocessed successfully
2025-01-22T18:29:05,696 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:4.77|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,1737570545,fa56db3d-cd0d-4fe4-92d3-b61ea442124a, pattern=[METRICS]
2025-01-22T18:29:05,696 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_METRICS - PredictionTime.ms:4.77|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,requestID:fa56db3d-cd0d-4fe4-92d3-b61ea442124a,timestamp:1737570545
2025-01-22T18:29:05,696 [INFO ] W-9000-youtubegoes5g_1.0 ACCESS_LOG - /127.0.0.1:41176 "POST /v1/models/youtubegoes5g:predict HTTP/1.1" 200 6
2025-01-22T18:29:05,696 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570545
2025-01-22T18:29:05,696 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:5867.223|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570545
2025-01-22T18:29:05,696 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:71.719|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570545
2025-01-22T18:29:05,696 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.job.Job - Waiting time ns: 71719, Backend time ns: 5894866
2025-01-22T18:29:05,696 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570545
2025-01-22T18:29:05,696 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2025-01-22T18:29:05,696 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 5
2025-01-22T18:29:05,696 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570545
2025-01-22 18:29:05.698 kserve.trace requestId: efb98f15-7e5d-4d84-8f43-1a7a397a9e06, preprocess_ms: 0.012159348, explain_ms: 0, predict_ms: 10.695457458, postprocess_ms: 0.005960464
2025-01-22 18:29:05.698 uvicorn.access INFO:     10.233.75.99:0 9 - "POST /v1/models/youtubegoes5g%3Apredict HTTP/1.1" 200 OK
2025-01-22 18:29:05.698 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.011808633804321289
2025-01-22 18:29:05.698 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.004904999999780557
2025-01-22T18:29:17,717 [INFO ] epollEventLoopGroup-3-2 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570557
2025-01-22T18:29:17,718 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1737570557718
2025-01-22T18:29:17,718 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Backend received inference at: 1737570557
2025-01-22T18:29:17,718 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Received data: [{'data': [13, 13, 13, 0, 13, 13, 13, 13, -76, -76, -81, -76, -78.5, -76, -76, -7, -7, -12, -7, -9.5, -7, -7, 12, 12, 7, 12, 9.5, 12, 12]}]
2025-01-22T18:29:17,719 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Input data preprocessed successfully
2025-01-22T18:29:17,722 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Inference performed successfully
2025-01-22T18:29:17,723 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Output postprocessed successfully
2025-01-22T18:29:17,723 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:4.5|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,1737570557,41f1e7ef-4a7a-4923-829c-843589732d39, pattern=[METRICS]
2025-01-22T18:29:17,723 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_METRICS - PredictionTime.ms:4.5|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,requestID:41f1e7ef-4a7a-4923-829c-843589732d39,timestamp:1737570557
2025-01-22T18:29:17,723 [INFO ] W-9000-youtubegoes5g_1.0 ACCESS_LOG - /127.0.0.1:51802 "POST /v1/models/youtubegoes5g:predict HTTP/1.1" 200 6
2025-01-22T18:29:17,723 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570557
2025-01-22T18:29:17,723 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:5280.016|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570557
2025-01-22T18:29:17,723 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:45.412|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570557
2025-01-22T18:29:17,723 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.job.Job - Waiting time ns: 45412, Backend time ns: 5341899
2025-01-22T18:29:17,723 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570557
2025-01-22T18:29:17,723 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2025-01-22T18:29:17,723 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 5
2025-01-22T18:29:17,723 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570557
2025-01-22 18:29:17.724 uvicorn.access INFO:     10.233.75.99:0 9 - "POST /v1/models/youtubegoes5g%3Apredict HTTP/1.1" 200 OK
2025-01-22 18:29:17.724 kserve.trace requestId: 45b3a361-b725-42fd-8fee-3ac275008507, preprocess_ms: 0.006198883, explain_ms: 0, predict_ms: 9.2856884, postprocess_ms: 0.017166138
2025-01-22 18:29:17.725 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.01027536392211914
2025-01-22 18:29:17.725 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.004637999998521991
2025-01-22T18:29:18,987 [INFO ] pool-3-thread-2 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570558
2025-01-22T18:29:18,987 [INFO ] pool-3-thread-2 TS_METRICS - DiskAvailable.Gigabytes:263.71203994750977|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570558
2025-01-22T18:29:18,987 [INFO ] pool-3-thread-2 TS_METRICS - DiskUsage.Gigabytes:208.2912254333496|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570558
2025-01-22T18:29:18,988 [INFO ] pool-3-thread-2 TS_METRICS - DiskUtilization.Percent:44.1|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570558
2025-01-22T18:29:18,988 [INFO ] pool-3-thread-2 TS_METRICS - MemoryAvailable.Megabytes:11226.72265625|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570558
2025-01-22T18:29:18,988 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUsed.Megabytes:8413.125|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570558
2025-01-22T18:29:18,988 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUtilization.Percent:43.8|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570558
2025-01-22T18:29:29,742 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570569
2025-01-22T18:29:29,742 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1737570569742
2025-01-22T18:29:29,742 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Backend received inference at: 1737570569
2025-01-22T18:29:29,742 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Received data: [{'data': [13, 13, 13, 0, 13, 13, 13, 13, -76, -76, -81, -76, -78.5, -76, -76, -7, -7, -12, -7, -9.5, -7, -7, 12, 12, 7, 12, 9.5, 12, 12]}]
2025-01-22T18:29:29,743 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Input data preprocessed successfully
2025-01-22T18:29:29,745 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Inference performed successfully
2025-01-22T18:29:29,745 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Output postprocessed successfully
2025-01-22T18:29:29,745 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:2.53|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,1737570569,69fea23e-0a71-40fb-8ebb-82145ef17234, pattern=[METRICS]
2025-01-22T18:29:29,745 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_METRICS - PredictionTime.ms:2.53|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,requestID:69fea23e-0a71-40fb-8ebb-82145ef17234,timestamp:1737570569
2025-01-22T18:29:29,745 [INFO ] W-9000-youtubegoes5g_1.0 ACCESS_LOG - /127.0.0.1:36398 "POST /v1/models/youtubegoes5g:predict HTTP/1.1" 200 3
2025-01-22T18:29:29,745 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570569
2025-01-22T18:29:29,746 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:3767.887|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570569
2025-01-22T18:29:29,746 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:66.362|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570569
2025-01-22T18:29:29,746 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.job.Job - Waiting time ns: 66362, Backend time ns: 3846202
2025-01-22T18:29:29,746 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570569
2025-01-22T18:29:29,746 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2025-01-22T18:29:29,746 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3
2025-01-22T18:29:29,746 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570569
2025-01-22 18:29:29.747 kserve.trace requestId: 10734401-6b48-4d84-b138-e6324665c3f7, preprocess_ms: 0.011920929, explain_ms: 0, predict_ms: 7.737159729, postprocess_ms: 0.004768372
2025-01-22 18:29:29.747 uvicorn.access INFO:     10.233.75.99:0 9 - "POST /v1/models/youtubegoes5g%3Apredict HTTP/1.1" 200 OK
2025-01-22 18:29:29.748 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.008739948272705078
2025-01-22 18:29:29.748 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.004516999999395921
2025-01-22T18:29:41,765 [INFO ] epollEventLoopGroup-3-4 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570581
2025-01-22T18:29:41,765 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1737570581765
2025-01-22T18:29:41,765 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Backend received inference at: 1737570581
2025-01-22T18:29:41,765 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Received data: [{'data': [13, 13, 13, 0, 13, 13, 13, 13, -76, -76, -81, -76, -78.5, -76, -76, -7, -7, -12, -7, -9.5, -7, -7, 12, 12, 7, 12, 9.5, 12, 12]}]
2025-01-22T18:29:41,766 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Input data preprocessed successfully
2025-01-22T18:29:41,767 [INFO ] W-9000-youtubegoes5g_1.0 ACCESS_LOG - /127.0.0.1:60544 "POST /v1/models/youtubegoes5g:predict HTTP/1.1" 200 2
2025-01-22T18:29:41,767 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570581
2025-01-22T18:29:41,767 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:2057.576|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570581
2025-01-22T18:29:41,767 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Inference performed successfully
2025-01-22T18:29:41,767 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:26.096|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570581
2025-01-22T18:29:41,767 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Output postprocessed successfully
2025-01-22T18:29:41,767 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.job.Job - Waiting time ns: 26096, Backend time ns: 2151944
2025-01-22T18:29:41,767 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:1.31|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,1737570581,d0685da2-82b1-4c69-97f3-aa5a520f4f74, pattern=[METRICS]
2025-01-22T18:29:41,767 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570581
2025-01-22T18:29:41,767 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2025-01-22T18:29:41,767 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2
2025-01-22T18:29:41,767 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_METRICS - PredictionTime.ms:1.31|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,requestID:d0685da2-82b1-4c69-97f3-aa5a520f4f74,timestamp:1737570581
2025-01-22T18:29:41,767 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570581
2025-01-22 18:29:41.768 kserve.trace requestId: c718b871-32d9-4c39-9535-62a50c0c6e3d, preprocess_ms: 0.011920929, explain_ms: 0, predict_ms: 6.125450134, postprocess_ms: 0.005245209
2025-01-22 18:29:41.769 uvicorn.access INFO:     10.233.75.99:0 9 - "POST /v1/models/youtubegoes5g%3Apredict HTTP/1.1" 200 OK
2025-01-22 18:29:41.769 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.007054567337036133
2025-01-22 18:29:41.769 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.004554999999527354
2025-01-22T18:29:53,787 [INFO ] epollEventLoopGroup-3-1 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570593
2025-01-22T18:29:53,787 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1737570593787
2025-01-22T18:29:53,788 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Backend received inference at: 1737570593
2025-01-22T18:29:53,788 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Received data: [{'data': [13, 13, 13, 0, 13, 13, 13, 13, -76, -76, -81, -76, -78.5, -76, -76, -7, -7, -12, -7, -9.5, -7, -7, 12, 12, 7, 12, 9.5, 12, 12]}]
2025-01-22T18:29:53,789 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Input data preprocessed successfully
2025-01-22T18:29:53,792 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Inference performed successfully
2025-01-22T18:29:53,793 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Output postprocessed successfully
2025-01-22T18:29:53,793 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:4.65|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,1737570593,c5d9eaf7-289a-4264-973f-01d138240c1a, pattern=[METRICS]
2025-01-22T18:29:53,793 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_METRICS - PredictionTime.ms:4.65|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,requestID:c5d9eaf7-289a-4264-973f-01d138240c1a,timestamp:1737570593
2025-01-22T18:29:53,793 [INFO ] W-9000-youtubegoes5g_1.0 ACCESS_LOG - /127.0.0.1:36350 "POST /v1/models/youtubegoes5g:predict HTTP/1.1" 200 6
2025-01-22T18:29:53,793 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570593
2025-01-22T18:29:53,793 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:5588.801|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570593
2025-01-22T18:29:53,793 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:40.486|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570593
2025-01-22T18:29:53,793 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.job.Job - Waiting time ns: 40486, Backend time ns: 5648627
2025-01-22T18:29:53,793 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570593
2025-01-22T18:29:53,793 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2025-01-22T18:29:53,793 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 5
2025-01-22T18:29:53,793 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570593
2025-01-22 18:29:53.794 kserve.trace requestId: 0892c88c-7b2a-4607-ad15-d64847bf68c5, preprocess_ms: 0.025510788, explain_ms: 0, predict_ms: 9.614467621, postprocess_ms: 0.005483627
2025-01-22 18:29:53.795 uvicorn.access INFO:     10.233.75.99:0 9 - "POST /v1/models/youtubegoes5g%3Apredict HTTP/1.1" 200 OK
2025-01-22 18:29:53.795 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.010657072067260742
2025-01-22 18:29:53.795 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.004815999998754705
2025-01-22T18:30:05,812 [INFO ] epollEventLoopGroup-3-2 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570605
2025-01-22T18:30:05,812 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1737570605812
2025-01-22T18:30:05,814 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Backend received inference at: 1737570605
2025-01-22T18:30:05,814 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Received data: [{'data': [13, 13, 13, 0, 13, 13, 13, 13, -76, -76, -81, -76, -78.5, -76, -76, -7, -7, -12, -7, -9.5, -7, -7, 12, 12, 7, 12, 9.5, 12, 12]}]
2025-01-22T18:30:05,814 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Input data preprocessed successfully
2025-01-22T18:30:05,815 [INFO ] W-9000-youtubegoes5g_1.0 ACCESS_LOG - /127.0.0.1:43914 "POST /v1/models/youtubegoes5g:predict HTTP/1.1" 200 3
2025-01-22T18:30:05,816 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Inference performed successfully
2025-01-22T18:30:05,816 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Output postprocessed successfully
2025-01-22T18:30:05,816 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:1.45|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,1737570605,040b0f29-5ca6-4560-adc7-f27e817d3b72, pattern=[METRICS]
2025-01-22T18:30:05,816 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_METRICS - PredictionTime.ms:1.45|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,requestID:040b0f29-5ca6-4560-adc7-f27e817d3b72,timestamp:1737570605
2025-01-22T18:30:05,815 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570605
2025-01-22T18:30:05,816 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:2537.356|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570605
2025-01-22T18:30:05,816 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:71.875|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570605
2025-01-22T18:30:05,816 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.job.Job - Waiting time ns: 71875, Backend time ns: 3537734
2025-01-22T18:30:05,816 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570605
2025-01-22T18:30:05,816 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2025-01-22T18:30:05,816 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1
2025-01-22T18:30:05,816 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:3.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570605
2025-01-22 18:30:05.817 kserve.trace requestId: df19d26a-9258-4560-8b7b-070c2db11902, preprocess_ms: 0.011920929, explain_ms: 0, predict_ms: 7.187843323, postprocess_ms: 0.004529953
2025-01-22 18:30:05.817 uvicorn.access INFO:     10.233.75.99:0 9 - "POST /v1/models/youtubegoes5g%3Apredict HTTP/1.1" 200 OK
2025-01-22 18:30:05.818 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.008371353149414062
2025-01-22 18:30:05.818 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.004468999999517109
2025-01-22T18:30:17,837 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570617
2025-01-22T18:30:17,837 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1737570617837
2025-01-22T18:30:17,839 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Backend received inference at: 1737570617
2025-01-22 18:30:17.840 kserve.trace requestId: 63ef8a1f-34c8-4f76-b4a8-41bb3c37a77b, preprocess_ms: 0.012159348, explain_ms: 0, predict_ms: 6.026744843, postprocess_ms: 0.046730042
2025-01-22 18:30:17.841 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.007052421569824219
2025-01-22 18:30:17.841 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.004553000000669272
2025-01-22T18:30:17,839 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Received data: [{'data': [13, 13, 13, 0, 13, 13, 13, 13, -76, -76, -81, -76, -78.5, -76, -76, -7, -7, -12, -7, -9.5, -7, -7, 12, 12, 7, 12, 9.5, 12, 12]}]
2025-01-22T18:30:17,839 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Input data preprocessed successfully
2025-01-22T18:30:17,839 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Inference performed successfully
2025-01-22T18:30:17,839 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Output postprocessed successfully
2025-01-22T18:30:17,839 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:1.2|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,1737570617,2b73e9df-8424-41a9-b78c-e77f9ef7bc98, pattern=[METRICS]
2025-01-22T18:30:17,839 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_METRICS - PredictionTime.ms:1.2|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,requestID:2b73e9df-8424-41a9-b78c-e77f9ef7bc98,timestamp:1737570617
2025-01-22T18:30:17,839 [INFO ] W-9000-youtubegoes5g_1.0 ACCESS_LOG - /127.0.0.1:50466 "POST /v1/models/youtubegoes5g:predict HTTP/1.1" 200 2
2025-01-22T18:30:17,839 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570617
2025-01-22T18:30:17,839 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:2158.231|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570617
2025-01-22T18:30:17,839 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:65.057|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570617
2025-01-22T18:30:17,839 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.job.Job - Waiting time ns: 65057, Backend time ns: 2185799
2025-01-22T18:30:17,839 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570617
2025-01-22T18:30:17,839 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2025-01-22T18:30:17,839 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0
2025-01-22T18:30:17,839 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:2.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570617
2025-01-22 18:30:17.841 uvicorn.access INFO:     10.233.75.99:0 9 - "POST /v1/models/youtubegoes5g%3Apredict HTTP/1.1" 200 OK
2025-01-22T18:30:18,995 [INFO ] pool-3-thread-2 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570618
2025-01-22T18:30:18,995 [INFO ] pool-3-thread-2 TS_METRICS - DiskAvailable.Gigabytes:263.7117500305176|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570618
2025-01-22T18:30:18,995 [INFO ] pool-3-thread-2 TS_METRICS - DiskUsage.Gigabytes:208.2915153503418|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570618
2025-01-22T18:30:18,995 [INFO ] pool-3-thread-2 TS_METRICS - DiskUtilization.Percent:44.1|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570618
2025-01-22T18:30:18,995 [INFO ] pool-3-thread-2 TS_METRICS - MemoryAvailable.Megabytes:11275.109375|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570618
2025-01-22T18:30:18,995 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUsed.Megabytes:8364.4921875|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570618
2025-01-22T18:30:18,995 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUtilization.Percent:43.6|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570618
2025-01-22T18:30:29,858 [INFO ] epollEventLoopGroup-3-4 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570629
2025-01-22T18:30:29,858 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1737570629858
2025-01-22T18:30:29,860 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Backend received inference at: 1737570629
2025-01-22T18:30:29,860 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Received data: [{'data': [13, 13, 13, 0, 13, 13, 13, 13, -76, -76, -81, -76, -78.5, -76, -76, -7, -7, -12, -7, -9.5, -7, -7, 12, 12, 7, 12, 9.5, 12, 12]}]
2025-01-22T18:30:29,860 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Input data preprocessed successfully
2025-01-22T18:30:29,860 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Inference performed successfully
2025-01-22T18:30:29,860 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Output postprocessed successfully
2025-01-22T18:30:29,860 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:1.18|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,1737570629,c19d7035-b256-4a71-bb59-b6bfbdc5dcce, pattern=[METRICS]
2025-01-22T18:30:29,860 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_METRICS - PredictionTime.ms:1.18|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,requestID:c19d7035-b256-4a71-bb59-b6bfbdc5dcce,timestamp:1737570629
2025-01-22T18:30:29,860 [INFO ] W-9000-youtubegoes5g_1.0 ACCESS_LOG - /127.0.0.1:47922 "POST /v1/models/youtubegoes5g:predict HTTP/1.1" 200 2
2025-01-22T18:30:29,860 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570629
2025-01-22T18:30:29,860 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:2222.482|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570629
2025-01-22T18:30:29,860 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:30.666|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570629
2025-01-22T18:30:29,860 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.job.Job - Waiting time ns: 30666, Backend time ns: 2284765
2025-01-22T18:30:29,860 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570629
2025-01-22T18:30:29,860 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2025-01-22T18:30:29,860 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0
2025-01-22T18:30:29,860 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:2.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570629
2025-01-22 18:30:29.862 kserve.trace requestId: 07c8e3ad-a30e-4b2a-988c-576c4576bd9c, preprocess_ms: 0.019788742, explain_ms: 0, predict_ms: 6.469011307, postprocess_ms: 0.004529953
2025-01-22 18:30:29.862 uvicorn.access INFO:     10.233.75.99:0 9 - "POST /v1/models/youtubegoes5g%3Apredict HTTP/1.1" 200 OK
2025-01-22 18:30:29.862 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.007559776306152344
2025-01-22 18:30:29.863 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.004453999999896041
2025-01-22T18:30:41,880 [INFO ] epollEventLoopGroup-3-1 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570641
2025-01-22T18:30:41,880 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1737570641880
2025-01-22T18:30:41,882 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Backend received inference at: 1737570641
2025-01-22T18:30:41,882 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Received data: [{'data': [13, 13, 13, 0, 13, 13, 13, 13, -76, -76, -81, -76, -78.5, -76, -76, -7, -7, -12, -7, -9.5, -7, -7, 12, 12, 7, 12, 9.5, 12, 12]}]
2025-01-22T18:30:41,883 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Input data preprocessed successfully
2025-01-22T18:30:41,883 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Inference performed successfully
2025-01-22T18:30:41,884 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Output postprocessed successfully
2025-01-22T18:30:41,884 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:2.16|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,1737570641,184bb455-05fb-4d57-853b-d0023e98f58b, pattern=[METRICS]
2025-01-22T18:30:41,884 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_METRICS - PredictionTime.ms:2.16|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,requestID:184bb455-05fb-4d57-853b-d0023e98f58b,timestamp:1737570641
2025-01-22T18:30:41,884 [INFO ] W-9000-youtubegoes5g_1.0 ACCESS_LOG - /127.0.0.1:40822 "POST /v1/models/youtubegoes5g:predict HTTP/1.1" 200 4
2025-01-22T18:30:41,884 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570641
2025-01-22T18:30:41,884 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:3874.596|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570641
2025-01-22T18:30:41,884 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:117.436|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570641
2025-01-22T18:30:41,884 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.job.Job - Waiting time ns: 117436, Backend time ns: 3856165
2025-01-22T18:30:41,884 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570641
2025-01-22T18:30:41,884 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2025-01-22T18:30:41,884 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3
2025-01-22T18:30:41,884 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570641
2025-01-22 18:30:41.886 uvicorn.access INFO:     10.233.75.99:0 9 - "POST /v1/models/youtubegoes5g%3Apredict HTTP/1.1" 200 OK
2025-01-22 18:30:41.886 kserve.trace requestId: 5e779b01-2558-4379-818b-b6f31dfaee20, preprocess_ms: 0.053405762, explain_ms: 0, predict_ms: 8.023023605, postprocess_ms: 0.005960464
2025-01-22 18:30:41.886 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.009020805358886719
2025-01-22 18:30:41.886 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.00430900000174006
2025-01-22T18:31:17,903 [INFO ] epollEventLoopGroup-3-2 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570677
2025-01-22T18:31:17,903 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1737570677903
2025-01-22T18:31:17,905 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Backend received inference at: 1737570677
2025-01-22T18:31:17,905 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Received data: [{'data': [13, 13, 13, 0, 13, 13, 13, 13, -76, -76, -81, -76, -78.5, -76, -76, -7, -7, -12, -7, -9.5, -7, -7, 12, 12, 7, 12, 9.5, 12, 12]}]
2025-01-22T18:31:17,905 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Input data preprocessed successfully
2025-01-22T18:31:17,907 [INFO ] W-9000-youtubegoes5g_1.0 ACCESS_LOG - /127.0.0.1:47810 "POST /v1/models/youtubegoes5g:predict HTTP/1.1" 200 4
2025-01-22T18:31:17,907 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570677
2025-01-22T18:31:17,907 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:3314.259|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570677
2025-01-22T18:31:17,907 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:32.94|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570677
2025-01-22T18:31:17,907 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.job.Job - Waiting time ns: 32940, Backend time ns: 3407138
2025-01-22T18:31:17,907 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570677
2025-01-22T18:31:17,907 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2025-01-22T18:31:17,907 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3
2025-01-22T18:31:17,907 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570677
2025-01-22T18:31:17,907 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Inference performed successfully
2025-01-22T18:31:17,907 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Output postprocessed successfully
2025-01-22T18:31:17,907 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:1.48|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,1737570677,253193ed-ec1d-41d8-ba54-ae0bbe895d4d, pattern=[METRICS]
2025-01-22T18:31:17,907 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_METRICS - PredictionTime.ms:1.48|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,requestID:253193ed-ec1d-41d8-ba54-ae0bbe895d4d,timestamp:1737570677
2025-01-22 18:31:17.909 kserve.trace requestId: a32e3b3e-8617-4faa-b114-9004546490a6, preprocess_ms: 0.012397766, explain_ms: 0, predict_ms: 7.846355438, postprocess_ms: 0.007867813
2025-01-22 18:31:17.909 uvicorn.access INFO:     10.233.75.99:0 9 - "POST /v1/models/youtubegoes5g%3Apredict HTTP/1.1" 200 OK
2025-01-22 18:31:17.909 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.009045600891113281
2025-01-22 18:31:17.909 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.004924000000755768
2025-01-22T18:31:18,993 [INFO ] pool-3-thread-2 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570678
2025-01-22T18:31:18,993 [INFO ] pool-3-thread-2 TS_METRICS - DiskAvailable.Gigabytes:263.7114906311035|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570678
2025-01-22T18:31:18,993 [INFO ] pool-3-thread-2 TS_METRICS - DiskUsage.Gigabytes:208.29177474975586|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570678
2025-01-22T18:31:18,993 [INFO ] pool-3-thread-2 TS_METRICS - DiskUtilization.Percent:44.1|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570678
2025-01-22T18:31:18,994 [INFO ] pool-3-thread-2 TS_METRICS - MemoryAvailable.Megabytes:11275.9765625|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570678
2025-01-22T18:31:18,994 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUsed.Megabytes:8363.625|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570678
2025-01-22T18:31:18,994 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUtilization.Percent:43.6|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570678
2025-01-22T18:31:29,928 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570689
2025-01-22T18:31:29,928 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1737570689928
2025-01-22T18:31:29,929 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Backend received inference at: 1737570689
2025-01-22T18:31:29,929 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Received data: [{'data': [13, 13, 13, 0, 13, 13, 13, 13, -76, -76, -81, -76, -78.5, -76, -76, -7, -7, -12, -7, -9.5, -7, -7, 12, 12, 7, 12, 9.5, 12, 12]}]
2025-01-22T18:31:29,929 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Input data preprocessed successfully
2025-01-22T18:31:29,932 [INFO ] W-9000-youtubegoes5g_1.0 ACCESS_LOG - /127.0.0.1:39484 "POST /v1/models/youtubegoes5g:predict HTTP/1.1" 200 4
2025-01-22T18:31:29,932 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570689
2025-01-22T18:31:29,932 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:3629.399|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570689
2025-01-22T18:31:29,932 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:49.799|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570689
2025-01-22T18:31:29,932 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.job.Job - Waiting time ns: 49799, Backend time ns: 3750809
2025-01-22T18:31:29,932 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570689
2025-01-22T18:31:29,932 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2025-01-22T18:31:29,932 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 4
2025-01-22T18:31:29,932 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570689
2025-01-22T18:31:29,932 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Inference performed successfully
2025-01-22T18:31:29,932 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Output postprocessed successfully
2025-01-22T18:31:29,932 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:1.24|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,1737570689,edb65134-b14b-446a-a75c-b86606886f01, pattern=[METRICS]
2025-01-22T18:31:29,932 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_METRICS - PredictionTime.ms:1.24|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,requestID:edb65134-b14b-446a-a75c-b86606886f01,timestamp:1737570689
2025-01-22 18:31:29.933 kserve.trace requestId: 72d4bd6f-e4fc-48a7-83b9-dcb87741bb0c, preprocess_ms: 0.012159348, explain_ms: 0, predict_ms: 7.607460022, postprocess_ms: 0.004291534
2025-01-22 18:31:29.933 uvicorn.access INFO:     10.233.75.99:0 9 - "POST /v1/models/youtubegoes5g%3Apredict HTTP/1.1" 200 OK
2025-01-22 18:31:29.934 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.008514642715454102
2025-01-22 18:31:29.934 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.004355999999461346
2025-01-22T18:31:41,952 [INFO ] epollEventLoopGroup-3-4 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570701
2025-01-22T18:31:41,952 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1737570701952
2025-01-22T18:31:41,953 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Backend received inference at: 1737570701
2025-01-22T18:31:41,953 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Received data: [{'data': [13, 13, 13, 0, 13, 13, 13, 13, -76, -76, -81, -76, -78.5, -76, -76, -7, -7, -12, -7, -9.5, -7, -7, 12, 12, 7, 12, 9.5, 12, 12]}]
2025-01-22T18:31:41,954 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Input data preprocessed successfully
2025-01-22T18:31:41,957 [INFO ] W-9000-youtubegoes5g_1.0 ACCESS_LOG - /127.0.0.1:33220 "POST /v1/models/youtubegoes5g:predict HTTP/1.1" 200 5
2025-01-22T18:31:41,957 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570701
2025-01-22T18:31:41,957 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:5093.937|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570701
2025-01-22T18:31:41,957 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:80.062|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570701
2025-01-22T18:31:41,957 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.job.Job - Waiting time ns: 80062, Backend time ns: 5147875
2025-01-22T18:31:41,957 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570701
2025-01-22T18:31:41,957 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2025-01-22T18:31:41,957 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Inference performed successfully
2025-01-22T18:31:41,957 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 4
2025-01-22T18:31:41,958 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:2.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570701
2025-01-22T18:31:41,957 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Output postprocessed successfully
2025-01-22T18:31:41,958 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:3.96|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,1737570701,86d7776e-d31a-4b18-9e9c-3aff32af05a3, pattern=[METRICS]
2025-01-22T18:31:41,958 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_METRICS - PredictionTime.ms:3.96|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,requestID:86d7776e-d31a-4b18-9e9c-3aff32af05a3,timestamp:1737570701
2025-01-22 18:31:41.959 kserve.trace requestId: 05d50690-8f0c-4d35-a135-bcee2cb689a1, preprocess_ms: 0.01502037, explain_ms: 0, predict_ms: 9.763479233, postprocess_ms: 0.00500679
2025-01-22 18:31:41.959 uvicorn.access INFO:     10.233.75.99:0 9 - "POST /v1/models/youtubegoes5g%3Apredict HTTP/1.1" 200 OK
2025-01-22 18:31:41.960 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.011070489883422852
2025-01-22 18:31:41.960 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.005408000000898028
2025-01-22T18:31:53,977 [INFO ] epollEventLoopGroup-3-1 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570713
2025-01-22T18:31:53,977 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1737570713977
2025-01-22T18:31:53,978 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Backend received inference at: 1737570713
2025-01-22T18:31:53,978 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Received data: [{'data': [13, 13, 13, 0, 13, 13, 13, 13, -76, -76, -81, -76, -78.5, -76, -76, -7, -7, -12, -7, -9.5, -7, -7, 12, 12, 7, 12, 9.5, 12, 12]}]
2025-01-22T18:31:53,978 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Input data preprocessed successfully
2025-01-22T18:31:53,979 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Inference performed successfully
2025-01-22T18:31:53,979 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Output postprocessed successfully
2025-01-22T18:31:53,979 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:1.28|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,1737570713,a67e8d1d-fb20-488c-9ca5-afa1c239ff49, pattern=[METRICS]
2025-01-22T18:31:53,979 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_METRICS - PredictionTime.ms:1.28|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,requestID:a67e8d1d-fb20-488c-9ca5-afa1c239ff49,timestamp:1737570713
2025-01-22T18:31:53,980 [INFO ] W-9000-youtubegoes5g_1.0 ACCESS_LOG - /127.0.0.1:43082 "POST /v1/models/youtubegoes5g:predict HTTP/1.1" 200 3
2025-01-22T18:31:53,980 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570713
2025-01-22T18:31:53,980 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:3101.698|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570713
2025-01-22T18:31:53,980 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:41.191|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570713
2025-01-22T18:31:53,980 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.job.Job - Waiting time ns: 41191, Backend time ns: 3188945
2025-01-22T18:31:53,980 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570713
2025-01-22T18:31:53,980 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2025-01-22T18:31:53,980 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3
2025-01-22T18:31:53,980 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570713
2025-01-22 18:31:53.981 kserve.trace requestId: eda1a149-8a40-4d3d-97ad-f3c90a85da63, preprocess_ms: 0.011920929, explain_ms: 0, predict_ms: 6.844997406, postprocess_ms: 0.005245209
2025-01-22 18:31:53.981 uvicorn.access INFO:     10.233.75.99:0 9 - "POST /v1/models/youtubegoes5g%3Apredict HTTP/1.1" 200 OK
2025-01-22 18:31:53.982 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.00805807113647461
2025-01-22 18:31:53.982 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.00467199999911827
2025-01-22T18:32:06,001 [INFO ] epollEventLoopGroup-3-2 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570726
2025-01-22T18:32:06,001 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1737570726001
2025-01-22T18:32:06,002 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Backend received inference at: 1737570726
2025-01-22T18:32:06,002 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Received data: [{'data': [13, 13, 13, 0, 13, 13, 13, 13, -76, -76, -81, -76, -78.5, -76, -76, -7, -7, -12, -7, -9.5, -7, -7, 12, 12, 7, 12, 9.5, 12, 12]}]
2025-01-22T18:32:06,002 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Input data preprocessed successfully
2025-01-22T18:32:06,005 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Inference performed successfully
2025-01-22T18:32:06,005 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Output postprocessed successfully
2025-01-22T18:32:06,005 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:1.42|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,1737570726,3c012d8d-fb67-44ed-9f97-8daa1fa4e50b, pattern=[METRICS]
2025-01-22T18:32:06,005 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_METRICS - PredictionTime.ms:1.42|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,requestID:3c012d8d-fb67-44ed-9f97-8daa1fa4e50b,timestamp:1737570726
2025-01-22T18:32:06,005 [INFO ] W-9000-youtubegoes5g_1.0 ACCESS_LOG - /127.0.0.1:58126 "POST /v1/models/youtubegoes5g:predict HTTP/1.1" 200 4
2025-01-22T18:32:06,005 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570726
2025-01-22T18:32:06,005 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:3911.026|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570726
2025-01-22T18:32:06,005 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:48.514|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570726
2025-01-22T18:32:06,005 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.job.Job - Waiting time ns: 48514, Backend time ns: 4412749
2025-01-22T18:32:06,005 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570726
2025-01-22T18:32:06,005 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2025-01-22T18:32:06,005 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 4
2025-01-22T18:32:06,005 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570726
2025-01-22 18:32:06.007 kserve.trace requestId: d7f0f2a3-4d11-4b75-a9ce-ff1e54dbcc13, preprocess_ms: 0.011920929, explain_ms: 0, predict_ms: 9.349107742, postprocess_ms: 0.007629395
2025-01-22 18:32:06.008 uvicorn.access INFO:     10.233.75.99:0 9 - "POST /v1/models/youtubegoes5g%3Apredict HTTP/1.1" 200 OK
2025-01-22 18:32:06.008 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.010790109634399414
2025-01-22 18:32:06.008 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.005235000000539003
2025-01-22T18:32:18,029 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570738
2025-01-22T18:32:18,030 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1737570738030
2025-01-22T18:32:18,030 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Backend received inference at: 1737570738
2025-01-22T18:32:18,030 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Received data: [{'data': [13, 13, 13, 0, 13, 13, 13, 13, -76, -76, -81, -76, -78.5, -76, -76, -7, -7, -12, -7, -9.5, -7, -7, 12, 12, 7, 12, 9.5, 12, 12]}]
2025-01-22T18:32:18,031 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Input data preprocessed successfully
2025-01-22T18:32:18,031 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Inference performed successfully
2025-01-22T18:32:18,031 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Output postprocessed successfully
2025-01-22T18:32:18,032 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:1.28|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,1737570738,2620d7af-119c-4603-9830-3119420895f2, pattern=[METRICS]
2025-01-22T18:32:18,032 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_METRICS - PredictionTime.ms:1.28|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,requestID:2620d7af-119c-4603-9830-3119420895f2,timestamp:1737570738
2025-01-22T18:32:18,033 [INFO ] W-9000-youtubegoes5g_1.0 ACCESS_LOG - /127.0.0.1:33360 "POST /v1/models/youtubegoes5g:predict HTTP/1.1" 200 4
2025-01-22T18:32:18,033 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570738
2025-01-22T18:32:18,033 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:3757.633|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570738
2025-01-22T18:32:18,033 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:43.242|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570738
2025-01-22 18:32:18.035 kserve.trace requestId: 21e7eec6-dbff-4281-804d-95127faee396, preprocess_ms: 0.011920929, explain_ms: 0, predict_ms: 7.710456848, postprocess_ms: 0.00500679
2025-01-22 18:32:18.035 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.008601665496826172
2025-01-22 18:32:18.035 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.004537000000709668
2025-01-22T18:32:18,033 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.job.Job - Waiting time ns: 43242, Backend time ns: 3867646
2025-01-22T18:32:18,033 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570738
2025-01-22T18:32:18,034 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2025-01-22T18:32:18,034 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3
2025-01-22T18:32:18,034 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570738
2025-01-22 18:32:18.035 uvicorn.access INFO:     10.233.75.99:0 9 - "POST /v1/models/youtubegoes5g%3Apredict HTTP/1.1" 200 OK
2025-01-22T18:32:18,988 [INFO ] pool-3-thread-2 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570738
2025-01-22T18:32:18,988 [INFO ] pool-3-thread-2 TS_METRICS - DiskAvailable.Gigabytes:263.71121978759766|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570738
2025-01-22T18:32:18,988 [INFO ] pool-3-thread-2 TS_METRICS - DiskUsage.Gigabytes:208.29204559326172|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570738
2025-01-22T18:32:18,988 [INFO ] pool-3-thread-2 TS_METRICS - DiskUtilization.Percent:44.1|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570738
2025-01-22T18:32:18,988 [INFO ] pool-3-thread-2 TS_METRICS - MemoryAvailable.Megabytes:11269.76953125|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570738
2025-01-22T18:32:18,988 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUsed.Megabytes:8369.83203125|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570738
2025-01-22T18:32:18,988 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUtilization.Percent:43.6|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570738
2025-01-22T18:32:30,058 [INFO ] epollEventLoopGroup-3-4 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570750
2025-01-22T18:32:30,059 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1737570750058
2025-01-22T18:32:30,059 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Backend received inference at: 1737570750
2025-01-22T18:32:30,059 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Received data: [{'data': [13, 13, 13, 0, 13, 13, 13, 13, -76, -76, -81, -76, -78.5, -76, -76, -7, -7, -12, -7, -9.5, -7, -7, 12, 12, 7, 12, 9.5, 12, 12]}]
2025-01-22T18:32:30,060 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Input data preprocessed successfully
2025-01-22T18:32:30,061 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Inference performed successfully
2025-01-22T18:32:30,061 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Output postprocessed successfully
2025-01-22T18:32:30,061 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:1.68|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,1737570750,d5cd181e-2cd3-44bb-8119-4729015f25ce, pattern=[METRICS]
2025-01-22T18:32:30,061 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_METRICS - PredictionTime.ms:1.68|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,requestID:d5cd181e-2cd3-44bb-8119-4729015f25ce,timestamp:1737570750
2025-01-22T18:32:30,061 [INFO ] W-9000-youtubegoes5g_1.0 ACCESS_LOG - /127.0.0.1:53030 "POST /v1/models/youtubegoes5g:predict HTTP/1.1" 200 3
2025-01-22T18:32:30,062 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570750
2025-01-22T18:32:30,062 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:3050.811|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570750
2025-01-22T18:32:30,062 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:98.112|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570750
2025-01-22T18:32:30,062 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.job.Job - Waiting time ns: 98112, Backend time ns: 3148711
2025-01-22T18:32:30,062 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570750
2025-01-22T18:32:30,062 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2025-01-22T18:32:30,062 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2
2025-01-22T18:32:30,062 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:2.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570750
2025-01-22 18:32:30.064 kserve.trace requestId: 219c29b7-4ffe-47bf-8216-c9c93bff3ab7, preprocess_ms: 0.012636185, explain_ms: 0, predict_ms: 7.630348206, postprocess_ms: 0.008583069
2025-01-22 18:32:30.064 uvicorn.access INFO:     10.233.75.99:0 9 - "POST /v1/models/youtubegoes5g%3Apredict HTTP/1.1" 200 OK
2025-01-22 18:32:30.065 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.009055376052856445
2025-01-22 18:32:30.065 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.0052390000000741566
2025-01-22T18:32:42,083 [INFO ] epollEventLoopGroup-3-1 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570762
2025-01-22T18:32:42,083 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1737570762083
2025-01-22T18:32:42,084 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Backend received inference at: 1737570762
2025-01-22T18:32:42,084 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Received data: [{'data': [13, 13, 13, 0, 13, 13, 13, 13, -76, -76, -81, -76, -78.5, -76, -76, -7, -7, -12, -7, -9.5, -7, -7, 12, 12, 7, 12, 9.5, 12, 12]}]
2025-01-22T18:32:42,084 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Input data preprocessed successfully
2025-01-22T18:32:42,087 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Inference performed successfully
2025-01-22T18:32:42,087 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Output postprocessed successfully
2025-01-22T18:32:42,087 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:2.75|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,1737570762,183343b3-cd6f-4ba1-a566-602d8e45ccfe, pattern=[METRICS]
2025-01-22T18:32:42,087 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_METRICS - PredictionTime.ms:2.75|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,requestID:183343b3-cd6f-4ba1-a566-602d8e45ccfe,timestamp:1737570762
2025-01-22T18:32:42,087 [INFO ] W-9000-youtubegoes5g_1.0 ACCESS_LOG - /127.0.0.1:59260 "POST /v1/models/youtubegoes5g:predict HTTP/1.1" 200 4
2025-01-22T18:32:42,087 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570762
2025-01-22T18:32:42,087 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:3950.954|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570762
2025-01-22T18:32:42,087 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:90.879|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570762
2025-01-22T18:32:42,087 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.job.Job - Waiting time ns: 90879, Backend time ns: 4025242
2025-01-22T18:32:42,087 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570762
2025-01-22T18:32:42,087 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2025-01-22T18:32:42,087 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3
2025-01-22T18:32:42,087 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570762
2025-01-22 18:32:42.089 kserve.trace requestId: e5e343c2-d115-473e-8008-a809632f5427, preprocess_ms: 0.012159348, explain_ms: 0, predict_ms: 8.895158768, postprocess_ms: 0.00834465
2025-01-22 18:32:42.090 uvicorn.access INFO:     10.233.75.99:0 9 - "POST /v1/models/youtubegoes5g%3Apredict HTTP/1.1" 200 OK
2025-01-22 18:32:42.090 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.010415077209472656
2025-01-22 18:32:42.090 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.005384000000049127
2025-01-22T18:32:54,112 [INFO ] epollEventLoopGroup-3-2 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570774
2025-01-22T18:32:54,112 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1737570774112
2025-01-22T18:32:54,113 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Backend received inference at: 1737570774
2025-01-22T18:32:54,113 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Received data: [{'data': [13, 13, 13, 0, 13, 13, 13, 13, -76, -76, -81, -76, -78.5, -76, -76, -7, -7, -12, -7, -9.5, -7, -7, 12, 12, 7, 12, 9.5, 12, 12]}]
2025-01-22T18:32:54,114 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Input data preprocessed successfully
2025-01-22T18:32:54,117 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Inference performed successfully
2025-01-22T18:32:54,117 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Output postprocessed successfully
2025-01-22T18:32:54,117 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:3.86|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,1737570774,4a8de274-0ab6-4245-b643-b7a5f926c197, pattern=[METRICS]
2025-01-22T18:32:54,117 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_METRICS - PredictionTime.ms:3.86|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,requestID:4a8de274-0ab6-4245-b643-b7a5f926c197,timestamp:1737570774
2025-01-22T18:32:54,118 [INFO ] W-9000-youtubegoes5g_1.0 ACCESS_LOG - /127.0.0.1:41944 "POST /v1/models/youtubegoes5g:predict HTTP/1.1" 200 6
2025-01-22T18:32:54,118 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570774
2025-01-22T18:32:54,118 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:5272.595|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570774
2025-01-22T18:32:54,118 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:42.585|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570774
2025-01-22T18:32:54,118 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.job.Job - Waiting time ns: 42585, Backend time ns: 5529080
2025-01-22T18:32:54,118 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570774
2025-01-22T18:32:54,118 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2025-01-22T18:32:54,118 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 5
2025-01-22T18:32:54,118 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570774
2025-01-22 18:32:54.119 kserve.trace requestId: c23cc86d-97b4-4708-b270-ccb3cb589236, preprocess_ms: 0.012397766, explain_ms: 0, predict_ms: 9.157419205, postprocess_ms: 0.00500679
2025-01-22 18:32:54.119 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.010172367095947266
2025-01-22 18:32:54.120 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.004584000000249944
2025-01-22 18:32:54.119 uvicorn.access INFO:     10.233.75.99:0 9 - "POST /v1/models/youtubegoes5g%3Apredict HTTP/1.1" 200 OK
2025-01-22T18:33:06,137 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570786
2025-01-22T18:33:06,137 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1737570786137
2025-01-22T18:33:06,138 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Backend received inference at: 1737570786
2025-01-22T18:33:06,138 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Received data: [{'data': [13, 13, 13, 0, 13, 13, 13, 13, -76, -76, -81, -76, -78.5, -76, -76, -7, -7, -12, -7, -9.5, -7, -7, 12, 12, 7, 12, 9.5, 12, 12]}]
2025-01-22T18:33:06,139 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Input data preprocessed successfully
2025-01-22T18:33:06,141 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Inference performed successfully
2025-01-22T18:33:06,141 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Output postprocessed successfully
2025-01-22T18:33:06,141 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:3.31|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,1737570786,3092c29a-9777-4b79-ada4-5bf46f749506, pattern=[METRICS]
2025-01-22T18:33:06,141 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_METRICS - PredictionTime.ms:3.31|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,requestID:3092c29a-9777-4b79-ada4-5bf46f749506,timestamp:1737570786
2025-01-22T18:33:06,142 [INFO ] W-9000-youtubegoes5g_1.0 ACCESS_LOG - /127.0.0.1:35292 "POST /v1/models/youtubegoes5g:predict HTTP/1.1" 200 5
2025-01-22T18:33:06,142 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570786
2025-01-22T18:33:06,142 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:4860.918|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570786
2025-01-22T18:33:06,142 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:67.896|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570786
2025-01-22T18:33:06,142 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.job.Job - Waiting time ns: 67896, Backend time ns: 5108699
2025-01-22T18:33:06,142 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570786
2025-01-22T18:33:06,142 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2025-01-22T18:33:06,142 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 5
2025-01-22T18:33:06,142 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570786
2025-01-22 18:33:06.143 kserve.trace requestId: 22f263db-8ba0-44b9-91f8-e1ea2c977928, preprocess_ms: 0.011920929, explain_ms: 0, predict_ms: 9.126663208, postprocess_ms: 0.005245209
2025-01-22 18:33:06.143 uvicorn.access INFO:     10.233.75.99:0 9 - "POST /v1/models/youtubegoes5g%3Apredict HTTP/1.1" 200 OK
2025-01-22 18:33:06.144 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.009981393814086914
2025-01-22 18:33:06.144 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.00456800000029034
2025-01-22T18:33:18,989 [INFO ] pool-3-thread-2 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570798
2025-01-22T18:33:18,989 [INFO ] pool-3-thread-2 TS_METRICS - DiskAvailable.Gigabytes:263.7109260559082|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570798
2025-01-22T18:33:18,989 [INFO ] pool-3-thread-2 TS_METRICS - DiskUsage.Gigabytes:208.29233932495117|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570798
2025-01-22T18:33:18,989 [INFO ] pool-3-thread-2 TS_METRICS - DiskUtilization.Percent:44.1|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570798
2025-01-22T18:33:18,989 [INFO ] pool-3-thread-2 TS_METRICS - MemoryAvailable.Megabytes:11271.296875|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570798
2025-01-22T18:33:18,989 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUsed.Megabytes:8368.3046875|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570798
2025-01-22T18:33:18,989 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUtilization.Percent:43.6|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570798
2025-01-22T18:33:42,162 [INFO ] epollEventLoopGroup-3-4 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570822
2025-01-22T18:33:42,162 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1737570822162
2025-01-22T18:33:42,163 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Backend received inference at: 1737570822
2025-01-22T18:33:42,163 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Received data: [{'data': [13, 13, 13, 0, 13, 13, 13, 13, -76, -76, -81, -76, -78.5, -76, -76, -7, -7, -12, -7, -9.5, -7, -7, 12, 12, 7, 12, 9.5, 12, 12]}]
2025-01-22T18:33:42,164 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Input data preprocessed successfully
2025-01-22T18:33:42,164 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Inference performed successfully
2025-01-22T18:33:42,165 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Output postprocessed successfully
2025-01-22T18:33:42,165 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:1.68|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,1737570822,1275baa6-d046-4e97-b77a-ff9246203bb5, pattern=[METRICS]
2025-01-22T18:33:42,165 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_METRICS - PredictionTime.ms:1.68|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,requestID:1275baa6-d046-4e97-b77a-ff9246203bb5,timestamp:1737570822
2025-01-22T18:33:42,165 [INFO ] W-9000-youtubegoes5g_1.0 ACCESS_LOG - /127.0.0.1:46302 "POST /v1/models/youtubegoes5g:predict HTTP/1.1" 200 3
2025-01-22T18:33:42,166 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570822
2025-01-22T18:33:42,166 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:3412.767|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570822
2025-01-22T18:33:42,166 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:91.834|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570822
2025-01-22T18:33:42,166 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.job.Job - Waiting time ns: 91834, Backend time ns: 3775090
2025-01-22T18:33:42,166 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570822
2025-01-22T18:33:42,166 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2025-01-22T18:33:42,166 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3
2025-01-22T18:33:42,166 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570822
2025-01-22 18:33:42.167 kserve.trace requestId: a9a093a5-e0d6-42bc-8f3f-b99425578e60, preprocess_ms: 0.014305115, explain_ms: 0, predict_ms: 8.041620255, postprocess_ms: 0.007390976
2025-01-22 18:33:42.168 uvicorn.access INFO:     10.233.75.99:0 9 - "POST /v1/models/youtubegoes5g%3Apredict HTTP/1.1" 200 OK
2025-01-22 18:33:42.168 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.00901341438293457
2025-01-22 18:33:42.168 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.005109000001539243
2025-01-22T18:33:54,186 [INFO ] epollEventLoopGroup-3-1 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570834
2025-01-22T18:33:54,186 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1737570834186
2025-01-22T18:33:54,187 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Backend received inference at: 1737570834
2025-01-22T18:33:54,187 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Received data: [{'data': [13, 13, 13, 0, 13, 13, 13, 13, -76, -76, -81, -76, -78.5, -76, -76, -7, -7, -12, -7, -9.5, -7, -7, 12, 12, 7, 12, 9.5, 12, 12]}]
2025-01-22T18:33:54,188 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Input data preprocessed successfully
2025-01-22T18:33:54,192 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Inference performed successfully
2025-01-22T18:33:54,192 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Output postprocessed successfully
2025-01-22T18:33:54,192 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:4.61|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,1737570834,dd91a39e-ef4d-4b1a-a368-791a7f8e99f8, pattern=[METRICS]
2025-01-22T18:33:54,192 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_METRICS - PredictionTime.ms:4.61|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,requestID:dd91a39e-ef4d-4b1a-a368-791a7f8e99f8,timestamp:1737570834
2025-01-22T18:33:54,192 [INFO ] W-9000-youtubegoes5g_1.0 ACCESS_LOG - /127.0.0.1:40446 "POST /v1/models/youtubegoes5g:predict HTTP/1.1" 200 6
2025-01-22T18:33:54,192 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570834
2025-01-22T18:33:54,192 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:5598.921|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570834
2025-01-22T18:33:54,192 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:53.102|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570834
2025-01-22T18:33:54,192 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.job.Job - Waiting time ns: 53102, Backend time ns: 5749784
2025-01-22T18:33:54,192 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570834
2025-01-22T18:33:54,192 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2025-01-22T18:33:54,192 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 5
2025-01-22T18:33:54,192 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570834
2025-01-22 18:33:54.193 kserve.trace requestId: ef301887-70d0-4214-898f-d5d1e4c85c87, preprocess_ms: 0.012397766, explain_ms: 0, predict_ms: 9.485721588, postprocess_ms: 0.004529953
2025-01-22 18:33:54.194 uvicorn.access INFO:     10.233.75.99:0 9 - "POST /v1/models/youtubegoes5g%3Apredict HTTP/1.1" 200 OK
2025-01-22 18:33:54.194 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.010510921478271484
2025-01-22 18:33:54.194 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.004473000000871252
2025-01-22T18:34:06,212 [INFO ] epollEventLoopGroup-3-2 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570846
2025-01-22T18:34:06,212 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1737570846212
2025-01-22T18:34:06,213 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Backend received inference at: 1737570846
2025-01-22T18:34:06,213 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Received data: [{'data': [13, 13, 13, 0, 13, 13, 13, 13, -76, -76, -81, -76, -78.5, -76, -76, -7, -7, -12, -7, -9.5, -7, -7, 12, 12, 7, 12, 9.5, 12, 12]}]
2025-01-22T18:34:06,214 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Input data preprocessed successfully
2025-01-22T18:34:06,219 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Inference performed successfully
2025-01-22T18:34:06,219 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Output postprocessed successfully
2025-01-22T18:34:06,219 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:5.67|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,1737570846,0dd68ccd-0117-4354-8531-96ec2339ff77, pattern=[METRICS]
2025-01-22T18:34:06,219 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_METRICS - PredictionTime.ms:5.67|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,requestID:0dd68ccd-0117-4354-8531-96ec2339ff77,timestamp:1737570846
2025-01-22T18:34:06,219 [INFO ] W-9000-youtubegoes5g_1.0 ACCESS_LOG - /127.0.0.1:33946 "POST /v1/models/youtubegoes5g:predict HTTP/1.1" 200 7
2025-01-22T18:34:06,219 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570846
2025-01-22T18:34:06,219 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:6831.38|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570846
2025-01-22T18:34:06,219 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:65.301|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570846
2025-01-22T18:34:06,219 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.job.Job - Waiting time ns: 65301, Backend time ns: 6974853
2025-01-22T18:34:06,219 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570846
2025-01-22T18:34:06,220 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2025-01-22T18:34:06,220 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 6
2025-01-22T18:34:06,220 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:2.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570846
2025-01-22 18:34:06.220 kserve.trace requestId: ff6f88cd-3734-4072-bda9-64ed1c4a7dd4, preprocess_ms: 0.012874603, explain_ms: 0, predict_ms: 10.422945023, postprocess_ms: 0.004529953
2025-01-22 18:34:06.221 uvicorn.access INFO:     10.233.75.99:0 9 - "POST /v1/models/youtubegoes5g%3Apredict HTTP/1.1" 200 OK
2025-01-22 18:34:06.221 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.011733055114746094
2025-01-22 18:34:06.221 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.0042709999997896375
2025-01-22T18:34:18,239 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570858
2025-01-22T18:34:18,239 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1737570858239
2025-01-22T18:34:18,240 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Backend received inference at: 1737570858
2025-01-22T18:34:18,240 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Received data: [{'data': [13, 13, 13, 0, 13, 13, 13, 13, -76, -76, -81, -76, -78.5, -76, -76, -7, -7, -12, -7, -9.5, -7, -7, 12, 12, 7, 12, 9.5, 12, 12]}]
2025-01-22T18:34:18,241 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Input data preprocessed successfully
2025-01-22T18:34:18,243 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Inference performed successfully
2025-01-22T18:34:18,244 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Output postprocessed successfully
2025-01-22T18:34:18,244 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:4.53|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,1737570858,4e397fac-b1fe-4876-a4fc-f192b06c8975, pattern=[METRICS]
2025-01-22T18:34:18,244 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_METRICS - PredictionTime.ms:4.53|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,requestID:4e397fac-b1fe-4876-a4fc-f192b06c8975,timestamp:1737570858
2025-01-22T18:34:18,245 [INFO ] W-9000-youtubegoes5g_1.0 ACCESS_LOG - /127.0.0.1:57540 "POST /v1/models/youtubegoes5g:predict HTTP/1.1" 200 6
2025-01-22T18:34:18,245 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570858
2025-01-22T18:34:18,245 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:5413.884|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570858
2025-01-22T18:34:18,245 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:51.306|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570858
2025-01-22T18:34:18,245 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.job.Job - Waiting time ns: 51306, Backend time ns: 5660969
2025-01-22T18:34:18,245 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570858
2025-01-22T18:34:18,245 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2025-01-22T18:34:18,245 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 6
2025-01-22T18:34:18,245 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570858
2025-01-22 18:34:18.246 kserve.trace requestId: 6553b0b9-2f62-4f44-9ec7-a631664ab76a, preprocess_ms: 0.011920929, explain_ms: 0, predict_ms: 10.472536087, postprocess_ms: 0.006914139
2025-01-22 18:34:18.247 uvicorn.access INFO:     10.233.75.99:0 9 - "POST /v1/models/youtubegoes5g%3Apredict HTTP/1.1" 200 OK
2025-01-22 18:34:18.247 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.011536121368408203
2025-01-22 18:34:18.247 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.005726000001232023
2025-01-22T18:34:18,991 [INFO ] pool-3-thread-2 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570858
2025-01-22T18:34:18,991 [INFO ] pool-3-thread-2 TS_METRICS - DiskAvailable.Gigabytes:263.7106513977051|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570858
2025-01-22T18:34:18,991 [INFO ] pool-3-thread-2 TS_METRICS - DiskUsage.Gigabytes:208.2926139831543|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570858
2025-01-22T18:34:18,992 [INFO ] pool-3-thread-2 TS_METRICS - DiskUtilization.Percent:44.1|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570858
2025-01-22T18:34:18,992 [INFO ] pool-3-thread-2 TS_METRICS - MemoryAvailable.Megabytes:11285.66015625|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570858
2025-01-22T18:34:18,992 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUsed.Megabytes:8353.94140625|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570858
2025-01-22T18:34:18,992 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUtilization.Percent:43.5|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570858
2025-01-22T18:34:30,267 [INFO ] epollEventLoopGroup-3-4 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570870
2025-01-22T18:34:30,268 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1737570870268
2025-01-22T18:34:30,268 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Backend received inference at: 1737570870
2025-01-22T18:34:30,268 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Received data: [{'data': [13, 13, 13, 0, 13, 13, 13, 13, -76, -76, -81, -76, -78.5, -76, -76, -7, -7, -12, -7, -9.5, -7, -7, 12, 12, 7, 12, 9.5, 12, 12]}]
2025-01-22T18:34:30,269 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Input data preprocessed successfully
2025-01-22T18:34:30,271 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Inference performed successfully
2025-01-22T18:34:30,271 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Output postprocessed successfully
2025-01-22T18:34:30,271 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:3.08|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,1737570870,ffdb44e0-4b89-4eff-824d-5073b71ecbb9, pattern=[METRICS]
2025-01-22T18:34:30,271 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_METRICS - PredictionTime.ms:3.08|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,requestID:ffdb44e0-4b89-4eff-824d-5073b71ecbb9,timestamp:1737570870
2025-01-22T18:34:30,272 [INFO ] W-9000-youtubegoes5g_1.0 ACCESS_LOG - /127.0.0.1:38892 "POST /v1/models/youtubegoes5g:predict HTTP/1.1" 200 5
2025-01-22T18:34:30,272 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570870
2025-01-22T18:34:30,272 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:4179.754|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570870
2025-01-22T18:34:30,272 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:45.946|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570870
2025-01-22T18:34:30,272 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.job.Job - Waiting time ns: 45946, Backend time ns: 4298671
2025-01-22T18:34:30,272 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570870
2025-01-22T18:34:30,272 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2025-01-22T18:34:30,272 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 4
2025-01-22T18:34:30,272 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570870
2025-01-22 18:34:30.274 kserve.trace requestId: 980be497-04e7-4f86-87ce-02767f3195bf, preprocess_ms: 0.018358231, explain_ms: 0, predict_ms: 8.562088013, postprocess_ms: 0.005483627
2025-01-22 18:34:30.274 uvicorn.access INFO:     10.233.75.99:0 9 - "POST /v1/models/youtubegoes5g%3Apredict HTTP/1.1" 200 OK
2025-01-22 18:34:30.274 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.009678840637207031
2025-01-22 18:34:30.274 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.004839999999603606
2025-01-22T18:34:42,292 [INFO ] epollEventLoopGroup-3-1 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570882
2025-01-22T18:34:42,292 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1737570882292
2025-01-22T18:34:42,293 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Backend received inference at: 1737570882
2025-01-22T18:34:42,293 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Received data: [{'data': [13, 13, 13, 0, 13, 13, 13, 13, -76, -76, -81, -76, -78.5, -76, -76, -7, -7, -12, -7, -9.5, -7, -7, 12, 12, 7, 12, 9.5, 12, 12]}]
2025-01-22T18:34:42,294 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Input data preprocessed successfully
2025-01-22T18:34:42,298 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Inference performed successfully
2025-01-22T18:34:42,298 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Output postprocessed successfully
2025-01-22T18:34:42,298 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:4.78|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,1737570882,1a355c10-05b0-4777-a614-b1faab7afa90, pattern=[METRICS]
2025-01-22T18:34:42,298 [INFO ] W-9000-youtubegoes5g_1.0 ACCESS_LOG - /127.0.0.1:44218 "POST /v1/models/youtubegoes5g:predict HTTP/1.1" 200 6
2025-01-22T18:34:42,298 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570882
2025-01-22T18:34:42,298 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:5777.082|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570882
2025-01-22T18:34:42,298 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:71.658|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570882
2025-01-22T18:34:42,298 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.job.Job - Waiting time ns: 71658, Backend time ns: 5892702
2025-01-22T18:34:42,298 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570882
2025-01-22T18:34:42,298 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2025-01-22T18:34:42,298 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 5
2025-01-22T18:34:42,298 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570882
2025-01-22T18:34:42,298 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_METRICS - PredictionTime.ms:4.78|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,requestID:1a355c10-05b0-4777-a614-b1faab7afa90,timestamp:1737570882
2025-01-22 18:34:42.299 kserve.trace requestId: 2c1829eb-f578-42f9-950c-9dcba246beb0, preprocess_ms: 0.009298325, explain_ms: 0, predict_ms: 9.998559952, postprocess_ms: 0.004291534
2025-01-22 18:34:42.299 uvicorn.access INFO:     10.233.75.99:0 9 - "POST /v1/models/youtubegoes5g%3Apredict HTTP/1.1" 200 OK
2025-01-22 18:34:42.300 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.010970592498779297
2025-01-22 18:34:42.300 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.004938000000038301
2025-01-22T18:34:54,318 [INFO ] epollEventLoopGroup-3-2 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570894
2025-01-22T18:34:54,318 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1737570894318
2025-01-22T18:34:54,319 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Backend received inference at: 1737570894
2025-01-22T18:34:54,319 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Received data: [{'data': [13, 13, 13, 0, 13, 13, 13, 13, -76, -76, -81, -76, -78.5, -76, -76, -7, -7, -12, -7, -9.5, -7, -7, 12, 12, 7, 12, 9.5, 12, 12]}]
2025-01-22T18:34:54,319 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Input data preprocessed successfully
2025-01-22T18:34:54,324 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Inference performed successfully
2025-01-22T18:34:54,324 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Output postprocessed successfully
2025-01-22T18:34:54,324 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:5.16|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,1737570894,f24dec05-4484-46c0-9ef3-987018393502, pattern=[METRICS]
2025-01-22T18:34:54,324 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_METRICS - PredictionTime.ms:5.16|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,requestID:f24dec05-4484-46c0-9ef3-987018393502,timestamp:1737570894
2025-01-22T18:34:54,324 [INFO ] W-9000-youtubegoes5g_1.0 ACCESS_LOG - /127.0.0.1:36918 "POST /v1/models/youtubegoes5g:predict HTTP/1.1" 200 6
2025-01-22T18:34:54,324 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570894
2025-01-22T18:34:54,324 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:6671.574|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570894
2025-01-22T18:34:54,325 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:41.037|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570894
2025-01-22T18:34:54,325 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.job.Job - Waiting time ns: 41037, Backend time ns: 6815489
2025-01-22T18:34:54,325 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570894
2025-01-22T18:34:54,325 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2025-01-22T18:34:54,325 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 6
2025-01-22T18:34:54,325 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570894
2025-01-22 18:34:54.326 kserve.trace requestId: 98d742dd-b23d-462c-a5af-3c7ed3e185d2, preprocess_ms: 0.012636185, explain_ms: 0, predict_ms: 10.607004166, postprocess_ms: 0.008106232
2025-01-22 18:34:54.326 uvicorn.access INFO:     10.233.75.99:0 9 - "POST /v1/models/youtubegoes5g%3Apredict HTTP/1.1" 200 OK
2025-01-22 18:34:54.327 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.012054920196533203
2025-01-22 18:34:54.327 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.00498899999911373
2025-01-22T18:35:06,344 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570906
2025-01-22T18:35:06,344 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1737570906344
2025-01-22T18:35:06,345 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Backend received inference at: 1737570906
2025-01-22T18:35:06,345 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Received data: [{'data': [13, 13, 13, 0, 13, 13, 13, 13, -76, -76, -81, -76, -78.5, -76, -76, -7, -7, -12, -7, -9.5, -7, -7, 12, 12, 7, 12, 9.5, 12, 12]}]
2025-01-22T18:35:06,346 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Input data preprocessed successfully
2025-01-22T18:35:06,350 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Inference performed successfully
2025-01-22T18:35:06,350 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Output postprocessed successfully
2025-01-22T18:35:06,350 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:4.44|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,1737570906,5c91ea36-b5e2-46f8-96ff-3a09e29f00eb, pattern=[METRICS]
2025-01-22T18:35:06,350 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_METRICS - PredictionTime.ms:4.44|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,requestID:5c91ea36-b5e2-46f8-96ff-3a09e29f00eb,timestamp:1737570906
2025-01-22T18:35:06,350 [INFO ] W-9000-youtubegoes5g_1.0 ACCESS_LOG - /127.0.0.1:32852 "POST /v1/models/youtubegoes5g:predict HTTP/1.1" 200 6
2025-01-22T18:35:06,350 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570906
2025-01-22T18:35:06,350 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:5723.735|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570906
2025-01-22T18:35:06,350 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:61.71|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570906
2025-01-22T18:35:06,350 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.job.Job - Waiting time ns: 61710, Backend time ns: 5846435
2025-01-22T18:35:06,350 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570906
2025-01-22T18:35:06,350 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2025-01-22T18:35:06,350 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 5
2025-01-22T18:35:06,350 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570906
2025-01-22 18:35:06.352 kserve.trace requestId: 1ced43c5-03b1-4716-8988-e70a9cd331eb, preprocess_ms: 0.012636185, explain_ms: 0, predict_ms: 9.924888611, postprocess_ms: 0.00834465
2025-01-22 18:35:06.352 uvicorn.access INFO:     10.233.75.99:0 9 - "POST /v1/models/youtubegoes5g%3Apredict HTTP/1.1" 200 OK
2025-01-22 18:35:06.352 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.011067390441894531
2025-01-22 18:35:06.352 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.004723999998532236
2025-01-22T18:35:18,369 [INFO ] epollEventLoopGroup-3-4 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570918
2025-01-22T18:35:18,369 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1737570918369
2025-01-22T18:35:18,370 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Backend received inference at: 1737570918
2025-01-22T18:35:18,370 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Received data: [{'data': [13, 13, 13, 0, 13, 13, 13, 13, -76, -76, -81, -76, -78.5, -76, -76, -7, -7, -12, -7, -9.5, -7, -7, 12, 12, 7, 12, 9.5, 12, 12]}]
2025-01-22T18:35:18,371 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Input data preprocessed successfully
2025-01-22T18:35:18,374 [INFO ] W-9000-youtubegoes5g_1.0 ACCESS_LOG - /127.0.0.1:40374 "POST /v1/models/youtubegoes5g:predict HTTP/1.1" 200 5
2025-01-22T18:35:18,374 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Inference performed successfully
2025-01-22T18:35:18,375 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570918
2025-01-22T18:35:18,375 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Output postprocessed successfully
2025-01-22T18:35:18,375 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:2.96|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,1737570918,7be7b886-9e89-4f91-aa9b-164d00d2f659, pattern=[METRICS]
2025-01-22T18:35:18,375 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:5135.838|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570918
2025-01-22T18:35:18,375 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_METRICS - PredictionTime.ms:2.96|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,requestID:7be7b886-9e89-4f91-aa9b-164d00d2f659,timestamp:1737570918
2025-01-22T18:35:18,376 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:214.47|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570918
2025-01-22T18:35:18,376 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.job.Job - Waiting time ns: 214470, Backend time ns: 6538609
2025-01-22T18:35:18,376 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570918
2025-01-22T18:35:18,376 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2025-01-22T18:35:18,376 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 4
2025-01-22T18:35:18,376 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:3.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570918
2025-01-22 18:35:18.376 kserve.trace requestId: f3e65f9b-54d6-468e-ac4c-66f33200e473, preprocess_ms: 0.01168251, explain_ms: 0, predict_ms: 9.582519531, postprocess_ms: 0.005960464
2025-01-22 18:35:18.376 uvicorn.access INFO:     10.233.75.99:0 9 - "POST /v1/models/youtubegoes5g%3Apredict HTTP/1.1" 200 OK
2025-01-22 18:35:18.376 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.010443925857543945
2025-01-22 18:35:18.377 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.004248000001098262
2025-01-22T18:35:18,989 [INFO ] pool-3-thread-2 TS_METRICS - CPUUtilization.Percent:50.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570918
2025-01-22T18:35:18,990 [INFO ] pool-3-thread-2 TS_METRICS - DiskAvailable.Gigabytes:263.71036529541016|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570918
2025-01-22T18:35:18,990 [INFO ] pool-3-thread-2 TS_METRICS - DiskUsage.Gigabytes:208.29290008544922|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570918
2025-01-22T18:35:18,990 [INFO ] pool-3-thread-2 TS_METRICS - DiskUtilization.Percent:44.1|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570918
2025-01-22T18:35:18,990 [INFO ] pool-3-thread-2 TS_METRICS - MemoryAvailable.Megabytes:11281.51171875|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570918
2025-01-22T18:35:18,990 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUsed.Megabytes:8358.08984375|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570918
2025-01-22T18:35:18,990 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUtilization.Percent:43.5|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570918
2025-01-22T18:35:30,394 [INFO ] epollEventLoopGroup-3-1 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570930
2025-01-22T18:35:30,394 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1737570930394
2025-01-22T18:35:30,395 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Backend received inference at: 1737570930
2025-01-22T18:35:30,395 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Received data: [{'data': [13, 13, 13, 0, 13, 13, 13, 13, -76, -76, -81, -76, -78.5, -76, -76, -7, -7, -12, -7, -9.5, -7, -7, 12, 12, 7, 12, 9.5, 12, 12]}]
2025-01-22T18:35:30,396 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Input data preprocessed successfully
2025-01-22T18:35:30,397 [INFO ] W-9000-youtubegoes5g_1.0 ACCESS_LOG - /127.0.0.1:56590 "POST /v1/models/youtubegoes5g:predict HTTP/1.1" 200 3
2025-01-22T18:35:30,397 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Inference performed successfully
2025-01-22T18:35:30,397 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Output postprocessed successfully
2025-01-22T18:35:30,397 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570930
2025-01-22T18:35:30,398 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:1.43|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,1737570930,b254b66d-dc48-4238-95cc-14460464ba0d, pattern=[METRICS]
2025-01-22T18:35:30,398 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:3388.869|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570930
2025-01-22T18:35:30,398 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:84.664|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570930
2025-01-22T18:35:30,398 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_METRICS - PredictionTime.ms:1.43|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,requestID:b254b66d-dc48-4238-95cc-14460464ba0d,timestamp:1737570930
2025-01-22T18:35:30,398 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.job.Job - Waiting time ns: 84664, Backend time ns: 3460807
2025-01-22T18:35:30,398 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570930
2025-01-22T18:35:30,398 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2025-01-22T18:35:30,398 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3
2025-01-22T18:35:30,398 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570930
2025-01-22 18:35:30.399 kserve.trace requestId: c6021c61-0e09-40a8-a27d-9b48bfd2404e, preprocess_ms: 0.013113022, explain_ms: 0, predict_ms: 7.263898849, postprocess_ms: 0.00500679
2025-01-22 18:35:30.399 uvicorn.access INFO:     10.233.75.99:0 9 - "POST /v1/models/youtubegoes5g%3Apredict HTTP/1.1" 200 OK
2025-01-22 18:35:30.399 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.00815582275390625
2025-01-22 18:35:30.399 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.004407000000355765
2025-01-22T18:36:06,416 [INFO ] epollEventLoopGroup-3-2 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570966
2025-01-22T18:36:06,416 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1737570966416
2025-01-22T18:36:06,417 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Backend received inference at: 1737570966
2025-01-22T18:36:06,417 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Received data: [{'data': [13, 13, 13, 0, 13, 13, 13, 13, -76, -76, -81, -76, -78.5, -76, -76, -7, -7, -12, -7, -9.5, -7, -7, 12, 12, 7, 12, 9.5, 12, 12]}]
2025-01-22T18:36:06,418 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Input data preprocessed successfully
2025-01-22T18:36:06,419 [INFO ] W-9000-youtubegoes5g_1.0 ACCESS_LOG - /127.0.0.1:59888 "POST /v1/models/youtubegoes5g:predict HTTP/1.1" 200 3
2025-01-22T18:36:06,419 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570966
2025-01-22T18:36:06,419 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:2532.331|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570966
2025-01-22T18:36:06,419 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Inference performed successfully
2025-01-22T18:36:06,419 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:77.482|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570966
2025-01-22T18:36:06,419 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Output postprocessed successfully
2025-01-22T18:36:06,419 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.job.Job - Waiting time ns: 77482, Backend time ns: 2691500
2025-01-22T18:36:06,419 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570966
2025-01-22T18:36:06,419 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2025-01-22T18:36:06,419 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2
2025-01-22T18:36:06,419 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570966
2025-01-22T18:36:06,419 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:1.53|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,1737570966,a1833e2a-9fa8-4dcf-8ffb-318159341542, pattern=[METRICS]
2025-01-22T18:36:06,419 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_METRICS - PredictionTime.ms:1.53|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,requestID:a1833e2a-9fa8-4dcf-8ffb-318159341542,timestamp:1737570966
2025-01-22 18:36:06.420 kserve.trace requestId: 1a906c26-a1f6-474b-9019-c5eb05d30da3, preprocess_ms: 0.012636185, explain_ms: 0, predict_ms: 7.245540619, postprocess_ms: 0.004291534
2025-01-22 18:36:06.421 uvicorn.access INFO:     10.233.75.99:0 9 - "POST /v1/models/youtubegoes5g%3Apredict HTTP/1.1" 200 OK
2025-01-22 18:36:06.421 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.008244514465332031
2025-01-22 18:36:06.421 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.005170999998881598
2025-01-22T18:36:18,437 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570978
2025-01-22T18:36:18,437 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1737570978437
2025-01-22T18:36:18,438 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Backend received inference at: 1737570978
2025-01-22T18:36:18,438 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Received data: [{'data': [13, 13, 13, 0, 13, 13, 13, 13, -76, -76, -81, -76, -78.5, -76, -76, -7, -7, -12, -7, -9.5, -7, -7, 12, 12, 7, 12, 9.5, 12, 12]}]
2025-01-22T18:36:18,439 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Input data preprocessed successfully
2025-01-22T18:36:18,439 [INFO ] W-9000-youtubegoes5g_1.0 ACCESS_LOG - /127.0.0.1:40588 "POST /v1/models/youtubegoes5g:predict HTTP/1.1" 200 2
2025-01-22T18:36:18,440 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570978
2025-01-22T18:36:18,440 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:2064.309|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570978
2025-01-22T18:36:18,440 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:26.843|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570978
2025-01-22T18:36:18,440 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.job.Job - Waiting time ns: 26843, Backend time ns: 2169962
2025-01-22T18:36:18,440 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570978
2025-01-22T18:36:18,440 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Inference performed successfully
2025-01-22T18:36:18,440 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Output postprocessed successfully
2025-01-22T18:36:18,440 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2025-01-22T18:36:18,440 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1
2025-01-22T18:36:18,440 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:2.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570978
2025-01-22T18:36:18,440 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:1.25|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,1737570978,d7fb0806-4f89-4f34-b9ca-060276ccb1b4, pattern=[METRICS]
2025-01-22T18:36:18,440 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_METRICS - PredictionTime.ms:1.25|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,requestID:d7fb0806-4f89-4f34-b9ca-060276ccb1b4,timestamp:1737570978
2025-01-22 18:36:18.441 kserve.trace requestId: 9ab05622-e508-40de-b139-faa395e7aa1c, preprocess_ms: 0.011920929, explain_ms: 0, predict_ms: 6.266355515, postprocess_ms: 0.022411346
2025-01-22 18:36:18.442 uvicorn.access INFO:     10.233.75.99:0 9 - "POST /v1/models/youtubegoes5g%3Apredict HTTP/1.1" 200 OK
2025-01-22 18:36:18.442 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.007590770721435547
2025-01-22 18:36:18.442 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.004641999999876134
2025-01-22T18:36:18,988 [INFO ] pool-3-thread-2 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570978
2025-01-22T18:36:18,988 [INFO ] pool-3-thread-2 TS_METRICS - DiskAvailable.Gigabytes:263.7100410461426|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570978
2025-01-22T18:36:18,988 [INFO ] pool-3-thread-2 TS_METRICS - DiskUsage.Gigabytes:208.2932243347168|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570978
2025-01-22T18:36:18,988 [INFO ] pool-3-thread-2 TS_METRICS - DiskUtilization.Percent:44.1|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570978
2025-01-22T18:36:18,988 [INFO ] pool-3-thread-2 TS_METRICS - MemoryAvailable.Megabytes:11217.84765625|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570978
2025-01-22T18:36:18,988 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUsed.Megabytes:8421.75390625|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570978
2025-01-22T18:36:18,988 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUtilization.Percent:43.9|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570978
2025-01-22T18:36:30,460 [INFO ] epollEventLoopGroup-3-4 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570990
2025-01-22T18:36:30,460 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1737570990460
2025-01-22T18:36:30,461 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Backend received inference at: 1737570990
2025-01-22T18:36:30,461 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Received data: [{'data': [13, 13, 13, 0, 13, 13, 13, 13, -76, -76, -81, -76, -78.5, -76, -76, -7, -7, -12, -7, -9.5, -7, -7, 12, 12, 7, 12, 9.5, 12, 12]}]
2025-01-22T18:36:30,462 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Input data preprocessed successfully
2025-01-22T18:36:30,463 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Inference performed successfully
2025-01-22T18:36:30,463 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Output postprocessed successfully
2025-01-22T18:36:30,463 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:1.76|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,1737570990,b0d9619c-6b12-4abb-8a91-cb1577aa1967, pattern=[METRICS]
2025-01-22T18:36:30,463 [INFO ] W-9000-youtubegoes5g_1.0 ACCESS_LOG - /127.0.0.1:58552 "POST /v1/models/youtubegoes5g:predict HTTP/1.1" 200 3
2025-01-22T18:36:30,463 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_METRICS - PredictionTime.ms:1.76|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,requestID:b0d9619c-6b12-4abb-8a91-cb1577aa1967,timestamp:1737570990
2025-01-22T18:36:30,463 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570990
2025-01-22T18:36:30,464 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:2971.02|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570990
2025-01-22T18:36:30,464 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:49.539|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570990
2025-01-22T18:36:30,464 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.job.Job - Waiting time ns: 49539, Backend time ns: 3476599
2025-01-22T18:36:30,464 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570990
2025-01-22T18:36:30,464 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2025-01-22T18:36:30,464 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3
2025-01-22T18:36:30,464 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737570990
2025-01-22 18:36:30.465 kserve.trace requestId: b6f31f96-0837-4ddc-8530-94b3a37f2ad3, preprocess_ms: 0.011920929, explain_ms: 0, predict_ms: 7.536411285, postprocess_ms: 0.007629395
2025-01-22 18:36:30.465 uvicorn.access INFO:     10.233.75.99:0 9 - "POST /v1/models/youtubegoes5g%3Apredict HTTP/1.1" 200 OK
2025-01-22 18:36:30.465 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.008462190628051758
2025-01-22 18:36:30.466 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.004769000001033419
2025-01-22T18:36:42,484 [INFO ] epollEventLoopGroup-3-1 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571002
2025-01-22T18:36:42,484 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1737571002484
2025-01-22T18:36:42,486 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Backend received inference at: 1737571002
2025-01-22T18:36:42,486 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Received data: [{'data': [13, 13, 13, 0, 13, 13, 13, 13, -76, -76, -81, -76, -78.5, -76, -76, -7, -7, -12, -7, -9.5, -7, -7, 12, 12, 7, 12, 9.5, 12, 12]}]
2025-01-22T18:36:42,486 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Input data preprocessed successfully
2025-01-22T18:36:42,486 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Inference performed successfully
2025-01-22T18:36:42,486 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Output postprocessed successfully
2025-01-22T18:36:42,486 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:1.13|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,1737571002,721e6712-99c3-46ad-8ee6-736d5f50d1fc, pattern=[METRICS]
2025-01-22T18:36:42,486 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_METRICS - PredictionTime.ms:1.13|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,requestID:721e6712-99c3-46ad-8ee6-736d5f50d1fc,timestamp:1737571002
2025-01-22T18:36:42,486 [INFO ] W-9000-youtubegoes5g_1.0 ACCESS_LOG - /127.0.0.1:34512 "POST /v1/models/youtubegoes5g:predict HTTP/1.1" 200 2
2025-01-22T18:36:42,486 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571002
2025-01-22T18:36:42,486 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:2075.254|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571002
2025-01-22T18:36:42,486 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:26.727|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571002
2025-01-22T18:36:42,486 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.job.Job - Waiting time ns: 26727, Backend time ns: 2279896
2025-01-22T18:36:42,486 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571002
2025-01-22T18:36:42,487 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2025-01-22T18:36:42,487 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2
2025-01-22T18:36:42,487 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571002
2025-01-22 18:36:42.489 kserve.trace requestId: 609f40e3-59be-4732-b1b4-f30c65a799c4, preprocess_ms: 0.012159348, explain_ms: 0, predict_ms: 6.943702698, postprocess_ms: 0.00500679
2025-01-22 18:36:42.489 uvicorn.access INFO:     10.233.75.99:0 9 - "POST /v1/models/youtubegoes5g%3Apredict HTTP/1.1" 200 OK
2025-01-22 18:36:42.489 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.007822275161743164
2025-01-22 18:36:42.489 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.0045699999973294325
2025-01-22T18:36:54,506 [INFO ] epollEventLoopGroup-3-2 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571014
2025-01-22T18:36:54,506 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1737571014506
2025-01-22T18:36:54,507 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Backend received inference at: 1737571014
2025-01-22T18:36:54,507 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Received data: [{'data': [13, 13, 13, 0, 13, 13, 13, 13, -76, -76, -81, -76, -78.5, -76, -76, -7, -7, -12, -7, -9.5, -7, -7, 12, 12, 7, 12, 9.5, 12, 12]}]
2025-01-22T18:36:54,508 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Input data preprocessed successfully
2025-01-22T18:36:54,508 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Inference performed successfully
2025-01-22T18:36:54,509 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Output postprocessed successfully
2025-01-22T18:36:54,509 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:1.84|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,1737571014,69c2ca2a-dcaa-45b7-aeaf-aaa3af0fcbc3, pattern=[METRICS]
2025-01-22T18:36:54,509 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_METRICS - PredictionTime.ms:1.84|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,requestID:69c2ca2a-dcaa-45b7-aeaf-aaa3af0fcbc3,timestamp:1737571014
2025-01-22T18:36:54,510 [INFO ] W-9000-youtubegoes5g_1.0 ACCESS_LOG - /127.0.0.1:49994 "POST /v1/models/youtubegoes5g:predict HTTP/1.1" 200 4
2025-01-22T18:36:54,510 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571014
2025-01-22T18:36:54,510 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:3565.883|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571014
2025-01-22T18:36:54,510 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:52.816|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571014
2025-01-22T18:36:54,510 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.job.Job - Waiting time ns: 52816, Backend time ns: 3987050
2025-01-22T18:36:54,510 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571014
2025-01-22T18:36:54,510 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2025-01-22T18:36:54,510 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 4
2025-01-22T18:36:54,510 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571014
2025-01-22 18:36:54.511 kserve.trace requestId: 07d88a29-37b0-4f98-8d44-0cfa128ec2b0, preprocess_ms: 0.012159348, explain_ms: 0, predict_ms: 7.477760315, postprocess_ms: 0.004529953
2025-01-22 18:36:54.511 uvicorn.access INFO:     10.233.75.99:0 9 - "POST /v1/models/youtubegoes5g%3Apredict HTTP/1.1" 200 OK
2025-01-22 18:36:54.511 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.008413553237915039
2025-01-22 18:36:54.511 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.004426999999850523
2025-01-22T18:37:06,530 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571026
2025-01-22T18:37:06,530 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1737571026530
2025-01-22T18:37:06,537 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Backend received inference at: 1737571026
2025-01-22T18:37:06,537 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Received data: [{'data': [13, 13, 13, 0, 13, 13, 13, 13, -76, -76, -81, -76, -78.5, -76, -76, -7, -7, -12, -7, -9.5, -7, -7, 12, 12, 7, 12, 9.5, 12, 12]}]
2025-01-22T18:37:06,537 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Input data preprocessed successfully
2025-01-22T18:37:06,538 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Inference performed successfully
2025-01-22T18:37:06,538 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Output postprocessed successfully
2025-01-22T18:37:06,538 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:6.18|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,1737571026,dbbde27a-59b5-456d-ade7-68c867b6003d, pattern=[METRICS]
2025-01-22T18:37:06,538 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_METRICS - PredictionTime.ms:6.18|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,requestID:dbbde27a-59b5-456d-ade7-68c867b6003d,timestamp:1737571026
2025-01-22T18:37:06,539 [INFO ] W-9000-youtubegoes5g_1.0 ACCESS_LOG - /127.0.0.1:41834 "POST /v1/models/youtubegoes5g:predict HTTP/1.1" 200 9
2025-01-22T18:37:06,539 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571026
2025-01-22T18:37:06,539 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:8403.294|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571026
2025-01-22T18:37:06,539 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:35.655|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571026
2025-01-22T18:37:06,539 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.job.Job - Waiting time ns: 35655, Backend time ns: 8484136
2025-01-22T18:37:06,539 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571026
2025-01-22T18:37:06,539 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2025-01-22T18:37:06,539 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 7
2025-01-22T18:37:06,539 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:2.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571026
2025-01-22 18:37:06.541 uvicorn.access INFO:     10.233.75.99:0 9 - "POST /v1/models/youtubegoes5g%3Apredict HTTP/1.1" 200 OK
2025-01-22 18:37:06.541 kserve.trace requestId: 713c6873-cf93-4f72-85ce-e7d62f5c3b4f, preprocess_ms: 0.020027161, explain_ms: 0, predict_ms: 13.516426086, postprocess_ms: 0.005722046
2025-01-22 18:37:06.542 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.014714956283569336
2025-01-22 18:37:06.542 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.0057809999998426065
2025-01-22T18:37:18,560 [INFO ] epollEventLoopGroup-3-4 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571038
2025-01-22T18:37:18,560 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1737571038560
2025-01-22T18:37:18,561 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Backend received inference at: 1737571038
2025-01-22T18:37:18,561 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Received data: [{'data': [13, 13, 13, 0, 13, 13, 13, 13, -76, -76, -81, -76, -78.5, -76, -76, -7, -7, -12, -7, -9.5, -7, -7, 12, 12, 7, 12, 9.5, 12, 12]}]
2025-01-22T18:37:18,561 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Input data preprocessed successfully
2025-01-22T18:37:18,565 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Inference performed successfully
2025-01-22T18:37:18,565 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Output postprocessed successfully
2025-01-22T18:37:18,565 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:4.34|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,1737571038,aaff0a5f-dc3a-40da-be69-1249ec5da584, pattern=[METRICS]
2025-01-22T18:37:18,565 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_METRICS - PredictionTime.ms:4.34|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,requestID:aaff0a5f-dc3a-40da-be69-1249ec5da584,timestamp:1737571038
2025-01-22T18:37:18,565 [INFO ] W-9000-youtubegoes5g_1.0 ACCESS_LOG - /127.0.0.1:41658 "POST /v1/models/youtubegoes5g:predict HTTP/1.1" 200 5
2025-01-22T18:37:18,565 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571038
2025-01-22T18:37:18,565 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:5374.923|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571038
2025-01-22T18:37:18,565 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:101.515|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571038
2025-01-22T18:37:18,565 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.job.Job - Waiting time ns: 101515, Backend time ns: 5428732
2025-01-22T18:37:18,565 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571038
2025-01-22T18:37:18,566 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2025-01-22T18:37:18,566 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 5
2025-01-22T18:37:18,566 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571038
2025-01-22 18:37:18.567 kserve.trace requestId: db25951e-1a99-4abe-a1be-f4292c7008cd, preprocess_ms: 0.012397766, explain_ms: 0, predict_ms: 9.536504745, postprocess_ms: 0.006437302
2025-01-22 18:37:18.567 uvicorn.access INFO:     10.233.75.99:0 9 - "POST /v1/models/youtubegoes5g%3Apredict HTTP/1.1" 200 OK
2025-01-22 18:37:18.568 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.010669469833374023
2025-01-22 18:37:18.568 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.005019000000174856
2025-01-22T18:37:18,992 [INFO ] pool-3-thread-2 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571038
2025-01-22T18:37:18,993 [INFO ] pool-3-thread-2 TS_METRICS - DiskAvailable.Gigabytes:263.70970153808594|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571038
2025-01-22T18:37:18,993 [INFO ] pool-3-thread-2 TS_METRICS - DiskUsage.Gigabytes:208.29356384277344|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571038
2025-01-22T18:37:18,993 [INFO ] pool-3-thread-2 TS_METRICS - DiskUtilization.Percent:44.1|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571038
2025-01-22T18:37:18,993 [INFO ] pool-3-thread-2 TS_METRICS - MemoryAvailable.Megabytes:11170.54296875|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571038
2025-01-22T18:37:18,993 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUsed.Megabytes:8469.05859375|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571038
2025-01-22T18:37:18,993 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUtilization.Percent:44.1|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571038
2025-01-22T18:37:30,585 [INFO ] epollEventLoopGroup-3-1 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571050
2025-01-22T18:37:30,585 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1737571050585
2025-01-22T18:37:30,586 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Backend received inference at: 1737571050
2025-01-22T18:37:30,586 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Received data: [{'data': [13, 13, 13, 0, 13, 13, 13, 13, -76, -76, -81, -76, -78.5, -76, -76, -7, -7, -12, -7, -9.5, -7, -7, 12, 12, 7, 12, 9.5, 12, 12]}]
2025-01-22T18:37:30,586 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Input data preprocessed successfully
2025-01-22T18:37:30,590 [INFO ] W-9000-youtubegoes5g_1.0 ACCESS_LOG - /127.0.0.1:44440 "POST /v1/models/youtubegoes5g:predict HTTP/1.1" 200 5
2025-01-22T18:37:30,590 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571050
2025-01-22T18:37:30,590 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Inference performed successfully
2025-01-22T18:37:30,590 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Output postprocessed successfully
2025-01-22T18:37:30,590 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:4.38|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,1737571050,6093e109-c4ff-4c84-b9f6-d192a65b546b, pattern=[METRICS]
2025-01-22T18:37:30,590 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_METRICS - PredictionTime.ms:4.38|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,requestID:6093e109-c4ff-4c84-b9f6-d192a65b546b,timestamp:1737571050
2025-01-22T18:37:30,590 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:5180.87|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571050
2025-01-22T18:37:30,591 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:61.592|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571050
2025-01-22T18:37:30,591 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.job.Job - Waiting time ns: 61592, Backend time ns: 5568420
2025-01-22T18:37:30,591 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571050
2025-01-22T18:37:30,591 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2025-01-22T18:37:30,591 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 4
2025-01-22T18:37:30,591 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:2.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571050
2025-01-22 18:37:30.592 uvicorn.access INFO:     10.233.75.99:0 9 - "POST /v1/models/youtubegoes5g%3Apredict HTTP/1.1" 200 OK
2025-01-22 18:37:30.592 kserve.trace requestId: 533d83db-0c44-464e-9b90-4469f8f6d423, preprocess_ms: 0.017166138, explain_ms: 0, predict_ms: 9.605169296, postprocess_ms: 0.00667572
2025-01-22 18:37:30.592 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.010638713836669922
2025-01-22 18:37:30.592 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.005059999999502907
2025-01-22T18:37:42,610 [INFO ] epollEventLoopGroup-3-2 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571062
2025-01-22T18:37:42,610 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1737571062610
2025-01-22T18:37:42,612 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Backend received inference at: 1737571062
2025-01-22T18:37:42,612 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Received data: [{'data': [13, 13, 13, 0, 13, 13, 13, 13, -76, -76, -81, -76, -78.5, -76, -76, -7, -7, -12, -7, -9.5, -7, -7, 12, 12, 7, 12, 9.5, 12, 12]}]
2025-01-22T18:37:42,612 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Input data preprocessed successfully
2025-01-22T18:37:42,612 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Inference performed successfully
2025-01-22T18:37:42,612 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Output postprocessed successfully
2025-01-22T18:37:42,612 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:1.25|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,1737571062,bd5102b7-3bbb-4d4b-97f4-47488f7540a6, pattern=[METRICS]
2025-01-22T18:37:42,612 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_METRICS - PredictionTime.ms:1.25|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,requestID:bd5102b7-3bbb-4d4b-97f4-47488f7540a6,timestamp:1737571062
2025-01-22T18:37:42,613 [INFO ] W-9000-youtubegoes5g_1.0 ACCESS_LOG - /127.0.0.1:41752 "POST /v1/models/youtubegoes5g:predict HTTP/1.1" 200 3
2025-01-22T18:37:42,613 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571062
2025-01-22T18:37:42,613 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:2123.122|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571062
2025-01-22T18:37:42,613 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:68.391|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571062
2025-01-22T18:37:42,613 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.job.Job - Waiting time ns: 68391, Backend time ns: 2201850
2025-01-22T18:37:42,613 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571062
2025-01-22T18:37:42,613 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2025-01-22T18:37:42,613 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2
2025-01-22T18:37:42,613 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571062
2025-01-22 18:37:42.615 kserve.trace requestId: d484d334-fddd-4370-9829-ace027a8bf49, preprocess_ms: 0.018119812, explain_ms: 0, predict_ms: 6.969928741, postprocess_ms: 0.005483627
2025-01-22 18:37:42.615 uvicorn.access INFO:     10.233.75.99:0 9 - "POST /v1/models/youtubegoes5g%3Apredict HTTP/1.1" 200 OK
2025-01-22 18:37:42.616 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.008233785629272461
2025-01-22 18:37:42.616 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.004968999999618973
2025-01-22T18:37:54,646 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571074
2025-01-22T18:37:54,646 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1737571074646
2025-01-22T18:37:54,647 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Backend received inference at: 1737571074
2025-01-22T18:37:54,647 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Received data: [{'data': [13, 13, 13, 0, 13, 13, 13, 13, -76, -76, -81, -76, -78.5, -76, -76, -7, -7, -12, -7, -9.5, -7, -7, 12, 12, 7, 12, 9.5, 12, 12]}]
2025-01-22T18:37:54,647 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Input data preprocessed successfully
2025-01-22T18:37:54,649 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Inference performed successfully
2025-01-22T18:37:54,649 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Output postprocessed successfully
2025-01-22T18:37:54,649 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:2.42|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,1737571074,8e5483d2-783e-46c0-af23-3a8b4f8e33fe, pattern=[METRICS]
2025-01-22T18:37:54,649 [INFO ] W-9000-youtubegoes5g_1.0 ACCESS_LOG - /127.0.0.1:40582 "POST /v1/models/youtubegoes5g:predict HTTP/1.1" 200 3
2025-01-22T18:37:54,649 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571074
2025-01-22T18:37:54,649 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:3352.665|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571074
2025-01-22T18:37:54,649 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:45.566|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571074
2025-01-22T18:37:54,649 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.job.Job - Waiting time ns: 45566, Backend time ns: 3434220
2025-01-22T18:37:54,649 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571074
2025-01-22T18:37:54,649 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2025-01-22T18:37:54,649 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3
2025-01-22T18:37:54,649 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571074
2025-01-22T18:37:54,649 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_METRICS - PredictionTime.ms:2.42|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,requestID:8e5483d2-783e-46c0-af23-3a8b4f8e33fe,timestamp:1737571074
2025-01-22 18:37:54.651 kserve.trace requestId: 9a744aa5-8ea5-4097-81df-a932377d174e, preprocess_ms: 0.012159348, explain_ms: 0, predict_ms: 7.851600647, postprocess_ms: 0.005245209
2025-01-22 18:37:54.652 uvicorn.access INFO:     10.233.75.99:0 9 - "POST /v1/models/youtubegoes5g%3Apredict HTTP/1.1" 200 OK
2025-01-22 18:37:54.652 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.008716821670532227
2025-01-22 18:37:54.652 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.004328999999415828
2025-01-22T18:38:18,993 [INFO ] pool-3-thread-2 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571098
2025-01-22T18:38:18,993 [INFO ] pool-3-thread-2 TS_METRICS - DiskAvailable.Gigabytes:263.70923614501953|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571098
2025-01-22T18:38:18,993 [INFO ] pool-3-thread-2 TS_METRICS - DiskUsage.Gigabytes:208.29402923583984|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571098
2025-01-22T18:38:18,993 [INFO ] pool-3-thread-2 TS_METRICS - DiskUtilization.Percent:44.1|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571098
2025-01-22T18:38:18,993 [INFO ] pool-3-thread-2 TS_METRICS - MemoryAvailable.Megabytes:11208.44921875|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571098
2025-01-22T18:38:18,993 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUsed.Megabytes:8431.15234375|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571098
2025-01-22T18:38:18,993 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUtilization.Percent:43.9|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571098
2025-01-22T18:38:30,669 [INFO ] epollEventLoopGroup-3-4 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571110
2025-01-22T18:38:30,670 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1737571110670
2025-01-22T18:38:30,670 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Backend received inference at: 1737571110
2025-01-22T18:38:30,670 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Received data: [{'data': [13, 13, 13, 0, 13, 13, 13, 13, -76, -76, -81, -76, -78.5, -76, -76, -7, -7, -12, -7, -9.5, -7, -7, 12, 12, 7, 12, 9.5, 12, 12]}]
2025-01-22T18:38:30,671 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Input data preprocessed successfully
2025-01-22T18:38:30,672 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Inference performed successfully
2025-01-22T18:38:30,672 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Output postprocessed successfully
2025-01-22T18:38:30,672 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:1.75|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,1737571110,b53e33b9-8058-437d-9ec6-e78c50864e21, pattern=[METRICS]
2025-01-22T18:38:30,672 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_METRICS - PredictionTime.ms:1.75|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,requestID:b53e33b9-8058-437d-9ec6-e78c50864e21,timestamp:1737571110
2025-01-22T18:38:30,672 [INFO ] W-9000-youtubegoes5g_1.0 ACCESS_LOG - /127.0.0.1:50990 "POST /v1/models/youtubegoes5g:predict HTTP/1.1" 200 3
2025-01-22T18:38:30,672 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571110
2025-01-22T18:38:30,673 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:2845.275|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571110
2025-01-22T18:38:30,673 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:51.039|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571110
2025-01-22T18:38:30,673 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.job.Job - Waiting time ns: 51039, Backend time ns: 3249279
2025-01-22T18:38:30,673 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571110
2025-01-22T18:38:30,673 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2025-01-22T18:38:30,673 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2
2025-01-22T18:38:30,673 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571110
2025-01-22 18:38:30.675 kserve.trace requestId: 6302710d-b527-4a14-8701-66044b921f12, preprocess_ms: 0.012397766, explain_ms: 0, predict_ms: 7.937192917, postprocess_ms: 0.005960464
2025-01-22 18:38:30.675 uvicorn.access INFO:     10.233.75.99:0 9 - "POST /v1/models/youtubegoes5g%3Apredict HTTP/1.1" 200 OK
2025-01-22 18:38:30.675 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.008874654769897461
2025-01-22 18:38:30.675 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.004735000002256129
2025-01-22T18:38:42,694 [INFO ] epollEventLoopGroup-3-1 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571122
2025-01-22T18:38:42,694 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1737571122694
2025-01-22T18:38:42,694 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Backend received inference at: 1737571122
2025-01-22T18:38:42,694 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Received data: [{'data': [13, 13, 13, 0, 13, 13, 13, 13, -76, -76, -81, -76, -78.5, -76, -76, -7, -7, -12, -7, -9.5, -7, -7, 12, 12, 7, 12, 9.5, 12, 12]}]
2025-01-22T18:38:42,695 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Input data preprocessed successfully
2025-01-22T18:38:42,701 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Inference performed successfully
2025-01-22T18:38:42,701 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Output postprocessed successfully
2025-01-22T18:38:42,701 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:7.01|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,1737571122,6b2837d4-a72a-46f2-87b1-8e5640084601, pattern=[METRICS]
2025-01-22T18:38:42,702 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_METRICS - PredictionTime.ms:7.01|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,requestID:6b2837d4-a72a-46f2-87b1-8e5640084601,timestamp:1737571122
2025-01-22T18:38:42,702 [INFO ] W-9000-youtubegoes5g_1.0 ACCESS_LOG - /127.0.0.1:43578 "POST /v1/models/youtubegoes5g:predict HTTP/1.1" 200 8
2025-01-22T18:38:42,702 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571122
2025-01-22T18:38:42,702 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:7826.055|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571122
2025-01-22T18:38:42,702 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:57.396|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571122
2025-01-22T18:38:42,702 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.job.Job - Waiting time ns: 57396, Backend time ns: 8072950
2025-01-22T18:38:42,702 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571122
2025-01-22T18:38:42,702 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2025-01-22T18:38:42,702 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 5
2025-01-22T18:38:42,702 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:3.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571122
2025-01-22 18:38:42.705 kserve.trace requestId: 76368d54-7b97-47dd-955a-f44f936ea14b, preprocess_ms: 0.01335144, explain_ms: 0, predict_ms: 13.466119766, postprocess_ms: 0.018835068
2025-01-22 18:38:42.705 uvicorn.access INFO:     10.233.75.99:0 9 - "POST /v1/models/youtubegoes5g%3Apredict HTTP/1.1" 200 OK
2025-01-22 18:38:42.705 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.014575004577636719
2025-01-22 18:38:42.705 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.004915000001346925
2025-01-22T18:38:54,722 [INFO ] epollEventLoopGroup-3-2 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571134
2025-01-22T18:38:54,722 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1737571134722
2025-01-22T18:38:54,723 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Backend received inference at: 1737571134
2025-01-22T18:38:54,723 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Received data: [{'data': [13, 13, 13, 0, 13, 13, 13, 13, -76, -76, -81, -76, -78.5, -76, -76, -7, -7, -12, -7, -9.5, -7, -7, 12, 12, 7, 12, 9.5, 12, 12]}]
2025-01-22T18:38:54,723 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Input data preprocessed successfully
2025-01-22T18:38:54,725 [INFO ] W-9000-youtubegoes5g_1.0 ACCESS_LOG - /127.0.0.1:44018 "POST /v1/models/youtubegoes5g:predict HTTP/1.1" 200 3
2025-01-22T18:38:54,725 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571134
2025-01-22T18:38:54,725 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:2941.107|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571134
2025-01-22T18:38:54,725 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:64.105|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571134
2025-01-22T18:38:54,725 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.job.Job - Waiting time ns: 64105, Backend time ns: 3026580
2025-01-22T18:38:54,725 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571134
2025-01-22T18:38:54,725 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2025-01-22T18:38:54,725 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2
2025-01-22T18:38:54,725 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571134
2025-01-22T18:38:54,725 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Inference performed successfully
2025-01-22T18:38:54,725 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Output postprocessed successfully
2025-01-22T18:38:54,725 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:2.15|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,1737571134,6b4c4eaa-080c-4604-8f11-c9aed482eae7, pattern=[METRICS]
2025-01-22T18:38:54,725 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_METRICS - PredictionTime.ms:2.15|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,requestID:6b4c4eaa-080c-4604-8f11-c9aed482eae7,timestamp:1737571134
2025-01-22 18:38:54.727 kserve.trace requestId: 918cb3ba-141c-4873-a5dc-b4764e29e7b5, preprocess_ms: 0.011444092, explain_ms: 0, predict_ms: 7.22026825, postprocess_ms: 0.005483627
2025-01-22 18:38:54.727 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.008057594299316406
2025-01-22 18:38:54.727 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.004333000000769971
2025-01-22 18:38:54.727 uvicorn.access INFO:     10.233.75.99:0 9 - "POST /v1/models/youtubegoes5g%3Apredict HTTP/1.1" 200 OK
2025-01-22T18:39:06,746 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571146
2025-01-22T18:39:06,746 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1737571146746
2025-01-22T18:39:06,748 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Backend received inference at: 1737571146
2025-01-22T18:39:06,748 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Received data: [{'data': [13, 13, 13, 0, 13, 13, 13, 13, -76, -76, -81, -76, -78.5, -76, -76, -7, -7, -12, -7, -9.5, -7, -7, 12, 12, 7, 12, 9.5, 12, 12]}]
2025-01-22T18:39:06,748 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Input data preprocessed successfully
2025-01-22T18:39:06,748 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Inference performed successfully
2025-01-22T18:39:06,748 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Output postprocessed successfully
2025-01-22T18:39:06,748 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:1.22|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,1737571146,14ca79eb-eba4-43ab-a412-0632fbd53052, pattern=[METRICS]
2025-01-22T18:39:06,748 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_METRICS - PredictionTime.ms:1.22|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,requestID:14ca79eb-eba4-43ab-a412-0632fbd53052,timestamp:1737571146
2025-01-22T18:39:06,748 [INFO ] W-9000-youtubegoes5g_1.0 ACCESS_LOG - /127.0.0.1:56932 "POST /v1/models/youtubegoes5g:predict HTTP/1.1" 200 2
2025-01-22T18:39:06,748 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571146
2025-01-22T18:39:06,748 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:2386.883|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571146
2025-01-22T18:39:06,748 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:162.733|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571146
2025-01-22T18:39:06,748 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.job.Job - Waiting time ns: 162733, Backend time ns: 2323023
2025-01-22T18:39:06,748 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571146
2025-01-22T18:39:06,748 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2025-01-22T18:39:06,748 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2
2025-01-22T18:39:06,748 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571146
2025-01-22 18:39:06.750 kserve.trace requestId: 75f4af9d-cb7b-9118-b32d-348b851dda0d, preprocess_ms: 0.011920929, explain_ms: 0, predict_ms: 7.029294968, postprocess_ms: 0.005245209
2025-01-22 18:39:06.751 uvicorn.access INFO:     10.233.75.99:0 9 - "POST /v1/models/youtubegoes5g%3Apredict HTTP/1.1" 200 OK
2025-01-22 18:39:06.751 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.007927894592285156
2025-01-22 18:39:06.751 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.004502999998294399
2025-01-22T18:39:18,768 [INFO ] epollEventLoopGroup-3-4 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571158
2025-01-22T18:39:18,769 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1737571158769
2025-01-22T18:39:18,769 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Backend received inference at: 1737571158
2025-01-22T18:39:18,770 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Received data: [{'data': [13, 13, 13, 0, 13, 13, 13, 13, -76, -76, -81, -76, -78.5, -76, -76, -7, -7, -12, -7, -9.5, -7, -7, 12, 12, 7, 12, 9.5, 12, 12]}]
2025-01-22T18:39:18,770 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Input data preprocessed successfully
2025-01-22T18:39:18,771 [INFO ] W-9000-youtubegoes5g_1.0 ACCESS_LOG - /127.0.0.1:53360 "POST /v1/models/youtubegoes5g:predict HTTP/1.1" 200 3
2025-01-22T18:39:18,771 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571158
2025-01-22T18:39:18,771 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:2552.623|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571158
2025-01-22T18:39:18,771 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:29.197|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571158
2025-01-22T18:39:18,771 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.job.Job - Waiting time ns: 29197, Backend time ns: 2648054
2025-01-22T18:39:18,771 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571158
2025-01-22T18:39:18,771 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2025-01-22T18:39:18,771 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2
2025-01-22T18:39:18,771 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571158
2025-01-22T18:39:18,771 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Inference performed successfully
2025-01-22T18:39:18,771 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Output postprocessed successfully
2025-01-22T18:39:18,772 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:1.64|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,1737571158,74c2dfe0-4548-46d7-938a-0470cda0b750, pattern=[METRICS]
2025-01-22T18:39:18,772 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_METRICS - PredictionTime.ms:1.64|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,requestID:74c2dfe0-4548-46d7-938a-0470cda0b750,timestamp:1737571158
2025-01-22 18:39:18.773 kserve.trace requestId: 9f9683b1-3a60-43ae-a0f8-2401e9ea430a, preprocess_ms: 0.011920929, explain_ms: 0, predict_ms: 6.990671158, postprocess_ms: 0.004768372
2025-01-22 18:39:18.774 uvicorn.access INFO:     10.233.75.99:0 9 - "POST /v1/models/youtubegoes5g%3Apredict HTTP/1.1" 200 OK
2025-01-22 18:39:18.774 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.007851123809814453
2025-01-22 18:39:18.774 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.004228999998304062
2025-01-22T18:39:18,984 [INFO ] pool-3-thread-2 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571158
2025-01-22T18:39:18,984 [INFO ] pool-3-thread-2 TS_METRICS - DiskAvailable.Gigabytes:263.70894622802734|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571158
2025-01-22T18:39:18,984 [INFO ] pool-3-thread-2 TS_METRICS - DiskUsage.Gigabytes:208.29431915283203|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571158
2025-01-22T18:39:18,984 [INFO ] pool-3-thread-2 TS_METRICS - DiskUtilization.Percent:44.1|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571158
2025-01-22T18:39:18,984 [INFO ] pool-3-thread-2 TS_METRICS - MemoryAvailable.Megabytes:11200.984375|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571158
2025-01-22T18:39:18,984 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUsed.Megabytes:8438.6171875|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571158
2025-01-22T18:39:18,984 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUtilization.Percent:43.9|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571158
2025-01-22T18:39:30,793 [INFO ] epollEventLoopGroup-3-1 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571170
2025-01-22T18:39:30,793 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1737571170793
2025-01-22T18:39:30,793 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Backend received inference at: 1737571170
2025-01-22T18:39:30,793 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Received data: [{'data': [13, 13, 13, 0, 13, 13, 13, 13, -76, -76, -81, -76, -78.5, -76, -76, -7, -7, -12, -7, -9.5, -7, -7, 12, 12, 7, 12, 9.5, 12, 12]}]
2025-01-22T18:39:30,794 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Input data preprocessed successfully
2025-01-22T18:39:30,796 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Inference performed successfully
2025-01-22T18:39:30,796 [INFO ] W-9000-youtubegoes5g_1.0 ACCESS_LOG - /127.0.0.1:45592 "POST /v1/models/youtubegoes5g:predict HTTP/1.1" 200 4
2025-01-22T18:39:30,796 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Output postprocessed successfully
2025-01-22T18:39:30,796 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:1.52|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,1737571170,a20056d9-4c6b-402c-abd3-82734b3791c4, pattern=[METRICS]
2025-01-22T18:39:30,796 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571170
2025-01-22T18:39:30,796 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:3435.398|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571170
2025-01-22T18:39:30,796 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_METRICS - PredictionTime.ms:1.52|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,requestID:a20056d9-4c6b-402c-abd3-82734b3791c4,timestamp:1737571170
2025-01-22T18:39:30,796 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:31.113|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571170
2025-01-22T18:39:30,796 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.job.Job - Waiting time ns: 31113, Backend time ns: 3531832
2025-01-22T18:39:30,796 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571170
2025-01-22T18:39:30,796 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2025-01-22T18:39:30,796 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3
2025-01-22T18:39:30,796 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571170
2025-01-22 18:39:30.797 kserve.trace requestId: b3ddb58f-3950-483e-9709-9f5ea9f5b83f, preprocess_ms: 0.012159348, explain_ms: 0, predict_ms: 8.79406929, postprocess_ms: 0.006198883
2025-01-22 18:39:30.798 uvicorn.access INFO:     10.233.75.99:0 9 - "POST /v1/models/youtubegoes5g%3Apredict HTTP/1.1" 200 OK
2025-01-22 18:39:30.798 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.009795427322387695
2025-01-22 18:39:30.798 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.005293000001984183
2025-01-22T18:39:42,817 [INFO ] epollEventLoopGroup-3-2 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571182
2025-01-22T18:39:42,817 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1737571182817
2025-01-22T18:39:42,818 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Backend received inference at: 1737571182
2025-01-22T18:39:42,818 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Received data: [{'data': [13, 13, 13, 0, 13, 13, 13, 13, -76, -76, -81, -76, -78.5, -76, -76, -7, -7, -12, -7, -9.5, -7, -7, 12, 12, 7, 12, 9.5, 12, 12]}]
2025-01-22T18:39:42,818 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Input data preprocessed successfully
2025-01-22T18:39:42,821 [INFO ] W-9000-youtubegoes5g_1.0 ACCESS_LOG - /127.0.0.1:37740 "POST /v1/models/youtubegoes5g:predict HTTP/1.1" 200 4
2025-01-22T18:39:42,821 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Inference performed successfully
2025-01-22T18:39:42,821 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571182
2025-01-22T18:39:42,821 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Output postprocessed successfully
2025-01-22T18:39:42,821 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:3860.483|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571182
2025-01-22T18:39:42,821 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:2.95|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,1737571182,a4c07d01-c9ea-4dcc-932e-3a2e5b9c2973, pattern=[METRICS]
2025-01-22T18:39:42,821 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:52.755|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571182
2025-01-22T18:39:42,821 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.job.Job - Waiting time ns: 52755, Backend time ns: 3947466
2025-01-22T18:39:42,821 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_METRICS - PredictionTime.ms:2.95|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,requestID:a4c07d01-c9ea-4dcc-932e-3a2e5b9c2973,timestamp:1737571182
2025-01-22T18:39:42,821 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571182
2025-01-22T18:39:42,821 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2025-01-22T18:39:42,821 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 4
2025-01-22T18:39:42,821 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571182
2025-01-22 18:39:42.822 kserve.trace requestId: c5a191fd-42bf-48f7-81f9-e90101224106, preprocess_ms: 0.010728836, explain_ms: 0, predict_ms: 7.601737976, postprocess_ms: 0.007390976
2025-01-22 18:39:42.822 uvicorn.access INFO:     10.233.75.99:0 9 - "POST /v1/models/youtubegoes5g%3Apredict HTTP/1.1" 200 OK
2025-01-22 18:39:42.823 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.008750677108764648
2025-01-22 18:39:42.823 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.004415000003064051
2025-01-22T18:39:54,840 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571194
2025-01-22T18:39:54,840 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1737571194840
2025-01-22T18:39:54,841 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Backend received inference at: 1737571194
2025-01-22T18:39:54,841 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Received data: [{'data': [13, 13, 13, 0, 13, 13, 13, 13, -76, -76, -81, -76, -78.5, -76, -76, -7, -7, -12, -7, -9.5, -7, -7, 12, 12, 7, 12, 9.5, 12, 12]}]
2025-01-22T18:39:54,842 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Input data preprocessed successfully
2025-01-22T18:39:54,844 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Inference performed successfully
2025-01-22T18:39:54,844 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Output postprocessed successfully
2025-01-22T18:39:54,844 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:3.18|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,1737571194,3394250b-69ee-47a8-9da0-3f19824e24d8, pattern=[METRICS]
2025-01-22T18:39:54,844 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_METRICS - PredictionTime.ms:3.18|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,requestID:3394250b-69ee-47a8-9da0-3f19824e24d8,timestamp:1737571194
2025-01-22T18:39:54,844 [INFO ] W-9000-youtubegoes5g_1.0 ACCESS_LOG - /127.0.0.1:51954 "POST /v1/models/youtubegoes5g:predict HTTP/1.1" 200 4
2025-01-22T18:39:54,845 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571194
2025-01-22T18:39:54,845 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:4260.413|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571194
2025-01-22T18:39:54,845 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:37.942|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571194
2025-01-22T18:39:54,845 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.job.Job - Waiting time ns: 37942, Backend time ns: 4371152
2025-01-22T18:39:54,845 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571194
2025-01-22T18:39:54,845 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2025-01-22T18:39:54,845 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 4
2025-01-22T18:39:54,845 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571194
2025-01-22 18:39:54.846 kserve.trace requestId: 45ba0c84-d624-4436-832c-2bca2df0a92a, preprocess_ms: 0.01335144, explain_ms: 0, predict_ms: 8.157968521, postprocess_ms: 0.004768372
2025-01-22 18:39:54.846 uvicorn.access INFO:     10.233.75.99:0 9 - "POST /v1/models/youtubegoes5g%3Apredict HTTP/1.1" 200 OK
2025-01-22 18:39:54.846 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.009063720703125
2025-01-22 18:39:54.846 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.004424999999173451
2025-01-22T18:40:06,864 [INFO ] epollEventLoopGroup-3-4 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571206
2025-01-22T18:40:06,864 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1737571206864
2025-01-22T18:40:06,864 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Backend received inference at: 1737571206
2025-01-22T18:40:06,864 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Received data: [{'data': [13, 13, 13, 0, 13, 13, 13, 13, -76, -76, -81, -76, -78.5, -76, -76, -7, -7, -12, -7, -9.5, -7, -7, 12, 12, 7, 12, 9.5, 12, 12]}]
2025-01-22T18:40:06,865 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Input data preprocessed successfully
2025-01-22T18:40:06,867 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Inference performed successfully
2025-01-22T18:40:06,867 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Output postprocessed successfully
2025-01-22T18:40:06,867 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:2.91|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,1737571206,2fb23c50-9a2b-49cd-a84c-9f40b79d08da, pattern=[METRICS]
2025-01-22T18:40:06,868 [INFO ] W-9000-youtubegoes5g_1.0 ACCESS_LOG - /127.0.0.1:60864 "POST /v1/models/youtubegoes5g:predict HTTP/1.1" 200 4
2025-01-22T18:40:06,868 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_METRICS - PredictionTime.ms:2.91|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,requestID:2fb23c50-9a2b-49cd-a84c-9f40b79d08da,timestamp:1737571206
2025-01-22T18:40:06,868 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571206
2025-01-22T18:40:06,868 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:3884.481|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571206
2025-01-22T18:40:06,868 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:46.412|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571206
2025-01-22T18:40:06,868 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.job.Job - Waiting time ns: 46412, Backend time ns: 4174235
2025-01-22T18:40:06,868 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571206
2025-01-22T18:40:06,868 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2025-01-22T18:40:06,868 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 4
2025-01-22T18:40:06,868 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571206
2025-01-22 18:40:06.869 kserve.trace requestId: f2ad039d-1844-4a95-afd3-ce04d060acf6, preprocess_ms: 0.01168251, explain_ms: 0, predict_ms: 8.054971695, postprocess_ms: 0.00500679
2025-01-22 18:40:06.869 uvicorn.access INFO:     10.233.75.99:0 9 - "POST /v1/models/youtubegoes5g%3Apredict HTTP/1.1" 200 OK
2025-01-22 18:40:06.870 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.009222984313964844
2025-01-22 18:40:06.870 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.004552999998850282
2025-01-22T18:40:18,886 [INFO ] epollEventLoopGroup-3-1 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571218
2025-01-22T18:40:18,886 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1737571218886
2025-01-22T18:40:18,887 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Backend received inference at: 1737571218
2025-01-22T18:40:18,887 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Received data: [{'data': [13, 13, 13, 0, 13, 13, 13, 13, -76, -76, -81, -76, -78.5, -76, -76, -7, -7, -12, -7, -9.5, -7, -7, 12, 12, 7, 12, 9.5, 12, 12]}]
2025-01-22T18:40:18,888 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Input data preprocessed successfully
2025-01-22T18:40:18,890 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Inference performed successfully
2025-01-22T18:40:18,890 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Output postprocessed successfully
2025-01-22T18:40:18,891 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:3.32|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,1737571218,d1bb8ead-cc0a-4718-9a22-a2b52244e4a3, pattern=[METRICS]
2025-01-22T18:40:18,891 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_METRICS - PredictionTime.ms:3.32|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,requestID:d1bb8ead-cc0a-4718-9a22-a2b52244e4a3,timestamp:1737571218
2025-01-22T18:40:18,891 [INFO ] W-9000-youtubegoes5g_1.0 ACCESS_LOG - /127.0.0.1:37896 "POST /v1/models/youtubegoes5g:predict HTTP/1.1" 200 5
2025-01-22T18:40:18,891 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571218
2025-01-22T18:40:18,891 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:4270.299|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571218
2025-01-22T18:40:18,891 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:29.235|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571218
2025-01-22T18:40:18,891 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.job.Job - Waiting time ns: 29235, Backend time ns: 4340624
2025-01-22T18:40:18,891 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571218
2025-01-22T18:40:18,891 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2025-01-22T18:40:18,891 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 4
2025-01-22T18:40:18,891 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571218
2025-01-22 18:40:18.892 kserve.trace requestId: e1c3e374-5bd7-4b9d-9d54-5fd14bb3ceda, preprocess_ms: 0.011920929, explain_ms: 0, predict_ms: 7.960796356, postprocess_ms: 0.004529953
2025-01-22 18:40:18.892 uvicorn.access INFO:     10.233.75.99:0 9 - "POST /v1/models/youtubegoes5g%3Apredict HTTP/1.1" 200 OK
2025-01-22 18:40:18.893 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.009115457534790039
2025-01-22 18:40:18.893 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.004322999999203603
2025-01-22T18:40:18,988 [INFO ] pool-3-thread-2 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571218
2025-01-22T18:40:18,988 [INFO ] pool-3-thread-2 TS_METRICS - DiskAvailable.Gigabytes:263.70869064331055|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571218
2025-01-22T18:40:18,988 [INFO ] pool-3-thread-2 TS_METRICS - DiskUsage.Gigabytes:208.29457473754883|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571218
2025-01-22T18:40:18,988 [INFO ] pool-3-thread-2 TS_METRICS - DiskUtilization.Percent:44.1|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571218
2025-01-22T18:40:18,988 [INFO ] pool-3-thread-2 TS_METRICS - MemoryAvailable.Megabytes:11277.87890625|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571218
2025-01-22T18:40:18,988 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUsed.Megabytes:8361.72265625|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571218
2025-01-22T18:40:18,989 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUtilization.Percent:43.6|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571218
2025-01-22T18:40:54,912 [INFO ] epollEventLoopGroup-3-2 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571254
2025-01-22T18:40:54,912 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1737571254912
2025-01-22T18:40:54,912 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Backend received inference at: 1737571254
2025-01-22T18:40:54,913 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Received data: [{'data': [13, 13, 13, 0, 13, 13, 13, 13, -76, -76, -81, -76, -78.5, -76, -76, -7, -7, -12, -7, -9.5, -7, -7, 12, 12, 7, 12, 9.5, 12, 12]}]
2025-01-22T18:40:54,913 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Input data preprocessed successfully
2025-01-22T18:40:54,917 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Inference performed successfully
2025-01-22T18:40:54,917 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Output postprocessed successfully
2025-01-22T18:40:54,917 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:2.8|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,1737571254,736aaad6-dcde-4aa8-ac62-055d081bc687, pattern=[METRICS]
2025-01-22T18:40:54,917 [INFO ] W-9000-youtubegoes5g_1.0 ACCESS_LOG - /127.0.0.1:33166 "POST /v1/models/youtubegoes5g:predict HTTP/1.1" 200 5
2025-01-22T18:40:54,917 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_METRICS - PredictionTime.ms:2.8|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,requestID:736aaad6-dcde-4aa8-ac62-055d081bc687,timestamp:1737571254
2025-01-22T18:40:54,917 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571254
2025-01-22T18:40:54,917 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:4936.153|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571254
2025-01-22T18:40:54,917 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:104.524|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571254
2025-01-22T18:40:54,917 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.job.Job - Waiting time ns: 104524, Backend time ns: 5178385
2025-01-22T18:40:54,917 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571254
2025-01-22T18:40:54,917 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2025-01-22T18:40:54,917 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 5
2025-01-22T18:40:54,917 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571254
2025-01-22 18:40:54.918 kserve.trace requestId: 2fbf6487-d37f-4b9b-b62b-245a848409c2, preprocess_ms: 0.021457672, explain_ms: 0, predict_ms: 9.255647659, postprocess_ms: 0.00500679
2025-01-22 18:40:54.918 uvicorn.access INFO:     10.233.75.99:0 9 - "POST /v1/models/youtubegoes5g%3Apredict HTTP/1.1" 200 OK
2025-01-22 18:40:54.918 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.010183334350585938
2025-01-22 18:40:54.918 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.00480999999854248
2025-01-22T18:41:06,935 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571266
2025-01-22T18:41:06,935 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1737571266935
2025-01-22T18:41:06,935 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Backend received inference at: 1737571266
2025-01-22T18:41:06,936 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Received data: [{'data': [13, 13, 13, 0, 13, 13, 13, 13, -76, -76, -81, -76, -78.5, -76, -76, -7, -7, -12, -7, -9.5, -7, -7, 12, 12, 7, 12, 9.5, 12, 12]}]
2025-01-22T18:41:06,936 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Input data preprocessed successfully
2025-01-22T18:41:06,938 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Inference performed successfully
2025-01-22T18:41:06,938 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Output postprocessed successfully
2025-01-22T18:41:06,938 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:1.73|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,1737571266,c81f33af-52b1-4637-90b4-772ce57fc7f2, pattern=[METRICS]
2025-01-22T18:41:06,938 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_METRICS - PredictionTime.ms:1.73|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,requestID:c81f33af-52b1-4637-90b4-772ce57fc7f2,timestamp:1737571266
2025-01-22T18:41:06,939 [INFO ] W-9000-youtubegoes5g_1.0 ACCESS_LOG - /127.0.0.1:49882 "POST /v1/models/youtubegoes5g:predict HTTP/1.1" 200 4
2025-01-22T18:41:06,939 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571266
2025-01-22T18:41:06,939 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:3904.141|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571266
2025-01-22T18:41:06,939 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:58.939|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571266
2025-01-22T18:41:06,939 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.job.Job - Waiting time ns: 58939, Backend time ns: 4104112
2025-01-22T18:41:06,939 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571266
2025-01-22T18:41:06,939 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2025-01-22T18:41:06,939 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 4
2025-01-22T18:41:06,939 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571266
2025-01-22 18:41:06.940 kserve.trace requestId: de942291-3a2c-4824-8898-132579a1ea31, preprocess_ms: 0.012159348, explain_ms: 0, predict_ms: 7.410049438, postprocess_ms: 0.004768372
2025-01-22 18:41:06.940 uvicorn.access INFO:     10.233.75.99:0 9 - "POST /v1/models/youtubegoes5g%3Apredict HTTP/1.1" 200 OK
2025-01-22 18:41:06.940 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.00824880599975586
2025-01-22 18:41:06.940 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.004000999999334454
2025-01-22T18:41:18,957 [INFO ] epollEventLoopGroup-3-4 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571278
2025-01-22T18:41:18,958 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1737571278958
2025-01-22T18:41:18,958 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Backend received inference at: 1737571278
2025-01-22T18:41:18,959 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Received data: [{'data': [13, 13, 13, 0, 13, 13, 13, 13, -76, -76, -81, -76, -78.5, -76, -76, -7, -7, -12, -7, -9.5, -7, -7, 12, 12, 7, 12, 9.5, 12, 12]}]
2025-01-22T18:41:18,959 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Input data preprocessed successfully
2025-01-22T18:41:18,962 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Inference performed successfully
2025-01-22T18:41:18,962 [INFO ] W-9000-youtubegoes5g_1.0 ACCESS_LOG - /127.0.0.1:33056 "POST /v1/models/youtubegoes5g:predict HTTP/1.1" 200 5
2025-01-22T18:41:18,962 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Output postprocessed successfully
2025-01-22T18:41:18,962 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571278
2025-01-22T18:41:18,962 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:1.7|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,1737571278,8aea6c49-1957-45e9-9915-5dcd1edff7bc, pattern=[METRICS]
2025-01-22T18:41:18,962 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:4237.269|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571278
2025-01-22T18:41:18,962 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_METRICS - PredictionTime.ms:1.7|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,requestID:8aea6c49-1957-45e9-9915-5dcd1edff7bc,timestamp:1737571278
2025-01-22T18:41:18,962 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:59.944|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571278
2025-01-22T18:41:18,962 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.job.Job - Waiting time ns: 59944, Backend time ns: 4478143
2025-01-22T18:41:18,962 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571278
2025-01-22T18:41:18,962 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2025-01-22T18:41:18,962 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 4
2025-01-22T18:41:18,962 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571278
2025-01-22 18:41:18.963 kserve.trace requestId: aed6ee2b-1312-4456-8a3c-c0056f6fd3ba, preprocess_ms: 0.011920929, explain_ms: 0, predict_ms: 8.227825165, postprocess_ms: 0.005245209
2025-01-22 18:41:18.965 uvicorn.access INFO:     10.233.75.99:0 9 - "POST /v1/models/youtubegoes5g%3Apredict HTTP/1.1" 200 OK
2025-01-22 18:41:18.966 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.011035919189453125
2025-01-22 18:41:18.966 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.0045429999991029035
2025-01-22T18:41:19,001 [INFO ] pool-3-thread-2 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571279
2025-01-22T18:41:19,001 [INFO ] pool-3-thread-2 TS_METRICS - DiskAvailable.Gigabytes:263.70843505859375|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571279
2025-01-22T18:41:19,001 [INFO ] pool-3-thread-2 TS_METRICS - DiskUsage.Gigabytes:208.29483032226562|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571279
2025-01-22T18:41:19,001 [INFO ] pool-3-thread-2 TS_METRICS - DiskUtilization.Percent:44.1|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571279
2025-01-22T18:41:19,001 [INFO ] pool-3-thread-2 TS_METRICS - MemoryAvailable.Megabytes:11269.828125|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571279
2025-01-22T18:41:19,001 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUsed.Megabytes:8369.7734375|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571279
2025-01-22T18:41:19,001 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUtilization.Percent:43.6|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571279
2025-01-22T18:41:30,983 [INFO ] epollEventLoopGroup-3-1 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571290
2025-01-22T18:41:30,983 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1737571290983
2025-01-22T18:41:30,984 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Backend received inference at: 1737571290
2025-01-22T18:41:30,984 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Received data: [{'data': [13, 13, 13, 0, 13, 13, 13, 13, -76, -76, -81, -76, -78.5, -76, -76, -7, -7, -12, -7, -9.5, -7, -7, 12, 12, 7, 12, 9.5, 12, 12]}]
2025-01-22T18:41:30,984 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Input data preprocessed successfully
2025-01-22T18:41:30,986 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Inference performed successfully
2025-01-22T18:41:30,986 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Output postprocessed successfully
2025-01-22T18:41:30,986 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:1.22|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,1737571290,1456c88a-1994-4cef-a336-3cea717ed25e, pattern=[METRICS]
2025-01-22T18:41:30,986 [INFO ] W-9000-youtubegoes5g_1.0 ACCESS_LOG - /127.0.0.1:49940 "POST /v1/models/youtubegoes5g:predict HTTP/1.1" 200 3
2025-01-22T18:41:30,986 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_METRICS - PredictionTime.ms:1.22|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,requestID:1456c88a-1994-4cef-a336-3cea717ed25e,timestamp:1737571290
2025-01-22T18:41:30,986 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571290
2025-01-22T18:41:30,987 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:3402.143|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571290
2025-01-22T18:41:30,987 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:95.421|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571290
2025-01-22T18:41:30,987 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.job.Job - Waiting time ns: 95421, Backend time ns: 3852849
2025-01-22T18:41:30,987 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571290
2025-01-22 18:41:30.988 kserve.trace requestId: d41b1c7f-403e-4f6e-97ed-ce132eed3eca, preprocess_ms: 0.012159348, explain_ms: 0, predict_ms: 7.879018784, postprocess_ms: 0.00500679
2025-01-22T18:41:30,987 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2025-01-22T18:41:30,987 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3
2025-01-22T18:41:30,987 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571290
2025-01-22 18:41:30.988 uvicorn.access INFO:     10.233.75.99:0 9 - "POST /v1/models/youtubegoes5g%3Apredict HTTP/1.1" 200 OK
2025-01-22 18:41:30.988 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.008702278137207031
2025-01-22 18:41:30.988 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.004042000000481494
2025-01-22T18:41:43,004 [INFO ] epollEventLoopGroup-3-2 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571303
2025-01-22T18:41:43,004 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1737571303004
2025-01-22T18:41:43,005 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Backend received inference at: 1737571303
2025-01-22T18:41:43,005 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Received data: [{'data': [13, 13, 13, 0, 13, 13, 13, 13, -76, -76, -81, -76, -78.5, -76, -76, -7, -7, -12, -7, -9.5, -7, -7, 12, 12, 7, 12, 9.5, 12, 12]}]
2025-01-22T18:41:43,005 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Input data preprocessed successfully
2025-01-22T18:41:43,006 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Inference performed successfully
2025-01-22T18:41:43,006 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Output postprocessed successfully
2025-01-22T18:41:43,006 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:1.38|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,1737571303,0c046e92-2ec1-468f-9a15-60b74f0807e3, pattern=[METRICS]
2025-01-22T18:41:43,006 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_METRICS - PredictionTime.ms:1.38|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,requestID:0c046e92-2ec1-468f-9a15-60b74f0807e3,timestamp:1737571303
2025-01-22T18:41:43,007 [INFO ] W-9000-youtubegoes5g_1.0 ACCESS_LOG - /127.0.0.1:58534 "POST /v1/models/youtubegoes5g:predict HTTP/1.1" 200 3
2025-01-22T18:41:43,008 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571303
2025-01-22T18:41:43,008 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:3514.119|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571303
2025-01-22T18:41:43,008 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:100.491|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571303
2025-01-22T18:41:43,008 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.job.Job - Waiting time ns: 100491, Backend time ns: 3679172
2025-01-22T18:41:43,008 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571303
2025-01-22T18:41:43,008 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2025-01-22T18:41:43,008 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3
2025-01-22T18:41:43,008 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571303
2025-01-22 18:41:43.009 kserve.trace requestId: f240ad56-2454-4649-981e-cf2ffefbd4c4, preprocess_ms: 0.011920929, explain_ms: 0, predict_ms: 7.51376152, postprocess_ms: 0.005722046
2025-01-22 18:41:43.009 uvicorn.access INFO:     10.233.75.99:0 9 - "POST /v1/models/youtubegoes5g%3Apredict HTTP/1.1" 200 OK
2025-01-22 18:41:43.009 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.008391857147216797
2025-01-22 18:41:43.010 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.0046600000005128095
2025-01-22T18:41:55,027 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571315
2025-01-22T18:41:55,027 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1737571315027
2025-01-22T18:41:55,028 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Backend received inference at: 1737571315
2025-01-22T18:41:55,029 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Received data: [{'data': [13, 13, 13, 0, 13, 13, 13, 13, -76, -76, -81, -76, -78.5, -76, -76, -7, -7, -12, -7, -9.5, -7, -7, 12, 12, 7, 12, 9.5, 12, 12]}]
2025-01-22T18:41:55,029 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Input data preprocessed successfully
2025-01-22T18:41:55,029 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Inference performed successfully
2025-01-22T18:41:55,029 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Output postprocessed successfully
2025-01-22T18:41:55,030 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:1.65|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,1737571315,7daae7ec-72bc-4f73-ac9e-bd33ba454f47, pattern=[METRICS]
2025-01-22T18:41:55,030 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_METRICS - PredictionTime.ms:1.65|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,requestID:7daae7ec-72bc-4f73-ac9e-bd33ba454f47,timestamp:1737571315
2025-01-22T18:41:55,030 [INFO ] W-9000-youtubegoes5g_1.0 ACCESS_LOG - /127.0.0.1:48820 "POST /v1/models/youtubegoes5g:predict HTTP/1.1" 200 3
2025-01-22T18:41:55,030 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571315
2025-01-22T18:41:55,030 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:2917.576|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571315
2025-01-22T18:41:55,031 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:40.466|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571315
2025-01-22T18:41:55,031 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.job.Job - Waiting time ns: 40466, Backend time ns: 3504901
2025-01-22T18:41:55,031 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571315
2025-01-22T18:41:55,031 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2025-01-22T18:41:55,031 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3
2025-01-22T18:41:55,031 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571315
2025-01-22 18:41:55.032 kserve.trace requestId: 98d5b200-0d2b-41a5-a1de-d00581aa6d3e, preprocess_ms: 0.011920929, explain_ms: 0, predict_ms: 8.152008057, postprocess_ms: 0.004529953
2025-01-22 18:41:55.032 uvicorn.access INFO:     10.233.75.99:0 9 - "POST /v1/models/youtubegoes5g%3Apredict HTTP/1.1" 200 OK
2025-01-22 18:41:55.032 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.008989095687866211
2025-01-22 18:41:55.032 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.0055310000007011695
2025-01-22T18:42:07,049 [INFO ] epollEventLoopGroup-3-4 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571327
2025-01-22T18:42:07,049 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1737571327049
2025-01-22T18:42:07,050 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Backend received inference at: 1737571327
2025-01-22T18:42:07,050 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Received data: [{'data': [13, 13, 13, 0, 13, 13, 13, 13, -76, -76, -81, -76, -78.5, -76, -76, -7, -7, -12, -7, -9.5, -7, -7, 12, 12, 7, 12, 9.5, 12, 12]}]
2025-01-22T18:42:07,051 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Input data preprocessed successfully
2025-01-22T18:42:07,051 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Inference performed successfully
2025-01-22T18:42:07,051 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Output postprocessed successfully
2025-01-22T18:42:07,052 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:1.35|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,1737571327,2126a59a-6cbd-488f-93f8-9a92c677e667, pattern=[METRICS]
2025-01-22T18:42:07,052 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_METRICS - PredictionTime.ms:1.35|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,requestID:2126a59a-6cbd-488f-93f8-9a92c677e667,timestamp:1737571327
2025-01-22T18:42:07,052 [INFO ] W-9000-youtubegoes5g_1.0 ACCESS_LOG - /127.0.0.1:36908 "POST /v1/models/youtubegoes5g:predict HTTP/1.1" 200 3
2025-01-22T18:42:07,052 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571327
2025-01-22T18:42:07,052 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:2415.733|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571327
2025-01-22T18:42:07,052 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:45.794|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571327
2025-01-22T18:42:07,052 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.job.Job - Waiting time ns: 45794, Backend time ns: 2542166
2025-01-22T18:42:07,052 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571327
2025-01-22T18:42:07,052 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2025-01-22T18:42:07,052 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2
2025-01-22T18:42:07,052 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571327
2025-01-22 18:42:07.053 kserve.trace requestId: 0a44ab87-d91f-49fc-b1be-16416a65ef1e, preprocess_ms: 0.012397766, explain_ms: 0, predict_ms: 6.376028061, postprocess_ms: 0.005245209
2025-01-22 18:42:07.054 uvicorn.access INFO:     10.233.75.99:0 9 - "POST /v1/models/youtubegoes5g%3Apredict HTTP/1.1" 200 OK
2025-01-22 18:42:07.054 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.007670879364013672
2025-01-22 18:42:07.054 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.00493099999948754
2025-01-22T18:42:18,992 [INFO ] pool-3-thread-2 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571338
2025-01-22T18:42:18,992 [INFO ] pool-3-thread-2 TS_METRICS - DiskAvailable.Gigabytes:263.7081604003906|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571338
2025-01-22T18:42:18,993 [INFO ] pool-3-thread-2 TS_METRICS - DiskUsage.Gigabytes:208.29510498046875|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571338
2025-01-22T18:42:18,993 [INFO ] pool-3-thread-2 TS_METRICS - DiskUtilization.Percent:44.1|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571338
2025-01-22T18:42:18,993 [INFO ] pool-3-thread-2 TS_METRICS - MemoryAvailable.Megabytes:11274.44140625|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571338
2025-01-22T18:42:18,993 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUsed.Megabytes:8365.16015625|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571338
2025-01-22T18:42:18,993 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUtilization.Percent:43.6|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571338
2025-01-22T18:42:19,071 [INFO ] epollEventLoopGroup-3-1 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571339
2025-01-22T18:42:19,071 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1737571339071
2025-01-22T18:42:19,072 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Backend received inference at: 1737571339
2025-01-22T18:42:19,072 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Received data: [{'data': [13, 13, 13, 0, 13, 13, 13, 13, -76, -76, -81, -76, -78.5, -76, -76, -7, -7, -12, -7, -9.5, -7, -7, 12, 12, 7, 12, 9.5, 12, 12]}]
2025-01-22T18:42:19,073 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Input data preprocessed successfully
2025-01-22T18:42:19,074 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Inference performed successfully
2025-01-22T18:42:19,074 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Output postprocessed successfully
2025-01-22T18:42:19,074 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:1.55|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,1737571339,738c5e49-8595-4a84-bfaa-7dac3158e0b3, pattern=[METRICS]
2025-01-22T18:42:19,074 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_METRICS - PredictionTime.ms:1.55|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,requestID:738c5e49-8595-4a84-bfaa-7dac3158e0b3,timestamp:1737571339
2025-01-22T18:42:19,074 [INFO ] W-9000-youtubegoes5g_1.0 ACCESS_LOG - /127.0.0.1:45120 "POST /v1/models/youtubegoes5g:predict HTTP/1.1" 200 3
2025-01-22T18:42:19,074 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571339
2025-01-22T18:42:19,074 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:2667.492|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571339
2025-01-22T18:42:19,074 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:67.686|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571339
2025-01-22T18:42:19,074 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.job.Job - Waiting time ns: 67686, Backend time ns: 2730359
2025-01-22T18:42:19,074 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571339
2025-01-22T18:42:19,074 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2025-01-22T18:42:19,074 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2
2025-01-22T18:42:19,074 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571339
2025-01-22 18:42:19.075 kserve.trace requestId: c3ce8135-fcc6-47b5-a8ac-969db1f9977b, preprocess_ms: 0.011920929, explain_ms: 0, predict_ms: 6.260871887, postprocess_ms: 0.004768372
2025-01-22 18:42:19.076 uvicorn.access INFO:     10.233.75.99:0 9 - "POST /v1/models/youtubegoes5g%3Apredict HTTP/1.1" 200 OK
2025-01-22 18:42:19.076 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.007368326187133789
2025-01-22 18:42:19.076 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.004317999999329913
2025-01-22T18:42:31,103 [INFO ] epollEventLoopGroup-3-2 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571351
2025-01-22T18:42:31,103 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1737571351103
2025-01-22T18:42:31,104 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Backend received inference at: 1737571351
2025-01-22T18:42:31,104 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Received data: [{'data': [13, 13, 13, 0, 13, 13, 13, 13, -76, -76, -81, -76, -78.5, -76, -76, -7, -7, -12, -7, -9.5, -7, -7, 12, 12, 7, 12, 9.5, 12, 12]}]
2025-01-22T18:42:31,108 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Input data preprocessed successfully
2025-01-22T18:42:31,108 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Inference performed successfully
2025-01-22T18:42:31,108 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Output postprocessed successfully
2025-01-22T18:42:31,109 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:4.74|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,1737571351,bd44da45-3c13-4076-bc6d-1f602e13b5a7, pattern=[METRICS]
2025-01-22T18:42:31,109 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_METRICS - PredictionTime.ms:4.74|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,requestID:bd44da45-3c13-4076-bc6d-1f602e13b5a7,timestamp:1737571351
2025-01-22T18:42:31,110 [INFO ] W-9000-youtubegoes5g_1.0 ACCESS_LOG - /127.0.0.1:41034 "POST /v1/models/youtubegoes5g:predict HTTP/1.1" 200 7
2025-01-22T18:42:31,110 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571351
2025-01-22T18:42:31,110 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:6887.936|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571351
2025-01-22T18:42:31,110 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:42.838|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571351
2025-01-22T18:42:31,110 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.job.Job - Waiting time ns: 42838, Backend time ns: 7099385
2025-01-22T18:42:31,110 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571351
2025-01-22T18:42:31,110 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2025-01-22T18:42:31,110 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 6
2025-01-22T18:42:31,110 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571351
2025-01-22 18:42:31.113 kserve.trace requestId: b1eafd4b-a1ba-4e2f-a3bd-40b2774b7b12, preprocess_ms: 0.012159348, explain_ms: 0, predict_ms: 11.702537537, postprocess_ms: 0.008583069
2025-01-22 18:42:31.113 uvicorn.access INFO:     10.233.75.99:0 9 - "POST /v1/models/youtubegoes5g%3Apredict HTTP/1.1" 200 OK
2025-01-22 18:42:31.114 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.013562440872192383
2025-01-22 18:42:31.114 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.005033000001276378
2025-01-22T18:42:43,132 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571363
2025-01-22T18:42:43,133 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1737571363133
2025-01-22T18:42:43,136 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Backend received inference at: 1737571363
2025-01-22T18:42:43,136 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Received data: [{'data': [13, 13, 13, 0, 13, 13, 13, 13, -76, -76, -81, -76, -78.5, -76, -76, -7, -7, -12, -7, -9.5, -7, -7, 12, 12, 7, 12, 9.5, 12, 12]}]
2025-01-22T18:42:43,136 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Input data preprocessed successfully
2025-01-22T18:42:43,138 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Inference performed successfully
2025-01-22T18:42:43,138 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Output postprocessed successfully
2025-01-22T18:42:43,138 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:4.6|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,1737571363,dea24d7e-9c5d-4813-938f-e62c03111781, pattern=[METRICS]
2025-01-22T18:42:43,138 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_METRICS - PredictionTime.ms:4.6|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,requestID:dea24d7e-9c5d-4813-938f-e62c03111781,timestamp:1737571363
2025-01-22T18:42:43,138 [INFO ] W-9000-youtubegoes5g_1.0 ACCESS_LOG - /127.0.0.1:53188 "POST /v1/models/youtubegoes5g:predict HTTP/1.1" 200 6
2025-01-22T18:42:43,138 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571363
2025-01-22T18:42:43,138 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:5605.395|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571363
2025-01-22T18:42:43,139 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:44.104|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571363
2025-01-22T18:42:43,139 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.job.Job - Waiting time ns: 44104, Backend time ns: 5852403
2025-01-22T18:42:43,139 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571363
2025-01-22T18:42:43,139 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2025-01-22T18:42:43,139 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 5
2025-01-22T18:42:43,139 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571363
2025-01-22 18:42:43.140 kserve.trace requestId: 6a4e13bc-b880-4680-964c-e0d6ae5a8162, preprocess_ms: 0.012397766, explain_ms: 0, predict_ms: 10.187864304, postprocess_ms: 0.005960464
2025-01-22 18:42:43.141 uvicorn.access INFO:     10.233.75.99:0 9 - "POST /v1/models/youtubegoes5g%3Apredict HTTP/1.1" 200 OK
2025-01-22 18:42:43.141 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.01138162612915039
2025-01-22 18:42:43.141 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.004415999999764608
2025-01-22T18:43:18,989 [INFO ] pool-3-thread-2 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571398
2025-01-22T18:43:18,990 [INFO ] pool-3-thread-2 TS_METRICS - DiskAvailable.Gigabytes:263.70791244506836|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571398
2025-01-22T18:43:18,990 [INFO ] pool-3-thread-2 TS_METRICS - DiskUsage.Gigabytes:208.29535293579102|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571398
2025-01-22T18:43:18,990 [INFO ] pool-3-thread-2 TS_METRICS - DiskUtilization.Percent:44.1|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571398
2025-01-22T18:43:18,990 [INFO ] pool-3-thread-2 TS_METRICS - MemoryAvailable.Megabytes:11282.0078125|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571398
2025-01-22T18:43:18,990 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUsed.Megabytes:8357.59375|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571398
2025-01-22T18:43:18,991 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUtilization.Percent:43.5|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571398
2025-01-22T18:43:19,160 [INFO ] epollEventLoopGroup-3-4 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571399
2025-01-22T18:43:19,160 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1737571399160
2025-01-22T18:43:19,161 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Backend received inference at: 1737571399
2025-01-22T18:43:19,161 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Received data: [{'data': [13, 13, 13, 0, 13, 13, 13, 13, -76, -76, -81, -76, -78.5, -76, -76, -7, -7, -12, -7, -9.5, -7, -7, 12, 12, 7, 12, 9.5, 12, 12]}]
2025-01-22T18:43:19,161 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Input data preprocessed successfully
2025-01-22T18:43:19,164 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Inference performed successfully
2025-01-22T18:43:19,164 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Output postprocessed successfully
2025-01-22T18:43:19,165 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:2.57|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,1737571399,da9294b0-b9e2-4494-b34a-622a076030a8, pattern=[METRICS]
2025-01-22T18:43:19,165 [INFO ] W-9000-youtubegoes5g_1.0 ACCESS_LOG - /127.0.0.1:49146 "POST /v1/models/youtubegoes5g:predict HTTP/1.1" 200 4
2025-01-22T18:43:19,165 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571399
2025-01-22T18:43:19,165 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:4676.164|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571399
2025-01-22T18:43:19,165 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:74.148|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571399
2025-01-22T18:43:19,165 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.job.Job - Waiting time ns: 74148, Backend time ns: 4785489
2025-01-22T18:43:19,165 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571399
2025-01-22T18:43:19,165 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2025-01-22T18:43:19,165 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 4
2025-01-22T18:43:19,165 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571399
2025-01-22T18:43:19,165 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_METRICS - PredictionTime.ms:2.57|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,requestID:da9294b0-b9e2-4494-b34a-622a076030a8,timestamp:1737571399
2025-01-22 18:43:19.166 kserve.trace requestId: 0858e6c0-aa17-4ffd-90e9-4d6cdb77d14f, preprocess_ms: 0.010728836, explain_ms: 0, predict_ms: 9.100914001, postprocess_ms: 0.00500679
2025-01-22 18:43:19.166 uvicorn.access INFO:     10.233.75.99:0 9 - "POST /v1/models/youtubegoes5g%3Apredict HTTP/1.1" 200 OK
2025-01-22 18:43:19.166 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.010191679000854492
2025-01-22 18:43:19.166 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.005123999999341322
2025-01-22T18:43:31,183 [INFO ] epollEventLoopGroup-3-1 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571411
2025-01-22T18:43:31,184 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1737571411184
2025-01-22T18:43:31,184 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Backend received inference at: 1737571411
2025-01-22T18:43:31,184 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Received data: [{'data': [13, 13, 13, 0, 13, 13, 13, 13, -76, -76, -81, -76, -78.5, -76, -76, -7, -7, -12, -7, -9.5, -7, -7, 12, 12, 7, 12, 9.5, 12, 12]}]
2025-01-22T18:43:31,185 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Input data preprocessed successfully
2025-01-22T18:43:31,186 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Inference performed successfully
2025-01-22T18:43:31,187 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Output postprocessed successfully
2025-01-22T18:43:31,187 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:2.11|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,1737571411,61aa951f-032b-498d-b148-4813a1176535, pattern=[METRICS]
2025-01-22T18:43:31,187 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_METRICS - PredictionTime.ms:2.11|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,requestID:61aa951f-032b-498d-b148-4813a1176535,timestamp:1737571411
2025-01-22T18:43:31,187 [INFO ] W-9000-youtubegoes5g_1.0 ACCESS_LOG - /127.0.0.1:48922 "POST /v1/models/youtubegoes5g:predict HTTP/1.1" 200 4
2025-01-22T18:43:31,187 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571411
2025-01-22T18:43:31,187 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:3182.064|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571411
2025-01-22T18:43:31,187 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:30.056|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571411
2025-01-22T18:43:31,187 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.job.Job - Waiting time ns: 30056, Backend time ns: 3742458
2025-01-22T18:43:31,187 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571411
2025-01-22T18:43:31,187 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2025-01-22T18:43:31,187 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3
2025-01-22T18:43:31,188 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571411
2025-01-22 18:43:31.188 kserve.trace requestId: b8554a16-8f84-4b0b-8ec8-3773626c4fe4, preprocess_ms: 0.044584274, explain_ms: 0, predict_ms: 7.222890854, postprocess_ms: 0.006437302
2025-01-22 18:43:31.189 uvicorn.access INFO:     10.233.75.99:0 9 - "POST /v1/models/youtubegoes5g%3Apredict HTTP/1.1" 200 OK
2025-01-22 18:43:31.189 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.008354663848876953
2025-01-22 18:43:31.189 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.004626999998436077
2025-01-22T18:43:43,206 [INFO ] epollEventLoopGroup-3-2 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571423
2025-01-22T18:43:43,206 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1737571423206
2025-01-22T18:43:43,208 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Backend received inference at: 1737571423
2025-01-22T18:43:43,209 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Received data: [{'data': [13, 13, 13, 0, 13, 13, 13, 13, -76, -76, -81, -76, -78.5, -76, -76, -7, -7, -12, -7, -9.5, -7, -7, 12, 12, 7, 12, 9.5, 12, 12]}]
2025-01-22T18:43:43,209 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Input data preprocessed successfully
2025-01-22T18:43:43,209 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Inference performed successfully
2025-01-22T18:43:43,209 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Output postprocessed successfully
2025-01-22T18:43:43,209 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:2.31|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,1737571423,410ea39e-0f2c-414b-adbe-403116bf5711, pattern=[METRICS]
2025-01-22T18:43:43,209 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_METRICS - PredictionTime.ms:2.31|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,requestID:410ea39e-0f2c-414b-adbe-403116bf5711,timestamp:1737571423
2025-01-22T18:43:43,209 [INFO ] W-9000-youtubegoes5g_1.0 ACCESS_LOG - /127.0.0.1:54518 "POST /v1/models/youtubegoes5g:predict HTTP/1.1" 200 3
2025-01-22T18:43:43,209 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571423
2025-01-22T18:43:43,210 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:3577.805|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571423
2025-01-22T18:43:43,210 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:212.301|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571423
2025-01-22T18:43:43,210 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.job.Job - Waiting time ns: 212301, Backend time ns: 3581461
2025-01-22T18:43:43,210 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571423
2025-01-22T18:43:43,210 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2025-01-22T18:43:43,210 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3
2025-01-22T18:43:43,210 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571423
2025-01-22 18:43:43.211 kserve.trace requestId: e4a33b38-047c-478f-baab-7825db8d7198, preprocess_ms: 0.011205673, explain_ms: 0, predict_ms: 7.328033447, postprocess_ms: 0.004529953
2025-01-22 18:43:43.211 uvicorn.access INFO:     10.233.75.99:0 9 - "POST /v1/models/youtubegoes5g%3Apredict HTTP/1.1" 200 OK
2025-01-22 18:43:43.211 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.00833439826965332
2025-01-22 18:43:43.211 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.004275999999663327
2025-01-22T18:43:55,229 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571435
2025-01-22T18:43:55,229 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1737571435229
2025-01-22T18:43:55,230 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Backend received inference at: 1737571435
2025-01-22T18:43:55,230 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Received data: [{'data': [13, 13, 13, 0, 13, 13, 13, 13, -76, -76, -81, -76, -78.5, -76, -76, -7, -7, -12, -7, -9.5, -7, -7, 12, 12, 7, 12, 9.5, 12, 12]}]
2025-01-22T18:43:55,230 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Input data preprocessed successfully
2025-01-22T18:43:55,231 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Inference performed successfully
2025-01-22T18:43:55,231 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Output postprocessed successfully
2025-01-22T18:43:55,231 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:1.46|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,1737571435,246787df-222a-40cc-b787-d9cea0504413, pattern=[METRICS]
2025-01-22T18:43:55,231 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_METRICS - PredictionTime.ms:1.46|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,requestID:246787df-222a-40cc-b787-d9cea0504413,timestamp:1737571435
2025-01-22T18:43:55,231 [INFO ] W-9000-youtubegoes5g_1.0 ACCESS_LOG - /127.0.0.1:51116 "POST /v1/models/youtubegoes5g:predict HTTP/1.1" 200 2
2025-01-22T18:43:55,232 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571435
2025-01-22T18:43:55,232 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:2475.819|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571435
2025-01-22T18:43:55,232 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:70.45|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571435
2025-01-22T18:43:55,232 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.job.Job - Waiting time ns: 70450, Backend time ns: 2542007
2025-01-22T18:43:55,232 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571435
2025-01-22T18:43:55,232 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2025-01-22T18:43:55,232 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1
2025-01-22T18:43:55,232 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:2.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571435
2025-01-22 18:43:55.233 kserve.trace requestId: d29e6596-90c7-40a5-afcf-dcf9aa64cd05, preprocess_ms: 0.012636185, explain_ms: 0, predict_ms: 6.596326828, postprocess_ms: 0.004053116
2025-01-22 18:43:55.233 uvicorn.access INFO:     10.233.75.99:0 9 - "POST /v1/models/youtubegoes5g%3Apredict HTTP/1.1" 200 OK
2025-01-22 18:43:55.234 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.007433176040649414
2025-01-22 18:43:55.234 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.004079999998793937
2025-01-22T18:44:07,252 [INFO ] epollEventLoopGroup-3-4 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571447
2025-01-22T18:44:07,252 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1737571447252
2025-01-22T18:44:07,253 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Backend received inference at: 1737571447
2025-01-22T18:44:07,253 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Received data: [{'data': [13, 13, 13, 0, 13, 13, 13, 13, -76, -76, -81, -76, -78.5, -76, -76, -7, -7, -12, -7, -9.5, -7, -7, 12, 12, 7, 12, 9.5, 12, 12]}]
2025-01-22T18:44:07,253 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Input data preprocessed successfully
2025-01-22T18:44:07,254 [INFO ] W-9000-youtubegoes5g_1.0 ACCESS_LOG - /127.0.0.1:41598 "POST /v1/models/youtubegoes5g:predict HTTP/1.1" 200 2
2025-01-22T18:44:07,254 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571447
2025-01-22T18:44:07,254 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:2420.063|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571447
2025-01-22T18:44:07,254 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:121.268|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571447
2025-01-22T18:44:07,254 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.job.Job - Waiting time ns: 121268, Backend time ns: 2598417
2025-01-22T18:44:07,254 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571447
2025-01-22T18:44:07,255 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2025-01-22T18:44:07,255 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2
2025-01-22T18:44:07,255 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571447
2025-01-22T18:44:07,255 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Inference performed successfully
2025-01-22T18:44:07,256 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Output postprocessed successfully
2025-01-22T18:44:07,256 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:1.45|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,1737571447,c2aa5b60-d4d8-4646-9e64-f09171b7c1cc, pattern=[METRICS]
2025-01-22T18:44:07,256 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_METRICS - PredictionTime.ms:1.45|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,requestID:c2aa5b60-d4d8-4646-9e64-f09171b7c1cc,timestamp:1737571447
2025-01-22 18:44:07.257 kserve.trace requestId: 0197f5f2-3759-4ece-9841-d30dd9a1a022, preprocess_ms: 0.012397766, explain_ms: 0, predict_ms: 7.102251053, postprocess_ms: 0.0
2025-01-22 18:44:07.257 uvicorn.access INFO:     10.233.75.99:0 9 - "POST /v1/models/youtubegoes5g%3Apredict HTTP/1.1" 200 OK
2025-01-22 18:44:07.257 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.00810098648071289
2025-01-22 18:44:07.257 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.004366999999547261
2025-01-22T18:44:19,001 [INFO ] pool-3-thread-2 TS_METRICS - CPUUtilization.Percent:50.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571459
2025-01-22T18:44:19,002 [INFO ] pool-3-thread-2 TS_METRICS - DiskAvailable.Gigabytes:263.70765686035156|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571459
2025-01-22T18:44:19,002 [INFO ] pool-3-thread-2 TS_METRICS - DiskUsage.Gigabytes:208.2956085205078|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571459
2025-01-22T18:44:19,002 [INFO ] pool-3-thread-2 TS_METRICS - DiskUtilization.Percent:44.1|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571459
2025-01-22T18:44:19,002 [INFO ] pool-3-thread-2 TS_METRICS - MemoryAvailable.Megabytes:11285.8203125|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571459
2025-01-22T18:44:19,002 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUsed.Megabytes:8353.78125|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571459
2025-01-22T18:44:19,002 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUtilization.Percent:43.5|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571459
2025-01-22T18:44:19,274 [INFO ] epollEventLoopGroup-3-1 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571459
2025-01-22T18:44:19,274 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1737571459274
2025-01-22T18:44:19,275 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Backend received inference at: 1737571459
2025-01-22T18:44:19,275 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Received data: [{'data': [13, 13, 13, 0, 13, 13, 13, 13, -76, -76, -81, -76, -78.5, -76, -76, -7, -7, -12, -7, -9.5, -7, -7, 12, 12, 7, 12, 9.5, 12, 12]}]
2025-01-22T18:44:19,275 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Input data preprocessed successfully
2025-01-22T18:44:19,276 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Inference performed successfully
2025-01-22T18:44:19,276 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Output postprocessed successfully
2025-01-22T18:44:19,276 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:1.34|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,1737571459,9ad5ae52-8576-4813-9382-a98fbf762482, pattern=[METRICS]
2025-01-22T18:44:19,276 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_METRICS - PredictionTime.ms:1.34|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,requestID:9ad5ae52-8576-4813-9382-a98fbf762482,timestamp:1737571459
2025-01-22T18:44:19,276 [INFO ] W-9000-youtubegoes5g_1.0 ACCESS_LOG - /127.0.0.1:43368 "POST /v1/models/youtubegoes5g:predict HTTP/1.1" 200 2
2025-01-22T18:44:19,276 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571459
2025-01-22T18:44:19,276 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:2419.969|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571459
2025-01-22T18:44:19,276 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:29.402|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571459
2025-01-22T18:44:19,276 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.job.Job - Waiting time ns: 29402, Backend time ns: 2573528
2025-01-22T18:44:19,276 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571459
2025-01-22T18:44:19,276 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2025-01-22T18:44:19,276 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2
2025-01-22T18:44:19,277 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571459
2025-01-22 18:44:19.278 kserve.trace requestId: a989c709-a8d3-44e6-ab50-563043e1530c, preprocess_ms: 0.011920929, explain_ms: 0, predict_ms: 7.216215134, postprocess_ms: 0.004768372
2025-01-22 18:44:19.278 uvicorn.access INFO:     10.233.75.99:0 9 - "POST /v1/models/youtubegoes5g%3Apredict HTTP/1.1" 200 OK
2025-01-22 18:44:19.279 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.008034706115722656
2025-01-22 18:44:19.279 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.0046380000003409805
2025-01-22T18:44:31,297 [INFO ] epollEventLoopGroup-3-2 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571471
2025-01-22T18:44:31,297 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1737571471297
2025-01-22T18:44:31,298 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Backend received inference at: 1737571471
2025-01-22T18:44:31,298 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Received data: [{'data': [13, 13, 13, 0, 13, 13, 13, 13, -76, -76, -81, -76, -78.5, -76, -76, -7, -7, -12, -7, -9.5, -7, -7, 12, 12, 7, 12, 9.5, 12, 12]}]
2025-01-22T18:44:31,299 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Input data preprocessed successfully
2025-01-22T18:44:31,299 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Inference performed successfully
2025-01-22T18:44:31,299 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Output postprocessed successfully
2025-01-22T18:44:31,299 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:1.56|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,1737571471,5b4f9810-7da2-4fcc-854e-7bd9ca9e15f4, pattern=[METRICS]
2025-01-22T18:44:31,299 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_METRICS - PredictionTime.ms:1.56|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,requestID:5b4f9810-7da2-4fcc-854e-7bd9ca9e15f4,timestamp:1737571471
2025-01-22T18:44:31,300 [INFO ] W-9000-youtubegoes5g_1.0 ACCESS_LOG - /127.0.0.1:52304 "POST /v1/models/youtubegoes5g:predict HTTP/1.1" 200 3
2025-01-22T18:44:31,300 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571471
2025-01-22T18:44:31,300 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:2517.369|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571471
2025-01-22T18:44:31,300 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:74.258|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571471
2025-01-22T18:44:31,300 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.job.Job - Waiting time ns: 74258, Backend time ns: 2543706
2025-01-22T18:44:31,300 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571471
2025-01-22T18:44:31,300 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2025-01-22T18:44:31,300 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3
2025-01-22T18:44:31,300 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571471
2025-01-22 18:44:31.302 kserve.trace requestId: 66b87cf4-66c3-4b1e-8714-9b747fb6c280, preprocess_ms: 0.01168251, explain_ms: 0, predict_ms: 7.668733597, postprocess_ms: 0.005483627
2025-01-22 18:44:31.302 uvicorn.access INFO:     10.233.75.99:0 9 - "POST /v1/models/youtubegoes5g%3Apredict HTTP/1.1" 200 OK
2025-01-22 18:44:31.302 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.008590221405029297
2025-01-22 18:44:31.302 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.004854000000705128
2025-01-22T18:44:43,321 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571483
2025-01-22T18:44:43,321 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1737571483321
2025-01-22T18:44:43,322 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Backend received inference at: 1737571483
2025-01-22T18:44:43,322 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Received data: [{'data': [13, 13, 13, 0, 13, 13, 13, 13, -76, -76, -81, -76, -78.5, -76, -76, -7, -7, -12, -7, -9.5, -7, -7, 12, 12, 7, 12, 9.5, 12, 12]}]
2025-01-22T18:44:43,323 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Input data preprocessed successfully
2025-01-22T18:44:43,323 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Inference performed successfully
2025-01-22T18:44:43,323 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Output postprocessed successfully
2025-01-22T18:44:43,323 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:1.38|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,1737571483,addfbc19-e962-4ed3-8270-d2fb362cbf8f, pattern=[METRICS]
2025-01-22T18:44:43,323 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_METRICS - PredictionTime.ms:1.38|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,requestID:addfbc19-e962-4ed3-8270-d2fb362cbf8f,timestamp:1737571483
2025-01-22T18:44:43,324 [INFO ] W-9000-youtubegoes5g_1.0 ACCESS_LOG - /127.0.0.1:54274 "POST /v1/models/youtubegoes5g:predict HTTP/1.1" 200 3
2025-01-22T18:44:43,324 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571483
2025-01-22T18:44:43,324 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:2370.388|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571483
2025-01-22T18:44:43,324 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:37.271|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571483
2025-01-22T18:44:43,324 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.job.Job - Waiting time ns: 37271, Backend time ns: 2461379
2025-01-22T18:44:43,324 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571483
2025-01-22T18:44:43,324 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2025-01-22T18:44:43,324 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3
2025-01-22T18:44:43,324 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571483
2025-01-22 18:44:43.326 kserve.trace requestId: 05a5dfc3-90ef-46e1-835f-6c0d45f59c47, preprocess_ms: 0.011920929, explain_ms: 0, predict_ms: 7.401704788, postprocess_ms: 0.015735626
2025-01-22 18:44:43.326 uvicorn.access INFO:     10.233.75.99:0 9 - "POST /v1/models/youtubegoes5g%3Apredict HTTP/1.1" 200 OK
2025-01-22 18:44:43.326 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.008321046829223633
2025-01-22 18:44:43.326 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.004441999999471591
2025-01-22T18:44:55,344 [INFO ] epollEventLoopGroup-3-4 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571495
2025-01-22T18:44:55,344 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1737571495344
2025-01-22T18:44:55,345 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Backend received inference at: 1737571495
2025-01-22T18:44:55,345 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Received data: [{'data': [13, 13, 13, 0, 13, 13, 13, 13, -76, -76, -81, -76, -78.5, -76, -76, -7, -7, -12, -7, -9.5, -7, -7, 12, 12, 7, 12, 9.5, 12, 12]}]
2025-01-22T18:44:55,346 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Input data preprocessed successfully
2025-01-22T18:44:55,346 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Inference performed successfully
2025-01-22T18:44:55,346 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Output postprocessed successfully
2025-01-22T18:44:55,347 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:1.67|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,1737571495,219f7415-a912-4a0b-a08e-4b9b11030344, pattern=[METRICS]
2025-01-22T18:44:55,347 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_METRICS - PredictionTime.ms:1.67|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,requestID:219f7415-a912-4a0b-a08e-4b9b11030344,timestamp:1737571495
2025-01-22T18:44:55,347 [INFO ] W-9000-youtubegoes5g_1.0 ACCESS_LOG - /127.0.0.1:35396 "POST /v1/models/youtubegoes5g:predict HTTP/1.1" 200 3
2025-01-22T18:44:55,347 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571495
2025-01-22T18:44:55,347 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:2836.775|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571495
2025-01-22T18:44:55,347 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:119.403|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571495
2025-01-22T18:44:55,347 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.job.Job - Waiting time ns: 119403, Backend time ns: 2878230
2025-01-22T18:44:55,347 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571495
2025-01-22T18:44:55,347 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2025-01-22T18:44:55,347 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3
2025-01-22T18:44:55,347 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571495
2025-01-22 18:44:55.348 kserve.trace requestId: f6a218f4-18dd-483d-8a54-e880125b89fd, preprocess_ms: 0.012636185, explain_ms: 0, predict_ms: 6.87623024, postprocess_ms: 0.003814697
2025-01-22 18:44:55.349 uvicorn.access INFO:     10.233.75.99:0 9 - "POST /v1/models/youtubegoes5g%3Apredict HTTP/1.1" 200 OK
2025-01-22 18:44:55.350 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.00891876220703125
2025-01-22 18:44:55.350 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.005160000000614673
2025-01-22T18:45:07,367 [INFO ] epollEventLoopGroup-3-1 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571507
2025-01-22T18:45:07,368 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1737571507368
2025-01-22T18:45:07,368 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Backend received inference at: 1737571507
2025-01-22T18:45:07,368 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Received data: [{'data': [13, 13, 13, 0, 13, 13, 13, 13, -76, -76, -81, -76, -78.5, -76, -76, -7, -7, -12, -7, -9.5, -7, -7, 12, 12, 7, 12, 9.5, 12, 12]}]
2025-01-22T18:45:07,369 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Input data preprocessed successfully
2025-01-22T18:45:07,369 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Inference performed successfully
2025-01-22T18:45:07,370 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Output postprocessed successfully
2025-01-22T18:45:07,370 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:1.34|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,1737571507,4f043b82-3b3f-4114-834e-b78d7712ad7f, pattern=[METRICS]
2025-01-22T18:45:07,370 [INFO ] W-9000-youtubegoes5g_1.0 ACCESS_LOG - /127.0.0.1:54106 "POST /v1/models/youtubegoes5g:predict HTTP/1.1" 200 3
2025-01-22T18:45:07,370 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571507
2025-01-22T18:45:07,370 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:2374.125|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571507
2025-01-22T18:45:07,370 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:97.219|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571507
2025-01-22T18:45:07,370 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.job.Job - Waiting time ns: 97219, Backend time ns: 2429027
2025-01-22T18:45:07,370 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571507
2025-01-22T18:45:07,370 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2025-01-22T18:45:07,370 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2
2025-01-22T18:45:07,370 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571507
2025-01-22T18:45:07,370 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_METRICS - PredictionTime.ms:1.34|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,requestID:4f043b82-3b3f-4114-834e-b78d7712ad7f,timestamp:1737571507
2025-01-22 18:45:07.371 kserve.trace requestId: 4b92b7ca-efeb-48c0-946a-ace951ab0d8d, preprocess_ms: 0.011920929, explain_ms: 0, predict_ms: 6.471395493, postprocess_ms: 0.004291534
2025-01-22 18:45:07.372 uvicorn.access INFO:     10.233.75.99:0 9 - "POST /v1/models/youtubegoes5g%3Apredict HTTP/1.1" 200 OK
2025-01-22 18:45:07.372 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.0078089237213134766
2025-01-22 18:45:07.372 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.004527000000962289
2025-01-22T18:45:18,993 [INFO ] pool-3-thread-2 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571518
2025-01-22T18:45:18,993 [INFO ] pool-3-thread-2 TS_METRICS - DiskAvailable.Gigabytes:263.70735931396484|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571518
2025-01-22T18:45:18,994 [INFO ] pool-3-thread-2 TS_METRICS - DiskUsage.Gigabytes:208.29590606689453|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571518
2025-01-22T18:45:18,994 [INFO ] pool-3-thread-2 TS_METRICS - DiskUtilization.Percent:44.1|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571518
2025-01-22T18:45:18,994 [INFO ] pool-3-thread-2 TS_METRICS - MemoryAvailable.Megabytes:11280.109375|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571518
2025-01-22T18:45:18,994 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUsed.Megabytes:8359.49609375|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571518
2025-01-22T18:45:18,994 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUtilization.Percent:43.5|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571518
2025-01-22T18:45:43,390 [INFO ] epollEventLoopGroup-3-2 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571543
2025-01-22T18:45:43,390 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1737571543390
2025-01-22T18:45:43,391 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Backend received inference at: 1737571543
2025-01-22T18:45:43,391 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Received data: [{'data': [13, 13, 13, 0, 13, 13, 13, 13, -76, -76, -81, -76, -78.5, -76, -76, -7, -7, -12, -7, -9.5, -7, -7, 12, 12, 7, 12, 9.5, 12, 12]}]
2025-01-22T18:45:43,391 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Input data preprocessed successfully
2025-01-22T18:45:43,392 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Inference performed successfully
2025-01-22T18:45:43,392 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Output postprocessed successfully
2025-01-22T18:45:43,392 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:1.32|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,1737571543,93adea52-f546-40f3-a4cf-c22c64ce8603, pattern=[METRICS]
2025-01-22T18:45:43,392 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_METRICS - PredictionTime.ms:1.32|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,requestID:93adea52-f546-40f3-a4cf-c22c64ce8603,timestamp:1737571543
2025-01-22T18:45:43,392 [INFO ] W-9000-youtubegoes5g_1.0 ACCESS_LOG - /127.0.0.1:42416 "POST /v1/models/youtubegoes5g:predict HTTP/1.1" 200 2
2025-01-22T18:45:43,392 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571543
2025-01-22T18:45:43,392 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:2160.911|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571543
2025-01-22T18:45:43,392 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:39.852|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571543
2025-01-22T18:45:43,392 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.job.Job - Waiting time ns: 39852, Backend time ns: 2257337
2025-01-22T18:45:43,392 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571543
2025-01-22T18:45:43,392 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2025-01-22T18:45:43,392 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2
2025-01-22T18:45:43,392 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571543
2025-01-22 18:45:43.393 kserve.trace requestId: 9c6665b6-a5fa-433f-b71a-401766d40ae0, preprocess_ms: 0.012159348, explain_ms: 0, predict_ms: 6.369113922, postprocess_ms: 0.0
2025-01-22 18:45:43.394 uvicorn.access INFO:     10.233.75.99:0 9 - "POST /v1/models/youtubegoes5g%3Apredict HTTP/1.1" 200 OK
2025-01-22 18:45:43.394 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.0072362422943115234
2025-01-22 18:45:43.394 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.0046469999997498235
2025-01-22T18:45:55,410 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571555
2025-01-22T18:45:55,411 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1737571555411
2025-01-22T18:45:55,411 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Backend received inference at: 1737571555
2025-01-22T18:45:55,411 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Received data: [{'data': [13, 13, 13, 0, 13, 13, 13, 13, -76, -76, -81, -76, -78.5, -76, -76, -7, -7, -12, -7, -9.5, -7, -7, 12, 12, 7, 12, 9.5, 12, 12]}]
2025-01-22T18:45:55,412 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Input data preprocessed successfully
2025-01-22T18:45:55,413 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Inference performed successfully
2025-01-22T18:45:55,413 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Output postprocessed successfully
2025-01-22T18:45:55,413 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:1.47|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,1737571555,512afd37-606b-448c-9892-9afc7f559748, pattern=[METRICS]
2025-01-22T18:45:55,413 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_METRICS - PredictionTime.ms:1.47|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,requestID:512afd37-606b-448c-9892-9afc7f559748,timestamp:1737571555
2025-01-22T18:45:55,413 [INFO ] W-9000-youtubegoes5g_1.0 ACCESS_LOG - /127.0.0.1:50028 "POST /v1/models/youtubegoes5g:predict HTTP/1.1" 200 3
2025-01-22T18:45:55,413 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571555
2025-01-22T18:45:55,413 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:2422.221|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571555
2025-01-22T18:45:55,413 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:46.577|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571555
2025-01-22T18:45:55,413 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.job.Job - Waiting time ns: 46577, Backend time ns: 2510722
2025-01-22T18:45:55,413 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571555
2025-01-22T18:45:55,413 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2025-01-22T18:45:55,413 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2
2025-01-22T18:45:55,413 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571555
2025-01-22 18:45:55.415 kserve.trace requestId: 80bfefb2-7603-4785-87a3-cffe31e1500a, preprocess_ms: 0.011920929, explain_ms: 0, predict_ms: 6.749391556, postprocess_ms: 0.005722046
2025-01-22 18:45:55.415 uvicorn.access INFO:     10.233.75.99:0 9 - "POST /v1/models/youtubegoes5g%3Apredict HTTP/1.1" 200 OK
2025-01-22 18:45:55.416 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.00771641731262207
2025-01-22 18:45:55.416 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.004141999999774271
2025-01-22T18:46:07,433 [INFO ] epollEventLoopGroup-3-4 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571567
2025-01-22T18:46:07,433 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1737571567433
2025-01-22T18:46:07,434 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Backend received inference at: 1737571567
2025-01-22T18:46:07,434 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Received data: [{'data': [13, 13, 13, 0, 13, 13, 13, 13, -76, -76, -81, -76, -78.5, -76, -76, -7, -7, -12, -7, -9.5, -7, -7, 12, 12, 7, 12, 9.5, 12, 12]}]
2025-01-22T18:46:07,435 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Input data preprocessed successfully
2025-01-22T18:46:07,436 [INFO ] W-9000-youtubegoes5g_1.0 ACCESS_LOG - /127.0.0.1:36414 "POST /v1/models/youtubegoes5g:predict HTTP/1.1" 200 3
2025-01-22T18:46:07,436 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571567
2025-01-22T18:46:07,436 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:2426.939|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571567
2025-01-22T18:46:07,436 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Inference performed successfully
2025-01-22T18:46:07,436 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Output postprocessed successfully
2025-01-22T18:46:07,436 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:1.39|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,1737571567,4f69dc89-9e76-4087-8633-65497310c0d8, pattern=[METRICS]
2025-01-22T18:46:07,436 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:100.977|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571567
2025-01-22T18:46:07,436 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_METRICS - PredictionTime.ms:1.39|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,requestID:4f69dc89-9e76-4087-8633-65497310c0d8,timestamp:1737571567
2025-01-22T18:46:07,436 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.job.Job - Waiting time ns: 100977, Backend time ns: 2675908
2025-01-22T18:46:07,436 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571567
2025-01-22T18:46:07,436 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2025-01-22T18:46:07,436 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2
2025-01-22T18:46:07,436 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571567
2025-01-22 18:46:07.437 kserve.trace requestId: 437f7be5-0354-49be-9e67-0da7a6f3c71e, preprocess_ms: 0.011444092, explain_ms: 0, predict_ms: 7.097005844, postprocess_ms: 0.005483627
2025-01-22 18:46:07.438 uvicorn.access INFO:     10.233.75.99:0 9 - "POST /v1/models/youtubegoes5g%3Apredict HTTP/1.1" 200 OK
2025-01-22 18:46:07.438 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.00806736946105957
2025-01-22 18:46:07.438 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.0047089999989111675
2025-01-22T18:46:18,992 [INFO ] pool-3-thread-2 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571578
2025-01-22T18:46:18,992 [INFO ] pool-3-thread-2 TS_METRICS - DiskAvailable.Gigabytes:263.70713806152344|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571578
2025-01-22T18:46:18,992 [INFO ] pool-3-thread-2 TS_METRICS - DiskUsage.Gigabytes:208.29612731933594|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571578
2025-01-22T18:46:18,992 [INFO ] pool-3-thread-2 TS_METRICS - DiskUtilization.Percent:44.1|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571578
2025-01-22T18:46:18,992 [INFO ] pool-3-thread-2 TS_METRICS - MemoryAvailable.Megabytes:11206.03125|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571578
2025-01-22T18:46:18,992 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUsed.Megabytes:8433.5703125|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571578
2025-01-22T18:46:18,992 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUtilization.Percent:43.9|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571578
2025-01-22T18:46:19,460 [INFO ] epollEventLoopGroup-3-1 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571579
2025-01-22T18:46:19,460 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1737571579460
2025-01-22T18:46:19,462 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Backend received inference at: 1737571579
2025-01-22T18:46:19,462 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Received data: [{'data': [13, 13, 13, 0, 13, 13, 13, 13, -76, -76, -81, -76, -78.5, -76, -76, -7, -7, -12, -7, -9.5, -7, -7, 12, 12, 7, 12, 9.5, 12, 12]}]
2025-01-22T18:46:19,463 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Input data preprocessed successfully
2025-01-22T18:46:19,464 [INFO ] W-9000-youtubegoes5g_1.0 ACCESS_LOG - /127.0.0.1:60728 "POST /v1/models/youtubegoes5g:predict HTTP/1.1" 200 4
2025-01-22T18:46:19,464 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571579
2025-01-22T18:46:19,464 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:3797.289|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571579
2025-01-22T18:46:19,464 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:27.686|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571579
2025-01-22T18:46:19,464 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.job.Job - Waiting time ns: 27686, Backend time ns: 3916587
2025-01-22T18:46:19,464 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571579
2025-01-22T18:46:19,464 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2025-01-22T18:46:19,464 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3
2025-01-22T18:46:19,464 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571579
2025-01-22T18:46:19,464 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Inference performed successfully
2025-01-22T18:46:19,464 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Output postprocessed successfully
2025-01-22T18:46:19,464 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:2.19|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,1737571579,3e415d8e-764d-4859-a79a-4b99f2efb546, pattern=[METRICS]
2025-01-22T18:46:19,464 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_METRICS - PredictionTime.ms:2.19|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,requestID:3e415d8e-764d-4859-a79a-4b99f2efb546,timestamp:1737571579
2025-01-22 18:46:19.466 kserve.trace requestId: 4ad4a48e-dda4-4b43-bf22-71ed0e5a6b18, preprocess_ms: 0.012636185, explain_ms: 0, predict_ms: 8.597135544, postprocess_ms: 0.00500679
2025-01-22 18:46:19.466 uvicorn.access INFO:     10.233.75.99:0 9 - "POST /v1/models/youtubegoes5g%3Apredict HTTP/1.1" 200 OK
2025-01-22 18:46:19.466 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.009602546691894531
2025-01-22 18:46:19.466 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.0043459999997139676
2025-01-22T18:46:31,482 [INFO ] epollEventLoopGroup-3-2 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571591
2025-01-22T18:46:31,482 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1737571591482
2025-01-22T18:46:31,483 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Backend received inference at: 1737571591
2025-01-22T18:46:31,483 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Received data: [{'data': [13, 13, 13, 0, 13, 13, 13, 13, -76, -76, -81, -76, -78.5, -76, -76, -7, -7, -12, -7, -9.5, -7, -7, 12, 12, 7, 12, 9.5, 12, 12]}]
2025-01-22T18:46:31,484 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Input data preprocessed successfully
2025-01-22T18:46:31,487 [INFO ] W-9000-youtubegoes5g_1.0 ACCESS_LOG - /127.0.0.1:54872 "POST /v1/models/youtubegoes5g:predict HTTP/1.1" 200 5
2025-01-22T18:46:31,487 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571591
2025-01-22T18:46:31,487 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:4217.649|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571591
2025-01-22T18:46:31,487 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Inference performed successfully
2025-01-22T18:46:31,487 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:53.257|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571591
2025-01-22T18:46:31,487 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Output postprocessed successfully
2025-01-22T18:46:31,487 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.job.Job - Waiting time ns: 53257, Backend time ns: 4486861
2025-01-22T18:46:31,487 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571591
2025-01-22T18:46:31,487 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2025-01-22T18:46:31,487 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 4
2025-01-22T18:46:31,487 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571591
2025-01-22T18:46:31,487 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:2.29|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,1737571591,7472ff15-6670-4f66-9981-9b2599eefe1c, pattern=[METRICS]
2025-01-22T18:46:31,487 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_METRICS - PredictionTime.ms:2.29|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,requestID:7472ff15-6670-4f66-9981-9b2599eefe1c,timestamp:1737571591
2025-01-22 18:46:31.488 kserve.trace requestId: be0cd497-ccf3-4e66-afc4-4c27bc487060, preprocess_ms: 0.011920929, explain_ms: 0, predict_ms: 8.280992508, postprocess_ms: 0.005483627
2025-01-22 18:46:31.488 uvicorn.access INFO:     10.233.75.99:0 9 - "POST /v1/models/youtubegoes5g%3Apredict HTTP/1.1" 200 OK
2025-01-22 18:46:31.489 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.009179353713989258
2025-01-22 18:46:31.489 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.004648000000088359
2025-01-22T18:46:43,506 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571603
2025-01-22T18:46:43,507 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1737571603506
2025-01-22T18:46:43,507 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Backend received inference at: 1737571603
2025-01-22T18:46:43,507 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Received data: [{'data': [13, 13, 13, 0, 13, 13, 13, 13, -76, -76, -81, -76, -78.5, -76, -76, -7, -7, -12, -7, -9.5, -7, -7, 12, 12, 7, 12, 9.5, 12, 12]}]
2025-01-22T18:46:43,508 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Input data preprocessed successfully
2025-01-22T18:46:43,509 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Inference performed successfully
2025-01-22T18:46:43,509 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Output postprocessed successfully
2025-01-22T18:46:43,509 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:1.68|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,1737571603,7984067a-d60a-450f-9caf-c8f04b5a9486, pattern=[METRICS]
2025-01-22T18:46:43,509 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_METRICS - PredictionTime.ms:1.68|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,requestID:7984067a-d60a-450f-9caf-c8f04b5a9486,timestamp:1737571603
2025-01-22T18:46:43,509 [INFO ] W-9000-youtubegoes5g_1.0 ACCESS_LOG - /127.0.0.1:53508 "POST /v1/models/youtubegoes5g:predict HTTP/1.1" 200 3
2025-01-22T18:46:43,509 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571603
2025-01-22T18:46:43,509 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:2812.07|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571603
2025-01-22T18:46:43,509 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:42.022|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571603
2025-01-22T18:46:43,509 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.job.Job - Waiting time ns: 42022, Backend time ns: 2942645
2025-01-22T18:46:43,509 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571603
2025-01-22T18:46:43,510 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2025-01-22T18:46:43,510 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2
2025-01-22T18:46:43,510 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:2.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571603
2025-01-22 18:46:43.511 kserve.trace requestId: 3cb7388d-3cbc-446f-8e89-56297940922f, preprocess_ms: 0.016689301, explain_ms: 0, predict_ms: 7.490873337, postprocess_ms: 0.005483627
2025-01-22 18:46:43.511 uvicorn.access INFO:     10.233.75.99:0 9 - "POST /v1/models/youtubegoes5g%3Apredict HTTP/1.1" 200 OK
2025-01-22 18:46:43.512 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.008775949478149414
2025-01-22 18:46:43.512 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.005170999998881598
2025-01-22T18:46:55,528 [INFO ] epollEventLoopGroup-3-4 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571615
2025-01-22T18:46:55,528 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1737571615528
2025-01-22T18:46:55,528 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Backend received inference at: 1737571615
2025-01-22T18:46:55,529 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Received data: [{'data': [13, 13, 13, 0, 13, 13, 13, 13, -76, -76, -81, -76, -78.5, -76, -76, -7, -7, -12, -7, -9.5, -7, -7, 12, 12, 7, 12, 9.5, 12, 12]}]
2025-01-22T18:46:55,529 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Input data preprocessed successfully
2025-01-22T18:46:55,530 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Inference performed successfully
2025-01-22T18:46:55,530 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Output postprocessed successfully
2025-01-22T18:46:55,530 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:1.32|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,1737571615,578c9df9-c438-4f7c-9ca5-85307a55df79, pattern=[METRICS]
2025-01-22T18:46:55,530 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_METRICS - PredictionTime.ms:1.32|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,requestID:578c9df9-c438-4f7c-9ca5-85307a55df79,timestamp:1737571615
2025-01-22T18:46:55,530 [INFO ] W-9000-youtubegoes5g_1.0 ACCESS_LOG - /127.0.0.1:50736 "POST /v1/models/youtubegoes5g:predict HTTP/1.1" 200 2
2025-01-22T18:46:55,530 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571615
2025-01-22T18:46:55,530 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:2291.905|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571615
2025-01-22T18:46:55,530 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:58.11|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571615
2025-01-22T18:46:55,530 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.job.Job - Waiting time ns: 58110, Backend time ns: 2400387
2025-01-22T18:46:55,530 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571615
2025-01-22T18:46:55,530 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2025-01-22T18:46:55,530 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2
2025-01-22T18:46:55,530 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571615
2025-01-22 18:46:55.532 kserve.trace requestId: 636446ee-1e70-4a9f-9348-7bf3e67f80df, preprocess_ms: 0.011205673, explain_ms: 0, predict_ms: 6.537675858, postprocess_ms: 0.005483627
2025-01-22 18:46:55.532 uvicorn.access INFO:     10.233.75.99:0 9 - "POST /v1/models/youtubegoes5g%3Apredict HTTP/1.1" 200 OK
2025-01-22 18:46:55.532 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.007504701614379883
2025-01-22 18:46:55.532 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.004724000000351225
2025-01-22T18:47:07,550 [INFO ] epollEventLoopGroup-3-1 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571627
2025-01-22T18:47:07,550 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1737571627550
2025-01-22T18:47:07,551 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Backend received inference at: 1737571627
2025-01-22T18:47:07,551 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Received data: [{'data': [13, 13, 13, 0, 13, 13, 13, 13, -76, -76, -81, -76, -78.5, -76, -76, -7, -7, -12, -7, -9.5, -7, -7, 12, 12, 7, 12, 9.5, 12, 12]}]
2025-01-22T18:47:07,551 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Input data preprocessed successfully
2025-01-22T18:47:07,552 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Inference performed successfully
2025-01-22T18:47:07,552 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Output postprocessed successfully
2025-01-22T18:47:07,553 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:1.87|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,1737571627,4197e8ef-857b-4a17-8187-cc8cf4f25615, pattern=[METRICS]
2025-01-22T18:47:07,553 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_METRICS - PredictionTime.ms:1.87|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,requestID:4197e8ef-857b-4a17-8187-cc8cf4f25615,timestamp:1737571627
2025-01-22T18:47:07,554 [INFO ] W-9000-youtubegoes5g_1.0 ACCESS_LOG - /127.0.0.1:43108 "POST /v1/models/youtubegoes5g:predict HTTP/1.1" 200 4
2025-01-22T18:47:07,554 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571627
2025-01-22T18:47:07,554 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:3625.21|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571627
2025-01-22T18:47:07,554 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:44.875|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571627
2025-01-22T18:47:07,554 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.job.Job - Waiting time ns: 44875, Backend time ns: 3712640
2025-01-22T18:47:07,554 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571627
2025-01-22T18:47:07,554 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2025-01-22T18:47:07,554 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 4
2025-01-22T18:47:07,554 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571627
2025-01-22 18:47:07.555 kserve.trace requestId: 99a214d1-7f39-41dd-93b9-493b7a6b1248, preprocess_ms: 0.012159348, explain_ms: 0, predict_ms: 8.317232132, postprocess_ms: 0.005722046
2025-01-22 18:47:07.555 uvicorn.access INFO:     10.233.75.99:0 9 - "POST /v1/models/youtubegoes5g%3Apredict HTTP/1.1" 200 OK
2025-01-22 18:47:07.555 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.009160041809082031
2025-01-22 18:47:07.555 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.004168000001300243
2025-01-22T18:47:18,996 [INFO ] pool-3-thread-2 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571638
2025-01-22T18:47:18,996 [INFO ] pool-3-thread-2 TS_METRICS - DiskAvailable.Gigabytes:263.7068672180176|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571638
2025-01-22T18:47:18,997 [INFO ] pool-3-thread-2 TS_METRICS - DiskUsage.Gigabytes:208.2963981628418|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571638
2025-01-22T18:47:18,997 [INFO ] pool-3-thread-2 TS_METRICS - DiskUtilization.Percent:44.1|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571638
2025-01-22T18:47:18,997 [INFO ] pool-3-thread-2 TS_METRICS - MemoryAvailable.Megabytes:11169.93359375|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571638
2025-01-22T18:47:18,997 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUsed.Megabytes:8469.66796875|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571638
2025-01-22T18:47:18,997 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUtilization.Percent:44.1|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571638
2025-01-22T18:47:19,574 [INFO ] epollEventLoopGroup-3-2 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571639
2025-01-22T18:47:19,574 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1737571639574
2025-01-22T18:47:19,575 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Backend received inference at: 1737571639
2025-01-22T18:47:19,575 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Received data: [{'data': [13, 13, 13, 0, 13, 13, 13, 13, -76, -76, -81, -76, -78.5, -76, -76, -7, -7, -12, -7, -9.5, -7, -7, 12, 12, 7, 12, 9.5, 12, 12]}]
2025-01-22T18:47:19,575 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Input data preprocessed successfully
2025-01-22T18:47:19,579 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Inference performed successfully
2025-01-22T18:47:19,579 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Output postprocessed successfully
2025-01-22T18:47:19,579 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:4.34|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,1737571639,5963ca6b-52c3-4ce0-a71b-fbd519eb1045, pattern=[METRICS]
2025-01-22T18:47:19,579 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_METRICS - PredictionTime.ms:4.34|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,requestID:5963ca6b-52c3-4ce0-a71b-fbd519eb1045,timestamp:1737571639
2025-01-22T18:47:19,579 [INFO ] W-9000-youtubegoes5g_1.0 ACCESS_LOG - /127.0.0.1:54906 "POST /v1/models/youtubegoes5g:predict HTTP/1.1" 200 5
2025-01-22T18:47:19,579 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571639
2025-01-22T18:47:19,579 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:5108.883|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571639
2025-01-22T18:47:19,579 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:36.586|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571639
2025-01-22T18:47:19,579 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.job.Job - Waiting time ns: 36586, Backend time ns: 5196075
2025-01-22T18:47:19,579 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571639
2025-01-22T18:47:19,579 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2025-01-22T18:47:19,579 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 5
2025-01-22T18:47:19,579 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571639
2025-01-22 18:47:19.580 kserve.trace requestId: 0bf9adb4-5290-4bcc-a0ef-9e46f62a4802, preprocess_ms: 0.012397766, explain_ms: 0, predict_ms: 8.798122406, postprocess_ms: 0.00500679
2025-01-22 18:47:19.581 uvicorn.access INFO:     10.233.75.99:0 9 - "POST /v1/models/youtubegoes5g%3Apredict HTTP/1.1" 200 OK
2025-01-22 18:47:19.581 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.009647369384765625
2025-01-22 18:47:19.581 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.004106000000319909
2025-01-22T18:47:31,598 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571651
2025-01-22T18:47:31,598 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1737571651598
2025-01-22T18:47:31,598 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Backend received inference at: 1737571651
2025-01-22T18:47:31,599 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Received data: [{'data': [13, 13, 13, 0, 13, 13, 13, 13, -76, -76, -81, -76, -78.5, -76, -76, -7, -7, -12, -7, -9.5, -7, -7, 12, 12, 7, 12, 9.5, 12, 12]}]
2025-01-22T18:47:31,599 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Input data preprocessed successfully
2025-01-22T18:47:31,601 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Inference performed successfully
2025-01-22T18:47:31,601 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Output postprocessed successfully
2025-01-22T18:47:31,602 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:2.89|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,1737571651,d164b698-e046-459a-8f90-9acd31eaa4af, pattern=[METRICS]
2025-01-22T18:47:31,602 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_METRICS - PredictionTime.ms:2.89|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,requestID:d164b698-e046-459a-8f90-9acd31eaa4af,timestamp:1737571651
2025-01-22T18:47:31,602 [INFO ] W-9000-youtubegoes5g_1.0 ACCESS_LOG - /127.0.0.1:43046 "POST /v1/models/youtubegoes5g:predict HTTP/1.1" 200 4
2025-01-22T18:47:31,602 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571651
2025-01-22T18:47:31,602 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:4073.841|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571651
2025-01-22T18:47:31,602 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:54.58|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571651
2025-01-22T18:47:31,602 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.job.Job - Waiting time ns: 54580, Backend time ns: 4136921
2025-01-22T18:47:31,602 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571651
2025-01-22T18:47:31,602 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2025-01-22T18:47:31,602 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 4
2025-01-22T18:47:31,602 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571651
2025-01-22 18:47:31.603 kserve.trace requestId: 72e52e51-0c0d-4515-b33e-661df8a6d413, preprocess_ms: 0.01168251, explain_ms: 0, predict_ms: 8.063077927, postprocess_ms: 0.00500679
2025-01-22 18:47:31.603 uvicorn.access INFO:     10.233.75.99:0 9 - "POST /v1/models/youtubegoes5g%3Apredict HTTP/1.1" 200 OK
2025-01-22 18:47:31.604 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.008892297744750977
2025-01-22 18:47:31.604 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.004575000000841101
2025-01-22T18:48:07,621 [INFO ] epollEventLoopGroup-3-4 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571687
2025-01-22T18:48:07,621 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1737571687621
2025-01-22T18:48:07,623 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Backend received inference at: 1737571687
2025-01-22T18:48:07,623 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Received data: [{'data': [13, 13, 13, 0, 13, 13, 13, 13, -76, -76, -81, -76, -78.5, -76, -76, -7, -7, -12, -7, -9.5, -7, -7, 12, 12, 7, 12, 9.5, 12, 12]}]
2025-01-22T18:48:07,623 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Input data preprocessed successfully
2025-01-22T18:48:07,623 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Inference performed successfully
2025-01-22T18:48:07,623 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Output postprocessed successfully
2025-01-22T18:48:07,623 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:1.17|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,1737571687,b9101979-fe96-417f-9249-941a4dcc9fac, pattern=[METRICS]
2025-01-22T18:48:07,623 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_METRICS - PredictionTime.ms:1.17|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,requestID:b9101979-fe96-417f-9249-941a4dcc9fac,timestamp:1737571687
2025-01-22T18:48:07,623 [INFO ] W-9000-youtubegoes5g_1.0 ACCESS_LOG - /127.0.0.1:34702 "POST /v1/models/youtubegoes5g:predict HTTP/1.1" 200 2
2025-01-22T18:48:07,623 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571687
2025-01-22T18:48:07,623 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:2150.863|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571687
2025-01-22T18:48:07,623 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:45.774|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571687
2025-01-22T18:48:07,623 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.job.Job - Waiting time ns: 45774, Backend time ns: 2198373
2025-01-22T18:48:07,623 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571687
2025-01-22T18:48:07,623 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2025-01-22T18:48:07,623 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0
2025-01-22T18:48:07,623 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:2.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571687
2025-01-22 18:48:07.624 kserve.trace requestId: 17683588-0478-489d-8444-b44373d1299d, preprocess_ms: 0.01168251, explain_ms: 0, predict_ms: 6.24704361, postprocess_ms: 0.005960464
2025-01-22 18:48:07.625 uvicorn.access INFO:     10.233.75.99:0 9 - "POST /v1/models/youtubegoes5g%3Apredict HTTP/1.1" 200 OK
2025-01-22 18:48:07.625 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.007169485092163086
2025-01-22 18:48:07.625 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.004635000001144363
2025-01-22T18:48:18,996 [INFO ] pool-3-thread-2 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571698
2025-01-22T18:48:18,996 [INFO ] pool-3-thread-2 TS_METRICS - DiskAvailable.Gigabytes:263.70667266845703|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571698
2025-01-22T18:48:18,996 [INFO ] pool-3-thread-2 TS_METRICS - DiskUsage.Gigabytes:208.29659271240234|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571698
2025-01-22T18:48:18,996 [INFO ] pool-3-thread-2 TS_METRICS - DiskUtilization.Percent:44.1|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571698
2025-01-22T18:48:18,996 [INFO ] pool-3-thread-2 TS_METRICS - MemoryAvailable.Megabytes:11227.7265625|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571698
2025-01-22T18:48:18,996 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUsed.Megabytes:8411.875|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571698
2025-01-22T18:48:18,996 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUtilization.Percent:43.8|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571698
2025-01-22T18:48:19,643 [INFO ] epollEventLoopGroup-3-1 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571699
2025-01-22T18:48:19,644 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1737571699644
2025-01-22T18:48:19,644 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Backend received inference at: 1737571699
2025-01-22T18:48:19,644 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Received data: [{'data': [13, 13, 13, 0, 13, 13, 13, 13, -76, -76, -81, -76, -78.5, -76, -76, -7, -7, -12, -7, -9.5, -7, -7, 12, 12, 7, 12, 9.5, 12, 12]}]
2025-01-22T18:48:19,645 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Input data preprocessed successfully
2025-01-22T18:48:19,648 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Inference performed successfully
2025-01-22T18:48:19,648 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Output postprocessed successfully
2025-01-22T18:48:19,648 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:3.04|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,1737571699,80e24641-2294-4102-92a6-2f5567731b3a, pattern=[METRICS]
2025-01-22T18:48:19,648 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_METRICS - PredictionTime.ms:3.04|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,requestID:80e24641-2294-4102-92a6-2f5567731b3a,timestamp:1737571699
2025-01-22T18:48:19,648 [INFO ] W-9000-youtubegoes5g_1.0 ACCESS_LOG - /127.0.0.1:59264 "POST /v1/models/youtubegoes5g:predict HTTP/1.1" 200 5
2025-01-22T18:48:19,648 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571699
2025-01-22T18:48:19,648 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:4622.629|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571699
2025-01-22T18:48:19,648 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:90.087|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571699
2025-01-22T18:48:19,648 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.job.Job - Waiting time ns: 90087, Backend time ns: 4706630
2025-01-22T18:48:19,648 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571699
2025-01-22T18:48:19,648 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2025-01-22T18:48:19,648 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 4
2025-01-22T18:48:19,648 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571699
2025-01-22 18:48:19.650 kserve.trace requestId: c49815f7-bd09-4ed5-8377-df798a4db44e, preprocess_ms: 0.011920929, explain_ms: 0, predict_ms: 9.021043777, postprocess_ms: 0.006198883
2025-01-22 18:48:19.650 uvicorn.access INFO:     10.233.75.99:0 9 - "POST /v1/models/youtubegoes5g%3Apredict HTTP/1.1" 200 OK
2025-01-22 18:48:19.651 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.010201692581176758
2025-01-22 18:48:19.651 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.005057000000306289
2025-01-22T18:48:31,670 [INFO ] epollEventLoopGroup-3-2 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571711
2025-01-22T18:48:31,670 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1737571711670
2025-01-22T18:48:31,672 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Backend received inference at: 1737571711
2025-01-22T18:48:31,672 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Received data: [{'data': [13, 13, 13, 0, 13, 13, 13, 13, -76, -76, -81, -76, -78.5, -76, -76, -7, -7, -12, -7, -9.5, -7, -7, 12, 12, 7, 12, 9.5, 12, 12]}]
2025-01-22T18:48:31,673 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Input data preprocessed successfully
2025-01-22T18:48:31,673 [INFO ] W-9000-youtubegoes5g_1.0 ACCESS_LOG - /127.0.0.1:59678 "POST /v1/models/youtubegoes5g:predict HTTP/1.1" 200 3
2025-01-22T18:48:31,673 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Inference performed successfully
2025-01-22T18:48:31,673 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571711
2025-01-22T18:48:31,673 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Output postprocessed successfully
2025-01-22T18:48:31,673 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:1.48|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,1737571711,db7309d0-03b3-4f4d-ad38-d34e93737b2a, pattern=[METRICS]
2025-01-22T18:48:31,673 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:3082.843|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571711
2025-01-22T18:48:31,673 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:222.161|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571711
2025-01-22T18:48:31,674 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_METRICS - PredictionTime.ms:1.48|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,requestID:db7309d0-03b3-4f4d-ad38-d34e93737b2a,timestamp:1737571711
2025-01-22T18:48:31,674 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.job.Job - Waiting time ns: 222161, Backend time ns: 3702118
2025-01-22T18:48:31,674 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571711
2025-01-22T18:48:31,674 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2025-01-22T18:48:31,674 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0
2025-01-22T18:48:31,674 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:4.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571711
2025-01-22 18:48:31.675 kserve.trace requestId: 3d25ecf4-5491-4c40-84a5-48e9d06bd51b, preprocess_ms: 0.010490417, explain_ms: 0, predict_ms: 8.613586426, postprocess_ms: 0.0
2025-01-22 18:48:31.675 uvicorn.access INFO:     10.233.75.99:0 9 - "POST /v1/models/youtubegoes5g%3Apredict HTTP/1.1" 200 OK
2025-01-22 18:48:31.676 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.009895086288452148
2025-01-22 18:48:31.676 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.004652999999962049
2025-01-22T18:48:43,692 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571723
2025-01-22T18:48:43,692 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1737571723692
2025-01-22T18:48:43,693 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Backend received inference at: 1737571723
2025-01-22T18:48:43,693 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Received data: [{'data': [13, 13, 13, 0, 13, 13, 13, 13, -76, -76, -81, -76, -78.5, -76, -76, -7, -7, -12, -7, -9.5, -7, -7, 12, 12, 7, 12, 9.5, 12, 12]}]
2025-01-22T18:48:43,693 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Input data preprocessed successfully
2025-01-22T18:48:43,694 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Inference performed successfully
2025-01-22T18:48:43,694 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Output postprocessed successfully
2025-01-22T18:48:43,694 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:1.27|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,1737571723,ec75fa86-516e-4efa-9e9c-2a184fb5a1db, pattern=[METRICS]
2025-01-22T18:48:43,694 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_METRICS - PredictionTime.ms:1.27|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,requestID:ec75fa86-516e-4efa-9e9c-2a184fb5a1db,timestamp:1737571723
2025-01-22T18:48:43,694 [INFO ] W-9000-youtubegoes5g_1.0 ACCESS_LOG - /127.0.0.1:53896 "POST /v1/models/youtubegoes5g:predict HTTP/1.1" 200 2
2025-01-22T18:48:43,694 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571723
2025-01-22T18:48:43,694 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:2542.719|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571723
2025-01-22T18:48:43,694 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:89.081|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571723
2025-01-22T18:48:43,695 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.job.Job - Waiting time ns: 89081, Backend time ns: 2689000
2025-01-22T18:48:43,695 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571723
2025-01-22T18:48:43,695 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2025-01-22T18:48:43,695 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1
2025-01-22T18:48:43,695 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:2.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571723
2025-01-22 18:48:43.696 kserve.trace requestId: 2e446bd1-e74d-4936-bb73-353316b0101c, preprocess_ms: 0.011920929, explain_ms: 0, predict_ms: 6.902217865, postprocess_ms: 0.014066696
2025-01-22 18:48:43.696 uvicorn.access INFO:     10.233.75.99:0 9 - "POST /v1/models/youtubegoes5g%3Apredict HTTP/1.1" 200 OK
2025-01-22 18:48:43.697 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.007931709289550781
2025-01-22 18:48:43.697 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.004812000001038541
2025-01-22T18:48:55,713 [INFO ] epollEventLoopGroup-3-4 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571735
2025-01-22T18:48:55,713 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1737571735713
2025-01-22T18:48:55,717 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Backend received inference at: 1737571735
2025-01-22T18:48:55,717 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Received data: [{'data': [13, 13, 13, 0, 13, 13, 13, 13, -76, -76, -81, -76, -78.5, -76, -76, -7, -7, -12, -7, -9.5, -7, -7, 12, 12, 7, 12, 9.5, 12, 12]}]
2025-01-22T18:48:55,717 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Input data preprocessed successfully
2025-01-22T18:48:55,718 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Inference performed successfully
2025-01-22T18:48:55,719 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Output postprocessed successfully
2025-01-22T18:48:55,719 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:4.62|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,1737571735,6e0f5464-2a9b-4743-864c-8087c5f12635, pattern=[METRICS]
2025-01-22T18:48:55,719 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_METRICS - PredictionTime.ms:4.62|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,requestID:6e0f5464-2a9b-4743-864c-8087c5f12635,timestamp:1737571735
2025-01-22T18:48:55,719 [INFO ] W-9000-youtubegoes5g_1.0 ACCESS_LOG - /127.0.0.1:51506 "POST /v1/models/youtubegoes5g:predict HTTP/1.1" 200 6
2025-01-22T18:48:55,719 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571735
2025-01-22T18:48:55,719 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:5673.622|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571735
2025-01-22T18:48:55,719 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:52.026|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571735
2025-01-22T18:48:55,719 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.job.Job - Waiting time ns: 52026, Backend time ns: 5823845
2025-01-22T18:48:55,719 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571735
2025-01-22T18:48:55,719 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2025-01-22T18:48:55,719 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 5
2025-01-22T18:48:55,719 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571735
2025-01-22 18:48:55.720 kserve.trace requestId: 4be3c559-9eb0-4e59-b1c1-aa800b6f074e, preprocess_ms: 0.012159348, explain_ms: 0, predict_ms: 9.269237518, postprocess_ms: 0.00500679
2025-01-22 18:48:55.720 uvicorn.access INFO:     10.233.75.99:0 9 - "POST /v1/models/youtubegoes5g%3Apredict HTTP/1.1" 200 OK
2025-01-22 18:48:55.721 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.01026153564453125
2025-01-22 18:48:55.721 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.004398999999466469
2025-01-22T18:49:07,739 [INFO ] epollEventLoopGroup-3-1 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571747
2025-01-22T18:49:07,739 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1737571747739
2025-01-22T18:49:07,740 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Backend received inference at: 1737571747
2025-01-22T18:49:07,740 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Received data: [{'data': [13, 13, 13, 0, 13, 13, 13, 13, -76, -76, -81, -76, -78.5, -76, -76, -7, -7, -12, -7, -9.5, -7, -7, 12, 12, 7, 12, 9.5, 12, 12]}]
2025-01-22T18:49:07,741 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Input data preprocessed successfully
2025-01-22T18:49:07,744 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Inference performed successfully
2025-01-22T18:49:07,744 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Output postprocessed successfully
2025-01-22T18:49:07,744 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:4.25|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,1737571747,fd0620eb-7498-47f1-ab89-d62917ddfc1d, pattern=[METRICS]
2025-01-22T18:49:07,744 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_METRICS - PredictionTime.ms:4.25|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,requestID:fd0620eb-7498-47f1-ab89-d62917ddfc1d,timestamp:1737571747
2025-01-22T18:49:07,745 [INFO ] W-9000-youtubegoes5g_1.0 ACCESS_LOG - /127.0.0.1:46756 "POST /v1/models/youtubegoes5g:predict HTTP/1.1" 200 6
2025-01-22T18:49:07,745 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571747
2025-01-22T18:49:07,745 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:5141.542|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571747
2025-01-22T18:49:07,745 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:33.893|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571747
2025-01-22T18:49:07,745 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.job.Job - Waiting time ns: 33893, Backend time ns: 5261882
2025-01-22T18:49:07,745 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571747
2025-01-22T18:49:07,745 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2025-01-22T18:49:07,745 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 5
2025-01-22T18:49:07,745 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571747
2025-01-22 18:49:07.746 kserve.trace requestId: 96644b9f-5f66-4e30-830f-b7ab75b22b70, preprocess_ms: 0.013113022, explain_ms: 0, predict_ms: 8.903026581, postprocess_ms: 0.004768372
2025-01-22 18:49:07.746 uvicorn.access INFO:     10.233.75.99:0 9 - "POST /v1/models/youtubegoes5g%3Apredict HTTP/1.1" 200 OK
2025-01-22 18:49:07.746 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.009788036346435547
2025-01-22 18:49:07.746 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.004457999999431195
2025-01-22T18:49:18,998 [INFO ] pool-3-thread-2 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571758
2025-01-22T18:49:18,998 [INFO ] pool-3-thread-2 TS_METRICS - DiskAvailable.Gigabytes:263.70643615722656|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571758
2025-01-22T18:49:18,998 [INFO ] pool-3-thread-2 TS_METRICS - DiskUsage.Gigabytes:208.2968292236328|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571758
2025-01-22T18:49:18,998 [INFO ] pool-3-thread-2 TS_METRICS - DiskUtilization.Percent:44.1|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571758
2025-01-22T18:49:18,998 [INFO ] pool-3-thread-2 TS_METRICS - MemoryAvailable.Megabytes:11224.73046875|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571758
2025-01-22T18:49:18,998 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUsed.Megabytes:8414.87109375|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571758
2025-01-22T18:49:18,998 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUtilization.Percent:43.8|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571758
2025-01-22T18:49:19,763 [INFO ] epollEventLoopGroup-3-2 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571759
2025-01-22T18:49:19,763 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1737571759763
2025-01-22T18:49:19,764 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Backend received inference at: 1737571759
2025-01-22T18:49:19,764 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Received data: [{'data': [13, 13, 13, 0, 13, 13, 13, 13, -76, -76, -81, -76, -78.5, -76, -76, -7, -7, -12, -7, -9.5, -7, -7, 12, 12, 7, 12, 9.5, 12, 12]}]
2025-01-22T18:49:19,765 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Input data preprocessed successfully
2025-01-22T18:49:19,767 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Inference performed successfully
2025-01-22T18:49:19,767 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Output postprocessed successfully
2025-01-22T18:49:19,767 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:3.5|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,1737571759,5e6f38af-ca32-4af0-a2bf-81a7dac222b7, pattern=[METRICS]
2025-01-22T18:49:19,767 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_METRICS - PredictionTime.ms:3.5|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,requestID:5e6f38af-ca32-4af0-a2bf-81a7dac222b7,timestamp:1737571759
2025-01-22T18:49:19,769 [INFO ] W-9000-youtubegoes5g_1.0 ACCESS_LOG - /127.0.0.1:41116 "POST /v1/models/youtubegoes5g:predict HTTP/1.1" 200 5
2025-01-22T18:49:19,769 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571759
2025-01-22T18:49:19,769 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:5324.397|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571759
2025-01-22T18:49:19,769 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:67.848|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571759
2025-01-22T18:49:19,769 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.job.Job - Waiting time ns: 67848, Backend time ns: 5489499
2025-01-22T18:49:19,769 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571759
2025-01-22T18:49:19,769 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2025-01-22T18:49:19,769 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 5
2025-01-22T18:49:19,769 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571759
2025-01-22 18:49:19.770 kserve.trace requestId: 39c9968f-20e3-4060-83fa-c690c3ec0a20, preprocess_ms: 0.011205673, explain_ms: 0, predict_ms: 8.957624435, postprocess_ms: 0.004529953
2025-01-22 18:49:19.770 uvicorn.access INFO:     10.233.75.99:0 9 - "POST /v1/models/youtubegoes5g%3Apredict HTTP/1.1" 200 OK
2025-01-22 18:49:19.770 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.009982824325561523
2025-01-22 18:49:19.771 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.004218999998556683
2025-01-22T18:49:31,789 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571771
2025-01-22T18:49:31,789 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1737571771789
2025-01-22T18:49:31,790 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Backend received inference at: 1737571771
2025-01-22T18:49:31,790 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Received data: [{'data': [13, 13, 13, 0, 13, 13, 13, 13, -76, -76, -81, -76, -78.5, -76, -76, -7, -7, -12, -7, -9.5, -7, -7, 12, 12, 7, 12, 9.5, 12, 12]}]
2025-01-22T18:49:31,790 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Input data preprocessed successfully
2025-01-22T18:49:31,794 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Inference performed successfully
2025-01-22T18:49:31,794 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Output postprocessed successfully
2025-01-22T18:49:31,794 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:4.57|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,1737571771,1bc05a4a-520f-411d-94ca-0592455e1c1c, pattern=[METRICS]
2025-01-22T18:49:31,794 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_METRICS - PredictionTime.ms:4.57|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,requestID:1bc05a4a-520f-411d-94ca-0592455e1c1c,timestamp:1737571771
2025-01-22T18:49:31,795 [INFO ] W-9000-youtubegoes5g_1.0 ACCESS_LOG - /127.0.0.1:51386 "POST /v1/models/youtubegoes5g:predict HTTP/1.1" 200 6
2025-01-22T18:49:31,795 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571771
2025-01-22T18:49:31,795 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:5704.797|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571771
2025-01-22T18:49:31,795 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:100.107|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571771
2025-01-22T18:49:31,795 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.job.Job - Waiting time ns: 100107, Backend time ns: 5791081
2025-01-22T18:49:31,795 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571771
2025-01-22T18:49:31,795 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2025-01-22T18:49:31,795 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 6
2025-01-22T18:49:31,795 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571771
2025-01-22 18:49:31.796 kserve.trace requestId: 14eb5e8e-29e7-4dd7-8790-e3e2e965d57f, preprocess_ms: 0.012636185, explain_ms: 0, predict_ms: 9.333610535, postprocess_ms: 0.004768372
2025-01-22 18:49:31.796 uvicorn.access INFO:     10.233.75.99:0 9 - "POST /v1/models/youtubegoes5g%3Apredict HTTP/1.1" 200 OK
2025-01-22 18:49:31.796 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.010133743286132812
2025-01-22 18:49:31.796 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.003987000000051921
2025-01-22T18:49:43,814 [INFO ] epollEventLoopGroup-3-4 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571783
2025-01-22T18:49:43,814 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1737571783814
2025-01-22T18:49:43,815 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Backend received inference at: 1737571783
2025-01-22T18:49:43,815 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Received data: [{'data': [13, 13, 13, 0, 13, 13, 13, 13, -76, -76, -81, -76, -78.5, -76, -76, -7, -7, -12, -7, -9.5, -7, -7, 12, 12, 7, 12, 9.5, 12, 12]}]
2025-01-22T18:49:43,816 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Input data preprocessed successfully
2025-01-22T18:49:43,818 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Inference performed successfully
2025-01-22T18:49:43,819 [INFO ] W-9000-youtubegoes5g_1.0 ACCESS_LOG - /127.0.0.1:47390 "POST /v1/models/youtubegoes5g:predict HTTP/1.1" 200 5
2025-01-22T18:49:43,819 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571783
2025-01-22T18:49:43,820 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:5042.762|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571783
2025-01-22T18:49:43,820 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:115.162|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571783
2025-01-22T18:49:43,820 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.job.Job - Waiting time ns: 115162, Backend time ns: 5164320
2025-01-22T18:49:43,820 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571783
2025-01-22T18:49:43,820 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2025-01-22T18:49:43,820 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Output postprocessed successfully
2025-01-22T18:49:43,820 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 4
2025-01-22T18:49:43,820 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:2.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571783
2025-01-22T18:49:43,820 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:3.9|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,1737571783,942921dc-40c1-4825-ba2a-ec87cd26461a, pattern=[METRICS]
2025-01-22T18:49:43,820 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_METRICS - PredictionTime.ms:3.9|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,requestID:942921dc-40c1-4825-ba2a-ec87cd26461a,timestamp:1737571783
2025-01-22 18:49:43.821 kserve.trace requestId: 3c2adf50-5505-493e-80b2-9ac2abffec8e, preprocess_ms: 0.01168251, explain_ms: 0, predict_ms: 9.783744812, postprocess_ms: 0.005483627
2025-01-22 18:49:43.821 uvicorn.access INFO:     10.233.75.99:0 9 - "POST /v1/models/youtubegoes5g%3Apredict HTTP/1.1" 200 OK
2025-01-22 18:49:43.822 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.010701417922973633
2025-01-22 18:49:43.822 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.004966000000422355
2025-01-22T18:49:55,840 [INFO ] epollEventLoopGroup-3-1 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571795
2025-01-22T18:49:55,840 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1737571795840
2025-01-22T18:49:55,841 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Backend received inference at: 1737571795
2025-01-22T18:49:55,841 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Received data: [{'data': [13, 13, 13, 0, 13, 13, 13, 13, -76, -76, -81, -76, -78.5, -76, -76, -7, -7, -12, -7, -9.5, -7, -7, 12, 12, 7, 12, 9.5, 12, 12]}]
2025-01-22T18:49:55,842 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Input data preprocessed successfully
2025-01-22T18:49:55,845 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Inference performed successfully
2025-01-22T18:49:55,845 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Output postprocessed successfully
2025-01-22T18:49:55,845 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:4.03|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,1737571795,667ae17d-9138-428f-9d20-8096d2fc290c, pattern=[METRICS]
2025-01-22T18:49:55,846 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_METRICS - PredictionTime.ms:4.03|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,requestID:667ae17d-9138-428f-9d20-8096d2fc290c,timestamp:1737571795
2025-01-22T18:49:55,846 [INFO ] W-9000-youtubegoes5g_1.0 ACCESS_LOG - /127.0.0.1:39724 "POST /v1/models/youtubegoes5g:predict HTTP/1.1" 200 6
2025-01-22T18:49:55,846 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571795
2025-01-22T18:49:55,846 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:5418.513|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571795
2025-01-22T18:49:55,846 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:172.666|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571795
2025-01-22T18:49:55,846 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.job.Job - Waiting time ns: 172666, Backend time ns: 5364762
2025-01-22T18:49:55,846 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571795
2025-01-22T18:49:55,846 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2025-01-22T18:49:55,846 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 5
2025-01-22T18:49:55,846 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571795
2025-01-22 18:49:55.847 kserve.trace requestId: afbdef0c-29be-492b-bcf3-5f7b5dc30c2d, preprocess_ms: 0.012636185, explain_ms: 0, predict_ms: 9.615898132, postprocess_ms: 0.00500679
2025-01-22 18:49:55.847 uvicorn.access INFO:     10.233.75.99:0 9 - "POST /v1/models/youtubegoes5g%3Apredict HTTP/1.1" 200 OK
2025-01-22 18:49:55.847 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.010614871978759766
2025-01-22 18:49:55.848 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.004956000000674976
2025-01-22T18:50:18,994 [INFO ] pool-3-thread-2 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571818
2025-01-22T18:50:18,994 [INFO ] pool-3-thread-2 TS_METRICS - DiskAvailable.Gigabytes:263.70618438720703|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571818
2025-01-22T18:50:18,995 [INFO ] pool-3-thread-2 TS_METRICS - DiskUsage.Gigabytes:208.29708099365234|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571818
2025-01-22T18:50:18,995 [INFO ] pool-3-thread-2 TS_METRICS - DiskUtilization.Percent:44.1|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571818
2025-01-22T18:50:18,995 [INFO ] pool-3-thread-2 TS_METRICS - MemoryAvailable.Megabytes:11281.48046875|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571818
2025-01-22T18:50:18,995 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUsed.Megabytes:8358.12109375|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571818
2025-01-22T18:50:18,995 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUtilization.Percent:43.5|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571818
2025-01-22T18:50:31,864 [INFO ] epollEventLoopGroup-3-2 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571831
2025-01-22T18:50:31,865 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1737571831865
2025-01-22T18:50:31,865 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Backend received inference at: 1737571831
2025-01-22T18:50:31,865 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Received data: [{'data': [13, 13, 13, 0, 13, 13, 13, 13, -76, -76, -81, -76, -78.5, -76, -76, -7, -7, -12, -7, -9.5, -7, -7, 12, 12, 7, 12, 9.5, 12, 12]}]
2025-01-22T18:50:31,866 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Input data preprocessed successfully
2025-01-22T18:50:31,867 [INFO ] W-9000-youtubegoes5g_1.0 ACCESS_LOG - /127.0.0.1:50444 "POST /v1/models/youtubegoes5g:predict HTTP/1.1" 200 3
2025-01-22T18:50:31,867 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571831
2025-01-22T18:50:31,867 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:2385.497|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571831
2025-01-22T18:50:31,867 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:78.55|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571831
2025-01-22T18:50:31,867 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.job.Job - Waiting time ns: 78550, Backend time ns: 2463882
2025-01-22T18:50:31,867 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571831
2025-01-22T18:50:31,867 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2025-01-22T18:50:31,867 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2
2025-01-22T18:50:31,867 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571831
2025-01-22T18:50:31,867 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Inference performed successfully
2025-01-22T18:50:31,867 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Output postprocessed successfully
2025-01-22T18:50:31,867 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:1.33|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,1737571831,64d7fc42-05ac-4209-85c3-e36ee5f31711, pattern=[METRICS]
2025-01-22T18:50:31,867 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_METRICS - PredictionTime.ms:1.33|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,requestID:64d7fc42-05ac-4209-85c3-e36ee5f31711,timestamp:1737571831
2025-01-22 18:50:31.869 kserve.trace requestId: 06eccce8-6a7e-4880-ba97-a8db77eb8e57, preprocess_ms: 0.01168251, explain_ms: 0, predict_ms: 7.122755051, postprocess_ms: 0.005483627
2025-01-22 18:50:31.869 uvicorn.access INFO:     10.233.75.99:0 9 - "POST /v1/models/youtubegoes5g%3Apredict HTTP/1.1" 200 OK
2025-01-22 18:50:31.869 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.007956266403198242
2025-01-22 18:50:31.869 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.004370000000562868
2025-01-22T18:50:43,886 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571843
2025-01-22T18:50:43,886 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1737571843886
2025-01-22T18:50:43,887 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Backend received inference at: 1737571843
2025-01-22T18:50:43,887 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Received data: [{'data': [13, 13, 13, 0, 13, 13, 13, 13, -76, -76, -81, -76, -78.5, -76, -76, -7, -7, -12, -7, -9.5, -7, -7, 12, 12, 7, 12, 9.5, 12, 12]}]
2025-01-22T18:50:43,888 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Input data preprocessed successfully
2025-01-22T18:50:43,888 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Inference performed successfully
2025-01-22T18:50:43,888 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Output postprocessed successfully
2025-01-22T18:50:43,888 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:1.22|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,1737571843,47bbfbf9-6473-4990-8918-e70451a1f775, pattern=[METRICS]
2025-01-22T18:50:43,888 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_METRICS - PredictionTime.ms:1.22|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,requestID:47bbfbf9-6473-4990-8918-e70451a1f775,timestamp:1737571843
2025-01-22T18:50:43,888 [INFO ] W-9000-youtubegoes5g_1.0 ACCESS_LOG - /127.0.0.1:53202 "POST /v1/models/youtubegoes5g:predict HTTP/1.1" 200 2
2025-01-22T18:50:43,888 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571843
2025-01-22T18:50:43,888 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:2030.743|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571843
2025-01-22T18:50:43,889 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:22.066|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571843
2025-01-22T18:50:43,889 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.job.Job - Waiting time ns: 22066, Backend time ns: 2279217
2025-01-22T18:50:43,889 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571843
2025-01-22T18:50:43,889 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2025-01-22T18:50:43,889 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1
2025-01-22T18:50:43,889 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:2.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571843
2025-01-22 18:50:43.890 kserve.trace requestId: 4d37c0e1-cfa6-415a-8011-f8a549e07968, preprocess_ms: 0.012159348, explain_ms: 0, predict_ms: 6.08921051, postprocess_ms: 0.004529953
2025-01-22 18:50:43.890 uvicorn.access INFO:     10.233.75.99:0 9 - "POST /v1/models/youtubegoes5g%3Apredict HTTP/1.1" 200 OK
2025-01-22 18:50:43.890 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.0072023868560791016
2025-01-22 18:50:43.890 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.004664000000047963
2025-01-22T18:50:55,908 [INFO ] epollEventLoopGroup-3-4 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571855
2025-01-22T18:50:55,908 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1737571855908
2025-01-22T18:50:55,909 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Backend received inference at: 1737571855
2025-01-22T18:50:55,909 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Received data: [{'data': [13, 13, 13, 0, 13, 13, 13, 13, -76, -76, -81, -76, -78.5, -76, -76, -7, -7, -12, -7, -9.5, -7, -7, 12, 12, 7, 12, 9.5, 12, 12]}]
2025-01-22T18:50:55,910 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Input data preprocessed successfully
2025-01-22T18:50:55,913 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Inference performed successfully
2025-01-22T18:50:55,913 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Output postprocessed successfully
2025-01-22T18:50:55,913 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:4.12|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,1737571855,22fa9d24-90a4-4ba2-8d64-a92472776882, pattern=[METRICS]
2025-01-22T18:50:55,913 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_METRICS - PredictionTime.ms:4.12|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,requestID:22fa9d24-90a4-4ba2-8d64-a92472776882,timestamp:1737571855
2025-01-22T18:50:55,914 [INFO ] W-9000-youtubegoes5g_1.0 ACCESS_LOG - /127.0.0.1:36016 "POST /v1/models/youtubegoes5g:predict HTTP/1.1" 200 6
2025-01-22T18:50:55,914 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571855
2025-01-22T18:50:55,914 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:5915.59|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571855
2025-01-22T18:50:55,914 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:103.323|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571855
2025-01-22T18:50:55,914 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.job.Job - Waiting time ns: 103323, Backend time ns: 5966151
2025-01-22T18:50:55,914 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571855
2025-01-22T18:50:55,914 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2025-01-22T18:50:55,914 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 5
2025-01-22T18:50:55,914 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571855
2025-01-22 18:50:55.915 kserve.trace requestId: 0b1e3199-64e4-47b9-9db0-6e489430daf5, preprocess_ms: 0.012397766, explain_ms: 0, predict_ms: 9.553432465, postprocess_ms: 0.00500679
2025-01-22 18:50:55.915 uvicorn.access INFO:     10.233.75.99:0 9 - "POST /v1/models/youtubegoes5g%3Apredict HTTP/1.1" 200 OK
2025-01-22 18:50:55.915 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.010396957397460938
2025-01-22 18:50:55.915 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.004193999999188236
2025-01-22T18:51:07,932 [INFO ] epollEventLoopGroup-3-1 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571867
2025-01-22T18:51:07,932 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1737571867932
2025-01-22T18:51:07,933 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Backend received inference at: 1737571867
2025-01-22T18:51:07,933 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Received data: [{'data': [13, 13, 13, 0, 13, 13, 13, 13, -76, -76, -81, -76, -78.5, -76, -76, -7, -7, -12, -7, -9.5, -7, -7, 12, 12, 7, 12, 9.5, 12, 12]}]
2025-01-22T18:51:07,934 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Input data preprocessed successfully
2025-01-22T18:51:07,938 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Inference performed successfully
2025-01-22T18:51:07,938 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Output postprocessed successfully
2025-01-22T18:51:07,938 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:5.23|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,1737571867,7c3a61ca-1e5a-46ea-8a22-8b099fd010c0, pattern=[METRICS]
2025-01-22T18:51:07,938 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_METRICS - PredictionTime.ms:5.23|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,requestID:7c3a61ca-1e5a-46ea-8a22-8b099fd010c0,timestamp:1737571867
2025-01-22T18:51:07,939 [INFO ] W-9000-youtubegoes5g_1.0 ACCESS_LOG - /127.0.0.1:56806 "POST /v1/models/youtubegoes5g:predict HTTP/1.1" 200 7
2025-01-22T18:51:07,939 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571867
2025-01-22T18:51:07,939 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:6207.812|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571867
2025-01-22T18:51:07,939 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:76.314|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571867
2025-01-22T18:51:07,939 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.job.Job - Waiting time ns: 76314, Backend time ns: 6329530
2025-01-22T18:51:07,939 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571867
2025-01-22T18:51:07,939 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2025-01-22T18:51:07,939 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 6
2025-01-22T18:51:07,939 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571867
2025-01-22 18:51:07.940 kserve.trace requestId: 988d5bce-7574-46e6-986a-3556f95d5190, preprocess_ms: 0.012636185, explain_ms: 0, predict_ms: 9.611368179, postprocess_ms: 0.004768372
2025-01-22 18:51:07.940 uvicorn.access INFO:     10.233.75.99:0 9 - "POST /v1/models/youtubegoes5g%3Apredict HTTP/1.1" 200 OK
2025-01-22 18:51:07.940 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.010576725006103516
2025-01-22 18:51:07.940 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.004129000000830274
2025-01-22T18:51:18,999 [INFO ] pool-3-thread-2 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571878
2025-01-22T18:51:18,999 [INFO ] pool-3-thread-2 TS_METRICS - DiskAvailable.Gigabytes:263.7059211730957|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571878
2025-01-22T18:51:18,999 [INFO ] pool-3-thread-2 TS_METRICS - DiskUsage.Gigabytes:208.29734420776367|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571878
2025-01-22T18:51:18,999 [INFO ] pool-3-thread-2 TS_METRICS - DiskUtilization.Percent:44.1|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571878
2025-01-22T18:51:18,999 [INFO ] pool-3-thread-2 TS_METRICS - MemoryAvailable.Megabytes:11281.5859375|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571878
2025-01-22T18:51:18,999 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUsed.Megabytes:8358.26171875|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571878
2025-01-22T18:51:18,999 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUtilization.Percent:43.5|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571878
2025-01-22T18:51:19,959 [INFO ] epollEventLoopGroup-3-2 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571879
2025-01-22T18:51:19,959 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1737571879959
2025-01-22T18:51:19,960 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Backend received inference at: 1737571879
2025-01-22T18:51:19,960 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Received data: [{'data': [13, 13, 13, 0, 13, 13, 13, 13, -76, -76, -81, -76, -78.5, -76, -76, -7, -7, -12, -7, -9.5, -7, -7, 12, 12, 7, 12, 9.5, 12, 12]}]
2025-01-22T18:51:19,961 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Input data preprocessed successfully
2025-01-22T18:51:19,963 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Inference performed successfully
2025-01-22T18:51:19,963 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Output postprocessed successfully
2025-01-22T18:51:19,963 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:2.61|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,1737571879,af04d451-c7f9-475d-b3dc-fc4a3d47fd9c, pattern=[METRICS]
2025-01-22T18:51:19,963 [INFO ] W-9000-youtubegoes5g_1.0 ACCESS_LOG - /127.0.0.1:57250 "POST /v1/models/youtubegoes5g:predict HTTP/1.1" 200 4
2025-01-22T18:51:19,963 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_METRICS - PredictionTime.ms:2.61|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,requestID:af04d451-c7f9-475d-b3dc-fc4a3d47fd9c,timestamp:1737571879
2025-01-22T18:51:19,963 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571879
2025-01-22T18:51:19,963 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:3857.617|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571879
2025-01-22T18:51:19,964 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:33.754|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571879
2025-01-22T18:51:19,964 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.job.Job - Waiting time ns: 33754, Backend time ns: 4038723
2025-01-22T18:51:19,964 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571879
2025-01-22T18:51:19,964 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2025-01-22T18:51:19,964 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3
2025-01-22T18:51:19,964 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:2.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571879
2025-01-22 18:51:19.965 kserve.trace requestId: 5c1b84e0-c3b2-4111-bf1d-a5244303e328, preprocess_ms: 0.012636185, explain_ms: 0, predict_ms: 7.999420166, postprocess_ms: 0.005722046
2025-01-22 18:51:19.965 uvicorn.access INFO:     10.233.75.99:0 9 - "POST /v1/models/youtubegoes5g%3Apredict HTTP/1.1" 200 OK
2025-01-22 18:51:19.966 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.00902700424194336
2025-01-22 18:51:19.966 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.004649000000426895
2025-01-22T18:51:31,990 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571891
2025-01-22T18:51:31,990 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1737571891990
2025-01-22T18:51:31,991 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Backend received inference at: 1737571891
2025-01-22T18:51:31,991 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Received data: [{'data': [13, 13, 13, 0, 13, 13, 13, 13, -76, -76, -81, -76, -78.5, -76, -76, -7, -7, -12, -7, -9.5, -7, -7, 12, 12, 7, 12, 9.5, 12, 12]}]
2025-01-22T18:51:31,991 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Input data preprocessed successfully
2025-01-22T18:51:31,992 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Inference performed successfully
2025-01-22T18:51:31,992 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Output postprocessed successfully
2025-01-22T18:51:31,992 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:1.18|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,1737571891,042545a0-5a1a-439f-ad0a-7d0f4e617c08, pattern=[METRICS]
2025-01-22T18:51:31,992 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_METRICS - PredictionTime.ms:1.18|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,requestID:042545a0-5a1a-439f-ad0a-7d0f4e617c08,timestamp:1737571891
2025-01-22T18:51:31,993 [INFO ] W-9000-youtubegoes5g_1.0 ACCESS_LOG - /127.0.0.1:54002 "POST /v1/models/youtubegoes5g:predict HTTP/1.1" 200 3
2025-01-22T18:51:31,993 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571891
2025-01-22T18:51:31,993 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:2441.546|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571891
2025-01-22T18:51:31,993 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:29.356|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571891
2025-01-22T18:51:31,993 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.job.Job - Waiting time ns: 29356, Backend time ns: 2579859
2025-01-22T18:51:31,993 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571891
2025-01-22T18:51:31,993 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2025-01-22T18:51:31,993 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3
2025-01-22T18:51:31,993 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571891
2025-01-22 18:51:31.994 kserve.trace requestId: e4dc9627-a0d6-4615-9301-56babd4a1fc5, preprocess_ms: 0.012636185, explain_ms: 0, predict_ms: 6.996870041, postprocess_ms: 0.005722046
2025-01-22 18:51:31.994 uvicorn.access INFO:     10.233.75.99:0 9 - "POST /v1/models/youtubegoes5g%3Apredict HTTP/1.1" 200 OK
2025-01-22 18:51:31.994 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.007917165756225586
2025-01-22 18:51:31.995 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.005176000000574277
2025-01-22T18:51:44,013 [INFO ] epollEventLoopGroup-3-4 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571904
2025-01-22T18:51:44,013 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1737571904013
2025-01-22T18:51:44,014 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Backend received inference at: 1737571904
2025-01-22T18:51:44,014 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Received data: [{'data': [13, 13, 13, 0, 13, 13, 13, 13, -76, -76, -81, -76, -78.5, -76, -76, -7, -7, -12, -7, -9.5, -7, -7, 12, 12, 7, 12, 9.5, 12, 12]}]
2025-01-22T18:51:44,015 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Input data preprocessed successfully
2025-01-22T18:51:44,017 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Inference performed successfully
2025-01-22T18:51:44,017 [INFO ] W-9000-youtubegoes5g_1.0 ACCESS_LOG - /127.0.0.1:37596 "POST /v1/models/youtubegoes5g:predict HTTP/1.1" 200 4
2025-01-22T18:51:44,017 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Output postprocessed successfully
2025-01-22T18:51:44,017 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571904
2025-01-22T18:51:44,017 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:2.11|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,1737571904,fc9c139a-c9fc-4181-86d2-6be32346ea3e, pattern=[METRICS]
2025-01-22T18:51:44,017 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:4222.684|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571904
2025-01-22T18:51:44,017 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:61.53|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571904
2025-01-22T18:51:44,017 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.job.Job - Waiting time ns: 61530, Backend time ns: 4333615
2025-01-22T18:51:44,017 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_METRICS - PredictionTime.ms:2.11|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,requestID:fc9c139a-c9fc-4181-86d2-6be32346ea3e,timestamp:1737571904
2025-01-22T18:51:44,018 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571904
2025-01-22T18:51:44,018 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2025-01-22T18:51:44,018 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 4
2025-01-22T18:51:44,018 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571904
2025-01-22 18:51:44.019 kserve.trace requestId: 34e4c235-680a-4fa1-bb21-0f6b1fa5ea09, preprocess_ms: 0.018835068, explain_ms: 0, predict_ms: 8.516073227, postprocess_ms: 0.005722046
2025-01-22 18:51:44.019 uvicorn.access INFO:     10.233.75.99:0 9 - "POST /v1/models/youtubegoes5g%3Apredict HTTP/1.1" 200 OK
2025-01-22 18:51:44.019 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.009693622589111328
2025-01-22 18:51:44.019 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.004918000000543543
2025-01-22T18:51:56,036 [INFO ] epollEventLoopGroup-3-1 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571916
2025-01-22T18:51:56,037 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1737571916037
2025-01-22T18:51:56,037 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Backend received inference at: 1737571916
2025-01-22T18:51:56,037 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Received data: [{'data': [13, 13, 13, 0, 13, 13, 13, 13, -76, -76, -81, -76, -78.5, -76, -76, -7, -7, -12, -7, -9.5, -7, -7, 12, 12, 7, 12, 9.5, 12, 12]}]
2025-01-22T18:51:56,038 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Input data preprocessed successfully
2025-01-22T18:51:56,042 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Inference performed successfully
2025-01-22T18:51:56,042 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Output postprocessed successfully
2025-01-22T18:51:56,042 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:4.64|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,1737571916,fcd81a17-e3dc-484d-add6-ee5cac6cc975, pattern=[METRICS]
2025-01-22T18:51:56,042 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_METRICS - PredictionTime.ms:4.64|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,requestID:fcd81a17-e3dc-484d-add6-ee5cac6cc975,timestamp:1737571916
2025-01-22T18:51:56,042 [INFO ] W-9000-youtubegoes5g_1.0 ACCESS_LOG - /127.0.0.1:55268 "POST /v1/models/youtubegoes5g:predict HTTP/1.1" 200 6
2025-01-22T18:51:56,042 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571916
2025-01-22T18:51:56,042 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:5748.746|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571916
2025-01-22T18:51:56,042 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:38.598|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571916
2025-01-22T18:51:56,042 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.job.Job - Waiting time ns: 38598, Backend time ns: 5827788
2025-01-22T18:51:56,042 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571916
2025-01-22T18:51:56,043 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2025-01-22T18:51:56,043 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 5
2025-01-22T18:51:56,043 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571916
2025-01-22 18:51:56.044 kserve.trace requestId: 4cbfd971-cdac-43b7-869e-14f18dd4f2ba, preprocess_ms: 0.012159348, explain_ms: 0, predict_ms: 9.440422058, postprocess_ms: 0.004768372
2025-01-22 18:51:56.044 uvicorn.access INFO:     10.233.75.99:0 9 - "POST /v1/models/youtubegoes5g%3Apredict HTTP/1.1" 200 OK
2025-01-22 18:51:56.044 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.010425090789794922
2025-01-22 18:51:56.044 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.004458999997950741
2025-01-22T18:52:08,060 [INFO ] epollEventLoopGroup-3-2 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571928
2025-01-22T18:52:08,060 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1737571928060
2025-01-22T18:52:08,061 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Backend received inference at: 1737571928
2025-01-22T18:52:08,061 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Received data: [{'data': [13, 13, 13, 0, 13, 13, 13, 13, -76, -76, -81, -76, -78.5, -76, -76, -7, -7, -12, -7, -9.5, -7, -7, 12, 12, 7, 12, 9.5, 12, 12]}]
2025-01-22T18:52:08,062 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Input data preprocessed successfully
2025-01-22T18:52:08,065 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Inference performed successfully
2025-01-22T18:52:08,065 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Output postprocessed successfully
2025-01-22T18:52:08,066 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:4.41|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,1737571928,cf99b02d-74dc-47a0-ad50-567c796e2038, pattern=[METRICS]
2025-01-22T18:52:08,066 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_METRICS - PredictionTime.ms:4.41|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,requestID:cf99b02d-74dc-47a0-ad50-567c796e2038,timestamp:1737571928
2025-01-22T18:52:08,066 [INFO ] W-9000-youtubegoes5g_1.0 ACCESS_LOG - /127.0.0.1:37770 "POST /v1/models/youtubegoes5g:predict HTTP/1.1" 200 6
2025-01-22T18:52:08,066 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571928
2025-01-22T18:52:08,066 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:5235.153|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571928
2025-01-22T18:52:08,066 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:45.846|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571928
2025-01-22T18:52:08,066 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.job.Job - Waiting time ns: 45846, Backend time ns: 5352371
2025-01-22T18:52:08,066 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571928
2025-01-22T18:52:08,066 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2025-01-22T18:52:08,066 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 5
2025-01-22T18:52:08,066 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571928
2025-01-22 18:52:08.067 kserve.trace requestId: 2dc5ecbd-b66f-48e6-b758-9c41df0fb1ad, preprocess_ms: 0.012159348, explain_ms: 0, predict_ms: 8.751630783, postprocess_ms: 0.004529953
2025-01-22 18:52:08.067 uvicorn.access INFO:     10.233.75.99:0 9 - "POST /v1/models/youtubegoes5g%3Apredict HTTP/1.1" 200 OK
2025-01-22 18:52:08.067 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.009586811065673828
2025-01-22 18:52:08.067 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.0041270000001532026
2025-01-22T18:52:18,990 [INFO ] pool-3-thread-2 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571938
2025-01-22T18:52:18,990 [INFO ] pool-3-thread-2 TS_METRICS - DiskAvailable.Gigabytes:263.7056884765625|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571938
2025-01-22T18:52:18,990 [INFO ] pool-3-thread-2 TS_METRICS - DiskUsage.Gigabytes:208.29757690429688|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571938
2025-01-22T18:52:18,990 [INFO ] pool-3-thread-2 TS_METRICS - DiskUtilization.Percent:44.1|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571938
2025-01-22T18:52:18,990 [INFO ] pool-3-thread-2 TS_METRICS - MemoryAvailable.Megabytes:11286.17578125|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571938
2025-01-22T18:52:18,990 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUsed.Megabytes:8353.42578125|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571938
2025-01-22T18:52:18,990 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUtilization.Percent:43.5|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571938
2025-01-22T18:52:20,086 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571940
2025-01-22T18:52:20,086 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1737571940086
2025-01-22T18:52:20,087 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Backend received inference at: 1737571940
2025-01-22T18:52:20,087 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Received data: [{'data': [13, 13, 13, 0, 13, 13, 13, 13, -76, -76, -81, -76, -78.5, -76, -76, -7, -7, -12, -7, -9.5, -7, -7, 12, 12, 7, 12, 9.5, 12, 12]}]
2025-01-22T18:52:20,087 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Input data preprocessed successfully
2025-01-22T18:52:20,089 [INFO ] W-9000-youtubegoes5g_1.0 ACCESS_LOG - /127.0.0.1:37950 "POST /v1/models/youtubegoes5g:predict HTTP/1.1" 200 3
2025-01-22T18:52:20,089 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571940
2025-01-22T18:52:20,089 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:3229.429|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571940
2025-01-22T18:52:20,089 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:106.785|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571940
2025-01-22T18:52:20,089 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.job.Job - Waiting time ns: 106785, Backend time ns: 3306655
2025-01-22T18:52:20,089 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571940
2025-01-22T18:52:20,089 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2025-01-22T18:52:20,089 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2
2025-01-22T18:52:20,089 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571940
2025-01-22T18:52:20,090 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Inference performed successfully
2025-01-22T18:52:20,090 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Output postprocessed successfully
2025-01-22T18:52:20,090 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:2.18|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,1737571940,6652c890-c14f-4be1-a9fe-d3d9456d317f, pattern=[METRICS]
2025-01-22T18:52:20,090 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_METRICS - PredictionTime.ms:2.18|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,requestID:6652c890-c14f-4be1-a9fe-d3d9456d317f,timestamp:1737571940
2025-01-22 18:52:20.091 kserve.trace requestId: 4ac04423-227a-4e67-9273-141101f79075, preprocess_ms: 0.01335144, explain_ms: 0, predict_ms: 7.59935379, postprocess_ms: 0.006437302
2025-01-22 18:52:20.091 uvicorn.access INFO:     10.233.75.99:0 9 - "POST /v1/models/youtubegoes5g%3Apredict HTTP/1.1" 200 OK
2025-01-22 18:52:20.092 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.00891876220703125
2025-01-22 18:52:20.092 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.004722000001493143
2025-01-22T18:52:56,110 [INFO ] epollEventLoopGroup-3-4 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571976
2025-01-22T18:52:56,110 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1737571976110
2025-01-22T18:52:56,111 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Backend received inference at: 1737571976
2025-01-22T18:52:56,111 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Received data: [{'data': [13, 13, 13, 0, 13, 13, 13, 13, -76, -76, -81, -76, -78.5, -76, -76, -7, -7, -12, -7, -9.5, -7, -7, 12, 12, 7, 12, 9.5, 12, 12]}]
2025-01-22T18:52:56,112 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Input data preprocessed successfully
2025-01-22T18:52:56,113 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Inference performed successfully
2025-01-22T18:52:56,113 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Output postprocessed successfully
2025-01-22T18:52:56,113 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:1.43|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,1737571976,e0e3eb81-e699-45e0-a3b8-02bda14b126b, pattern=[METRICS]
2025-01-22T18:52:56,113 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_METRICS - PredictionTime.ms:1.43|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,requestID:e0e3eb81-e699-45e0-a3b8-02bda14b126b,timestamp:1737571976
2025-01-22T18:52:56,113 [INFO ] W-9000-youtubegoes5g_1.0 ACCESS_LOG - /127.0.0.1:56620 "POST /v1/models/youtubegoes5g:predict HTTP/1.1" 200 3
2025-01-22T18:52:56,113 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571976
2025-01-22T18:52:56,113 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:2836.543|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571976
2025-01-22T18:52:56,113 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:71.175|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571976
2025-01-22T18:52:56,113 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.job.Job - Waiting time ns: 71175, Backend time ns: 2915492
2025-01-22T18:52:56,113 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571976
2025-01-22T18:52:56,113 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2025-01-22T18:52:56,113 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2
2025-01-22T18:52:56,113 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571976
2025-01-22 18:52:56.115 kserve.trace requestId: 141cf2b8-7247-475e-864a-209f6280b69a, preprocess_ms: 0.014066696, explain_ms: 0, predict_ms: 7.799386978, postprocess_ms: 0.006914139
2025-01-22 18:52:56.115 uvicorn.access INFO:     10.233.75.99:0 9 - "POST /v1/models/youtubegoes5g%3Apredict HTTP/1.1" 200 OK
2025-01-22 18:52:56.116 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.008851766586303711
2025-01-22 18:52:56.116 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.005124999999679858
2025-01-22T18:53:08,134 [INFO ] epollEventLoopGroup-3-1 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571988
2025-01-22T18:53:08,135 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1737571988135
2025-01-22T18:53:08,137 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Backend received inference at: 1737571988
2025-01-22T18:53:08,137 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Received data: [{'data': [13, 13, 13, 0, 13, 13, 13, 13, -76, -76, -81, -76, -78.5, -76, -76, -7, -7, -12, -7, -9.5, -7, -7, 12, 12, 7, 12, 9.5, 12, 12]}]
2025-01-22T18:53:08,137 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Input data preprocessed successfully
2025-01-22T18:53:08,137 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Inference performed successfully
2025-01-22T18:53:08,137 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Output postprocessed successfully
2025-01-22T18:53:08,137 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:1.15|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,1737571988,2515abdc-17e6-44a0-a532-06f799e44336, pattern=[METRICS]
2025-01-22T18:53:08,137 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_METRICS - PredictionTime.ms:1.15|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,requestID:2515abdc-17e6-44a0-a532-06f799e44336,timestamp:1737571988
2025-01-22T18:53:08,137 [INFO ] W-9000-youtubegoes5g_1.0 ACCESS_LOG - /127.0.0.1:41522 "POST /v1/models/youtubegoes5g:predict HTTP/1.1" 200 3
2025-01-22T18:53:08,137 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571988
2025-01-22T18:53:08,137 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:2260.6|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571988
2025-01-22T18:53:08,137 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:54.586|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571988
2025-01-22T18:53:08,137 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.job.Job - Waiting time ns: 54586, Backend time ns: 2388478
2025-01-22T18:53:08,137 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571988
2025-01-22T18:53:08,137 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2025-01-22T18:53:08,137 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2
2025-01-22T18:53:08,137 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571988
2025-01-22 18:53:08.139 kserve.trace requestId: 1ac6f846-db0e-46ac-b0d9-8ec20f081460, preprocess_ms: 0.019311905, explain_ms: 0, predict_ms: 7.808208466, postprocess_ms: 0.005960464
2025-01-22 18:53:08.139 uvicorn.access INFO:     10.233.75.99:0 9 - "POST /v1/models/youtubegoes5g%3Apredict HTTP/1.1" 200 OK
2025-01-22 18:53:08.139 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.008978843688964844
2025-01-22 18:53:08.139 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.005783000002338667
2025-01-22T18:53:18,993 [INFO ] pool-3-thread-2 TS_METRICS - CPUUtilization.Percent:50.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571998
2025-01-22T18:53:18,993 [INFO ] pool-3-thread-2 TS_METRICS - DiskAvailable.Gigabytes:263.7054328918457|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571998
2025-01-22T18:53:18,993 [INFO ] pool-3-thread-2 TS_METRICS - DiskUsage.Gigabytes:208.29783248901367|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571998
2025-01-22T18:53:18,993 [INFO ] pool-3-thread-2 TS_METRICS - DiskUtilization.Percent:44.1|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571998
2025-01-22T18:53:18,993 [INFO ] pool-3-thread-2 TS_METRICS - MemoryAvailable.Megabytes:11293.44921875|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571998
2025-01-22T18:53:18,993 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUsed.Megabytes:8346.15234375|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571998
2025-01-22T18:53:18,994 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUtilization.Percent:43.5|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737571998
2025-01-22T18:53:20,158 [INFO ] epollEventLoopGroup-3-2 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572000
2025-01-22T18:53:20,158 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1737572000158
2025-01-22T18:53:20,159 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Backend received inference at: 1737572000
2025-01-22T18:53:20,159 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Received data: [{'data': [13, 13, 13, 0, 13, 13, 13, 13, -76, -76, -81, -76, -78.5, -76, -76, -7, -7, -12, -7, -9.5, -7, -7, 12, 12, 7, 12, 9.5, 12, 12]}]
2025-01-22T18:53:20,159 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Input data preprocessed successfully
2025-01-22T18:53:20,160 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Inference performed successfully
2025-01-22T18:53:20,160 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Output postprocessed successfully
2025-01-22T18:53:20,161 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:1.42|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,1737572000,1d10358d-82bb-472a-b67a-15bc519dd50b, pattern=[METRICS]
2025-01-22T18:53:20,161 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_METRICS - PredictionTime.ms:1.42|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,requestID:1d10358d-82bb-472a-b67a-15bc519dd50b,timestamp:1737572000
2025-01-22T18:53:20,161 [INFO ] W-9000-youtubegoes5g_1.0 ACCESS_LOG - /127.0.0.1:56592 "POST /v1/models/youtubegoes5g:predict HTTP/1.1" 200 3
2025-01-22T18:53:20,161 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572000
2025-01-22T18:53:20,161 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:2770.823|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572000
2025-01-22T18:53:20,161 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:82.105|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572000
2025-01-22T18:53:20,161 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.job.Job - Waiting time ns: 82105, Backend time ns: 3110046
2025-01-22T18:53:20,161 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572000
2025-01-22T18:53:20,161 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2025-01-22T18:53:20,161 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3
2025-01-22T18:53:20,161 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572000
2025-01-22 18:53:20.162 kserve.trace requestId: 9faeebc3-e042-4690-80db-50bc8f0477db, preprocess_ms: 0.011920929, explain_ms: 0, predict_ms: 6.99877739, postprocess_ms: 0.004529953
2025-01-22 18:53:20.163 uvicorn.access INFO:     10.233.75.99:0 9 - "POST /v1/models/youtubegoes5g%3Apredict HTTP/1.1" 200 OK
2025-01-22 18:53:20.163 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.007902145385742188
2025-01-22 18:53:20.163 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.004369000000224332
2025-01-22T18:53:32,181 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572012
2025-01-22T18:53:32,181 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1737572012181
2025-01-22T18:53:32,183 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Backend received inference at: 1737572012
2025-01-22T18:53:32,183 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Received data: [{'data': [13, 13, 13, 0, 13, 13, 13, 13, -76, -76, -81, -76, -78.5, -76, -76, -7, -7, -12, -7, -9.5, -7, -7, 12, 12, 7, 12, 9.5, 12, 12]}]
2025-01-22T18:53:32,184 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Input data preprocessed successfully
2025-01-22T18:53:32,184 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Inference performed successfully
2025-01-22T18:53:32,184 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Output postprocessed successfully
2025-01-22T18:53:32,184 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:1.29|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,1737572012,9eca042a-a77d-41c9-acd7-5dd9f8f6034c, pattern=[METRICS]
2025-01-22T18:53:32,184 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_METRICS - PredictionTime.ms:1.29|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,requestID:9eca042a-a77d-41c9-acd7-5dd9f8f6034c,timestamp:1737572012
2025-01-22T18:53:32,184 [INFO ] W-9000-youtubegoes5g_1.0 ACCESS_LOG - /127.0.0.1:46634 "POST /v1/models/youtubegoes5g:predict HTTP/1.1" 200 3
2025-01-22T18:53:32,184 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572012
2025-01-22T18:53:32,184 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:2756.237|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572012
2025-01-22T18:53:32,184 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:147.745|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572012
2025-01-22T18:53:32,184 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.job.Job - Waiting time ns: 147745, Backend time ns: 2789203
2025-01-22T18:53:32,184 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572012
2025-01-22T18:53:32,184 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2025-01-22T18:53:32,184 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3
2025-01-22T18:53:32,184 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572012
2025-01-22 18:53:32.185 kserve.trace requestId: a01986eb-977c-4937-94b1-94a2e7d7ecea, preprocess_ms: 0.028371811, explain_ms: 0, predict_ms: 7.110834122, postprocess_ms: 0.005245209
2025-01-22 18:53:32.186 uvicorn.access INFO:     10.233.75.99:0 9 - "POST /v1/models/youtubegoes5g%3Apredict HTTP/1.1" 200 OK
2025-01-22 18:53:32.186 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.008348226547241211
2025-01-22 18:53:32.186 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.004951999999320833
2025-01-22T18:53:44,205 [INFO ] epollEventLoopGroup-3-4 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572024
2025-01-22T18:53:44,205 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1737572024205
2025-01-22T18:53:44,207 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Backend received inference at: 1737572024
2025-01-22T18:53:44,207 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Received data: [{'data': [13, 13, 13, 0, 13, 13, 13, 13, -76, -76, -81, -76, -78.5, -76, -76, -7, -7, -12, -7, -9.5, -7, -7, 12, 12, 7, 12, 9.5, 12, 12]}]
2025-01-22T18:53:44,207 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Input data preprocessed successfully
2025-01-22T18:53:44,207 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Inference performed successfully
2025-01-22T18:53:44,208 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Output postprocessed successfully
2025-01-22T18:53:44,208 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:1.4|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,1737572024,a1bb3f45-761f-444d-8344-a908b2ae8ac7, pattern=[METRICS]
2025-01-22T18:53:44,208 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_METRICS - PredictionTime.ms:1.4|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,requestID:a1bb3f45-761f-444d-8344-a908b2ae8ac7,timestamp:1737572024
2025-01-22T18:53:44,208 [INFO ] W-9000-youtubegoes5g_1.0 ACCESS_LOG - /127.0.0.1:55310 "POST /v1/models/youtubegoes5g:predict HTTP/1.1" 200 3
2025-01-22T18:53:44,208 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572024
2025-01-22T18:53:44,208 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:2670.475|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572024
2025-01-22T18:53:44,208 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:107.87|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572024
2025-01-22T18:53:44,208 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.job.Job - Waiting time ns: 107870, Backend time ns: 3037351
2025-01-22T18:53:44,208 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572024
2025-01-22T18:53:44,208 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2025-01-22T18:53:44,208 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0
2025-01-22T18:53:44,208 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:3.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572024
2025-01-22 18:53:44.210 kserve.trace requestId: 6f8efb93-2e2d-4a75-882e-735df8ea251c, preprocess_ms: 0.012159348, explain_ms: 0, predict_ms: 8.251190186, postprocess_ms: 0.005245209
2025-01-22 18:53:44.210 uvicorn.access INFO:     10.233.75.99:0 9 - "POST /v1/models/youtubegoes5g%3Apredict HTTP/1.1" 200 OK
2025-01-22 18:53:44.211 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.00942087173461914
2025-01-22 18:53:44.211 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.00598100000024715
2025-01-22T18:53:56,229 [INFO ] epollEventLoopGroup-3-1 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572036
2025-01-22T18:53:56,229 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1737572036229
2025-01-22T18:53:56,231 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Backend received inference at: 1737572036
2025-01-22T18:53:56,231 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Received data: [{'data': [13, 13, 13, 0, 13, 13, 13, 13, -76, -76, -81, -76, -78.5, -76, -76, -7, -7, -12, -7, -9.5, -7, -7, 12, 12, 7, 12, 9.5, 12, 12]}]
2025-01-22T18:53:56,231 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Input data preprocessed successfully
2025-01-22T18:53:56,233 [INFO ] W-9000-youtubegoes5g_1.0 ACCESS_LOG - /127.0.0.1:42636 "POST /v1/models/youtubegoes5g:predict HTTP/1.1" 200 4
2025-01-22T18:53:56,233 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572036
2025-01-22T18:53:56,233 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:3349.283|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572036
2025-01-22T18:53:56,233 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:157.193|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572036
2025-01-22T18:53:56,233 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.job.Job - Waiting time ns: 157193, Backend time ns: 3388816
2025-01-22T18:53:56,233 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572036
2025-01-22T18:53:56,233 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2025-01-22T18:53:56,233 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3
2025-01-22T18:53:56,233 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Inference performed successfully
2025-01-22T18:53:56,233 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572036
2025-01-22T18:53:56,233 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Output postprocessed successfully
2025-01-22T18:53:56,233 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:1.37|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,1737572036,f5b505a1-9a9c-4d58-ae0d-52c00502eaf1, pattern=[METRICS]
2025-01-22T18:53:56,233 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_METRICS - PredictionTime.ms:1.37|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,requestID:f5b505a1-9a9c-4d58-ae0d-52c00502eaf1,timestamp:1737572036
2025-01-22 18:53:56.234 kserve.trace requestId: e8efa37d-1f4b-43db-b4fc-cdf4ed39616e, preprocess_ms: 0.012159348, explain_ms: 0, predict_ms: 8.041381836, postprocess_ms: 0.004768372
2025-01-22 18:53:56.234 uvicorn.access INFO:     10.233.75.99:0 9 - "POST /v1/models/youtubegoes5g%3Apredict HTTP/1.1" 200 OK
2025-01-22 18:53:56.235 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.008979082107543945
2025-01-22 18:53:56.235 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.004988000000594184
2025-01-22T18:54:08,253 [INFO ] epollEventLoopGroup-3-2 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572048
2025-01-22T18:54:08,253 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1737572048253
2025-01-22T18:54:08,253 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Backend received inference at: 1737572048
2025-01-22T18:54:08,254 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Received data: [{'data': [13, 13, 13, 0, 13, 13, 13, 13, -76, -76, -81, -76, -78.5, -76, -76, -7, -7, -12, -7, -9.5, -7, -7, 12, 12, 7, 12, 9.5, 12, 12]}]
2025-01-22T18:54:08,254 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Input data preprocessed successfully
2025-01-22T18:54:08,255 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Inference performed successfully
2025-01-22T18:54:08,255 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Output postprocessed successfully
2025-01-22T18:54:08,255 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:1.27|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,1737572048,965c7d9d-43c3-471e-8b2b-12bd5639ec2e, pattern=[METRICS]
2025-01-22T18:54:08,255 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_METRICS - PredictionTime.ms:1.27|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,requestID:965c7d9d-43c3-471e-8b2b-12bd5639ec2e,timestamp:1737572048
2025-01-22T18:54:08,255 [INFO ] W-9000-youtubegoes5g_1.0 ACCESS_LOG - /127.0.0.1:33400 "POST /v1/models/youtubegoes5g:predict HTTP/1.1" 200 2
2025-01-22T18:54:08,255 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572048
2025-01-22T18:54:08,255 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:2605.069|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572048
2025-01-22T18:54:08,255 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:43.477|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572048
2025-01-22T18:54:08,255 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.job.Job - Waiting time ns: 43477, Backend time ns: 2667228
2025-01-22T18:54:08,255 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572048
2025-01-22T18:54:08,255 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2025-01-22T18:54:08,255 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2
2025-01-22T18:54:08,255 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572048
2025-01-22 18:54:08.257 kserve.trace requestId: d5b448f8-a89d-4148-a0ca-90769c7a17fb, preprocess_ms: 0.011920929, explain_ms: 0, predict_ms: 6.477117538, postprocess_ms: 0.00500679
2025-01-22 18:54:08.257 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.007386207580566406
2025-01-22 18:54:08.257 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.004172999999354943
2025-01-22 18:54:08.257 uvicorn.access INFO:     10.233.75.99:0 9 - "POST /v1/models/youtubegoes5g%3Apredict HTTP/1.1" 200 OK
2025-01-22T18:54:18,995 [INFO ] pool-3-thread-2 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572058
2025-01-22T18:54:18,996 [INFO ] pool-3-thread-2 TS_METRICS - DiskAvailable.Gigabytes:263.70519256591797|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572058
2025-01-22T18:54:18,996 [INFO ] pool-3-thread-2 TS_METRICS - DiskUsage.Gigabytes:208.2980728149414|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572058
2025-01-22T18:54:18,996 [INFO ] pool-3-thread-2 TS_METRICS - DiskUtilization.Percent:44.1|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572058
2025-01-22T18:54:18,996 [INFO ] pool-3-thread-2 TS_METRICS - MemoryAvailable.Megabytes:11296.3359375|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572058
2025-01-22T18:54:18,996 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUsed.Megabytes:8343.26953125|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572058
2025-01-22T18:54:18,997 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUtilization.Percent:43.5|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572058
2025-01-22T18:54:20,284 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572060
2025-01-22T18:54:20,284 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1737572060284
2025-01-22T18:54:20,285 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Backend received inference at: 1737572060
2025-01-22T18:54:20,285 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Received data: [{'data': [13, 13, 13, 0, 13, 13, 13, 13, -76, -76, -81, -76, -78.5, -76, -76, -7, -7, -12, -7, -9.5, -7, -7, 12, 12, 7, 12, 9.5, 12, 12]}]
2025-01-22T18:54:20,285 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Input data preprocessed successfully
2025-01-22T18:54:20,287 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Inference performed successfully
2025-01-22T18:54:20,287 [INFO ] W-9000-youtubegoes5g_1.0 ACCESS_LOG - /127.0.0.1:43534 "POST /v1/models/youtubegoes5g:predict HTTP/1.1" 200 3
2025-01-22T18:54:20,287 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Output postprocessed successfully
2025-01-22T18:54:20,287 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572060
2025-01-22T18:54:20,287 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:1.4|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,1737572060,3c473374-9952-4b38-9bd2-72813313f554, pattern=[METRICS]
2025-01-22T18:54:20,287 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:3391.875|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572060
2025-01-22T18:54:20,287 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_METRICS - PredictionTime.ms:1.4|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,requestID:3c473374-9952-4b38-9bd2-72813313f554,timestamp:1737572060
2025-01-22T18:54:20,287 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:97.382|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572060
2025-01-22T18:54:20,287 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.job.Job - Waiting time ns: 97382, Backend time ns: 3469372
2025-01-22T18:54:20,287 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572060
2025-01-22T18:54:20,287 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2025-01-22T18:54:20,287 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3
2025-01-22T18:54:20,287 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572060
2025-01-22 18:54:20.289 kserve.trace requestId: b48c7e8a-77e7-45fd-8655-800c0898eaa4, preprocess_ms: 0.012636185, explain_ms: 0, predict_ms: 16.883611679, postprocess_ms: 0.008583069
2025-01-22 18:54:20.289 uvicorn.access INFO:     10.233.75.99:0 9 - "POST /v1/models/youtubegoes5g%3Apredict HTTP/1.1" 200 OK
2025-01-22 18:54:20.289 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.017946958541870117
2025-01-22 18:54:20.289 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.005519999998796266
2025-01-22T18:54:32,308 [INFO ] epollEventLoopGroup-3-4 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572072
2025-01-22T18:54:32,308 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1737572072308
2025-01-22T18:54:32,309 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Backend received inference at: 1737572072
2025-01-22T18:54:32,309 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Received data: [{'data': [13, 13, 13, 0, 13, 13, 13, 13, -76, -76, -81, -76, -78.5, -76, -76, -7, -7, -12, -7, -9.5, -7, -7, 12, 12, 7, 12, 9.5, 12, 12]}]
2025-01-22T18:54:32,310 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Input data preprocessed successfully
2025-01-22T18:54:32,313 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Inference performed successfully
2025-01-22T18:54:32,313 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Output postprocessed successfully
2025-01-22T18:54:32,314 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:4.88|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,1737572072,10dcaee9-28a4-4308-8bbf-d69382cb25b2, pattern=[METRICS]
2025-01-22T18:54:32,314 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_METRICS - PredictionTime.ms:4.88|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,requestID:10dcaee9-28a4-4308-8bbf-d69382cb25b2,timestamp:1737572072
2025-01-22T18:54:32,314 [INFO ] W-9000-youtubegoes5g_1.0 ACCESS_LOG - /127.0.0.1:35752 "POST /v1/models/youtubegoes5g:predict HTTP/1.1" 200 7
2025-01-22T18:54:32,314 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572072
2025-01-22T18:54:32,314 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:5929.451|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572072
2025-01-22T18:54:32,314 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:48.289|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572072
2025-01-22T18:54:32,314 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.job.Job - Waiting time ns: 48289, Backend time ns: 6087885
2025-01-22T18:54:32,314 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572072
2025-01-22T18:54:32,314 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2025-01-22T18:54:32,314 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 6
2025-01-22T18:54:32,314 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572072
2025-01-22 18:54:32.315 kserve.trace requestId: a18e5fac-96b8-4f73-904a-a6045064ab73, preprocess_ms: 0.011444092, explain_ms: 0, predict_ms: 10.02240181, postprocess_ms: 0.00500679
2025-01-22 18:54:32.315 uvicorn.access INFO:     10.233.75.99:0 9 - "POST /v1/models/youtubegoes5g%3Apredict HTTP/1.1" 200 OK
2025-01-22 18:54:32.315 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.011066198348999023
2025-01-22 18:54:32.315 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.004591000000800705
2025-01-22T18:54:44,332 [INFO ] epollEventLoopGroup-3-1 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572084
2025-01-22T18:54:44,332 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1737572084332
2025-01-22T18:54:44,333 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Backend received inference at: 1737572084
2025-01-22T18:54:44,333 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Received data: [{'data': [13, 13, 13, 0, 13, 13, 13, 13, -76, -76, -81, -76, -78.5, -76, -76, -7, -7, -12, -7, -9.5, -7, -7, 12, 12, 7, 12, 9.5, 12, 12]}]
2025-01-22T18:54:44,334 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Input data preprocessed successfully
2025-01-22T18:54:44,334 [INFO ] W-9000-youtubegoes5g_1.0 ACCESS_LOG - /127.0.0.1:53832 "POST /v1/models/youtubegoes5g:predict HTTP/1.1" 200 2
2025-01-22T18:54:44,334 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572084
2025-01-22T18:54:44,334 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:2253.744|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572084
2025-01-22T18:54:44,334 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:51.57|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572084
2025-01-22T18:54:44,334 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.job.Job - Waiting time ns: 51570, Backend time ns: 2357360
2025-01-22T18:54:44,334 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572084
2025-01-22T18:54:44,334 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Inference performed successfully
2025-01-22T18:54:44,335 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2025-01-22T18:54:44,335 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Output postprocessed successfully
2025-01-22T18:54:44,335 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1
2025-01-22T18:54:44,335 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:2.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572084
2025-01-22T18:54:44,335 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:1.35|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,1737572084,84480d1e-a8da-4a2c-bf88-818cddf5d224, pattern=[METRICS]
2025-01-22T18:54:44,335 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_METRICS - PredictionTime.ms:1.35|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,requestID:84480d1e-a8da-4a2c-bf88-818cddf5d224,timestamp:1737572084
2025-01-22 18:54:44.336 kserve.trace requestId: f34bf1a3-dbca-412f-b50a-80358e693850, preprocess_ms: 0.011920929, explain_ms: 0, predict_ms: 6.053209305, postprocess_ms: 0.004529953
2025-01-22 18:54:44.336 uvicorn.access INFO:     10.233.75.99:0 9 - "POST /v1/models/youtubegoes5g%3Apredict HTTP/1.1" 200 OK
2025-01-22 18:54:44.336 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.006998538970947266
2025-01-22 18:54:44.336 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.00432600000021921
2025-01-22T18:55:18,989 [INFO ] pool-3-thread-2 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572118
2025-01-22T18:55:18,989 [INFO ] pool-3-thread-2 TS_METRICS - DiskAvailable.Gigabytes:263.7049674987793|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572118
2025-01-22T18:55:18,989 [INFO ] pool-3-thread-2 TS_METRICS - DiskUsage.Gigabytes:208.29829788208008|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572118
2025-01-22T18:55:18,989 [INFO ] pool-3-thread-2 TS_METRICS - DiskUtilization.Percent:44.1|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572118
2025-01-22T18:55:18,989 [INFO ] pool-3-thread-2 TS_METRICS - MemoryAvailable.Megabytes:11284.08984375|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572118
2025-01-22T18:55:18,989 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUsed.Megabytes:8355.51171875|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572118
2025-01-22T18:55:18,989 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUtilization.Percent:43.5|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572118
2025-01-22T18:55:20,354 [INFO ] epollEventLoopGroup-3-2 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572120
2025-01-22T18:55:20,354 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1737572120354
2025-01-22T18:55:20,355 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Backend received inference at: 1737572120
2025-01-22T18:55:20,355 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Received data: [{'data': [13, 13, 13, 0, 13, 13, 13, 13, -76, -76, -81, -76, -78.5, -76, -76, -7, -7, -12, -7, -9.5, -7, -7, 12, 12, 7, 12, 9.5, 12, 12]}]
2025-01-22T18:55:20,356 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Input data preprocessed successfully
2025-01-22T18:55:20,357 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Inference performed successfully
2025-01-22T18:55:20,357 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Output postprocessed successfully
2025-01-22T18:55:20,357 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:1.29|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,1737572120,4df3dc67-340d-4bc7-83d0-af1bbed79083, pattern=[METRICS]
2025-01-22T18:55:20,357 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_METRICS - PredictionTime.ms:1.29|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,requestID:4df3dc67-340d-4bc7-83d0-af1bbed79083,timestamp:1737572120
2025-01-22T18:55:20,357 [INFO ] W-9000-youtubegoes5g_1.0 ACCESS_LOG - /127.0.0.1:49646 "POST /v1/models/youtubegoes5g:predict HTTP/1.1" 200 3
2025-01-22T18:55:20,357 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572120
2025-01-22T18:55:20,357 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:2356.753|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572120
2025-01-22T18:55:20,357 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:87.767|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572120
2025-01-22T18:55:20,357 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.job.Job - Waiting time ns: 87767, Backend time ns: 2414193
2025-01-22T18:55:20,357 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572120
2025-01-22T18:55:20,357 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2025-01-22T18:55:20,357 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2
2025-01-22T18:55:20,357 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572120
2025-01-22 18:55:20.359 kserve.trace requestId: 84a6862b-2960-4b37-82f8-c603a4295be7, preprocess_ms: 0.012397766, explain_ms: 0, predict_ms: 7.37452507, postprocess_ms: 0.00500679
2025-01-22 18:55:20.359 uvicorn.access INFO:     10.233.75.99:0 9 - "POST /v1/models/youtubegoes5g%3Apredict HTTP/1.1" 200 OK
2025-01-22 18:55:20.359 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.00846242904663086
2025-01-22 18:55:20.359 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.005095999998957268
2025-01-22T18:55:32,385 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572132
2025-01-22T18:55:32,385 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1737572132385
2025-01-22T18:55:32,386 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Backend received inference at: 1737572132
2025-01-22T18:55:32,386 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Received data: [{'data': [13, 13, 13, 0, 13, 13, 13, 13, -76, -76, -81, -76, -78.5, -76, -76, -7, -7, -12, -7, -9.5, -7, -7, 12, 12, 7, 12, 9.5, 12, 12]}]
2025-01-22T18:55:32,387 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Input data preprocessed successfully
2025-01-22T18:55:32,391 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Inference performed successfully
2025-01-22T18:55:32,391 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Output postprocessed successfully
2025-01-22T18:55:32,391 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:4.58|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,1737572132,4cd16fed-791e-4b28-9a4d-512e16f06634, pattern=[METRICS]
2025-01-22T18:55:32,391 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_METRICS - PredictionTime.ms:4.58|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,requestID:4cd16fed-791e-4b28-9a4d-512e16f06634,timestamp:1737572132
2025-01-22T18:55:32,391 [INFO ] W-9000-youtubegoes5g_1.0 ACCESS_LOG - /127.0.0.1:36620 "POST /v1/models/youtubegoes5g:predict HTTP/1.1" 200 6
2025-01-22T18:55:32,391 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572132
2025-01-22T18:55:32,391 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:5564.108|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572132
2025-01-22T18:55:32,391 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:55.46|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572132
2025-01-22T18:55:32,391 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.job.Job - Waiting time ns: 55460, Backend time ns: 5658454
2025-01-22T18:55:32,391 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572132
2025-01-22T18:55:32,391 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2025-01-22T18:55:32,391 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 5
2025-01-22T18:55:32,391 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572132
2025-01-22 18:55:32.393 kserve.trace requestId: abbe1d6a-e97d-4801-af4e-2c535ed37bc9, preprocess_ms: 0.012397766, explain_ms: 0, predict_ms: 9.720563889, postprocess_ms: 0.000715256
2025-01-22 18:55:32.393 uvicorn.access INFO:     10.233.75.99:0 9 - "POST /v1/models/youtubegoes5g%3Apredict HTTP/1.1" 200 OK
2025-01-22 18:55:32.393 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.011008262634277344
2025-01-22 18:55:32.394 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.005129999999553547
2025-01-22T18:55:44,409 [INFO ] epollEventLoopGroup-3-4 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572144
2025-01-22T18:55:44,409 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1737572144409
2025-01-22T18:55:44,410 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Backend received inference at: 1737572144
2025-01-22T18:55:44,410 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Received data: [{'data': [13, 13, 13, 0, 13, 13, 13, 13, -76, -76, -81, -76, -78.5, -76, -76, -7, -7, -12, -7, -9.5, -7, -7, 12, 12, 7, 12, 9.5, 12, 12]}]
2025-01-22T18:55:44,411 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Input data preprocessed successfully
2025-01-22T18:55:44,412 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Inference performed successfully
2025-01-22T18:55:44,412 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Output postprocessed successfully
2025-01-22T18:55:44,412 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:1.58|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,1737572144,3790fb68-a5cc-4d6d-9bc5-87d9c9907356, pattern=[METRICS]
2025-01-22T18:55:44,412 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_METRICS - PredictionTime.ms:1.58|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,requestID:3790fb68-a5cc-4d6d-9bc5-87d9c9907356,timestamp:1737572144
2025-01-22T18:55:44,412 [INFO ] W-9000-youtubegoes5g_1.0 ACCESS_LOG - /127.0.0.1:37786 "POST /v1/models/youtubegoes5g:predict HTTP/1.1" 200 3
2025-01-22T18:55:44,412 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572144
2025-01-22T18:55:44,412 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:2660.181|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572144
2025-01-22T18:55:44,412 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:36.65|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572144
2025-01-22T18:55:44,412 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.job.Job - Waiting time ns: 36650, Backend time ns: 2810567
2025-01-22T18:55:44,412 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572144
2025-01-22T18:55:44,412 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2025-01-22T18:55:44,412 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2
2025-01-22T18:55:44,412 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572144
2025-01-22 18:55:44.414 kserve.trace requestId: 1a242bf4-f7aa-4495-92e0-f19a35d2de26, preprocess_ms: 0.013113022, explain_ms: 0, predict_ms: 6.571292877, postprocess_ms: 0.004529953
2025-01-22 18:55:44.414 uvicorn.access INFO:     10.233.75.99:0 9 - "POST /v1/models/youtubegoes5g%3Apredict HTTP/1.1" 200 OK
2025-01-22 18:55:44.414 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.0074808597564697266
2025-01-22 18:55:44.414 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.004327000000557746
2025-01-22T18:55:56,433 [INFO ] epollEventLoopGroup-3-1 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572156
2025-01-22T18:55:56,433 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1737572156433
2025-01-22T18:55:56,433 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Backend received inference at: 1737572156
2025-01-22T18:55:56,434 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Received data: [{'data': [13, 13, 13, 0, 13, 13, 13, 13, -76, -76, -81, -76, -78.5, -76, -76, -7, -7, -12, -7, -9.5, -7, -7, 12, 12, 7, 12, 9.5, 12, 12]}]
2025-01-22T18:55:56,436 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Input data preprocessed successfully
2025-01-22T18:55:56,438 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Inference performed successfully
2025-01-22T18:55:56,439 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Output postprocessed successfully
2025-01-22T18:55:56,439 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:5.14|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,1737572156,9683a3ac-56f5-49b0-a296-ea9b322baf33, pattern=[METRICS]
2025-01-22T18:55:56,439 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_METRICS - PredictionTime.ms:5.14|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,requestID:9683a3ac-56f5-49b0-a296-ea9b322baf33,timestamp:1737572156
2025-01-22T18:55:56,439 [INFO ] W-9000-youtubegoes5g_1.0 ACCESS_LOG - /127.0.0.1:47188 "POST /v1/models/youtubegoes5g:predict HTTP/1.1" 200 6
2025-01-22T18:55:56,439 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572156
2025-01-22T18:55:56,439 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:6238.09|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572156
2025-01-22T18:55:56,439 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:34.35|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572156
2025-01-22T18:55:56,439 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.job.Job - Waiting time ns: 34350, Backend time ns: 6384431
2025-01-22T18:55:56,439 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572156
2025-01-22T18:55:56,439 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2025-01-22T18:55:56,439 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 6
2025-01-22T18:55:56,439 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572156
2025-01-22 18:55:56.440 kserve.trace requestId: 47b14287-72c6-42a4-83b2-e8ce3fd8f6e4, preprocess_ms: 0.012397766, explain_ms: 0, predict_ms: 10.849475861, postprocess_ms: 0.005483627
2025-01-22 18:55:56.441 uvicorn.access INFO:     10.233.75.99:0 9 - "POST /v1/models/youtubegoes5g%3Apredict HTTP/1.1" 200 OK
2025-01-22 18:55:56.441 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.012162208557128906
2025-01-22 18:55:56.441 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.005244999998467392
2025-01-22T18:56:08,458 [INFO ] epollEventLoopGroup-3-2 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572168
2025-01-22T18:56:08,458 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1737572168458
2025-01-22T18:56:08,459 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Backend received inference at: 1737572168
2025-01-22T18:56:08,459 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Received data: [{'data': [13, 13, 13, 0, 13, 13, 13, 13, -76, -76, -81, -76, -78.5, -76, -76, -7, -7, -12, -7, -9.5, -7, -7, 12, 12, 7, 12, 9.5, 12, 12]}]
2025-01-22T18:56:08,460 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Input data preprocessed successfully
2025-01-22T18:56:08,463 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Inference performed successfully
2025-01-22T18:56:08,463 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Output postprocessed successfully
2025-01-22T18:56:08,464 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:4.54|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,1737572168,16b9ae17-b5bb-4f5e-bd88-e4c3c2937f28, pattern=[METRICS]
2025-01-22T18:56:08,464 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_METRICS - PredictionTime.ms:4.54|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,requestID:16b9ae17-b5bb-4f5e-bd88-e4c3c2937f28,timestamp:1737572168
2025-01-22T18:56:08,464 [INFO ] W-9000-youtubegoes5g_1.0 ACCESS_LOG - /127.0.0.1:48544 "POST /v1/models/youtubegoes5g:predict HTTP/1.1" 200 6
2025-01-22T18:56:08,464 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572168
2025-01-22T18:56:08,464 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:5586.451|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572168
2025-01-22T18:56:08,464 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:43.661|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572168
2025-01-22T18:56:08,464 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.job.Job - Waiting time ns: 43661, Backend time ns: 5708316
2025-01-22T18:56:08,464 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572168
2025-01-22T18:56:08,464 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2025-01-22T18:56:08,464 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 6
2025-01-22T18:56:08,464 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572168
2025-01-22 18:56:08.465 kserve.trace requestId: 235753f0-acf8-438f-8db0-3b2c88b239df, preprocess_ms: 0.012159348, explain_ms: 0, predict_ms: 9.507417679, postprocess_ms: 0.010967255
2025-01-22 18:56:08.465 uvicorn.access INFO:     10.233.75.99:0 9 - "POST /v1/models/youtubegoes5g%3Apredict HTTP/1.1" 200 OK
2025-01-22 18:56:08.466 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.01045989990234375
2025-01-22 18:56:08.466 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.004670000002079178
2025-01-22T18:56:18,988 [INFO ] pool-3-thread-2 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572178
2025-01-22T18:56:18,988 [INFO ] pool-3-thread-2 TS_METRICS - DiskAvailable.Gigabytes:263.7046928405762|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572178
2025-01-22T18:56:18,988 [INFO ] pool-3-thread-2 TS_METRICS - DiskUsage.Gigabytes:208.2985725402832|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572178
2025-01-22T18:56:18,988 [INFO ] pool-3-thread-2 TS_METRICS - DiskUtilization.Percent:44.1|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572178
2025-01-22T18:56:18,989 [INFO ] pool-3-thread-2 TS_METRICS - MemoryAvailable.Megabytes:11212.16796875|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572178
2025-01-22T18:56:18,989 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUsed.Megabytes:8427.43359375|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572178
2025-01-22T18:56:18,989 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUtilization.Percent:43.9|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572178
2025-01-22T18:56:20,483 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572180
2025-01-22T18:56:20,483 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1737572180483
2025-01-22T18:56:20,484 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Backend received inference at: 1737572180
2025-01-22T18:56:20,484 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Received data: [{'data': [13, 13, 13, 0, 13, 13, 13, 13, -76, -76, -81, -76, -78.5, -76, -76, -7, -7, -12, -7, -9.5, -7, -7, 12, 12, 7, 12, 9.5, 12, 12]}]
2025-01-22T18:56:20,485 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Input data preprocessed successfully
2025-01-22T18:56:20,487 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Inference performed successfully
2025-01-22T18:56:20,487 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Output postprocessed successfully
2025-01-22T18:56:20,487 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:3.49|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,1737572180,7cf9eaee-b05c-4113-a8b5-71e403914c17, pattern=[METRICS]
2025-01-22T18:56:20,488 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_METRICS - PredictionTime.ms:3.49|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,requestID:7cf9eaee-b05c-4113-a8b5-71e403914c17,timestamp:1737572180
2025-01-22T18:56:20,488 [INFO ] W-9000-youtubegoes5g_1.0 ACCESS_LOG - /127.0.0.1:42450 "POST /v1/models/youtubegoes5g:predict HTTP/1.1" 200 5
2025-01-22T18:56:20,488 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572180
2025-01-22T18:56:20,489 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:5542.015|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572180
2025-01-22T18:56:20,489 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:81.896|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572180
2025-01-22T18:56:20,489 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.job.Job - Waiting time ns: 81896, Backend time ns: 5622574
2025-01-22T18:56:20,489 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572180
2025-01-22T18:56:20,489 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2025-01-22T18:56:20,489 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 5
2025-01-22T18:56:20,489 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572180
2025-01-22 18:56:20.490 kserve.trace requestId: 7b75fdfc-1702-41fc-b3e5-bf9d30d3e8c4, preprocess_ms: 0.018596649, explain_ms: 0, predict_ms: 9.930849075, postprocess_ms: 0.005245209
2025-01-22 18:56:20.490 uvicorn.access INFO:     10.233.75.99:0 9 - "POST /v1/models/youtubegoes5g%3Apredict HTTP/1.1" 200 OK
2025-01-22 18:56:20.490 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.010952949523925781
2025-01-22 18:56:20.491 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.00509299999976065
2025-01-22T18:56:32,507 [INFO ] epollEventLoopGroup-3-4 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572192
2025-01-22T18:56:32,507 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1737572192507
2025-01-22T18:56:32,508 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Backend received inference at: 1737572192
2025-01-22T18:56:32,508 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Received data: [{'data': [13, 13, 13, 0, 13, 13, 13, 13, -76, -76, -81, -76, -78.5, -76, -76, -7, -7, -12, -7, -9.5, -7, -7, 12, 12, 7, 12, 9.5, 12, 12]}]
2025-01-22T18:56:32,509 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Input data preprocessed successfully
2025-01-22T18:56:32,512 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Inference performed successfully
2025-01-22T18:56:32,512 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Output postprocessed successfully
2025-01-22T18:56:32,513 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:4.81|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,1737572192,74d209fe-d96d-4a67-aeb1-53edeb90ee59, pattern=[METRICS]
2025-01-22T18:56:32,513 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_METRICS - PredictionTime.ms:4.81|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,requestID:74d209fe-d96d-4a67-aeb1-53edeb90ee59,timestamp:1737572192
2025-01-22T18:56:32,513 [INFO ] W-9000-youtubegoes5g_1.0 ACCESS_LOG - /127.0.0.1:60836 "POST /v1/models/youtubegoes5g:predict HTTP/1.1" 200 6
2025-01-22T18:56:32,513 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572192
2025-01-22T18:56:32,513 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:5978.953|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572192
2025-01-22T18:56:32,513 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:56.841|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572192
2025-01-22T18:56:32,513 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.job.Job - Waiting time ns: 56841, Backend time ns: 6049374
2025-01-22T18:56:32,513 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572192
2025-01-22T18:56:32,513 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2025-01-22T18:56:32,513 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 6
2025-01-22T18:56:32,513 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572192
2025-01-22 18:56:32.514 kserve.trace requestId: fddef418-559d-44e4-ba57-d516c100063d, preprocess_ms: 0.012159348, explain_ms: 0, predict_ms: 10.007619858, postprocess_ms: 0.000238419
2025-01-22 18:56:32.515 uvicorn.access INFO:     10.233.75.99:0 9 - "POST /v1/models/youtubegoes5g%3Apredict HTTP/1.1" 200 OK
2025-01-22 18:56:32.515 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.011010885238647461
2025-01-22 18:56:32.515 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.004677000000810949
2025-01-22T18:56:44,535 [INFO ] epollEventLoopGroup-3-1 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572204
2025-01-22T18:56:44,535 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1737572204535
2025-01-22T18:56:44,535 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Backend received inference at: 1737572204
2025-01-22T18:56:44,536 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Received data: [{'data': [13, 13, 13, 0, 13, 13, 13, 13, -76, -76, -81, -76, -78.5, -76, -76, -7, -7, -12, -7, -9.5, -7, -7, 12, 12, 7, 12, 9.5, 12, 12]}]
2025-01-22T18:56:44,536 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Input data preprocessed successfully
2025-01-22T18:56:44,539 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Inference performed successfully
2025-01-22T18:56:44,540 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Output postprocessed successfully
2025-01-22T18:56:44,540 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:4.0|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,1737572204,58917d8d-6ab7-4e54-9096-ed583a5d9032, pattern=[METRICS]
2025-01-22T18:56:44,540 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_METRICS - PredictionTime.ms:4.0|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,requestID:58917d8d-6ab7-4e54-9096-ed583a5d9032,timestamp:1737572204
2025-01-22T18:56:44,540 [INFO ] W-9000-youtubegoes5g_1.0 ACCESS_LOG - /127.0.0.1:32790 "POST /v1/models/youtubegoes5g:predict HTTP/1.1" 200 6
2025-01-22T18:56:44,540 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572204
2025-01-22T18:56:44,540 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:5492.254|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572204
2025-01-22T18:56:44,540 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:34.854|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572204
2025-01-22T18:56:44,540 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.job.Job - Waiting time ns: 34854, Backend time ns: 5611225
2025-01-22T18:56:44,540 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572204
2025-01-22T18:56:44,540 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2025-01-22T18:56:44,540 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 5
2025-01-22T18:56:44,540 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572204
2025-01-22 18:56:44.542 kserve.trace requestId: 57be2f43-5eb9-41d2-a426-49e21bcd3702, preprocess_ms: 0.01168251, explain_ms: 0, predict_ms: 9.993314743, postprocess_ms: 0.005722046
2025-01-22 18:56:44.542 uvicorn.access INFO:     10.233.75.99:0 9 - "POST /v1/models/youtubegoes5g%3Apredict HTTP/1.1" 200 OK
2025-01-22 18:56:44.542 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.011172056198120117
2025-01-22 18:56:44.543 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.005140999999639462
2025-01-22T18:56:56,561 [INFO ] epollEventLoopGroup-3-2 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572216
2025-01-22T18:56:56,561 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1737572216561
2025-01-22T18:56:56,561 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Backend received inference at: 1737572216
2025-01-22T18:56:56,561 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Received data: [{'data': [13, 13, 13, 0, 13, 13, 13, 13, -76, -76, -81, -76, -78.5, -76, -76, -7, -7, -12, -7, -9.5, -7, -7, 12, 12, 7, 12, 9.5, 12, 12]}]
2025-01-22T18:56:56,562 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Input data preprocessed successfully
2025-01-22T18:56:56,565 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Inference performed successfully
2025-01-22T18:56:56,565 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Output postprocessed successfully
2025-01-22T18:56:56,565 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:3.71|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,1737572216,475dd86d-2925-42d5-83ca-696c1182c1ce, pattern=[METRICS]
2025-01-22T18:56:56,565 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_METRICS - PredictionTime.ms:3.71|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,requestID:475dd86d-2925-42d5-83ca-696c1182c1ce,timestamp:1737572216
2025-01-22T18:56:56,566 [INFO ] W-9000-youtubegoes5g_1.0 ACCESS_LOG - /127.0.0.1:42188 "POST /v1/models/youtubegoes5g:predict HTTP/1.1" 200 5
2025-01-22T18:56:56,566 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572216
2025-01-22T18:56:56,566 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:4900.398|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572216
2025-01-22T18:56:56,566 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:50.421|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572216
2025-01-22T18:56:56,566 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.job.Job - Waiting time ns: 50421, Backend time ns: 5070260
2025-01-22T18:56:56,566 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572216
2025-01-22T18:56:56,566 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2025-01-22T18:56:56,566 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 5
2025-01-22T18:56:56,566 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572216
2025-01-22 18:56:56.567 kserve.trace requestId: e0ea45f3-6feb-43cb-9f6d-af045853da48, preprocess_ms: 0.013589859, explain_ms: 0, predict_ms: 8.330106735, postprocess_ms: 0.005245209
2025-01-22 18:56:56.567 uvicorn.access INFO:     10.233.75.99:0 9 - "POST /v1/models/youtubegoes5g%3Apredict HTTP/1.1" 200 OK
2025-01-22 18:56:56.567 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.009349584579467773
2025-01-22 18:56:56.567 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.004202000000077533
2025-01-22T18:57:08,584 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572228
2025-01-22T18:57:08,584 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1737572228584
2025-01-22T18:57:08,585 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Backend received inference at: 1737572228
2025-01-22T18:57:08,585 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Received data: [{'data': [13, 13, 13, 0, 13, 13, 13, 13, -76, -76, -81, -76, -78.5, -76, -76, -7, -7, -12, -7, -9.5, -7, -7, 12, 12, 7, 12, 9.5, 12, 12]}]
2025-01-22T18:57:08,586 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Input data preprocessed successfully
2025-01-22T18:57:08,586 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Inference performed successfully
2025-01-22T18:57:08,586 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Output postprocessed successfully
2025-01-22T18:57:08,587 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:1.57|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,1737572228,7b4f38a2-290f-4766-aa56-4e611550a55a, pattern=[METRICS]
2025-01-22T18:57:08,587 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_METRICS - PredictionTime.ms:1.57|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,requestID:7b4f38a2-290f-4766-aa56-4e611550a55a,timestamp:1737572228
2025-01-22T18:57:08,588 [INFO ] W-9000-youtubegoes5g_1.0 ACCESS_LOG - /127.0.0.1:50684 "POST /v1/models/youtubegoes5g:predict HTTP/1.1" 200 4
2025-01-22T18:57:08,588 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572228
2025-01-22T18:57:08,588 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:3442.536|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572228
2025-01-22T18:57:08,588 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:36.847|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572228
2025-01-22T18:57:08,588 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.job.Job - Waiting time ns: 36847, Backend time ns: 3532693
2025-01-22T18:57:08,588 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572228
2025-01-22T18:57:08,588 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2025-01-22T18:57:08,588 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 4
2025-01-22T18:57:08,588 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572228
2025-01-22 18:57:08.589 kserve.trace requestId: dfdcdda9-222d-4f4d-a36c-e83fabf705f6, preprocess_ms: 0.012159348, explain_ms: 0, predict_ms: 7.508277893, postprocess_ms: 0.005960464
2025-01-22 18:57:08.589 uvicorn.access INFO:     10.233.75.99:0 9 - "POST /v1/models/youtubegoes5g%3Apredict HTTP/1.1" 200 OK
2025-01-22 18:57:08.590 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.008512735366821289
2025-01-22 18:57:08.590 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.004527999999481835
2025-01-22T18:57:18,987 [INFO ] pool-3-thread-2 TS_METRICS - CPUUtilization.Percent:50.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572238
2025-01-22T18:57:18,987 [INFO ] pool-3-thread-2 TS_METRICS - DiskAvailable.Gigabytes:263.7044219970703|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572238
2025-01-22T18:57:18,987 [INFO ] pool-3-thread-2 TS_METRICS - DiskUsage.Gigabytes:208.29884338378906|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572238
2025-01-22T18:57:18,987 [INFO ] pool-3-thread-2 TS_METRICS - DiskUtilization.Percent:44.1|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572238
2025-01-22T18:57:18,987 [INFO ] pool-3-thread-2 TS_METRICS - MemoryAvailable.Megabytes:11141.59375|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572238
2025-01-22T18:57:18,987 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUsed.Megabytes:8498.0078125|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572238
2025-01-22T18:57:18,987 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUtilization.Percent:44.2|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572238
2025-01-22T18:57:44,611 [INFO ] epollEventLoopGroup-3-4 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572264
2025-01-22T18:57:44,611 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1737572264611
2025-01-22T18:57:44,612 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Backend received inference at: 1737572264
2025-01-22T18:57:44,612 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Received data: [{'data': [13, 13, 13, 0, 13, 13, 13, 13, -76, -76, -81, -76, -78.5, -76, -76, -7, -7, -12, -7, -9.5, -7, -7, 12, 12, 7, 12, 9.5, 12, 12]}]
2025-01-22T18:57:44,612 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Input data preprocessed successfully
2025-01-22T18:57:44,613 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Inference performed successfully
2025-01-22T18:57:44,613 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Output postprocessed successfully
2025-01-22T18:57:44,613 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:1.24|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,1737572264,4d651e90-9ea3-41df-af9f-3fb52aaa7adc, pattern=[METRICS]
2025-01-22T18:57:44,613 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_METRICS - PredictionTime.ms:1.24|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,requestID:4d651e90-9ea3-41df-af9f-3fb52aaa7adc,timestamp:1737572264
2025-01-22T18:57:44,614 [INFO ] W-9000-youtubegoes5g_1.0 ACCESS_LOG - /127.0.0.1:37524 "POST /v1/models/youtubegoes5g:predict HTTP/1.1" 200 3
2025-01-22T18:57:44,614 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572264
2025-01-22T18:57:44,614 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:3158.756|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572264
2025-01-22T18:57:44,614 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:29.859|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572264
2025-01-22T18:57:44,614 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.job.Job - Waiting time ns: 29859, Backend time ns: 3245519
2025-01-22T18:57:44,614 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572264
2025-01-22T18:57:44,614 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2025-01-22T18:57:44,614 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3
2025-01-22T18:57:44,614 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572264
2025-01-22 18:57:44.616 kserve.trace requestId: 59d93e05-7061-445f-9aac-d22dabb2f5c1, preprocess_ms: 0.012397766, explain_ms: 0, predict_ms: 7.375717163, postprocess_ms: 0.008821487
2025-01-22 18:57:44.616 uvicorn.access INFO:     10.233.75.99:0 9 - "POST /v1/models/youtubegoes5g%3Apredict HTTP/1.1" 200 OK
2025-01-22 18:57:44.616 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.008291006088256836
2025-01-22 18:57:44.616 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.004539999998087296
2025-01-22T18:57:56,634 [INFO ] epollEventLoopGroup-3-1 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572276
2025-01-22T18:57:56,634 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1737572276634
2025-01-22T18:57:56,635 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Backend received inference at: 1737572276
2025-01-22T18:57:56,635 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Received data: [{'data': [13, 13, 13, 0, 13, 13, 13, 13, -76, -76, -81, -76, -78.5, -76, -76, -7, -7, -12, -7, -9.5, -7, -7, 12, 12, 7, 12, 9.5, 12, 12]}]
2025-01-22T18:57:56,636 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Input data preprocessed successfully
2025-01-22T18:57:56,637 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Inference performed successfully
2025-01-22T18:57:56,637 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Output postprocessed successfully
2025-01-22T18:57:56,638 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:1.94|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,1737572276,d2bdeac3-4673-4cc8-b128-a694f8544786, pattern=[METRICS]
2025-01-22T18:57:56,638 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_METRICS - PredictionTime.ms:1.94|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,requestID:d2bdeac3-4673-4cc8-b128-a694f8544786,timestamp:1737572276
2025-01-22T18:57:56,638 [INFO ] W-9000-youtubegoes5g_1.0 ACCESS_LOG - /127.0.0.1:42504 "POST /v1/models/youtubegoes5g:predict HTTP/1.1" 200 4
2025-01-22T18:57:56,638 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572276
2025-01-22T18:57:56,639 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:4040.117|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572276
2025-01-22T18:57:56,639 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:56.538|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572276
2025-01-22T18:57:56,639 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.job.Job - Waiting time ns: 56538, Backend time ns: 4206435
2025-01-22T18:57:56,639 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572276
2025-01-22T18:57:56,639 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2025-01-22T18:57:56,639 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3
2025-01-22T18:57:56,639 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:2.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572276
2025-01-22 18:57:56.639 kserve.trace requestId: 24564579-0425-4f7d-a4bd-5539bb402705, preprocess_ms: 0.022172928, explain_ms: 0, predict_ms: 7.815599442, postprocess_ms: 0.005483627
2025-01-22 18:57:56.640 uvicorn.access INFO:     10.233.75.99:0 9 - "POST /v1/models/youtubegoes5g%3Apredict HTTP/1.1" 200 OK
2025-01-22 18:57:56.640 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.008858203887939453
2025-01-22 18:57:56.640 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.004522999999608146
2025-01-22T18:58:08,657 [INFO ] epollEventLoopGroup-3-2 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572288
2025-01-22T18:58:08,658 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1737572288658
2025-01-22T18:58:08,659 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Backend received inference at: 1737572288
2025-01-22T18:58:08,659 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Received data: [{'data': [13, 13, 13, 0, 13, 13, 13, 13, -76, -76, -81, -76, -78.5, -76, -76, -7, -7, -12, -7, -9.5, -7, -7, 12, 12, 7, 12, 9.5, 12, 12]}]
2025-01-22T18:58:08,659 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Input data preprocessed successfully
2025-01-22T18:58:08,661 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Inference performed successfully
2025-01-22T18:58:08,661 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Output postprocessed successfully
2025-01-22T18:58:08,661 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:2.7|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,1737572288,5b173fc5-4238-488d-bb5b-325977ac54f3, pattern=[METRICS]
2025-01-22T18:58:08,661 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_METRICS - PredictionTime.ms:2.7|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,requestID:5b173fc5-4238-488d-bb5b-325977ac54f3,timestamp:1737572288
2025-01-22T18:58:08,662 [INFO ] W-9000-youtubegoes5g_1.0 ACCESS_LOG - /127.0.0.1:38402 "POST /v1/models/youtubegoes5g:predict HTTP/1.1" 200 5
2025-01-22T18:58:08,662 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572288
2025-01-22T18:58:08,662 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:4012.114|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572288
2025-01-22T18:58:08,662 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:75.011|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572288
2025-01-22T18:58:08,662 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.job.Job - Waiting time ns: 75011, Backend time ns: 4300318
2025-01-22T18:58:08,662 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572288
2025-01-22T18:58:08,662 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2025-01-22T18:58:08,662 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 4
2025-01-22T18:58:08,662 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572288
2025-01-22 18:58:08.664 kserve.trace requestId: ec34c3e0-8a29-40d8-9853-c86db80ea8c6, preprocess_ms: 0.018358231, explain_ms: 0, predict_ms: 9.803533554, postprocess_ms: 0.005245209
2025-01-22 18:58:08.664 uvicorn.access INFO:     10.233.75.99:0 9 - "POST /v1/models/youtubegoes5g%3Apredict HTTP/1.1" 200 OK
2025-01-22 18:58:08.664 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.010931253433227539
2025-01-22 18:58:08.664 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.006111000000601052
2025-01-22T18:58:18,993 [INFO ] pool-3-thread-2 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572298
2025-01-22T18:58:18,993 [INFO ] pool-3-thread-2 TS_METRICS - DiskAvailable.Gigabytes:263.70419692993164|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572298
2025-01-22T18:58:18,993 [INFO ] pool-3-thread-2 TS_METRICS - DiskUsage.Gigabytes:208.29906845092773|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572298
2025-01-22T18:58:18,993 [INFO ] pool-3-thread-2 TS_METRICS - DiskUtilization.Percent:44.1|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572298
2025-01-22T18:58:18,993 [INFO ] pool-3-thread-2 TS_METRICS - MemoryAvailable.Megabytes:11195.1484375|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572298
2025-01-22T18:58:18,993 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUsed.Megabytes:8444.453125|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572298
2025-01-22T18:58:18,993 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUtilization.Percent:44.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572298
2025-01-22T18:58:20,681 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572300
2025-01-22T18:58:20,682 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1737572300682
2025-01-22T18:58:20,683 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Backend received inference at: 1737572300
2025-01-22T18:58:20,683 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Received data: [{'data': [13, 13, 13, 0, 13, 13, 13, 13, -76, -76, -81, -76, -78.5, -76, -76, -7, -7, -12, -7, -9.5, -7, -7, 12, 12, 7, 12, 9.5, 12, 12]}]
2025-01-22T18:58:20,684 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Input data preprocessed successfully
2025-01-22T18:58:20,685 [INFO ] W-9000-youtubegoes5g_1.0 ACCESS_LOG - /127.0.0.1:34828 "POST /v1/models/youtubegoes5g:predict HTTP/1.1" 200 4
2025-01-22T18:58:20,685 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572300
2025-01-22T18:58:20,685 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:3211.184|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572300
2025-01-22T18:58:20,685 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:78.866|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572300
2025-01-22T18:58:20,685 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.job.Job - Waiting time ns: 78866, Backend time ns: 3397000
2025-01-22T18:58:20,685 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572300
2025-01-22T18:58:20,685 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2025-01-22T18:58:20,685 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3
2025-01-22T18:58:20,685 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572300
2025-01-22T18:58:20,685 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Inference performed successfully
2025-01-22T18:58:20,685 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Output postprocessed successfully
2025-01-22T18:58:20,685 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:1.79|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,1737572300,66d35775-08b8-4cb1-8ba1-4b2d421ba853, pattern=[METRICS]
2025-01-22T18:58:20,685 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_METRICS - PredictionTime.ms:1.79|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,requestID:66d35775-08b8-4cb1-8ba1-4b2d421ba853,timestamp:1737572300
2025-01-22 18:58:20.687 kserve.trace requestId: 8881f65a-d2f2-43b0-83a0-892fbc8954d8, preprocess_ms: 0.012636185, explain_ms: 0, predict_ms: 7.717847824, postprocess_ms: 0.00500679
2025-01-22 18:58:20.687 uvicorn.access INFO:     10.233.75.99:0 9 - "POST /v1/models/youtubegoes5g%3Apredict HTTP/1.1" 200 OK
2025-01-22 18:58:20.687 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.008605718612670898
2025-01-22 18:58:20.687 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.004241000000547501
2025-01-22T18:58:32,706 [INFO ] epollEventLoopGroup-3-4 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572312
2025-01-22T18:58:32,706 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1737572312706
2025-01-22 18:58:32.710 kserve.trace requestId: 43f68907-6f80-404c-8b70-c83ad6d5d183, preprocess_ms: 0.014305115, explain_ms: 0, predict_ms: 7.957696915, postprocess_ms: 0.005245209
2025-01-22 18:58:32.710 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.008941411972045898
2025-01-22 18:58:32.711 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.006049999999959255
2025-01-22T18:58:32,708 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Backend received inference at: 1737572312
2025-01-22T18:58:32,708 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Received data: [{'data': [13, 13, 13, 0, 13, 13, 13, 13, -76, -76, -81, -76, -78.5, -76, -76, -7, -7, -12, -7, -9.5, -7, -7, 12, 12, 7, 12, 9.5, 12, 12]}]
2025-01-22T18:58:32,708 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Input data preprocessed successfully
2025-01-22T18:58:32,708 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Inference performed successfully
2025-01-22T18:58:32,708 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Output postprocessed successfully
2025-01-22T18:58:32,708 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:1.19|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,1737572312,b76f5ad9-f299-4bb2-b17e-3df452cc9e46, pattern=[METRICS]
2025-01-22T18:58:32,708 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_METRICS - PredictionTime.ms:1.19|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,requestID:b76f5ad9-f299-4bb2-b17e-3df452cc9e46,timestamp:1737572312
2025-01-22T18:58:32,708 [INFO ] W-9000-youtubegoes5g_1.0 ACCESS_LOG - /127.0.0.1:56172 "POST /v1/models/youtubegoes5g:predict HTTP/1.1" 200 2
2025-01-22T18:58:32,708 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572312
2025-01-22T18:58:32,708 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:2215.032|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572312
2025-01-22T18:58:32,708 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:63.456|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572312
2025-01-22T18:58:32,708 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.job.Job - Waiting time ns: 63456, Backend time ns: 2225069
2025-01-22T18:58:32,708 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572312
2025-01-22T18:58:32,708 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2025-01-22T18:58:32,708 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2
2025-01-22T18:58:32,708 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572312
2025-01-22 18:58:32.710 uvicorn.access INFO:     10.233.75.99:0 9 - "POST /v1/models/youtubegoes5g%3Apredict HTTP/1.1" 200 OK
2025-01-22T18:58:44,728 [INFO ] epollEventLoopGroup-3-1 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572324
2025-01-22T18:58:44,728 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1737572324728
2025-01-22T18:58:44,729 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Backend received inference at: 1737572324
2025-01-22T18:58:44,729 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Received data: [{'data': [13, 13, 13, 0, 13, 13, 13, 13, -76, -76, -81, -76, -78.5, -76, -76, -7, -7, -12, -7, -9.5, -7, -7, 12, 12, 7, 12, 9.5, 12, 12]}]
2025-01-22T18:58:44,729 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Input data preprocessed successfully
2025-01-22T18:58:44,733 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Inference performed successfully
2025-01-22T18:58:44,733 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Output postprocessed successfully
2025-01-22T18:58:44,733 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:4.33|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,1737572324,1f3e1c8c-63d0-4eb5-a5b9-93a81027d4da, pattern=[METRICS]
2025-01-22T18:58:44,733 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_METRICS - PredictionTime.ms:4.33|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,requestID:1f3e1c8c-63d0-4eb5-a5b9-93a81027d4da,timestamp:1737572324
2025-01-22T18:58:44,733 [INFO ] W-9000-youtubegoes5g_1.0 ACCESS_LOG - /127.0.0.1:53168 "POST /v1/models/youtubegoes5g:predict HTTP/1.1" 200 5
2025-01-22T18:58:44,733 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572324
2025-01-22T18:58:44,733 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:5219.614|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572324
2025-01-22T18:58:44,733 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:39.905|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572324
2025-01-22T18:58:44,733 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.job.Job - Waiting time ns: 39905, Backend time ns: 5284685
2025-01-22T18:58:44,733 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572324
2025-01-22T18:58:44,733 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2025-01-22T18:58:44,733 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 5
2025-01-22T18:58:44,733 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572324
2025-01-22 18:58:44.734 kserve.trace requestId: cf612532-76e7-4ba5-9dd0-d9909734c1b2, preprocess_ms: 0.012874603, explain_ms: 0, predict_ms: 9.210109711, postprocess_ms: 0.004768372
2025-01-22 18:58:44.735 uvicorn.access INFO:     10.233.75.99:0 9 - "POST /v1/models/youtubegoes5g%3Apredict HTTP/1.1" 200 OK
2025-01-22 18:58:44.735 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.01005411148071289
2025-01-22 18:58:44.735 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.004603999999744701
2025-01-22T18:58:56,754 [INFO ] epollEventLoopGroup-3-2 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572336
2025-01-22T18:58:56,754 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1737572336754
2025-01-22T18:58:56,755 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Backend received inference at: 1737572336
2025-01-22T18:58:56,755 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Received data: [{'data': [13, 13, 13, 0, 13, 13, 13, 13, -76, -76, -81, -76, -78.5, -76, -76, -7, -7, -12, -7, -9.5, -7, -7, 12, 12, 7, 12, 9.5, 12, 12]}]
2025-01-22T18:58:56,755 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Input data preprocessed successfully
2025-01-22T18:58:56,757 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Inference performed successfully
2025-01-22T18:58:56,757 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Output postprocessed successfully
2025-01-22T18:58:56,757 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:2.6|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,1737572336,149f5b5a-7c5c-4380-94e8-24741699b65c, pattern=[METRICS]
2025-01-22T18:58:56,757 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_METRICS - PredictionTime.ms:2.6|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,requestID:149f5b5a-7c5c-4380-94e8-24741699b65c,timestamp:1737572336
2025-01-22T18:58:56,758 [INFO ] W-9000-youtubegoes5g_1.0 ACCESS_LOG - /127.0.0.1:60966 "POST /v1/models/youtubegoes5g:predict HTTP/1.1" 200 4
2025-01-22T18:58:56,758 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572336
2025-01-22T18:58:56,758 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:3781.887|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572336
2025-01-22T18:58:56,758 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:71.14|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572336
2025-01-22T18:58:56,758 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.job.Job - Waiting time ns: 71140, Backend time ns: 4006869
2025-01-22T18:58:56,758 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572336
2025-01-22T18:58:56,758 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2025-01-22T18:58:56,758 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 4
2025-01-22T18:58:56,758 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572336
2025-01-22 18:58:56.759 kserve.trace requestId: c4362db6-0652-4d3e-9f46-7cfb1e59c506, preprocess_ms: 0.013828278, explain_ms: 0, predict_ms: 7.822275162, postprocess_ms: 0.005245209
2025-01-22 18:58:56.760 uvicorn.access INFO:     10.233.75.99:0 9 - "POST /v1/models/youtubegoes5g%3Apredict HTTP/1.1" 200 OK
2025-01-22 18:58:56.760 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.00884389877319336
2025-01-22 18:58:56.760 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.004369000000224332
2025-01-22T18:59:08,778 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572348
2025-01-22T18:59:08,778 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1737572348778
2025-01-22T18:59:08,779 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Backend received inference at: 1737572348
2025-01-22T18:59:08,780 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Received data: [{'data': [13, 13, 13, 0, 13, 13, 13, 13, -76, -76, -81, -76, -78.5, -76, -76, -7, -7, -12, -7, -9.5, -7, -7, 12, 12, 7, 12, 9.5, 12, 12]}]
2025-01-22T18:59:08,781 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Input data preprocessed successfully
2025-01-22T18:59:08,781 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Inference performed successfully
2025-01-22T18:59:08,781 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Output postprocessed successfully
2025-01-22T18:59:08,782 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:1.93|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,1737572348,1ff5ff4c-b23e-4d62-90d7-99ae43b2046c, pattern=[METRICS]
2025-01-22T18:59:08,782 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_METRICS - PredictionTime.ms:1.93|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,requestID:1ff5ff4c-b23e-4d62-90d7-99ae43b2046c,timestamp:1737572348
2025-01-22T18:59:08,783 [INFO ] W-9000-youtubegoes5g_1.0 ACCESS_LOG - /127.0.0.1:49596 "POST /v1/models/youtubegoes5g:predict HTTP/1.1" 200 5
2025-01-22T18:59:08,783 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572348
2025-01-22T18:59:08,783 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:4592.322|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572348
2025-01-22T18:59:08,783 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:188.624|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572348
2025-01-22T18:59:08,783 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.job.Job - Waiting time ns: 188624, Backend time ns: 4563376
2025-01-22T18:59:08,783 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572348
2025-01-22T18:59:08,783 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2025-01-22T18:59:08,783 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 4
2025-01-22T18:59:08,783 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572348
2025-01-22 18:59:08.784 kserve.trace requestId: 65f360dc-f3b2-4b0e-9879-1fe1e5427ec6, preprocess_ms: 0.012397766, explain_ms: 0, predict_ms: 8.354187012, postprocess_ms: 0.005960464
2025-01-22 18:59:08.784 uvicorn.access INFO:     10.233.75.99:0 9 - "POST /v1/models/youtubegoes5g%3Apredict HTTP/1.1" 200 OK
2025-01-22 18:59:08.785 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.009300947189331055
2025-01-22 18:59:08.785 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.004392000000734697
2025-01-22T18:59:18,991 [INFO ] pool-3-thread-2 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572358
2025-01-22T18:59:18,991 [INFO ] pool-3-thread-2 TS_METRICS - DiskAvailable.Gigabytes:263.7039222717285|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572358
2025-01-22T18:59:18,991 [INFO ] pool-3-thread-2 TS_METRICS - DiskUsage.Gigabytes:208.29934310913086|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572358
2025-01-22T18:59:18,991 [INFO ] pool-3-thread-2 TS_METRICS - DiskUtilization.Percent:44.1|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572358
2025-01-22T18:59:18,991 [INFO ] pool-3-thread-2 TS_METRICS - MemoryAvailable.Megabytes:11193.37890625|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572358
2025-01-22T18:59:18,991 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUsed.Megabytes:8446.22265625|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572358
2025-01-22T18:59:18,991 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUtilization.Percent:44.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572358
2025-01-22T18:59:20,809 [INFO ] epollEventLoopGroup-3-4 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572360
2025-01-22T18:59:20,809 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1737572360809
2025-01-22T18:59:20,810 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Backend received inference at: 1737572360
2025-01-22T18:59:20,810 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Received data: [{'data': [13, 13, 13, 0, 13, 13, 13, 13, -76, -76, -81, -76, -78.5, -76, -76, -7, -7, -12, -7, -9.5, -7, -7, 12, 12, 7, 12, 9.5, 12, 12]}]
2025-01-22T18:59:20,810 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Input data preprocessed successfully
2025-01-22T18:59:20,813 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Inference performed successfully
2025-01-22T18:59:20,813 [INFO ] W-9000-youtubegoes5g_1.0 ACCESS_LOG - /127.0.0.1:53002 "POST /v1/models/youtubegoes5g:predict HTTP/1.1" 200 4
2025-01-22T18:59:20,813 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Output postprocessed successfully
2025-01-22T18:59:20,814 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:3.48|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,1737572360,7cf409b8-73bf-4acc-a8de-e8778bb89832, pattern=[METRICS]
2025-01-22T18:59:20,814 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572360
2025-01-22T18:59:20,814 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:4712.438|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572360
2025-01-22T18:59:20,814 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:28.792|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572360
2025-01-22T18:59:20,814 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_METRICS - PredictionTime.ms:3.48|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,requestID:7cf409b8-73bf-4acc-a8de-e8778bb89832,timestamp:1737572360
2025-01-22T18:59:20,814 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.job.Job - Waiting time ns: 28792, Backend time ns: 4856885
2025-01-22T18:59:20,814 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572360
2025-01-22T18:59:20,814 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2025-01-22T18:59:20,814 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3
2025-01-22T18:59:20,814 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:2.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572360
2025-01-22 18:59:20.815 kserve.trace requestId: c33712ec-ed06-48ee-b8b1-6f5118bddd68, preprocess_ms: 0.011920929, explain_ms: 0, predict_ms: 9.528160095, postprocess_ms: 0.005483627
2025-01-22 18:59:20.815 uvicorn.access INFO:     10.233.75.99:0 9 - "POST /v1/models/youtubegoes5g%3Apredict HTTP/1.1" 200 OK
2025-01-22 18:59:20.816 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.010596036911010742
2025-01-22 18:59:20.816 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.004961999999068212
2025-01-22T18:59:32,835 [INFO ] epollEventLoopGroup-3-1 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572372
2025-01-22T18:59:32,835 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1737572372835
2025-01-22T18:59:32,836 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Backend received inference at: 1737572372
2025-01-22T18:59:32,836 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Received data: [{'data': [13, 13, 13, 0, 13, 13, 13, 13, -76, -76, -81, -76, -78.5, -76, -76, -7, -7, -12, -7, -9.5, -7, -7, 12, 12, 7, 12, 9.5, 12, 12]}]
2025-01-22T18:59:32,837 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Input data preprocessed successfully
2025-01-22T18:59:32,841 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Inference performed successfully
2025-01-22T18:59:32,841 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Output postprocessed successfully
2025-01-22T18:59:32,841 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:5.02|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,1737572372,245a864c-f229-4834-8211-caf13e13e608, pattern=[METRICS]
2025-01-22T18:59:32,841 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_METRICS - PredictionTime.ms:5.02|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,requestID:245a864c-f229-4834-8211-caf13e13e608,timestamp:1737572372
2025-01-22T18:59:32,842 [INFO ] W-9000-youtubegoes5g_1.0 ACCESS_LOG - /127.0.0.1:49286 "POST /v1/models/youtubegoes5g:predict HTTP/1.1" 200 7
2025-01-22T18:59:32,842 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572372
2025-01-22T18:59:32,842 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:6463.459|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572372
2025-01-22T18:59:32,842 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:81.734|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572372
2025-01-22T18:59:32,842 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.job.Job - Waiting time ns: 81734, Backend time ns: 6586647
2025-01-22T18:59:32,842 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572372
2025-01-22T18:59:32,842 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2025-01-22T18:59:32,842 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 6
2025-01-22T18:59:32,842 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572372
2025-01-22 18:59:32.843 kserve.trace requestId: 2af84a0b-e54d-4cab-9fd9-738404a13834, preprocess_ms: 0.012397766, explain_ms: 0, predict_ms: 10.123729706, postprocess_ms: 0.004768372
2025-01-22 18:59:32.843 uvicorn.access INFO:     10.233.75.99:0 9 - "POST /v1/models/youtubegoes5g%3Apredict HTTP/1.1" 200 OK
2025-01-22 18:59:32.843 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.011101245880126953
2025-01-22 18:59:32.843 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.004339999999501742
2025-01-22T19:00:08,863 [INFO ] epollEventLoopGroup-3-2 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572408
2025-01-22T19:00:08,863 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1737572408863
2025-01-22T19:00:08,864 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Backend received inference at: 1737572408
2025-01-22T19:00:08,864 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Received data: [{'data': [13, 13, 13, 0, 13, 13, 13, 13, -76, -76, -81, -76, -78.5, -76, -76, -7, -7, -12, -7, -9.5, -7, -7, 12, 12, 7, 12, 9.5, 12, 12]}]
2025-01-22T19:00:08,865 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Input data preprocessed successfully
2025-01-22T19:00:08,868 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Inference performed successfully
2025-01-22T19:00:08,868 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Output postprocessed successfully
2025-01-22T19:00:08,868 [INFO ] W-9000-youtubegoes5g_1.0 ACCESS_LOG - /127.0.0.1:46114 "POST /v1/models/youtubegoes5g:predict HTTP/1.1" 200 5
2025-01-22T19:00:08,868 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572408
2025-01-22T19:00:08,868 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:5187.148|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572408
2025-01-22T19:00:08,868 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:49.829|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572408
2025-01-22T19:00:08,869 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:3.04|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,1737572408,e05c7b51-3449-44aa-8cae-d842e52081f8, pattern=[METRICS]
2025-01-22T19:00:08,868 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.job.Job - Waiting time ns: 49829, Backend time ns: 5301417
2025-01-22T19:00:08,869 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_METRICS - PredictionTime.ms:3.04|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,requestID:e05c7b51-3449-44aa-8cae-d842e52081f8,timestamp:1737572408
2025-01-22T19:00:08,869 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572408
2025-01-22T19:00:08,869 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2025-01-22T19:00:08,869 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 5
2025-01-22T19:00:08,869 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572408
2025-01-22 19:00:08.870 kserve.trace requestId: e941dcd3-738a-40a9-a553-4171e9e69d78, preprocess_ms: 0.016212463, explain_ms: 0, predict_ms: 9.563207626, postprocess_ms: 0.004768372
2025-01-22 19:00:08.870 uvicorn.access INFO:     10.233.75.99:0 9 - "POST /v1/models/youtubegoes5g%3Apredict HTTP/1.1" 200 OK
2025-01-22 19:00:08.870 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.010623931884765625
2025-01-22 19:00:08.870 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.0047309999990829965
2025-01-22T19:00:18,989 [INFO ] pool-3-thread-2 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572418
2025-01-22T19:00:18,989 [INFO ] pool-3-thread-2 TS_METRICS - DiskAvailable.Gigabytes:263.703670501709|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572418
2025-01-22T19:00:18,989 [INFO ] pool-3-thread-2 TS_METRICS - DiskUsage.Gigabytes:208.2995948791504|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572418
2025-01-22T19:00:18,989 [INFO ] pool-3-thread-2 TS_METRICS - DiskUtilization.Percent:44.1|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572418
2025-01-22T19:00:18,989 [INFO ] pool-3-thread-2 TS_METRICS - MemoryAvailable.Megabytes:11267.81640625|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572418
2025-01-22T19:00:18,989 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUsed.Megabytes:8371.78515625|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572418
2025-01-22T19:00:18,989 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUtilization.Percent:43.6|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572418
2025-01-22T19:00:20,889 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572420
2025-01-22T19:00:20,889 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1737572420889
2025-01-22T19:00:20,890 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Backend received inference at: 1737572420
2025-01-22T19:00:20,890 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Received data: [{'data': [13, 13, 13, 0, 13, 13, 13, 13, -76, -76, -81, -76, -78.5, -76, -76, -7, -7, -12, -7, -9.5, -7, -7, 12, 12, 7, 12, 9.5, 12, 12]}]
2025-01-22T19:00:20,891 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Input data preprocessed successfully
2025-01-22T19:00:20,892 [INFO ] W-9000-youtubegoes5g_1.0 ACCESS_LOG - /127.0.0.1:53856 "POST /v1/models/youtubegoes5g:predict HTTP/1.1" 200 3
2025-01-22T19:00:20,892 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572420
2025-01-22T19:00:20,892 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:2698.853|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572420
2025-01-22T19:00:20,892 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:56.178|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572420
2025-01-22T19:00:20,892 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.job.Job - Waiting time ns: 56178, Backend time ns: 2788265
2025-01-22T19:00:20,892 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572420
2025-01-22T19:00:20,892 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2025-01-22T19:00:20,892 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3
2025-01-22T19:00:20,892 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572420
2025-01-22T19:00:20,892 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Inference performed successfully
2025-01-22T19:00:20,892 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Output postprocessed successfully
2025-01-22T19:00:20,892 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:1.37|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,1737572420,bae95aa4-5fbe-4f93-af4c-6bde3aa7a726, pattern=[METRICS]
2025-01-22T19:00:20,892 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_METRICS - PredictionTime.ms:1.37|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,requestID:bae95aa4-5fbe-4f93-af4c-6bde3aa7a726,timestamp:1737572420
2025-01-22 19:00:20.894 kserve.trace requestId: e85c1fdb-be0e-49a7-b014-49f8bd71b779, preprocess_ms: 0.01168251, explain_ms: 0, predict_ms: 7.390737534, postprocess_ms: 0.00500679
2025-01-22 19:00:20.894 uvicorn.access INFO:     10.233.75.99:0 9 - "POST /v1/models/youtubegoes5g%3Apredict HTTP/1.1" 200 OK
2025-01-22 19:00:20.894 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.008303165435791016
2025-01-22 19:00:20.894 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.004440000000613509
2025-01-22T19:00:32,912 [INFO ] epollEventLoopGroup-3-4 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572432
2025-01-22T19:00:32,912 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1737572432912
2025-01-22T19:00:32,913 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Backend received inference at: 1737572432
2025-01-22T19:00:32,913 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Received data: [{'data': [13, 13, 13, 0, 13, 13, 13, 13, -76, -76, -81, -76, -78.5, -76, -76, -7, -7, -12, -7, -9.5, -7, -7, 12, 12, 7, 12, 9.5, 12, 12]}]
2025-01-22T19:00:32,914 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Input data preprocessed successfully
2025-01-22T19:00:32,914 [INFO ] W-9000-youtubegoes5g_1.0 ACCESS_LOG - /127.0.0.1:59768 "POST /v1/models/youtubegoes5g:predict HTTP/1.1" 200 2
2025-01-22T19:00:32,914 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572432
2025-01-22T19:00:32,914 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1965.808|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572432
2025-01-22T19:00:32,914 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:32.0|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572432
2025-01-22T19:00:32,914 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.job.Job - Waiting time ns: 32000, Backend time ns: 2077324
2025-01-22T19:00:32,914 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572432
2025-01-22T19:00:32,914 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2025-01-22T19:00:32,914 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1
2025-01-22T19:00:32,915 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:2.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572432
2025-01-22T19:00:32,915 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Inference performed successfully
2025-01-22T19:00:32,915 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Output postprocessed successfully
2025-01-22T19:00:32,915 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:1.19|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,1737572432,6970db3e-eb4e-499b-8857-28e36cb86e60, pattern=[METRICS]
2025-01-22T19:00:32,915 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_METRICS - PredictionTime.ms:1.19|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,requestID:6970db3e-eb4e-499b-8857-28e36cb86e60,timestamp:1737572432
2025-01-22 19:00:32.916 kserve.trace requestId: 044d934f-71bc-4625-93c4-62229f49bb41, preprocess_ms: 0.011920929, explain_ms: 0, predict_ms: 6.120443344, postprocess_ms: 0.005245209
2025-01-22 19:00:32.916 uvicorn.access INFO:     10.233.75.99:0 9 - "POST /v1/models/youtubegoes5g%3Apredict HTTP/1.1" 200 OK
2025-01-22 19:00:32.916 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.007045269012451172
2025-01-22 19:00:32.916 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.004283000002033077
2025-01-22T19:00:44,933 [INFO ] epollEventLoopGroup-3-1 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572444
2025-01-22T19:00:44,933 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1737572444933
2025-01-22T19:00:44,935 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Backend received inference at: 1737572444
2025-01-22T19:00:44,935 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Received data: [{'data': [13, 13, 13, 0, 13, 13, 13, 13, -76, -76, -81, -76, -78.5, -76, -76, -7, -7, -12, -7, -9.5, -7, -7, 12, 12, 7, 12, 9.5, 12, 12]}]
2025-01-22T19:00:44,935 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Input data preprocessed successfully
2025-01-22T19:00:44,936 [INFO ] W-9000-youtubegoes5g_1.0 ACCESS_LOG - /127.0.0.1:40344 "POST /v1/models/youtubegoes5g:predict HTTP/1.1" 200 3
2025-01-22T19:00:44,936 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572444
2025-01-22T19:00:44,936 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:2262.156|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572444
2025-01-22T19:00:44,936 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:69.838|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572444
2025-01-22T19:00:44,936 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.job.Job - Waiting time ns: 69838, Backend time ns: 2493836
2025-01-22T19:00:44,936 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572444
2025-01-22T19:00:44,936 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2025-01-22T19:00:44,936 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Inference performed successfully
2025-01-22T19:00:44,936 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1
2025-01-22T19:00:44,936 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:2.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572444
2025-01-22T19:00:44,936 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Output postprocessed successfully
2025-01-22T19:00:44,936 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:1.32|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,1737572444,0ed2c09d-e931-49fb-b14b-6f89f592060c, pattern=[METRICS]
2025-01-22T19:00:44,936 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_METRICS - PredictionTime.ms:1.32|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,requestID:0ed2c09d-e931-49fb-b14b-6f89f592060c,timestamp:1737572444
2025-01-22 19:00:44.938 kserve.trace requestId: 9a8a40f9-6446-4456-b69e-a22cb37d1c8f, preprocess_ms: 0.011920929, explain_ms: 0, predict_ms: 6.778717041, postprocess_ms: 0.005483627
2025-01-22 19:00:44.938 uvicorn.access INFO:     10.233.75.99:0 9 - "POST /v1/models/youtubegoes5g%3Apredict HTTP/1.1" 200 OK
2025-01-22 19:00:44.938 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.007701873779296875
2025-01-22 19:00:44.938 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.004387999999380554
2025-01-22T19:00:56,955 [INFO ] epollEventLoopGroup-3-2 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572456
2025-01-22T19:00:56,956 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1737572456956
2025-01-22T19:00:56,956 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Backend received inference at: 1737572456
2025-01-22T19:00:56,956 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Received data: [{'data': [13, 13, 13, 0, 13, 13, 13, 13, -76, -76, -81, -76, -78.5, -76, -76, -7, -7, -12, -7, -9.5, -7, -7, 12, 12, 7, 12, 9.5, 12, 12]}]
2025-01-22T19:00:56,957 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Input data preprocessed successfully
2025-01-22T19:00:56,958 [INFO ] W-9000-youtubegoes5g_1.0 ACCESS_LOG - /127.0.0.1:51046 "POST /v1/models/youtubegoes5g:predict HTTP/1.1" 200 3
2025-01-22T19:00:56,958 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572456
2025-01-22T19:00:56,959 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:2729.813|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572456
2025-01-22T19:00:56,959 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:38.205|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572456
2025-01-22T19:00:56,959 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.job.Job - Waiting time ns: 38205, Backend time ns: 3111473
2025-01-22T19:00:56,959 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572456
2025-01-22T19:00:56,959 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2025-01-22T19:00:56,959 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2
2025-01-22T19:00:56,959 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572456
2025-01-22T19:00:56,959 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Inference performed successfully
2025-01-22T19:00:56,959 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Output postprocessed successfully
2025-01-22T19:00:56,959 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:1.66|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,1737572456,166f61e6-f882-4298-a952-fad728d69330, pattern=[METRICS]
2025-01-22T19:00:56,959 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_METRICS - PredictionTime.ms:1.66|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,requestID:166f61e6-f882-4298-a952-fad728d69330,timestamp:1737572456
2025-01-22 19:00:56.960 kserve.trace requestId: 213db006-8113-4c2d-b558-bed66d6753e0, preprocess_ms: 0.00500679, explain_ms: 0, predict_ms: 7.447957993, postprocess_ms: 0.005722046
2025-01-22 19:00:56.961 uvicorn.access INFO:     10.233.75.99:0 9 - "POST /v1/models/youtubegoes5g%3Apredict HTTP/1.1" 200 OK
2025-01-22 19:00:56.961 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.008839845657348633
2025-01-22 19:00:56.961 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.005169000000023516
2025-01-22T19:01:08,978 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572468
2025-01-22T19:01:08,978 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1737572468978
2025-01-22T19:01:08,979 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Backend received inference at: 1737572468
2025-01-22T19:01:08,979 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Received data: [{'data': [13, 13, 13, 0, 13, 13, 13, 13, -76, -76, -81, -76, -78.5, -76, -76, -7, -7, -12, -7, -9.5, -7, -7, 12, 12, 7, 12, 9.5, 12, 12]}]
2025-01-22T19:01:08,980 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Input data preprocessed successfully
2025-01-22T19:01:08,981 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Inference performed successfully
2025-01-22T19:01:08,981 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Output postprocessed successfully
2025-01-22T19:01:08,981 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:1.54|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,1737572468,78fd102e-479d-4b6d-8db0-605fe55219d5, pattern=[METRICS]
2025-01-22T19:01:08,981 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_METRICS - PredictionTime.ms:1.54|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,requestID:78fd102e-479d-4b6d-8db0-605fe55219d5,timestamp:1737572468
2025-01-22T19:01:08,981 [INFO ] W-9000-youtubegoes5g_1.0 ACCESS_LOG - /127.0.0.1:60382 "POST /v1/models/youtubegoes5g:predict HTTP/1.1" 200 3
2025-01-22T19:01:08,981 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572468
2025-01-22T19:01:08,981 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:2727.412|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572468
2025-01-22T19:01:08,981 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:133.796|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572468
2025-01-22T19:01:08,981 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.job.Job - Waiting time ns: 133796, Backend time ns: 2968021
2025-01-22T19:01:08,981 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572468
2025-01-22T19:01:08,981 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2025-01-22T19:01:08,981 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2
2025-01-22T19:01:08,981 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572468
2025-01-22 19:01:08.983 kserve.trace requestId: 8bbc6afc-e0f2-4745-97fc-2512909018fd, preprocess_ms: 0.007390976, explain_ms: 0, predict_ms: 7.694005966, postprocess_ms: 0.004529953
2025-01-22 19:01:08.983 uvicorn.access INFO:     10.233.75.99:0 9 - "POST /v1/models/youtubegoes5g%3Apredict HTTP/1.1" 200 OK
2025-01-22 19:01:08.983 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.008544206619262695
2025-01-22 19:01:08.983 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.004890000000159489
2025-01-22T19:01:18,989 [INFO ] pool-3-thread-2 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572478
2025-01-22T19:01:18,989 [INFO ] pool-3-thread-2 TS_METRICS - DiskAvailable.Gigabytes:263.7034454345703|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572478
2025-01-22T19:01:18,989 [INFO ] pool-3-thread-2 TS_METRICS - DiskUsage.Gigabytes:208.29981994628906|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572478
2025-01-22T19:01:18,989 [INFO ] pool-3-thread-2 TS_METRICS - DiskUtilization.Percent:44.1|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572478
2025-01-22T19:01:18,989 [INFO ] pool-3-thread-2 TS_METRICS - MemoryAvailable.Megabytes:11274.88671875|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572478
2025-01-22T19:01:18,989 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUsed.Megabytes:8364.71484375|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572478
2025-01-22T19:01:18,989 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUtilization.Percent:43.6|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572478
2025-01-22T19:01:21,002 [INFO ] epollEventLoopGroup-3-4 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572481
2025-01-22T19:01:21,003 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1737572481003
2025-01-22T19:01:21,003 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Backend received inference at: 1737572481
2025-01-22T19:01:21,004 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Received data: [{'data': [13, 13, 13, 0, 13, 13, 13, 13, -76, -76, -81, -76, -78.5, -76, -76, -7, -7, -12, -7, -9.5, -7, -7, 12, 12, 7, 12, 9.5, 12, 12]}]
2025-01-22T19:01:21,004 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Input data preprocessed successfully
2025-01-22T19:01:21,005 [INFO ] W-9000-youtubegoes5g_1.0 ACCESS_LOG - /127.0.0.1:39726 "POST /v1/models/youtubegoes5g:predict HTTP/1.1" 200 3
2025-01-22T19:01:21,006 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572481
2025-01-22T19:01:21,006 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:2839.717|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572481
2025-01-22T19:01:21,006 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:43.421|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572481
2025-01-22T19:01:21,006 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.job.Job - Waiting time ns: 43421, Backend time ns: 3005507
2025-01-22T19:01:21,006 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572481
2025-01-22T19:01:21,006 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2025-01-22T19:01:21,006 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 0
2025-01-22T19:01:21,006 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:3.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572481
2025-01-22T19:01:21,006 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Inference performed successfully
2025-01-22T19:01:21,006 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Output postprocessed successfully
2025-01-22T19:01:21,006 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:1.84|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,1737572481,0a62c2bb-9f66-4f34-9640-3d6244f755d4, pattern=[METRICS]
2025-01-22T19:01:21,006 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_METRICS - PredictionTime.ms:1.84|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,requestID:0a62c2bb-9f66-4f34-9640-3d6244f755d4,timestamp:1737572481
2025-01-22 19:01:21.008 kserve.trace requestId: c61acf57-a6f3-4110-84bc-6c716df365a4, preprocess_ms: 0.028848648, explain_ms: 0, predict_ms: 9.152650833, postprocess_ms: 0.007152557
2025-01-22 19:01:21.009 uvicorn.access INFO:     10.233.75.99:0 9 - "POST /v1/models/youtubegoes5g%3Apredict HTTP/1.1" 200 OK
2025-01-22 19:01:21.009 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.010964155197143555
2025-01-22 19:01:21.009 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.005315999998856569
2025-01-22T19:01:33,028 [INFO ] epollEventLoopGroup-3-1 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572493
2025-01-22T19:01:33,029 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1737572493029
2025-01-22T19:01:33,029 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Backend received inference at: 1737572493
2025-01-22T19:01:33,029 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Received data: [{'data': [13, 13, 13, 0, 13, 13, 13, 13, -76, -76, -81, -76, -78.5, -76, -76, -7, -7, -12, -7, -9.5, -7, -7, 12, 12, 7, 12, 9.5, 12, 12]}]
2025-01-22T19:01:33,030 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Input data preprocessed successfully
2025-01-22T19:01:33,031 [INFO ] W-9000-youtubegoes5g_1.0 ACCESS_LOG - /127.0.0.1:56542 "POST /v1/models/youtubegoes5g:predict HTTP/1.1" 200 3
2025-01-22T19:01:33,031 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572493
2025-01-22T19:01:33,032 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:2667.066|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572493
2025-01-22T19:01:33,032 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:56.768|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572493
2025-01-22T19:01:33,032 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.job.Job - Waiting time ns: 56768, Backend time ns: 2924029
2025-01-22T19:01:33,032 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572493
2025-01-22T19:01:33,032 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2025-01-22T19:01:33,032 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2
2025-01-22T19:01:33,032 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572493
2025-01-22T19:01:33,032 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Inference performed successfully
2025-01-22T19:01:33,032 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Output postprocessed successfully
2025-01-22T19:01:33,032 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:1.73|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,1737572493,b47ea22c-217f-4f6e-ae0a-226f0c6000a7, pattern=[METRICS]
2025-01-22T19:01:33,032 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_METRICS - PredictionTime.ms:1.73|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,requestID:b47ea22c-217f-4f6e-ae0a-226f0c6000a7,timestamp:1737572493
2025-01-22 19:01:33.034 kserve.trace requestId: 905d0feb-0d68-4bb9-b38c-399c12986352, preprocess_ms: 0.013113022, explain_ms: 0, predict_ms: 7.237195969, postprocess_ms: 0.005245209
2025-01-22 19:01:33.034 uvicorn.access INFO:     10.233.75.99:0 9 - "POST /v1/models/youtubegoes5g%3Apredict HTTP/1.1" 200 OK
2025-01-22 19:01:33.034 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.0081024169921875
2025-01-22 19:01:33.034 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.004398000000946922
2025-01-22T19:01:45,054 [INFO ] epollEventLoopGroup-3-2 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572505
2025-01-22T19:01:45,054 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1737572505054
2025-01-22T19:01:45,055 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Backend received inference at: 1737572505
2025-01-22T19:01:45,055 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Received data: [{'data': [13, 13, 13, 0, 13, 13, 13, 13, -76, -76, -81, -76, -78.5, -76, -76, -7, -7, -12, -7, -9.5, -7, -7, 12, 12, 7, 12, 9.5, 12, 12]}]
2025-01-22T19:01:45,056 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Input data preprocessed successfully
2025-01-22T19:01:45,056 [INFO ] W-9000-youtubegoes5g_1.0 ACCESS_LOG - /127.0.0.1:47644 "POST /v1/models/youtubegoes5g:predict HTTP/1.1" 200 2
2025-01-22T19:01:45,056 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Inference performed successfully
2025-01-22T19:01:45,056 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Output postprocessed successfully
2025-01-22T19:01:45,056 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572505
2025-01-22T19:01:45,056 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:1.14|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,1737572505,c3228855-658c-4663-907f-e8e7065f404d, pattern=[METRICS]
2025-01-22T19:01:45,056 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1988.035|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572505
2025-01-22T19:01:45,056 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_METRICS - PredictionTime.ms:1.14|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,requestID:c3228855-658c-4663-907f-e8e7065f404d,timestamp:1737572505
2025-01-22T19:01:45,057 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:94.905|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572505
2025-01-22T19:01:45,057 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.job.Job - Waiting time ns: 94905, Backend time ns: 2165386
2025-01-22T19:01:45,057 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572505
2025-01-22T19:01:45,057 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2025-01-22T19:01:45,057 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1
2025-01-22T19:01:45,057 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:2.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572505
2025-01-22 19:01:45.058 kserve.trace requestId: 7ff9ca3f-c65f-4f2b-a186-954a55a30a25, preprocess_ms: 0.011920929, explain_ms: 0, predict_ms: 6.046295166, postprocess_ms: 0.004291534
2025-01-22 19:01:45.058 uvicorn.access INFO:     10.233.75.99:0 9 - "POST /v1/models/youtubegoes5g%3Apredict HTTP/1.1" 200 OK
2025-01-22 19:01:45.058 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.006902456283569336
2025-01-22 19:01:45.058 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.004519000000072992
2025-01-22T19:01:57,079 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572517
2025-01-22T19:01:57,080 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1737572517080
2025-01-22T19:01:57,080 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Backend received inference at: 1737572517
2025-01-22T19:01:57,080 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Received data: [{'data': [13, 13, 13, 0, 13, 13, 13, 13, -76, -76, -81, -76, -78.5, -76, -76, -7, -7, -12, -7, -9.5, -7, -7, 12, 12, 7, 12, 9.5, 12, 12]}]
2025-01-22T19:01:57,081 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Input data preprocessed successfully
2025-01-22T19:01:57,083 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Inference performed successfully
2025-01-22T19:01:57,083 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Output postprocessed successfully
2025-01-22T19:01:57,083 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:2.66|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,1737572517,2ed7e87a-4a98-414d-b18c-f759051ff2fd, pattern=[METRICS]
2025-01-22T19:01:57,083 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_METRICS - PredictionTime.ms:2.66|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,requestID:2ed7e87a-4a98-414d-b18c-f759051ff2fd,timestamp:1737572517
2025-01-22T19:01:57,083 [INFO ] W-9000-youtubegoes5g_1.0 ACCESS_LOG - /127.0.0.1:59332 "POST /v1/models/youtubegoes5g:predict HTTP/1.1" 200 4
2025-01-22T19:01:57,083 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572517
2025-01-22T19:01:57,083 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:3679.086|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572517
2025-01-22T19:01:57,083 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:40.681|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572517
2025-01-22T19:01:57,083 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.job.Job - Waiting time ns: 40681, Backend time ns: 3770260
2025-01-22T19:01:57,083 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572517
2025-01-22T19:01:57,083 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2025-01-22T19:01:57,083 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3
2025-01-22T19:01:57,083 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572517
2025-01-22 19:01:57.085 kserve.trace requestId: f0ad24c5-a4cf-4ba1-9e8a-f83e84e76db8, preprocess_ms: 0.012397766, explain_ms: 0, predict_ms: 8.046865463, postprocess_ms: 0.00500679
2025-01-22 19:01:57.085 uvicorn.access INFO:     10.233.75.99:0 9 - "POST /v1/models/youtubegoes5g%3Apredict HTTP/1.1" 200 OK
2025-01-22 19:01:57.085 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.008964776992797852
2025-01-22 19:01:57.085 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.0048920000008365605
2025-01-22T19:02:18,994 [INFO ] pool-3-thread-2 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572538
2025-01-22T19:02:18,994 [INFO ] pool-3-thread-2 TS_METRICS - DiskAvailable.Gigabytes:263.7031707763672|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572538
2025-01-22T19:02:18,994 [INFO ] pool-3-thread-2 TS_METRICS - DiskUsage.Gigabytes:208.3000946044922|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572538
2025-01-22T19:02:18,994 [INFO ] pool-3-thread-2 TS_METRICS - DiskUtilization.Percent:44.1|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572538
2025-01-22T19:02:18,994 [INFO ] pool-3-thread-2 TS_METRICS - MemoryAvailable.Megabytes:11135.25390625|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572538
2025-01-22T19:02:18,994 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUsed.Megabytes:8504.3515625|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572538
2025-01-22T19:02:18,994 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUtilization.Percent:44.3|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572538
2025-01-22T19:02:33,102 [INFO ] epollEventLoopGroup-3-4 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572553
2025-01-22T19:02:33,102 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1737572553102
2025-01-22T19:02:33,103 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Backend received inference at: 1737572553
2025-01-22T19:02:33,103 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Received data: [{'data': [13, 13, 13, 0, 13, 13, 13, 13, -76, -76, -81, -76, -78.5, -76, -76, -7, -7, -12, -7, -9.5, -7, -7, 12, 12, 7, 12, 9.5, 12, 12]}]
2025-01-22T19:02:33,103 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Input data preprocessed successfully
2025-01-22T19:02:33,104 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Inference performed successfully
2025-01-22T19:02:33,104 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Output postprocessed successfully
2025-01-22T19:02:33,104 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:1.17|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,1737572553,cecaefc5-ee4a-4db7-b027-7cf5cd582533, pattern=[METRICS]
2025-01-22T19:02:33,104 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_METRICS - PredictionTime.ms:1.17|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,requestID:cecaefc5-ee4a-4db7-b027-7cf5cd582533,timestamp:1737572553
2025-01-22T19:02:33,104 [INFO ] W-9000-youtubegoes5g_1.0 ACCESS_LOG - /127.0.0.1:53584 "POST /v1/models/youtubegoes5g:predict HTTP/1.1" 200 2
2025-01-22T19:02:33,104 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572553
2025-01-22T19:02:33,104 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:2073.204|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572553
2025-01-22T19:02:33,104 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:24.585|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572553
2025-01-22T19:02:33,104 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.job.Job - Waiting time ns: 24585, Backend time ns: 2294917
2025-01-22T19:02:33,104 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572553
2025-01-22T19:02:33,104 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2025-01-22T19:02:33,105 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2
2025-01-22T19:02:33,105 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1737572553
2025-01-22 19:02:33.106 kserve.trace requestId: 68658def-a08b-46df-834e-d5a714919a6b, preprocess_ms: 0.012636185, explain_ms: 0, predict_ms: 6.273031235, postprocess_ms: 0.004768372
2025-01-22 19:02:33.106 uvicorn.access INFO:     10.233.75.99:0 9 - "POST /v1/models/youtubegoes5g%3Apredict HTTP/1.1" 200 OK
2025-01-22 19:02:33.106 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.0072574615478515625
2025-01-22 19:02:33.106 kserve.trace kserve.io.kserve.protocol.rest.v1_endpoints.predict: 0.00476399999934074

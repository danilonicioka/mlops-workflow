{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7fdb664-7216-4d08-aba0-afb5986d6adf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install -r requirements-components-test.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32f2b06e-4971-46eb-bd54-4473990ebf7d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import kfp\n",
    "from kfp.dsl import component, pipeline, Input, Output, Dataset, Model, Metrics, ClassificationMetrics, Artifact\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from env file\n",
    "load_dotenv('env')\n",
    "\n",
    "# Github variables\n",
    "GITHUB_USERNAME = os.getenv(\"GITHUB_USERNAME\")\n",
    "GITHUB_TOKEN = os.getenv(\"GITHUB_TOKEN\")\n",
    "GITHUB_REPO_URL = \"https://github.com/danilonicioka/mlops-workflow.git\"\n",
    "GITHUB_CLONED_DIR = \"mlops-workflow\"\n",
    "GITHUB_DVC_BRANCH = \"dvc\"\n",
    "GITHUB_MAIN_BRANCH = \"main\"\n",
    "\n",
    "# Kubeflow variables\n",
    "KUBEFLOW_PIPELINE_NAME = \"mlops\"\n",
    "KUBEFLOW_HOST_URL = \"http://ml-pipeline.kubeflow:8888\"  # KFP host URL\n",
    "KUBEFLOW_PIPELINE_ID=\"7451916e-eee8-4c14-ad5f-8dee5aa61e3b\"\n",
    "with open(os.environ['KF_PIPELINES_SA_TOKEN_PATH'], \"r\") as f:\n",
    "    KUBEFLOW_TOKEN = f.read()\n",
    "\n",
    "# DVC variables\n",
    "DVC_REMOTE_DB = \"minio_remote\"\n",
    "DVC_REMOTE_DB_URL = \"s3://dvc-data\"\n",
    "DVC_FILE_DIR = 'data/external'\n",
    "DVC_FILE_NAME = 'dataset.csv'\n",
    "\n",
    "# MinIO variables\n",
    "MINIO_URL = \"minio-service.kubeflow:9000\"\n",
    "MINIO_ACCESS_KEY = os.getenv(\"MINIO_ACCESS_KEY\")\n",
    "MINIO_SECRET_KEY = os.getenv(\"MINIO_SECRET_KEY\")\n",
    "MINIO_MODEL_BUCKET_NAME = \"model-files\"\n",
    "MINIO_MODEL_OBJECT_NAME = \"model-store/youtubegoes5g/model.pt\"\n",
    "\n",
    "# Triggers variables\n",
    "TRIGGER_TYPE = '1'\n",
    "PERFORMANCE_FACTOR = 0.05\n",
    "# Temp dir and files to save accuracy for trigger 3\n",
    "TEMP_DIR = \"tmp\"\n",
    "TEMP_FILE_ACC_IN_LAST_RUN = \"accuracy_in_last_run.txt\"\n",
    "LAST_ACC_OBJECT_NAME = \"accuracy-score/last_acc.txt\"\n",
    "\n",
    "# Model variables\n",
    "MODEL_LR = 0.0001\n",
    "MODEL_EPOCHS = 3500\n",
    "MODEL_PRINT_FREQUENCY_PER_N_EPOCHS = 500\n",
    "MODEL_NAME = \"youtubegoes5g\"\n",
    "\n",
    "# Kserve variables\n",
    "#MODEL_FRAMEWORK = \"pytorch\"\n",
    "KSERVE_NAMESPACE = \"kubeflow-user-example-com\"\n",
    "KSERVE_SVC_ACC = \"sa-minio-kserve\"\n",
    "#MODEL_URI = \"pvc://model-store-claim\"\n",
    "#MODEL_URI = \"minio-service.kubeflow:9000/model-files\"\n",
    "\n",
    "# Model archiver gen vars\n",
    "MODEL_STORE_POD_NAME = \"model-store-pod\"\n",
    "MODEL_STORE_POD_CONTAINER_NAME = \"model-store\"\n",
    "MAR_POD_NAME = \"margen-pod\"\n",
    "MAR_POD_CONTAINER_NAME = \"margen-container\"\n",
    "MAR_OBJECT_NAME = \"model-store/youtubegoes5g.mar\"\n",
    "K8S_API_TOKEN = os.getenv(\"K8S_API_TOKEN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25cc32d0-2995-476b-bfae-c84d1474c205",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Model Serving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7b3f4eb-6022-4040-96f0-6006aa0c61ed",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/kfp/client/client.py:159: FutureWarning: This client only works with Kubeflow Pipeline v2.0.0-beta.2 and later versions.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<a href=\"http://ml-pipeline.kubeflow:8888/#/experiments/details/c85b5150-a41f-4f4e-bf3b-9697a1789764\" target=\"_blank\" >Experiment details</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<a href=\"http://ml-pipeline.kubeflow:8888/#/runs/details/9280bf87-b0cb-4082-9720-7db3c2319000\" target=\"_blank\" >Run details</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "RunPipelineResult(run_id=9280bf87-b0cb-4082-9720-7db3c2319000)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@component(base_image=\"python:3.11.9\", packages_to_install=['kserve==0.13.0','kubernetes==30.1.0'])\n",
    "def model_serving(\n",
    "    # mar_gen_cond: Input[Artifact],\n",
    "    # cond_info: Output[Metrics],\n",
    "    bucket_name: str,\n",
    "    model_name: str,\n",
    "    kserve_namespace: str,\n",
    "    kserve_svc_acc: str\n",
    "):\n",
    "    # Create kserve instance\n",
    "    from kubernetes import client \n",
    "    from kserve import KServeClient, constants, V1beta1InferenceService, V1beta1InferenceServiceSpec, V1beta1PredictorSpec, V1beta1TorchServeSpec\n",
    "    from datetime import datetime\n",
    "    import time\n",
    "    \n",
    "    # # exec if a new model was uploaded\n",
    "    # with open(mar_gen_cond.path) as f:\n",
    "    #     up_model = f.read()\n",
    "        \n",
    "    # # if up_model == '1':\n",
    "    # cond_info.log_metric(\"Inference Service\", \"Created/Updated\")\n",
    "\n",
    "    #Inference server config\n",
    "    now = datetime.now()\n",
    "    kserve_version='v1beta1'\n",
    "    api_version = constants.KSERVE_GROUP + '/' + kserve_version\n",
    "\n",
    "    # with open(model_uri.path) as f:\n",
    "    #     uri = f.read()\n",
    "    uri = f's3://{bucket_name}'\n",
    "\n",
    "    isvc = V1beta1InferenceService(api_version=api_version,\n",
    "                                   kind=constants.KSERVE_KIND,\n",
    "                                   metadata=client.V1ObjectMeta(\n",
    "                                       name=model_name, namespace=kserve_namespace, annotations={'sidecar.istio.io/inject':'false'}),\n",
    "                                   spec=V1beta1InferenceServiceSpec(\n",
    "                                   predictor=V1beta1PredictorSpec(\n",
    "                                       service_account_name=kserve_svc_acc,\n",
    "                                       pytorch=(V1beta1TorchServeSpec(\n",
    "                                           storage_uri=uri))))\n",
    "    )\n",
    "\n",
    "    KServe = KServeClient()\n",
    "\n",
    "    #replace old inference service with a new one\n",
    "    try:\n",
    "        KServe.delete(name=model_name, namespace=kserve_namespace)\n",
    "        print(\"Old model deleted\")\n",
    "    except:\n",
    "        print(\"Couldn't delete old model\")\n",
    "    time.sleep(10)\n",
    "\n",
    "    KServe.create(isvc)\n",
    "    # else:\n",
    "    #     cond_info.log_metric(\"Inference Service\", \"Not Created/Updated\")\n",
    "        \n",
    "@pipeline\n",
    "def my_pipeline(\n",
    "    github_repo_url: str,\n",
    "    github_cloned_dir: str,\n",
    "    github_dvc_branch: str,\n",
    "    github_main_branch: str,\n",
    "    github_username: str,\n",
    "    github_token: str,\n",
    "    dvc_remote_name: str,\n",
    "    dvc_remote_db_url: str,\n",
    "    minio_url: str,\n",
    "    minio_access_key: str,\n",
    "    minio_secret_key: str,\n",
    "    dvc_file_dir: str,\n",
    "    dvc_file_name: str,\n",
    "    model_name: str,\n",
    "    kserve_namespace: str,\n",
    "    model_lr: float,\n",
    "    model_epochs: int,\n",
    "    model_print_frequency_per_n_epochs: int,\n",
    "    bucket_name: str,\n",
    "    minio_model_object_name: str,\n",
    "    kserve_svc_acc: str,\n",
    "    trigger_type: str,\n",
    "    performance_factor: float,\n",
    "    last_accuracy_object_name: str,\n",
    "    tmp_dir: str,\n",
    "    tmp_file_last_acc: str,\n",
    "    k8s_api_token: str\n",
    "):\n",
    "    model_serving_task = model_serving(bucket_name=bucket_name,\n",
    "                                       model_name=model_name, \n",
    "                                       kserve_namespace=kserve_namespace,\n",
    "                                       kserve_svc_acc=kserve_svc_acc)\n",
    "    model_serving_task.set_caching_options(False)\n",
    "\n",
    "# Compile the pipeline\n",
    "pipeline_filename = f\"{KUBEFLOW_PIPELINE_NAME}.yaml\"\n",
    "kfp.compiler.Compiler().compile(\n",
    "    pipeline_func=my_pipeline,\n",
    "    package_path=pipeline_filename)\n",
    "\n",
    "# Submit the pipeline to the KFP cluster\n",
    "client = kfp.Client(\n",
    "    host=KUBEFLOW_HOST_URL,\n",
    "    existing_token=KUBEFLOW_TOKEN)  \n",
    "\n",
    "client.create_run_from_pipeline_func(\n",
    "    my_pipeline,\n",
    "    enable_caching=False,\n",
    "    arguments={\n",
    "        'github_repo_url': GITHUB_REPO_URL,\n",
    "        'github_cloned_dir': GITHUB_CLONED_DIR,\n",
    "        'github_dvc_branch': GITHUB_DVC_BRANCH,\n",
    "        'github_main_branch': GITHUB_MAIN_BRANCH,\n",
    "        'github_username': GITHUB_USERNAME,\n",
    "        'github_token': GITHUB_TOKEN,\n",
    "        'dvc_remote_name': DVC_REMOTE_DB,\n",
    "        'dvc_remote_db_url': DVC_REMOTE_DB_URL,\n",
    "        'minio_url': MINIO_URL,\n",
    "        'minio_access_key': MINIO_ACCESS_KEY,\n",
    "        'minio_secret_key': MINIO_SECRET_KEY,\n",
    "        'dvc_file_dir': DVC_FILE_DIR,\n",
    "        'dvc_file_name': DVC_FILE_NAME,\n",
    "        'model_name': MODEL_NAME,\n",
    "        'kserve_namespace': KSERVE_NAMESPACE,\n",
    "        'model_lr': MODEL_LR,\n",
    "        'model_epochs': MODEL_EPOCHS,\n",
    "        'model_print_frequency_per_n_epochs': MODEL_PRINT_FREQUENCY_PER_N_EPOCHS,\n",
    "        'bucket_name': MINIO_MODEL_BUCKET_NAME,\n",
    "        'minio_model_object_name': MINIO_MODEL_OBJECT_NAME,\n",
    "        'kserve_svc_acc': KSERVE_SVC_ACC,\n",
    "        'trigger_type': TRIGGER_TYPE,\n",
    "        'performance_factor': PERFORMANCE_FACTOR,\n",
    "        'last_accuracy_object_name': LAST_ACC_OBJECT_NAME,\n",
    "        'tmp_dir': TEMP_DIR,\n",
    "        'tmp_file_last_acc': TEMP_FILE_ACC_IN_LAST_RUN,\n",
    "        'k8s_api_token': K8S_API_TOKEN\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df87b304-7903-4cbc-92c5-d387f3d474a4",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Mar gen Component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "98a1775e-5fa1-4f3d-93a8-d028295e92d7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pod created. status='{'conditions': None,\n",
      " 'container_statuses': None,\n",
      " 'ephemeral_container_statuses': None,\n",
      " 'host_ip': None,\n",
      " 'init_container_statuses': None,\n",
      " 'message': None,\n",
      " 'nominated_node_name': None,\n",
      " 'phase': 'Pending',\n",
      " 'pod_i_ps': None,\n",
      " 'pod_ip': None,\n",
      " 'qos_class': 'Burstable',\n",
      " 'reason': None,\n",
      " 'start_time': None}'\n",
      "Error from server (Conflict): {\"kind\":\"Status\",\"apiVersion\":\"v1\",\"metadata\":{},\"status\":\"Failure\",\"message\":\"persistentvolumeclaims \\\"model-pv-claim\\\" already exists\",\"reason\":\"AlreadyExists\",\"details\":{\"name\":\"model-pv-claim\",\"kind\":\"persistentvolumeclaims\"},\"code\":409}\n",
      "\n",
      "model-store-pod running \n",
      "Response: \n",
      "Response: mkdir: cannot create directory '/pv/config/': File exists\n",
      "\n",
      "Response: mkdir: cannot create directory '/pv/scripts/': File exists\n",
      "\n",
      "File model-store/youtubegoes5g/model.pt downloaded successfully to model.pt.\n",
      "STDOUT: pv/model-store/youtubegoes5g/model.pt\n",
      "\n",
      "STDOUT: pv/model-store/youtubegoes5g/custom_handler.py\n",
      "\n",
      "STDOUT: pv/model-store/youtubegoes5g/model.py\n",
      "\n",
      "STDOUT: pv/model-store/properties.json\n",
      "\n",
      "STDOUT: pv/scripts/margen.sh\n",
      "\n",
      "{'api_version': 'v1',\n",
      " 'kind': 'Pod',\n",
      " 'metadata': {'annotations': {'kubectl.kubernetes.io/default-container': 'model-store',\n",
      "                              'kubectl.kubernetes.io/default-logs-container': 'model-store',\n",
      "                              'prometheus.io/path': '/stats/prometheus',\n",
      "                              'prometheus.io/port': '15020',\n",
      "                              'prometheus.io/scrape': 'true',\n",
      "                              'sidecar.istio.io/status': '{\"initContainers\":[\"istio-init\"],\"containers\":[\"istio-proxy\"],\"volumes\":[\"workload-socket\",\"credential-socket\",\"workload-certs\",\"istio-envoy\",\"istio-data\",\"istio-podinfo\",\"istio-token\",\"istiod-ca-cert\"],\"imagePullSecrets\":null,\"revision\":\"default\"}'},\n",
      "              'creation_timestamp': datetime.datetime(2024, 11, 7, 19, 21, 35, tzinfo=tzlocal()),\n",
      "              'deletion_grace_period_seconds': 30,\n",
      "              'deletion_timestamp': datetime.datetime(2024, 11, 7, 19, 22, 23, tzinfo=tzlocal()),\n",
      "              'finalizers': None,\n",
      "              'generate_name': None,\n",
      "              'generation': None,\n",
      "              'labels': {'security.istio.io/tlsMode': 'istio',\n",
      "                         'service.istio.io/canonical-name': 'model-store-pod',\n",
      "                         'service.istio.io/canonical-revision': 'latest'},\n",
      "              'managed_fields': [{'api_version': 'v1',\n",
      "                                  'fields_type': 'FieldsV1',\n",
      "                                  'fields_v1': {'f:spec': {'f:containers': {'k:{\"name\":\"model-store\"}': {'.': {},\n",
      "                                                                                                         'f:args': {},\n",
      "                                                                                                         'f:command': {},\n",
      "                                                                                                         'f:image': {},\n",
      "                                                                                                         'f:imagePullPolicy': {},\n",
      "                                                                                                         'f:name': {},\n",
      "                                                                                                         'f:resources': {'.': {},\n",
      "                                                                                                                         'f:limits': {'.': {},\n",
      "                                                                                                                                      'f:cpu': {},\n",
      "                                                                                                                                      'f:memory': {}},\n",
      "                                                                                                                         'f:requests': {'.': {},\n",
      "                                                                                                                                        'f:cpu': {},\n",
      "                                                                                                                                        'f:memory': {}}},\n",
      "                                                                                                         'f:terminationMessagePath': {},\n",
      "                                                                                                         'f:terminationMessagePolicy': {},\n",
      "                                                                                                         'f:volumeMounts': {'.': {},\n",
      "                                                                                                                            'k:{\"mountPath\":\"/pv\"}': {'.': {},\n",
      "                                                                                                                                                      'f:mountPath': {},\n",
      "                                                                                                                                                      'f:name': {}}}}},\n",
      "                                                           'f:dnsPolicy': {},\n",
      "                                                           'f:enableServiceLinks': {},\n",
      "                                                           'f:restartPolicy': {},\n",
      "                                                           'f:schedulerName': {},\n",
      "                                                           'f:securityContext': {},\n",
      "                                                           'f:terminationGracePeriodSeconds': {},\n",
      "                                                           'f:volumes': {'.': {},\n",
      "                                                                         'k:{\"name\":\"model-store\"}': {'.': {},\n",
      "                                                                                                      'f:name': {},\n",
      "                                                                                                      'f:persistentVolumeClaim': {'.': {},\n",
      "                                                                                                                                  'f:claimName': {}}}}}},\n",
      "                                  'manager': 'OpenAPI-Generator',\n",
      "                                  'operation': 'Update',\n",
      "                                  'subresource': None,\n",
      "                                  'time': datetime.datetime(2024, 11, 7, 19, 21, 35, tzinfo=tzlocal())},\n",
      "                                 {'api_version': 'v1',\n",
      "                                  'fields_type': 'FieldsV1',\n",
      "                                  'fields_v1': {'f:status': {'f:conditions': {'k:{\"type\":\"ContainersReady\"}': {'.': {},\n",
      "                                                                                                               'f:lastProbeTime': {},\n",
      "                                                                                                               'f:lastTransitionTime': {},\n",
      "                                                                                                               'f:status': {},\n",
      "                                                                                                               'f:type': {}},\n",
      "                                                                              'k:{\"type\":\"Initialized\"}': {'.': {},\n",
      "                                                                                                           'f:lastProbeTime': {},\n",
      "                                                                                                           'f:lastTransitionTime': {},\n",
      "                                                                                                           'f:status': {},\n",
      "                                                                                                           'f:type': {}},\n",
      "                                                                              'k:{\"type\":\"Ready\"}': {'.': {},\n",
      "                                                                                                     'f:lastProbeTime': {},\n",
      "                                                                                                     'f:lastTransitionTime': {},\n",
      "                                                                                                     'f:status': {},\n",
      "                                                                                                     'f:type': {}}},\n",
      "                                                             'f:containerStatuses': {},\n",
      "                                                             'f:hostIP': {},\n",
      "                                                             'f:initContainerStatuses': {},\n",
      "                                                             'f:phase': {},\n",
      "                                                             'f:podIP': {},\n",
      "                                                             'f:podIPs': {'.': {},\n",
      "                                                                          'k:{\"ip\":\"10.233.97.174\"}': {'.': {},\n",
      "                                                                                                       'f:ip': {}}},\n",
      "                                                             'f:startTime': {}}},\n",
      "                                  'manager': 'kubelet',\n",
      "                                  'operation': 'Update',\n",
      "                                  'subresource': 'status',\n",
      "                                  'time': datetime.datetime(2024, 11, 7, 19, 21, 53, tzinfo=tzlocal())}],\n",
      "              'name': 'model-store-pod',\n",
      "              'namespace': 'kubeflow-user-example-com',\n",
      "              'owner_references': None,\n",
      "              'resource_version': '104728984',\n",
      "              'self_link': None,\n",
      "              'uid': '7fa2359c-14cc-4f37-bbdd-e5a6402c96ee'},\n",
      " 'spec': {'active_deadline_seconds': None,\n",
      "          'affinity': None,\n",
      "          'automount_service_account_token': None,\n",
      "          'containers': [{'args': ['infinity'],\n",
      "                          'command': ['sleep'],\n",
      "                          'env': None,\n",
      "                          'env_from': None,\n",
      "                          'image': 'ubuntu',\n",
      "                          'image_pull_policy': 'Always',\n",
      "                          'lifecycle': None,\n",
      "                          'liveness_probe': None,\n",
      "                          'name': 'model-store',\n",
      "                          'ports': None,\n",
      "                          'readiness_probe': None,\n",
      "                          'resources': {'claims': None,\n",
      "                                        'limits': {'cpu': '2', 'memory': '4Gi'},\n",
      "                                        'requests': {'cpu': '2',\n",
      "                                                     'memory': '4Gi'}},\n",
      "                          'security_context': None,\n",
      "                          'startup_probe': None,\n",
      "                          'stdin': None,\n",
      "                          'stdin_once': None,\n",
      "                          'termination_message_path': '/dev/termination-log',\n",
      "                          'termination_message_policy': 'File',\n",
      "                          'tty': None,\n",
      "                          'volume_devices': None,\n",
      "                          'volume_mounts': [{'mount_path': '/pv',\n",
      "                                             'mount_propagation': None,\n",
      "                                             'name': 'model-store',\n",
      "                                             'read_only': None,\n",
      "                                             'sub_path': None,\n",
      "                                             'sub_path_expr': None},\n",
      "                                            {'mount_path': '/var/run/secrets/kubernetes.io/serviceaccount',\n",
      "                                             'mount_propagation': None,\n",
      "                                             'name': 'kube-api-access-cjs7t',\n",
      "                                             'read_only': True,\n",
      "                                             'sub_path': None,\n",
      "                                             'sub_path_expr': None}],\n",
      "                          'working_dir': None},\n",
      "                         {'args': ['proxy',\n",
      "                                   'sidecar',\n",
      "                                   '--domain',\n",
      "                                   '$(POD_NAMESPACE).svc.cluster.local',\n",
      "                                   '--proxyLogLevel=warning',\n",
      "                                   '--proxyComponentLogLevel=misc:error',\n",
      "                                   '--log_output_level=default:info',\n",
      "                                   '--concurrency',\n",
      "                                   '2'],\n",
      "                          'command': None,\n",
      "                          'env': [{'name': 'JWT_POLICY',\n",
      "                                   'value': 'third-party-jwt',\n",
      "                                   'value_from': None},\n",
      "                                  {'name': 'PILOT_CERT_PROVIDER',\n",
      "                                   'value': 'istiod',\n",
      "                                   'value_from': None},\n",
      "                                  {'name': 'CA_ADDR',\n",
      "                                   'value': 'istiod.istio-system.svc:15012',\n",
      "                                   'value_from': None},\n",
      "                                  {'name': 'POD_NAME',\n",
      "                                   'value': None,\n",
      "                                   'value_from': {'config_map_key_ref': None,\n",
      "                                                  'field_ref': {'api_version': 'v1',\n",
      "                                                                'field_path': 'metadata.name'},\n",
      "                                                  'resource_field_ref': None,\n",
      "                                                  'secret_key_ref': None}},\n",
      "                                  {'name': 'POD_NAMESPACE',\n",
      "                                   'value': None,\n",
      "                                   'value_from': {'config_map_key_ref': None,\n",
      "                                                  'field_ref': {'api_version': 'v1',\n",
      "                                                                'field_path': 'metadata.namespace'},\n",
      "                                                  'resource_field_ref': None,\n",
      "                                                  'secret_key_ref': None}},\n",
      "                                  {'name': 'INSTANCE_IP',\n",
      "                                   'value': None,\n",
      "                                   'value_from': {'config_map_key_ref': None,\n",
      "                                                  'field_ref': {'api_version': 'v1',\n",
      "                                                                'field_path': 'status.podIP'},\n",
      "                                                  'resource_field_ref': None,\n",
      "                                                  'secret_key_ref': None}},\n",
      "                                  {'name': 'SERVICE_ACCOUNT',\n",
      "                                   'value': None,\n",
      "                                   'value_from': {'config_map_key_ref': None,\n",
      "                                                  'field_ref': {'api_version': 'v1',\n",
      "                                                                'field_path': 'spec.serviceAccountName'},\n",
      "                                                  'resource_field_ref': None,\n",
      "                                                  'secret_key_ref': None}},\n",
      "                                  {'name': 'HOST_IP',\n",
      "                                   'value': None,\n",
      "                                   'value_from': {'config_map_key_ref': None,\n",
      "                                                  'field_ref': {'api_version': 'v1',\n",
      "                                                                'field_path': 'status.hostIP'},\n",
      "                                                  'resource_field_ref': None,\n",
      "                                                  'secret_key_ref': None}},\n",
      "                                  {'name': 'PROXY_CONFIG',\n",
      "                                   'value': '{\"tracing\":{}}\\n',\n",
      "                                   'value_from': None},\n",
      "                                  {'name': 'ISTIO_META_POD_PORTS',\n",
      "                                   'value': '[\\n]',\n",
      "                                   'value_from': None},\n",
      "                                  {'name': 'ISTIO_META_APP_CONTAINERS',\n",
      "                                   'value': 'model-store',\n",
      "                                   'value_from': None},\n",
      "                                  {'name': 'ISTIO_META_CLUSTER_ID',\n",
      "                                   'value': 'Kubernetes',\n",
      "                                   'value_from': None},\n",
      "                                  {'name': 'ISTIO_META_NODE_NAME',\n",
      "                                   'value': None,\n",
      "                                   'value_from': {'config_map_key_ref': None,\n",
      "                                                  'field_ref': {'api_version': 'v1',\n",
      "                                                                'field_path': 'spec.nodeName'},\n",
      "                                                  'resource_field_ref': None,\n",
      "                                                  'secret_key_ref': None}},\n",
      "                                  {'name': 'ISTIO_META_INTERCEPTION_MODE',\n",
      "                                   'value': 'REDIRECT',\n",
      "                                   'value_from': None},\n",
      "                                  {'name': 'ISTIO_META_WORKLOAD_NAME',\n",
      "                                   'value': 'model-store-pod',\n",
      "                                   'value_from': None},\n",
      "                                  {'name': 'ISTIO_META_OWNER',\n",
      "                                   'value': 'kubernetes://apis/v1/namespaces/kubeflow-user-example-com/pods/model-store-pod',\n",
      "                                   'value_from': None},\n",
      "                                  {'name': 'ISTIO_META_MESH_ID',\n",
      "                                   'value': 'cluster.local',\n",
      "                                   'value_from': None},\n",
      "                                  {'name': 'TRUST_DOMAIN',\n",
      "                                   'value': 'cluster.local',\n",
      "                                   'value_from': None}],\n",
      "                          'env_from': None,\n",
      "                          'image': 'docker.io/istio/proxyv2:1.17.5',\n",
      "                          'image_pull_policy': 'IfNotPresent',\n",
      "                          'lifecycle': None,\n",
      "                          'liveness_probe': None,\n",
      "                          'name': 'istio-proxy',\n",
      "                          'ports': [{'container_port': 15090,\n",
      "                                     'host_ip': None,\n",
      "                                     'host_port': None,\n",
      "                                     'name': 'http-envoy-prom',\n",
      "                                     'protocol': 'TCP'}],\n",
      "                          'readiness_probe': {'_exec': None,\n",
      "                                              'failure_threshold': 30,\n",
      "                                              'grpc': None,\n",
      "                                              'http_get': {'host': None,\n",
      "                                                           'http_headers': None,\n",
      "                                                           'path': '/healthz/ready',\n",
      "                                                           'port': 15021,\n",
      "                                                           'scheme': 'HTTP'},\n",
      "                                              'initial_delay_seconds': 1,\n",
      "                                              'period_seconds': 2,\n",
      "                                              'success_threshold': 1,\n",
      "                                              'tcp_socket': None,\n",
      "                                              'termination_grace_period_seconds': None,\n",
      "                                              'timeout_seconds': 3},\n",
      "                          'resources': {'claims': None,\n",
      "                                        'limits': {'cpu': '2', 'memory': '1Gi'},\n",
      "                                        'requests': {'cpu': '100m',\n",
      "                                                     'memory': '128Mi'}},\n",
      "                          'security_context': {'allow_privilege_escalation': False,\n",
      "                                               'capabilities': {'add': None,\n",
      "                                                                'drop': ['ALL']},\n",
      "                                               'privileged': False,\n",
      "                                               'proc_mount': None,\n",
      "                                               'read_only_root_filesystem': True,\n",
      "                                               'run_as_group': 1337,\n",
      "                                               'run_as_non_root': True,\n",
      "                                               'run_as_user': 1337,\n",
      "                                               'se_linux_options': None,\n",
      "                                               'seccomp_profile': None,\n",
      "                                               'windows_options': None},\n",
      "                          'startup_probe': None,\n",
      "                          'stdin': None,\n",
      "                          'stdin_once': None,\n",
      "                          'termination_message_path': '/dev/termination-log',\n",
      "                          'termination_message_policy': 'File',\n",
      "                          'tty': None,\n",
      "                          'volume_devices': None,\n",
      "                          'volume_mounts': [{'mount_path': '/var/run/secrets/workload-spiffe-uds',\n",
      "                                             'mount_propagation': None,\n",
      "                                             'name': 'workload-socket',\n",
      "                                             'read_only': None,\n",
      "                                             'sub_path': None,\n",
      "                                             'sub_path_expr': None},\n",
      "                                            {'mount_path': '/var/run/secrets/credential-uds',\n",
      "                                             'mount_propagation': None,\n",
      "                                             'name': 'credential-socket',\n",
      "                                             'read_only': None,\n",
      "                                             'sub_path': None,\n",
      "                                             'sub_path_expr': None},\n",
      "                                            {'mount_path': '/var/run/secrets/workload-spiffe-credentials',\n",
      "                                             'mount_propagation': None,\n",
      "                                             'name': 'workload-certs',\n",
      "                                             'read_only': None,\n",
      "                                             'sub_path': None,\n",
      "                                             'sub_path_expr': None},\n",
      "                                            {'mount_path': '/var/run/secrets/istio',\n",
      "                                             'mount_propagation': None,\n",
      "                                             'name': 'istiod-ca-cert',\n",
      "                                             'read_only': None,\n",
      "                                             'sub_path': None,\n",
      "                                             'sub_path_expr': None},\n",
      "                                            {'mount_path': '/var/lib/istio/data',\n",
      "                                             'mount_propagation': None,\n",
      "                                             'name': 'istio-data',\n",
      "                                             'read_only': None,\n",
      "                                             'sub_path': None,\n",
      "                                             'sub_path_expr': None},\n",
      "                                            {'mount_path': '/etc/istio/proxy',\n",
      "                                             'mount_propagation': None,\n",
      "                                             'name': 'istio-envoy',\n",
      "                                             'read_only': None,\n",
      "                                             'sub_path': None,\n",
      "                                             'sub_path_expr': None},\n",
      "                                            {'mount_path': '/var/run/secrets/tokens',\n",
      "                                             'mount_propagation': None,\n",
      "                                             'name': 'istio-token',\n",
      "                                             'read_only': None,\n",
      "                                             'sub_path': None,\n",
      "                                             'sub_path_expr': None},\n",
      "                                            {'mount_path': '/etc/istio/pod',\n",
      "                                             'mount_propagation': None,\n",
      "                                             'name': 'istio-podinfo',\n",
      "                                             'read_only': None,\n",
      "                                             'sub_path': None,\n",
      "                                             'sub_path_expr': None},\n",
      "                                            {'mount_path': '/var/run/secrets/kubernetes.io/serviceaccount',\n",
      "                                             'mount_propagation': None,\n",
      "                                             'name': 'kube-api-access-cjs7t',\n",
      "                                             'read_only': True,\n",
      "                                             'sub_path': None,\n",
      "                                             'sub_path_expr': None}],\n",
      "                          'working_dir': None}],\n",
      "          'dns_config': None,\n",
      "          'dns_policy': 'ClusterFirst',\n",
      "          'enable_service_links': True,\n",
      "          'ephemeral_containers': None,\n",
      "          'host_aliases': None,\n",
      "          'host_ipc': None,\n",
      "          'host_network': None,\n",
      "          'host_pid': None,\n",
      "          'host_users': None,\n",
      "          'hostname': None,\n",
      "          'image_pull_secrets': None,\n",
      "          'init_containers': [{'args': ['istio-iptables',\n",
      "                                        '-p',\n",
      "                                        '15001',\n",
      "                                        '-z',\n",
      "                                        '15006',\n",
      "                                        '-u',\n",
      "                                        '1337',\n",
      "                                        '-m',\n",
      "                                        'REDIRECT',\n",
      "                                        '-i',\n",
      "                                        '*',\n",
      "                                        '-x',\n",
      "                                        '',\n",
      "                                        '-b',\n",
      "                                        '*',\n",
      "                                        '-d',\n",
      "                                        '15090,15021,15020',\n",
      "                                        '--log_output_level=default:info'],\n",
      "                               'command': None,\n",
      "                               'env': None,\n",
      "                               'env_from': None,\n",
      "                               'image': 'docker.io/istio/proxyv2:1.17.5',\n",
      "                               'image_pull_policy': 'IfNotPresent',\n",
      "                               'lifecycle': None,\n",
      "                               'liveness_probe': None,\n",
      "                               'name': 'istio-init',\n",
      "                               'ports': None,\n",
      "                               'readiness_probe': None,\n",
      "                               'resources': {'claims': None,\n",
      "                                             'limits': {'cpu': '2',\n",
      "                                                        'memory': '1Gi'},\n",
      "                                             'requests': {'cpu': '100m',\n",
      "                                                          'memory': '128Mi'}},\n",
      "                               'security_context': {'allow_privilege_escalation': False,\n",
      "                                                    'capabilities': {'add': ['NET_ADMIN',\n",
      "                                                                             'NET_RAW'],\n",
      "                                                                     'drop': ['ALL']},\n",
      "                                                    'privileged': False,\n",
      "                                                    'proc_mount': None,\n",
      "                                                    'read_only_root_filesystem': False,\n",
      "                                                    'run_as_group': 0,\n",
      "                                                    'run_as_non_root': False,\n",
      "                                                    'run_as_user': 0,\n",
      "                                                    'se_linux_options': None,\n",
      "                                                    'seccomp_profile': None,\n",
      "                                                    'windows_options': None},\n",
      "                               'startup_probe': None,\n",
      "                               'stdin': None,\n",
      "                               'stdin_once': None,\n",
      "                               'termination_message_path': '/dev/termination-log',\n",
      "                               'termination_message_policy': 'File',\n",
      "                               'tty': None,\n",
      "                               'volume_devices': None,\n",
      "                               'volume_mounts': [{'mount_path': '/var/run/secrets/kubernetes.io/serviceaccount',\n",
      "                                                  'mount_propagation': None,\n",
      "                                                  'name': 'kube-api-access-cjs7t',\n",
      "                                                  'read_only': True,\n",
      "                                                  'sub_path': None,\n",
      "                                                  'sub_path_expr': None}],\n",
      "                               'working_dir': None}],\n",
      "          'node_name': 'node5',\n",
      "          'node_selector': None,\n",
      "          'os': None,\n",
      "          'overhead': None,\n",
      "          'preemption_policy': 'PreemptLowerPriority',\n",
      "          'priority': 0,\n",
      "          'priority_class_name': None,\n",
      "          'readiness_gates': None,\n",
      "          'resource_claims': None,\n",
      "          'restart_policy': 'Always',\n",
      "          'runtime_class_name': None,\n",
      "          'scheduler_name': 'default-scheduler',\n",
      "          'scheduling_gates': None,\n",
      "          'security_context': {'fs_group': None,\n",
      "                               'fs_group_change_policy': None,\n",
      "                               'run_as_group': None,\n",
      "                               'run_as_non_root': None,\n",
      "                               'run_as_user': None,\n",
      "                               'se_linux_options': None,\n",
      "                               'seccomp_profile': None,\n",
      "                               'supplemental_groups': None,\n",
      "                               'sysctls': None,\n",
      "                               'windows_options': None},\n",
      "          'service_account': 'default',\n",
      "          'service_account_name': 'default',\n",
      "          'set_hostname_as_fqdn': None,\n",
      "          'share_process_namespace': None,\n",
      "          'subdomain': None,\n",
      "          'termination_grace_period_seconds': 30,\n",
      "          'tolerations': [{'effect': 'NoExecute',\n",
      "                           'key': 'node.kubernetes.io/not-ready',\n",
      "                           'operator': 'Exists',\n",
      "                           'toleration_seconds': 300,\n",
      "                           'value': None},\n",
      "                          {'effect': 'NoExecute',\n",
      "                           'key': 'node.kubernetes.io/unreachable',\n",
      "                           'operator': 'Exists',\n",
      "                           'toleration_seconds': 300,\n",
      "                           'value': None}],\n",
      "          'topology_spread_constraints': None,\n",
      "          'volumes': [{'aws_elastic_block_store': None,\n",
      "                       'azure_disk': None,\n",
      "                       'azure_file': None,\n",
      "                       'cephfs': None,\n",
      "                       'cinder': None,\n",
      "                       'config_map': None,\n",
      "                       'csi': None,\n",
      "                       'downward_api': None,\n",
      "                       'empty_dir': {'medium': None, 'size_limit': None},\n",
      "                       'ephemeral': None,\n",
      "                       'fc': None,\n",
      "                       'flex_volume': None,\n",
      "                       'flocker': None,\n",
      "                       'gce_persistent_disk': None,\n",
      "                       'git_repo': None,\n",
      "                       'glusterfs': None,\n",
      "                       'host_path': None,\n",
      "                       'iscsi': None,\n",
      "                       'name': 'workload-socket',\n",
      "                       'nfs': None,\n",
      "                       'persistent_volume_claim': None,\n",
      "                       'photon_persistent_disk': None,\n",
      "                       'portworx_volume': None,\n",
      "                       'projected': None,\n",
      "                       'quobyte': None,\n",
      "                       'rbd': None,\n",
      "                       'scale_io': None,\n",
      "                       'secret': None,\n",
      "                       'storageos': None,\n",
      "                       'vsphere_volume': None},\n",
      "                      {'aws_elastic_block_store': None,\n",
      "                       'azure_disk': None,\n",
      "                       'azure_file': None,\n",
      "                       'cephfs': None,\n",
      "                       'cinder': None,\n",
      "                       'config_map': None,\n",
      "                       'csi': None,\n",
      "                       'downward_api': None,\n",
      "                       'empty_dir': {'medium': None, 'size_limit': None},\n",
      "                       'ephemeral': None,\n",
      "                       'fc': None,\n",
      "                       'flex_volume': None,\n",
      "                       'flocker': None,\n",
      "                       'gce_persistent_disk': None,\n",
      "                       'git_repo': None,\n",
      "                       'glusterfs': None,\n",
      "                       'host_path': None,\n",
      "                       'iscsi': None,\n",
      "                       'name': 'credential-socket',\n",
      "                       'nfs': None,\n",
      "                       'persistent_volume_claim': None,\n",
      "                       'photon_persistent_disk': None,\n",
      "                       'portworx_volume': None,\n",
      "                       'projected': None,\n",
      "                       'quobyte': None,\n",
      "                       'rbd': None,\n",
      "                       'scale_io': None,\n",
      "                       'secret': None,\n",
      "                       'storageos': None,\n",
      "                       'vsphere_volume': None},\n",
      "                      {'aws_elastic_block_store': None,\n",
      "                       'azure_disk': None,\n",
      "                       'azure_file': None,\n",
      "                       'cephfs': None,\n",
      "                       'cinder': None,\n",
      "                       'config_map': None,\n",
      "                       'csi': None,\n",
      "                       'downward_api': None,\n",
      "                       'empty_dir': {'medium': None, 'size_limit': None},\n",
      "                       'ephemeral': None,\n",
      "                       'fc': None,\n",
      "                       'flex_volume': None,\n",
      "                       'flocker': None,\n",
      "                       'gce_persistent_disk': None,\n",
      "                       'git_repo': None,\n",
      "                       'glusterfs': None,\n",
      "                       'host_path': None,\n",
      "                       'iscsi': None,\n",
      "                       'name': 'workload-certs',\n",
      "                       'nfs': None,\n",
      "                       'persistent_volume_claim': None,\n",
      "                       'photon_persistent_disk': None,\n",
      "                       'portworx_volume': None,\n",
      "                       'projected': None,\n",
      "                       'quobyte': None,\n",
      "                       'rbd': None,\n",
      "                       'scale_io': None,\n",
      "                       'secret': None,\n",
      "                       'storageos': None,\n",
      "                       'vsphere_volume': None},\n",
      "                      {'aws_elastic_block_store': None,\n",
      "                       'azure_disk': None,\n",
      "                       'azure_file': None,\n",
      "                       'cephfs': None,\n",
      "                       'cinder': None,\n",
      "                       'config_map': None,\n",
      "                       'csi': None,\n",
      "                       'downward_api': None,\n",
      "                       'empty_dir': {'medium': 'Memory', 'size_limit': None},\n",
      "                       'ephemeral': None,\n",
      "                       'fc': None,\n",
      "                       'flex_volume': None,\n",
      "                       'flocker': None,\n",
      "                       'gce_persistent_disk': None,\n",
      "                       'git_repo': None,\n",
      "                       'glusterfs': None,\n",
      "                       'host_path': None,\n",
      "                       'iscsi': None,\n",
      "                       'name': 'istio-envoy',\n",
      "                       'nfs': None,\n",
      "                       'persistent_volume_claim': None,\n",
      "                       'photon_persistent_disk': None,\n",
      "                       'portworx_volume': None,\n",
      "                       'projected': None,\n",
      "                       'quobyte': None,\n",
      "                       'rbd': None,\n",
      "                       'scale_io': None,\n",
      "                       'secret': None,\n",
      "                       'storageos': None,\n",
      "                       'vsphere_volume': None},\n",
      "                      {'aws_elastic_block_store': None,\n",
      "                       'azure_disk': None,\n",
      "                       'azure_file': None,\n",
      "                       'cephfs': None,\n",
      "                       'cinder': None,\n",
      "                       'config_map': None,\n",
      "                       'csi': None,\n",
      "                       'downward_api': None,\n",
      "                       'empty_dir': {'medium': None, 'size_limit': None},\n",
      "                       'ephemeral': None,\n",
      "                       'fc': None,\n",
      "                       'flex_volume': None,\n",
      "                       'flocker': None,\n",
      "                       'gce_persistent_disk': None,\n",
      "                       'git_repo': None,\n",
      "                       'glusterfs': None,\n",
      "                       'host_path': None,\n",
      "                       'iscsi': None,\n",
      "                       'name': 'istio-data',\n",
      "                       'nfs': None,\n",
      "                       'persistent_volume_claim': None,\n",
      "                       'photon_persistent_disk': None,\n",
      "                       'portworx_volume': None,\n",
      "                       'projected': None,\n",
      "                       'quobyte': None,\n",
      "                       'rbd': None,\n",
      "                       'scale_io': None,\n",
      "                       'secret': None,\n",
      "                       'storageos': None,\n",
      "                       'vsphere_volume': None},\n",
      "                      {'aws_elastic_block_store': None,\n",
      "                       'azure_disk': None,\n",
      "                       'azure_file': None,\n",
      "                       'cephfs': None,\n",
      "                       'cinder': None,\n",
      "                       'config_map': None,\n",
      "                       'csi': None,\n",
      "                       'downward_api': {'default_mode': 420,\n",
      "                                        'items': [{'field_ref': {'api_version': 'v1',\n",
      "                                                                 'field_path': 'metadata.labels'},\n",
      "                                                   'mode': None,\n",
      "                                                   'path': 'labels',\n",
      "                                                   'resource_field_ref': None},\n",
      "                                                  {'field_ref': {'api_version': 'v1',\n",
      "                                                                 'field_path': 'metadata.annotations'},\n",
      "                                                   'mode': None,\n",
      "                                                   'path': 'annotations',\n",
      "                                                   'resource_field_ref': None}]},\n",
      "                       'empty_dir': None,\n",
      "                       'ephemeral': None,\n",
      "                       'fc': None,\n",
      "                       'flex_volume': None,\n",
      "                       'flocker': None,\n",
      "                       'gce_persistent_disk': None,\n",
      "                       'git_repo': None,\n",
      "                       'glusterfs': None,\n",
      "                       'host_path': None,\n",
      "                       'iscsi': None,\n",
      "                       'name': 'istio-podinfo',\n",
      "                       'nfs': None,\n",
      "                       'persistent_volume_claim': None,\n",
      "                       'photon_persistent_disk': None,\n",
      "                       'portworx_volume': None,\n",
      "                       'projected': None,\n",
      "                       'quobyte': None,\n",
      "                       'rbd': None,\n",
      "                       'scale_io': None,\n",
      "                       'secret': None,\n",
      "                       'storageos': None,\n",
      "                       'vsphere_volume': None},\n",
      "                      {'aws_elastic_block_store': None,\n",
      "                       'azure_disk': None,\n",
      "                       'azure_file': None,\n",
      "                       'cephfs': None,\n",
      "                       'cinder': None,\n",
      "                       'config_map': None,\n",
      "                       'csi': None,\n",
      "                       'downward_api': None,\n",
      "                       'empty_dir': None,\n",
      "                       'ephemeral': None,\n",
      "                       'fc': None,\n",
      "                       'flex_volume': None,\n",
      "                       'flocker': None,\n",
      "                       'gce_persistent_disk': None,\n",
      "                       'git_repo': None,\n",
      "                       'glusterfs': None,\n",
      "                       'host_path': None,\n",
      "                       'iscsi': None,\n",
      "                       'name': 'istio-token',\n",
      "                       'nfs': None,\n",
      "                       'persistent_volume_claim': None,\n",
      "                       'photon_persistent_disk': None,\n",
      "                       'portworx_volume': None,\n",
      "                       'projected': {'default_mode': 420,\n",
      "                                     'sources': [{'config_map': None,\n",
      "                                                  'downward_api': None,\n",
      "                                                  'secret': None,\n",
      "                                                  'service_account_token': {'audience': 'istio-ca',\n",
      "                                                                            'expiration_seconds': 43200,\n",
      "                                                                            'path': 'istio-token'}}]},\n",
      "                       'quobyte': None,\n",
      "                       'rbd': None,\n",
      "                       'scale_io': None,\n",
      "                       'secret': None,\n",
      "                       'storageos': None,\n",
      "                       'vsphere_volume': None},\n",
      "                      {'aws_elastic_block_store': None,\n",
      "                       'azure_disk': None,\n",
      "                       'azure_file': None,\n",
      "                       'cephfs': None,\n",
      "                       'cinder': None,\n",
      "                       'config_map': {'default_mode': 420,\n",
      "                                      'items': None,\n",
      "                                      'name': 'istio-ca-root-cert',\n",
      "                                      'optional': None},\n",
      "                       'csi': None,\n",
      "                       'downward_api': None,\n",
      "                       'empty_dir': None,\n",
      "                       'ephemeral': None,\n",
      "                       'fc': None,\n",
      "                       'flex_volume': None,\n",
      "                       'flocker': None,\n",
      "                       'gce_persistent_disk': None,\n",
      "                       'git_repo': None,\n",
      "                       'glusterfs': None,\n",
      "                       'host_path': None,\n",
      "                       'iscsi': None,\n",
      "                       'name': 'istiod-ca-cert',\n",
      "                       'nfs': None,\n",
      "                       'persistent_volume_claim': None,\n",
      "                       'photon_persistent_disk': None,\n",
      "                       'portworx_volume': None,\n",
      "                       'projected': None,\n",
      "                       'quobyte': None,\n",
      "                       'rbd': None,\n",
      "                       'scale_io': None,\n",
      "                       'secret': None,\n",
      "                       'storageos': None,\n",
      "                       'vsphere_volume': None},\n",
      "                      {'aws_elastic_block_store': None,\n",
      "                       'azure_disk': None,\n",
      "                       'azure_file': None,\n",
      "                       'cephfs': None,\n",
      "                       'cinder': None,\n",
      "                       'config_map': None,\n",
      "                       'csi': None,\n",
      "                       'downward_api': None,\n",
      "                       'empty_dir': None,\n",
      "                       'ephemeral': None,\n",
      "                       'fc': None,\n",
      "                       'flex_volume': None,\n",
      "                       'flocker': None,\n",
      "                       'gce_persistent_disk': None,\n",
      "                       'git_repo': None,\n",
      "                       'glusterfs': None,\n",
      "                       'host_path': None,\n",
      "                       'iscsi': None,\n",
      "                       'name': 'model-store',\n",
      "                       'nfs': None,\n",
      "                       'persistent_volume_claim': {'claim_name': 'model-pv-claim',\n",
      "                                                   'read_only': None},\n",
      "                       'photon_persistent_disk': None,\n",
      "                       'portworx_volume': None,\n",
      "                       'projected': None,\n",
      "                       'quobyte': None,\n",
      "                       'rbd': None,\n",
      "                       'scale_io': None,\n",
      "                       'secret': None,\n",
      "                       'storageos': None,\n",
      "                       'vsphere_volume': None},\n",
      "                      {'aws_elastic_block_store': None,\n",
      "                       'azure_disk': None,\n",
      "                       'azure_file': None,\n",
      "                       'cephfs': None,\n",
      "                       'cinder': None,\n",
      "                       'config_map': None,\n",
      "                       'csi': None,\n",
      "                       'downward_api': None,\n",
      "                       'empty_dir': None,\n",
      "                       'ephemeral': None,\n",
      "                       'fc': None,\n",
      "                       'flex_volume': None,\n",
      "                       'flocker': None,\n",
      "                       'gce_persistent_disk': None,\n",
      "                       'git_repo': None,\n",
      "                       'glusterfs': None,\n",
      "                       'host_path': None,\n",
      "                       'iscsi': None,\n",
      "                       'name': 'kube-api-access-cjs7t',\n",
      "                       'nfs': None,\n",
      "                       'persistent_volume_claim': None,\n",
      "                       'photon_persistent_disk': None,\n",
      "                       'portworx_volume': None,\n",
      "                       'projected': {'default_mode': 420,\n",
      "                                     'sources': [{'config_map': None,\n",
      "                                                  'downward_api': None,\n",
      "                                                  'secret': None,\n",
      "                                                  'service_account_token': {'audience': None,\n",
      "                                                                            'expiration_seconds': 3607,\n",
      "                                                                            'path': 'token'}},\n",
      "                                                 {'config_map': {'items': [{'key': 'ca.crt',\n",
      "                                                                            'mode': None,\n",
      "                                                                            'path': 'ca.crt'}],\n",
      "                                                                 'name': 'kube-root-ca.crt',\n",
      "                                                                 'optional': None},\n",
      "                                                  'downward_api': None,\n",
      "                                                  'secret': None,\n",
      "                                                  'service_account_token': None},\n",
      "                                                 {'config_map': None,\n",
      "                                                  'downward_api': {'items': [{'field_ref': {'api_version': 'v1',\n",
      "                                                                                            'field_path': 'metadata.namespace'},\n",
      "                                                                              'mode': None,\n",
      "                                                                              'path': 'namespace',\n",
      "                                                                              'resource_field_ref': None}]},\n",
      "                                                  'secret': None,\n",
      "                                                  'service_account_token': None}]},\n",
      "                       'quobyte': None,\n",
      "                       'rbd': None,\n",
      "                       'scale_io': None,\n",
      "                       'secret': None,\n",
      "                       'storageos': None,\n",
      "                       'vsphere_volume': None}]},\n",
      " 'status': {'conditions': [{'last_probe_time': None,\n",
      "                            'last_transition_time': datetime.datetime(2024, 11, 7, 19, 21, 51, tzinfo=tzlocal()),\n",
      "                            'message': None,\n",
      "                            'reason': None,\n",
      "                            'status': 'True',\n",
      "                            'type': 'Initialized'},\n",
      "                           {'last_probe_time': None,\n",
      "                            'last_transition_time': datetime.datetime(2024, 11, 7, 19, 21, 53, tzinfo=tzlocal()),\n",
      "                            'message': None,\n",
      "                            'reason': None,\n",
      "                            'status': 'True',\n",
      "                            'type': 'Ready'},\n",
      "                           {'last_probe_time': None,\n",
      "                            'last_transition_time': datetime.datetime(2024, 11, 7, 19, 21, 53, tzinfo=tzlocal()),\n",
      "                            'message': None,\n",
      "                            'reason': None,\n",
      "                            'status': 'True',\n",
      "                            'type': 'ContainersReady'},\n",
      "                           {'last_probe_time': None,\n",
      "                            'last_transition_time': datetime.datetime(2024, 11, 7, 19, 21, 35, tzinfo=tzlocal()),\n",
      "                            'message': None,\n",
      "                            'reason': None,\n",
      "                            'status': 'True',\n",
      "                            'type': 'PodScheduled'}],\n",
      "            'container_statuses': [{'container_id': 'containerd://a08059f183669b5cba46a5bd9c1706bf462da865338382e08739bfc31b827c7e',\n",
      "                                    'image': 'docker.io/istio/proxyv2:1.17.5',\n",
      "                                    'image_id': 'docker.io/istio/proxyv2@sha256:101201e7ebae599d1c95191c51ca1daccf0b5eedb96b0f5f6e1a00abe0d1b31e',\n",
      "                                    'last_state': {'running': None,\n",
      "                                                   'terminated': None,\n",
      "                                                   'waiting': None},\n",
      "                                    'name': 'istio-proxy',\n",
      "                                    'ready': True,\n",
      "                                    'restart_count': 0,\n",
      "                                    'started': True,\n",
      "                                    'state': {'running': {'started_at': datetime.datetime(2024, 11, 7, 19, 21, 52, tzinfo=tzlocal())},\n",
      "                                              'terminated': None,\n",
      "                                              'waiting': None}},\n",
      "                                   {'container_id': 'containerd://a69109459dfd7857148bfb2d09fede5cd0a5f68ef09386993dc318eab1082706',\n",
      "                                    'image': 'docker.io/library/ubuntu:latest',\n",
      "                                    'image_id': 'docker.io/library/ubuntu@sha256:99c35190e22d294cdace2783ac55effc69d32896daaa265f0bbedbcde4fbe3e5',\n",
      "                                    'last_state': {'running': None,\n",
      "                                                   'terminated': None,\n",
      "                                                   'waiting': None},\n",
      "                                    'name': 'model-store',\n",
      "                                    'ready': True,\n",
      "                                    'restart_count': 0,\n",
      "                                    'started': True,\n",
      "                                    'state': {'running': {'started_at': datetime.datetime(2024, 11, 7, 19, 21, 52, tzinfo=tzlocal())},\n",
      "                                              'terminated': None,\n",
      "                                              'waiting': None}}],\n",
      "            'ephemeral_container_statuses': None,\n",
      "            'host_ip': '10.15.201.5',\n",
      "            'init_container_statuses': [{'container_id': 'containerd://6ef5478c8df8dd458323366920e0aa0d2cc3c0643c11ff4653ded8a8915bfa19',\n",
      "                                         'image': 'docker.io/istio/proxyv2:1.17.5',\n",
      "                                         'image_id': 'docker.io/istio/proxyv2@sha256:101201e7ebae599d1c95191c51ca1daccf0b5eedb96b0f5f6e1a00abe0d1b31e',\n",
      "                                         'last_state': {'running': None,\n",
      "                                                        'terminated': None,\n",
      "                                                        'waiting': None},\n",
      "                                         'name': 'istio-init',\n",
      "                                         'ready': True,\n",
      "                                         'restart_count': 0,\n",
      "                                         'started': None,\n",
      "                                         'state': {'running': None,\n",
      "                                                   'terminated': {'container_id': 'containerd://6ef5478c8df8dd458323366920e0aa0d2cc3c0643c11ff4653ded8a8915bfa19',\n",
      "                                                                  'exit_code': 0,\n",
      "                                                                  'finished_at': datetime.datetime(2024, 11, 7, 19, 21, 50, tzinfo=tzlocal()),\n",
      "                                                                  'message': None,\n",
      "                                                                  'reason': 'Completed',\n",
      "                                                                  'signal': None,\n",
      "                                                                  'started_at': datetime.datetime(2024, 11, 7, 19, 21, 50, tzinfo=tzlocal())},\n",
      "                                                   'waiting': None}}],\n",
      "            'message': None,\n",
      "            'nominated_node_name': None,\n",
      "            'phase': 'Running',\n",
      "            'pod_i_ps': [{'ip': '10.233.97.174'}],\n",
      "            'pod_ip': '10.233.97.174',\n",
      "            'qos_class': 'Burstable',\n",
      "            'reason': None,\n",
      "            'start_time': datetime.datetime(2024, 11, 7, 19, 21, 35, tzinfo=tzlocal())}}\n",
      "pod created. status='{'conditions': None,\n",
      " 'container_statuses': None,\n",
      " 'ephemeral_container_statuses': None,\n",
      " 'host_ip': None,\n",
      " 'init_container_statuses': None,\n",
      " 'message': None,\n",
      " 'nominated_node_name': None,\n",
      " 'phase': 'Pending',\n",
      " 'pod_i_ps': None,\n",
      " 'pod_ip': None,\n",
      " 'qos_class': 'Burstable',\n",
      " 'reason': None,\n",
      " 'start_time': None}'\n",
      "margen-pod running \n",
      "Response: WARNING - Overwriting /home/model-server/youtubegoes5g.mar ...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/venv/bin/torch-model-archiver\", line 8, in <module>\n",
      "    sys.exit(generate_model_archive())\n",
      "  File \"/home/venv/lib/python3.10/site-packages/model_archiver/model_packaging.py\", line 72, in generate_model_archive\n",
      "    package_model(config, manifest=manifest)\n",
      "  File \"/home/venv/lib/python3.10/site-packages/model_archiver/model_packaging.py\", line 53, in package_model\n",
      "    shutil.rmtree(model_path)\n",
      "  File \"/usr/lib/python3.10/shutil.py\", line 715, in rmtree\n",
      "    onerror(os.lstat, path, sys.exc_info())\n",
      "  File \"/usr/lib/python3.10/shutil.py\", line 713, in rmtree\n",
      "    orig_st = os.lstat(path)\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '/tmp/youtubegoes5g'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def mar_gen(\n",
    "    github_repo_url: str,\n",
    "    github_cloned_dir: str,\n",
    "    github_main_branch: str,\n",
    "    github_username: str,\n",
    "    github_token: str,\n",
    "    minio_url: str,\n",
    "    minio_access_key: str,\n",
    "    minio_secret_key: str,\n",
    "    kserve_namespace: str,\n",
    "    bucket_name: str,\n",
    "    k8s_api_token: str\n",
    "):\n",
    "    from kubernetes import client, config, utils, watch\n",
    "    import time\n",
    "    from kubernetes.client import Configuration\n",
    "    from kubernetes.client.api import core_v1_api\n",
    "    from kubernetes.client.rest import ApiException\n",
    "    from kubernetes.stream import stream\n",
    "    import io\n",
    "    import tarfile\n",
    "    import pathlib\n",
    "    import os\n",
    "    from minio import Minio\n",
    "    from minio.error import S3Error\n",
    "    from git import Repo\n",
    "    from subprocess import run\n",
    "    ## aux functions\n",
    "\n",
    "    # clone repo to get custom files for model\n",
    "    def clone_repository_with_token(github_repo_url, \n",
    "                                    github_cloned_dir, \n",
    "                                    github_branch, \n",
    "                                    github_username, \n",
    "                                    github_token):\n",
    "        \"\"\"Clone a Git repository using a GitHub token in the URL and specifying the branch.\"\"\"\n",
    "        try:\n",
    "            # Construct the URL with the GitHub username and token\n",
    "            url_with_token = f\"https://{github_username}:{github_token}@{github_repo_url.split('//')[1]}\"\n",
    "\n",
    "            # Clone the repository from the specified branch\n",
    "            repo = Repo.clone_from(url_with_token, github_cloned_dir, branch=github_branch)\n",
    "            return \"Repository cloned successfully\"\n",
    "        except Exception as e:\n",
    "            return f\"Error occurred during repository cloning: {e}\"\n",
    "\n",
    "    # to wait some time while pod isn't running yet\n",
    "    def wait_pod(core_v1, namespace, label, pod_name, time_in_sec):\n",
    "        w = watch.Watch()\n",
    "        for event in w.stream(func=core_v1.list_namespaced_pod,\n",
    "                                  namespace=namespace,\n",
    "                                  label_selector=label,\n",
    "                                  timeout_seconds=time_in_sec):\n",
    "            if event[\"object\"].status.phase == \"Running\":\n",
    "                w.stop()\n",
    "                end_time = time.time()\n",
    "                print(f\"{pod_name} running \")\n",
    "                return\n",
    "            # event.type: ADDED, MODIFIED, DELETED\n",
    "            if event[\"type\"] == \"DELETED\":\n",
    "                # Pod was deleted while we were waiting for it to start.\n",
    "                print(f\"{pod_name} deleted before it started\")\n",
    "                w.stop()\n",
    "                return\n",
    "\n",
    "    # kubectl exec\n",
    "    def exec_commands(api_instance, namespace, pod_name, pod_container_name, command):\n",
    "        name = pod_name\n",
    "        resp = None\n",
    "        try:\n",
    "            resp = api_instance.read_namespaced_pod(name=name,\n",
    "                                                    namespace=namespace)\n",
    "        except ApiException as e:\n",
    "            if e.status != 404:\n",
    "                print(f\"Unknown error: {e}\")\n",
    "                exit(1)\n",
    "\n",
    "        if not resp:\n",
    "            print(f\"Pod {name} does not exist.\")\n",
    "\n",
    "        # Calling exec and waiting for response\n",
    "        exec_command = [\n",
    "            '/bin/sh',\n",
    "            '-c',\n",
    "            command]\n",
    "        # When calling a pod with multiple containers running the target container\n",
    "        # has to be specified with a keyword argument container=<name>.\n",
    "        resp = stream(api_instance.connect_get_namespaced_pod_exec,\n",
    "              name=pod_name,\n",
    "              container=pod_container_name,\n",
    "              namespace=namespace,\n",
    "              command=exec_command,\n",
    "              stderr=True, stdin=False,\n",
    "              stdout=True, tty=False)\n",
    "        print(\"Response: \" + resp)\n",
    "\n",
    "    # Copy from or to pod\n",
    "    def copy_to_tar(source_path, dest_path, tar):\n",
    "        \"\"\"\n",
    "        Adds a file or directory to a tar archive.\n",
    "\n",
    "        Parameters:\n",
    "        - source_path: Path to the source file or directory on the local machine.\n",
    "        - dest_path: Destination directory inside the pod where files should be copied.\n",
    "        - tar: The tarfile object to which files and directories will be added.\n",
    "        \"\"\"\n",
    "        source_path = pathlib.Path(source_path)\n",
    "\n",
    "        if source_path.is_file():\n",
    "            # If it's a file, add to the tarfile with the destination path\n",
    "            tar.add(source_path, arcname=pathlib.Path(dest_path).joinpath(source_path.name))\n",
    "        elif source_path.is_dir():\n",
    "            # If it's a directory, recursively add all its content\n",
    "            for root, dirs, files in os.walk(source_path):\n",
    "                root_path = pathlib.Path(root)\n",
    "                # Compute the relative path within the tar and add to destination path\n",
    "                for file in files:\n",
    "                    file_path = root_path / file\n",
    "                    tar.add(file_path, arcname=pathlib.Path(dest_path).joinpath(file_path.relative_to(source_path)))\n",
    "\n",
    "    def extract_tar_to_local(tar_stream, dest_path):\n",
    "        \"\"\"\n",
    "        Extracts a tar archive stream to a local directory.\n",
    "\n",
    "        Parameters:\n",
    "        - tar_stream: Tar stream from the pod.\n",
    "        - dest_path: Local directory where the files will be extracted.\n",
    "        \"\"\"\n",
    "        with tarfile.open(fileobj=tar_stream, mode='r:') as tar:\n",
    "            tar.extractall(path=dest_path)\n",
    "\n",
    "    def copy_file_or_dir(api_instance, namespace, pod_name, pod_container_name, source_path, dest_path, to_pod=True):\n",
    "        \"\"\"\n",
    "        Copies a file or directory between a Kubernetes pod and the local machine.\n",
    "\n",
    "        Parameters:\n",
    "        - api_instance: Kubernetes API client instance.\n",
    "        - namespace: Namespace of the pod.\n",
    "        - pod_name: Name of the pod.\n",
    "        - pod_container_name: Name of the container within the pod.\n",
    "        - source_path: Path to the source file or directory (local or in the pod).\n",
    "        - dest_path: Destination directory (local or in the pod).\n",
    "        - to_pod: If True, copy from local to pod; if False, copy from pod to local.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            if to_pod:\n",
    "                # Copying from local to pod\n",
    "                buf = io.BytesIO()\n",
    "                with tarfile.open(fileobj=buf, mode='w:tar') as tar:\n",
    "                    copy_to_tar(source_path, dest_path, tar)\n",
    "\n",
    "                buf.seek(0)  # Reset buffer position after writing tar\n",
    "\n",
    "                exec_command = ['tar', 'xvf', '-', '-C', '/']\n",
    "                resp = stream(api_instance.connect_get_namespaced_pod_exec,\n",
    "                              pod_name,\n",
    "                              namespace,\n",
    "                              container=pod_container_name,\n",
    "                              command=exec_command,\n",
    "                              stderr=True, stdin=True, stdout=True, tty=False,\n",
    "                              _preload_content=False)\n",
    "\n",
    "                # Send tar file to pod\n",
    "                while resp.is_open():\n",
    "                    resp.update(timeout=1)\n",
    "                    if resp.peek_stdout():\n",
    "                        print(f\"STDOUT: {resp.read_stdout()}\")\n",
    "                    if resp.peek_stderr():\n",
    "                        print(f\"STDERR: {resp.read_stderr()}\")\n",
    "                    if buf.getvalue():\n",
    "                        resp.write_stdin(buf.read())  # Write tar data to pod\n",
    "                    else:\n",
    "                        resp.write_stdin('\\n')  # Signal end of input\n",
    "                        break\n",
    "                resp.close()\n",
    "\n",
    "            else:\n",
    "                # Copying from pod to local\n",
    "                exec_command = ['tar', 'cvf', '-', source_path]\n",
    "                resp = stream(api_instance.connect_get_namespaced_pod_exec,\n",
    "                              pod_name,\n",
    "                              namespace,\n",
    "                              container=pod_container_name,\n",
    "                              command=exec_command,\n",
    "                              stderr=True, stdin=False, stdout=True, tty=False,\n",
    "                              _preload_content=False)\n",
    "\n",
    "                tar_stream = io.BytesIO()\n",
    "                while resp.is_open():\n",
    "                    resp.update(timeout=1)\n",
    "                    if resp.peek_stdout():\n",
    "                        tar_stream.write(resp.read_stdout().encode('utf-8'))  # Write stdout (tar) to stream\n",
    "                    if resp.peek_stderr():\n",
    "                        print(f\"STDERR: {resp.read_stderr()}\")\n",
    "\n",
    "                tar_stream.seek(0)  # Reset stream position for extraction\n",
    "                extract_tar_to_local(tar_stream, dest_path)\n",
    "                resp.close()\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error copying file or directory: {e}\")\n",
    "\n",
    "    # init minio client\n",
    "    def minio_setup(minio_url, minio_access_key, minio_secret_key):\n",
    "        # Initialize Minio client with just the base URL (without path)\n",
    "        client = Minio(\n",
    "            minio_url,  # Ensure minio_url does not include a path, only the base URL (e.g., http://localhost:9000)\n",
    "            access_key=minio_access_key,\n",
    "            secret_key=minio_secret_key,\n",
    "            secure=False  # Minio is using HTTP on localhost:9000\n",
    "        )\n",
    "        return client\n",
    "\n",
    "    # upload file to minio using a client\n",
    "    def upload_file(client, bucket_name, object_name, filepath):\n",
    "        # Create the bucket if it does not exist\n",
    "        if not client.bucket_exists(bucket_name):\n",
    "            client.make_bucket(bucket_name)\n",
    "            create_bucket_result = f\"Successfully created bucket: {bucket_name}\"\n",
    "        else:\n",
    "            create_bucket_result = f\"Bucket {bucket_name} already exists\"\n",
    "\n",
    "        try:\n",
    "            # Upload the file to the specified path in the bucket\n",
    "            client.fput_object(bucket_name, object_name, filepath)\n",
    "            return (f'Successfully uploaded {filepath} to {bucket_name}/{object_name}')\n",
    "\n",
    "        except Exception as e:\n",
    "            # Log and raise any upload errors\n",
    "            raise Exception(f'Failed to upload model to Minio: {e}')\n",
    "\n",
    "    # clone the repo\n",
    "    clone_result = clone_repository_with_token(github_repo_url, \n",
    "                                               github_cloned_dir, \n",
    "                                               github_main_branch, \n",
    "                                               github_username, \n",
    "                                               github_token)\n",
    "\n",
    "    ## init access to cluster when outside or inside the cluster\n",
    "    # config.load_kube_config(\"kubeconfig\")\n",
    "    config.load_incluster_config()\n",
    "    k8s_client = client.ApiClient()\n",
    "\n",
    "    # apply model-store manifests \n",
    "    model_store_yaml_dir = f'{github_cloned_dir}/model-archiver/model-store-manifests/'\n",
    "    try:\n",
    "        pv_result = utils.create_from_directory(k8s_client, model_store_yaml_dir, verbose=True)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "    # init config to exec commands in pods\n",
    "    try:\n",
    "        c = Configuration().get_default_copy()\n",
    "    except AttributeError:\n",
    "        c = Configuration()\n",
    "        c.assert_hostname = False\n",
    "    Configuration.set_default(c)\n",
    "    core_v1 = core_v1_api.CoreV1Api()\n",
    "\n",
    "    # Create folders for model-store, config and scripts in PV\n",
    "    model_store_pod_name = \"model-store-pod\"\n",
    "    model_store_pod_container_name = \"model-store\"\n",
    "    model_store_pod_label = \"service.istio.io/canonical-name=model-store-pod\"\n",
    "\n",
    "    # Wait for pods to run before exec\n",
    "    wait_pod(core_v1, kserve_namespace, model_store_pod_label, model_store_pod_name, 120)\n",
    "\n",
    "    mkdir_ms_command = \"mkdir -p /pv/model-store/youtubegoes5g/\"\n",
    "    mkdir_ms_result = exec_commands(core_v1, \n",
    "                                    kserve_namespace, \n",
    "                                    model_store_pod_name, \n",
    "                                    model_store_pod_container_name, \n",
    "                                    mkdir_ms_command)\n",
    "    mkdir_conf_command = \"mkdir /pv/config/\"\n",
    "    mkdir_conf_result = exec_commands(core_v1, \n",
    "                                      kserve_namespace, \n",
    "                                      model_store_pod_name, \n",
    "                                      model_store_pod_container_name, \n",
    "                                      mkdir_conf_command)\n",
    "    mkdir_scripts_command = \"mkdir /pv/scripts/\"\n",
    "    mkdir_scripts_result = exec_commands(core_v1, \n",
    "                                         kserve_namespace, \n",
    "                                         model_store_pod_name, \n",
    "                                         model_store_pod_container_name, \n",
    "                                         mkdir_scripts_command)\n",
    "\n",
    "    # download pt file from minio\n",
    "    pt_object_name = 'model-store/youtubegoes5g/model.pt'\n",
    "    pt_local_file_path = 'model.pt'\n",
    "\n",
    "    # Initialize the MinIO client\n",
    "    client = minio_setup(minio_url, minio_access_key, minio_secret_key)\n",
    "\n",
    "    try:\n",
    "        # Download the file from MinIO\n",
    "        client.fget_object(bucket_name, pt_object_name, pt_local_file_path)\n",
    "        print(f\"File {pt_object_name} downloaded successfully to {pt_local_file_path}.\")\n",
    "    except S3Error as exc:\n",
    "        print(f\"Error occurred: {exc}\")\n",
    "\n",
    "    # cp pt file to model store pod\n",
    "    model_pt_source_path = 'model.pt'\n",
    "    model_store_dest_path = \"/pv/model-store/youtubegoes5g/\"\n",
    "\n",
    "    cp_pt_result = copy_file_or_dir(core_v1, \n",
    "                                    kserve_namespace, \n",
    "                                    model_store_pod_name, \n",
    "                                    model_store_pod_container_name, \n",
    "                                    model_pt_source_path, \n",
    "                                    model_store_dest_path, \n",
    "                                    to_pod=True)\n",
    "\n",
    "    # cp handler file to model store pod\n",
    "    model_handler_source_path = f'{github_cloned_dir}/model-archiver/model-store/youtubegoes5g/custom_handler.py'\n",
    "\n",
    "    cp_handler_result = copy_file_or_dir(core_v1, \n",
    "                                         kserve_namespace, \n",
    "                                         model_store_pod_name, \n",
    "                                         model_store_pod_container_name, \n",
    "                                         model_handler_source_path, \n",
    "                                         model_store_dest_path, \n",
    "                                         to_pod=True)\n",
    "\n",
    "    # cp model.py file to model store pod\n",
    "    model_py_source_path =  f'{github_cloned_dir}/model-archiver/model-store/youtubegoes5g/model.py'\n",
    "\n",
    "    cp_py_result = copy_file_or_dir(core_v1, \n",
    "                                    kserve_namespace, \n",
    "                                    model_store_pod_name, \n",
    "                                    model_store_pod_container_name, \n",
    "                                    model_py_source_path, \n",
    "                                    model_store_dest_path, \n",
    "                                    to_pod=True)\n",
    "\n",
    "    # cp properties.json file to model store pod\n",
    "    prop_source_path = f'{github_cloned_dir}/model-archiver/model-store/properties.json'\n",
    "    model_prop_dest_path = \"/pv/model-store/\"\n",
    "\n",
    "    cp_prop_result = copy_file_or_dir(core_v1, \n",
    "                                      kserve_namespace, \n",
    "                                      model_store_pod_name, \n",
    "                                      model_store_pod_container_name, \n",
    "                                      prop_source_path, \n",
    "                                      model_prop_dest_path, \n",
    "                                      to_pod=True)\n",
    "\n",
    "    # cp config.properties file to model store pod\n",
    "    config_source_path = f'{github_cloned_dir}/model-archiver/config/config.properties'\n",
    "#         config_dest_path = \"/pv/config/\"\n",
    "\n",
    "#         cp_conf_result = copy_file_or_dir(core_v1, \n",
    "#                                           kserve_namespace, \n",
    "#                                           model_store_pod_name, \n",
    "#                                           model_store_pod_container_name, \n",
    "#                                           config_source_path, \n",
    "#                                           config_dest_path, \n",
    "#                                           to_pod=True)\n",
    "\n",
    "    # cp margen script file to model store pod\n",
    "    scripts_source_path = f'{github_cloned_dir}/model-archiver/scripts/margen.sh'\n",
    "    scripts_dest_path = \"/pv/scripts/\"\n",
    "\n",
    "    cp_scripts_result = copy_file_or_dir(core_v1, \n",
    "                                      kserve_namespace, \n",
    "                                      model_store_pod_name, \n",
    "                                      model_store_pod_container_name, \n",
    "                                      scripts_source_path, \n",
    "                                      scripts_dest_path, \n",
    "                                      to_pod=True)\n",
    "\n",
    "    # Delete model_store_pod\n",
    "    try:\n",
    "        api_response = core_v1.delete_namespaced_pod(model_store_pod_name, kserve_namespace)\n",
    "        print(api_response)\n",
    "    except ApiException as e:\n",
    "        print(\"Exception when calling CoreV1Api->delete_namespaced_pod: %s\\n\" % e)\n",
    "\n",
    "    # Upload config.properties to minio for IS\n",
    "    config_object_name = \"config/config.properties\"\n",
    "    # up_config_result = upload_file(client, bucket_name, config_object_name, config_source_path)\n",
    "\n",
    "    # Create model archiver pod\n",
    "    mar_yaml_dir = f'{github_cloned_dir}/model-archiver/manifests/'\n",
    "    mar_pod_name = \"margen-pod\"\n",
    "    mar_pod_container_name = \"margen-container\"\n",
    "    mar_pod_label = \"service.istio.io/canonical-name=margen-pod\"\n",
    "\n",
    "    try:\n",
    "        margen_result = utils.create_from_directory(k8s_client, mar_yaml_dir, verbose=True)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "    # Wait for pods to run before exec\n",
    "    wait_pod(core_v1, kserve_namespace, mar_pod_label, mar_pod_name, 120)\n",
    "\n",
    "    # Exec mar gen in a script\n",
    "    mar_gen_command = \"bash scripts/margen.sh\"\n",
    "    mar_gen_result = exec_commands(core_v1, \n",
    "                                   kserve_namespace, \n",
    "                                   mar_pod_name, \n",
    "                                   mar_pod_container_name, \n",
    "                                   mar_gen_command)\n",
    "\n",
    "#     # Copy mar file to local\n",
    "#     mar_source_path = \"youtubegoes5g.mar\"\n",
    "#     mar_dest_path = \"./\"\n",
    "\n",
    "#     mar_cp_result = copy_file_or_dir(core_v1, \n",
    "#                                      kserve_namespace, \n",
    "#                                      mar_pod_name, \n",
    "#                                      mar_pod_container_name, \n",
    "#                                      mar_source_path, \n",
    "#                                      mar_dest_path, \n",
    "#                                      to_pod=False)\n",
    "\n",
    "#     # Upload mar file to minio\n",
    "#     mar_object_name = \"model-store/youtubegoes5g.mar\"\n",
    "#     mar_filepath = './youtubegoes5g.mar'\n",
    "\n",
    "#     # up_mar_result = upload_file(client, bucket_name, mar_object_name, mar_filepath)\n",
    "\n",
    "#     # Delete margen pod\n",
    "#     try:\n",
    "#         api_response = core_v1.delete_namespaced_pod(mar_pod_name, kserve_namespace)\n",
    "#         print(api_response)\n",
    "#     except ApiException as e:\n",
    "#         print(\"Exception when calling CoreV1Api->delete_namespaced_pod: %s\\n\" % e)\n",
    "        \n",
    "mar_gen(GITHUB_REPO_URL,\n",
    "        GITHUB_CLONED_DIR,\n",
    "        GITHUB_MAIN_BRANCH,\n",
    "        GITHUB_USERNAME,\n",
    "        GITHUB_TOKEN,\n",
    "        MINIO_URL,\n",
    "        MINIO_ACCESS_KEY,\n",
    "        MINIO_SECRET_KEY,\n",
    "        KSERVE_NAMESPACE,\n",
    "        MINIO_MODEL_BUCKET_NAME,\n",
    "        K8S_API_TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "1261c82d-960d-4360-979c-c9736ea0f122",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/kfp/client/client.py:159: FutureWarning: This client only works with Kubeflow Pipeline v2.0.0-beta.2 and later versions.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<a href=\"http://ml-pipeline.kubeflow:8888/#/experiments/details/23d52751-4aeb-4e71-a47e-01c1ced25793\" target=\"_blank\" >Experiment details</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<a href=\"http://ml-pipeline.kubeflow:8888/#/runs/details/cd9ed8eb-ddb9-49d3-a1c2-2661fe10a3bf\" target=\"_blank\" >Run details</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "RunPipelineResult(run_id=cd9ed8eb-ddb9-49d3-a1c2-2661fe10a3bf)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@component(base_image=\"python:3.11.9\", packages_to_install=['gitpython', 'kubernetes==30.1.0','Minio==7.2.5'])\n",
    "def mar_gen(\n",
    "    github_repo_url: str,\n",
    "    github_cloned_dir: str,\n",
    "    github_main_branch: str,\n",
    "    github_username: str,\n",
    "    github_token: str,\n",
    "    minio_url: str,\n",
    "    minio_access_key: str,\n",
    "    minio_secret_key: str,\n",
    "    kserve_namespace: str,\n",
    "    bucket_name: str,\n",
    "    k8s_api_token: str\n",
    "):\n",
    "    from kubernetes import client, config, utils, watch\n",
    "    import time\n",
    "    from kubernetes.client import Configuration\n",
    "    from kubernetes.client.api import core_v1_api\n",
    "    from kubernetes.client.rest import ApiException\n",
    "    from kubernetes.stream import stream\n",
    "    import io\n",
    "    import tarfile\n",
    "    import pathlib\n",
    "    import os\n",
    "    from minio import Minio\n",
    "    from minio.error import S3Error\n",
    "    from git import Repo\n",
    "    from subprocess import run\n",
    "\n",
    "    def clone_repository_with_token(github_repo_url, \n",
    "                                    github_cloned_dir, \n",
    "                                    github_branch, \n",
    "                                    github_username, \n",
    "                                    github_token):\n",
    "        \"\"\"Clone a Git repository using a GitHub token in the URL and specifying the branch.\"\"\"\n",
    "        try:\n",
    "            # Construct the URL with the GitHub username and token\n",
    "            url_with_token = f\"https://{github_username}:{github_token}@{github_repo_url.split('//')[1]}\"\n",
    "\n",
    "            # Clone the repository from the specified branch\n",
    "            repo = Repo.clone_from(url_with_token, github_cloned_dir, branch=github_branch)\n",
    "            return \"Repository cloned successfully\"\n",
    "        except Exception as e:\n",
    "            return f\"Error occurred during repository cloning: {e}\"\n",
    "\n",
    "    # github_repo_url = GITHUB_REPO_URL\n",
    "    # github_cloned_dir = GITHUB_CLONED_DIR\n",
    "    # github_main_branch = GITHUB_MAIN_BRANCH\n",
    "    # github_username = GITHUB_USERNAME\n",
    "    # github_token = GITHUB_TOKEN\n",
    "\n",
    "    clone_result = clone_repository_with_token(github_repo_url, \n",
    "                                               github_cloned_dir, \n",
    "                                               github_main_branch, \n",
    "                                               github_username, \n",
    "                                               github_token)\n",
    "\n",
    "    # config.load_kube_config(\"kubeconfig\")\n",
    "    config.load_incluster_config()\n",
    "    k8s_client = client.ApiClient()\n",
    "    model_store_yaml_dir = f'{github_cloned_dir}/model-archiver/model-store-manifests/'\n",
    "\n",
    "    try:\n",
    "        pv_result = utils.create_from_directory(k8s_client, model_store_yaml_dir, verbose=True)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "    def wait_pod(core_v1, namespace, label, pod_name, time_in_sec):\n",
    "        w = watch.Watch()\n",
    "        for event in w.stream(func=core_v1.list_namespaced_pod,\n",
    "                                  namespace=namespace,\n",
    "                                  label_selector=label,\n",
    "                                  timeout_seconds=time_in_sec):\n",
    "            if event[\"object\"].status.phase == \"Running\":\n",
    "                w.stop()\n",
    "                end_time = time.time()\n",
    "                print(f\"{pod_name} running \")\n",
    "                return\n",
    "            # event.type: ADDED, MODIFIED, DELETED\n",
    "            if event[\"type\"] == \"DELETED\":\n",
    "                # Pod was deleted while we were waiting for it to start.\n",
    "                print(f\"{pod_name} deleted before it started\")\n",
    "                w.stop()\n",
    "                return\n",
    "\n",
    "    def exec_commands(api_instance, namespace, pod_name, pod_container_name, command):\n",
    "        name = pod_name\n",
    "        resp = None\n",
    "        try:\n",
    "            resp = api_instance.read_namespaced_pod(name=name,\n",
    "                                                    namespace=namespace)\n",
    "        except ApiException as e:\n",
    "            if e.status != 404:\n",
    "                print(f\"Unknown error: {e}\")\n",
    "                exit(1)\n",
    "\n",
    "        if not resp:\n",
    "            print(f\"Pod {name} does not exist.\")\n",
    "\n",
    "        # Calling exec and waiting for response\n",
    "        exec_command = [\n",
    "            '/bin/sh',\n",
    "            '-c',\n",
    "            command]\n",
    "        # When calling a pod with multiple containers running the target container\n",
    "        # has to be specified with a keyword argument container=<name>.\n",
    "        resp = stream(api_instance.connect_get_namespaced_pod_exec,\n",
    "              name=pod_name,\n",
    "              container=pod_container_name,\n",
    "              namespace=namespace,\n",
    "              command=exec_command,\n",
    "              stderr=True, stdin=False,\n",
    "              stdout=True, tty=False)\n",
    "        print(\"Response: \" + resp)\n",
    "\n",
    "    try:\n",
    "        c = Configuration().get_default_copy()\n",
    "    except AttributeError:\n",
    "        c = Configuration()\n",
    "        c.assert_hostname = False\n",
    "    Configuration.set_default(c)\n",
    "    core_v1 = core_v1_api.CoreV1Api()\n",
    "\n",
    "    # Create folders for model-store and config in PV\n",
    "    # kserve_namespace = KSERVE_NAMESPACE\n",
    "    # model_store_pod_name = MODEL_STORE_POD_NAME\n",
    "    # model_store_pod_container_name = MODEL_STORE_POD_CONTAINER_NAME\n",
    "    model_store_pod_name = \"model-store-pod\"\n",
    "    model_store_pod_container_name = \"model-store\"\n",
    "    model_store_pod_label = \"service.istio.io/canonical-name=model-store-pod\"\n",
    "\n",
    "    # kserve_namespace = KSERVE_NAMESPACE\n",
    "\n",
    "    # Wait for pods to run before exec\n",
    "    wait_pod(core_v1, kserve_namespace, model_store_pod_label, model_store_pod_name, 120)\n",
    "\n",
    "    mkdir_ms_command = \"mkdir -p /pv/model-store/youtubegoes5g/\"\n",
    "    mkdir_ms_result = exec_commands(core_v1, \n",
    "                                    kserve_namespace, \n",
    "                                    model_store_pod_name, \n",
    "                                    model_store_pod_container_name, \n",
    "                                    mkdir_ms_command)\n",
    "    mkdir_conf_command = \"mkdir /pv/config/\"\n",
    "    mkdir_conf_result = exec_commands(core_v1, \n",
    "                                      kserve_namespace, \n",
    "                                      model_store_pod_name, \n",
    "                                      model_store_pod_container_name, \n",
    "                                      mkdir_conf_command)\n",
    "    mkdir_scripts_command = \"mkdir /pv/scripts/\"\n",
    "    mkdir_scripts_result = exec_commands(core_v1, \n",
    "                                         kserve_namespace, \n",
    "                                         model_store_pod_name, \n",
    "                                         model_store_pod_container_name, \n",
    "                                         mkdir_scripts_command)\n",
    "\n",
    "    # Copy from or to pod\n",
    "    def copy_to_tar(source_path, dest_path, tar):\n",
    "        \"\"\"\n",
    "        Adds a file or directory to a tar archive.\n",
    "\n",
    "        Parameters:\n",
    "        - source_path: Path to the source file or directory on the local machine.\n",
    "        - dest_path: Destination directory inside the pod where files should be copied.\n",
    "        - tar: The tarfile object to which files and directories will be added.\n",
    "        \"\"\"\n",
    "        source_path = pathlib.Path(source_path)\n",
    "\n",
    "        if source_path.is_file():\n",
    "            # If it's a file, add to the tarfile with the destination path\n",
    "            tar.add(source_path, arcname=pathlib.Path(dest_path).joinpath(source_path.name))\n",
    "        elif source_path.is_dir():\n",
    "            # If it's a directory, recursively add all its content\n",
    "            for root, dirs, files in os.walk(source_path):\n",
    "                root_path = pathlib.Path(root)\n",
    "                # Compute the relative path within the tar and add to destination path\n",
    "                for file in files:\n",
    "                    file_path = root_path / file\n",
    "                    tar.add(file_path, arcname=pathlib.Path(dest_path).joinpath(file_path.relative_to(source_path)))\n",
    "\n",
    "    def extract_tar_to_local(tar_stream, dest_path):\n",
    "        \"\"\"\n",
    "        Extracts a tar archive stream to a local directory.\n",
    "\n",
    "        Parameters:\n",
    "        - tar_stream: Tar stream from the pod.\n",
    "        - dest_path: Local directory where the files will be extracted.\n",
    "        \"\"\"\n",
    "        with tarfile.open(fileobj=tar_stream, mode='r:') as tar:\n",
    "            tar.extractall(path=dest_path)\n",
    "\n",
    "    def copy_file_or_dir(api_instance, namespace, pod_name, pod_container_name, source_path, dest_path, to_pod=True):\n",
    "        \"\"\"\n",
    "        Copies a file or directory between a Kubernetes pod and the local machine.\n",
    "\n",
    "        Parameters:\n",
    "        - api_instance: Kubernetes API client instance.\n",
    "        - namespace: Namespace of the pod.\n",
    "        - pod_name: Name of the pod.\n",
    "        - pod_container_name: Name of the container within the pod.\n",
    "        - source_path: Path to the source file or directory (local or in the pod).\n",
    "        - dest_path: Destination directory (local or in the pod).\n",
    "        - to_pod: If True, copy from local to pod; if False, copy from pod to local.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            if to_pod:\n",
    "                # Copying from local to pod\n",
    "                buf = io.BytesIO()\n",
    "                with tarfile.open(fileobj=buf, mode='w:tar') as tar:\n",
    "                    copy_to_tar(source_path, dest_path, tar)\n",
    "\n",
    "                buf.seek(0)  # Reset buffer position after writing tar\n",
    "\n",
    "                exec_command = ['tar', 'xvf', '-', '-C', '/']\n",
    "                resp = stream(api_instance.connect_get_namespaced_pod_exec,\n",
    "                              pod_name,\n",
    "                              namespace,\n",
    "                              container=pod_container_name,\n",
    "                              command=exec_command,\n",
    "                              stderr=True, stdin=True, stdout=True, tty=False,\n",
    "                              _preload_content=False)\n",
    "\n",
    "                # Send tar file to pod\n",
    "                while resp.is_open():\n",
    "                    resp.update(timeout=1)\n",
    "                    if resp.peek_stdout():\n",
    "                        print(f\"STDOUT: {resp.read_stdout()}\")\n",
    "                    if resp.peek_stderr():\n",
    "                        print(f\"STDERR: {resp.read_stderr()}\")\n",
    "                    if buf.getvalue():\n",
    "                        resp.write_stdin(buf.read())  # Write tar data to pod\n",
    "                    else:\n",
    "                        resp.write_stdin('\\n')  # Signal end of input\n",
    "                        break\n",
    "                resp.close()\n",
    "\n",
    "            else:\n",
    "                # Copying from pod to local\n",
    "                exec_command = ['tar', 'cvf', '-', source_path]\n",
    "                resp = stream(api_instance.connect_get_namespaced_pod_exec,\n",
    "                              pod_name,\n",
    "                              namespace,\n",
    "                              container=pod_container_name,\n",
    "                              command=exec_command,\n",
    "                              stderr=True, stdin=False, stdout=True, tty=False,\n",
    "                              _preload_content=False)\n",
    "\n",
    "                tar_stream = io.BytesIO()\n",
    "                while resp.is_open():\n",
    "                    resp.update(timeout=1)\n",
    "                    if resp.peek_stdout():\n",
    "                        tar_stream.write(resp.read_stdout().encode('utf-8'))  # Write stdout (tar) to stream\n",
    "                    if resp.peek_stderr():\n",
    "                        print(f\"STDERR: {resp.read_stderr()}\")\n",
    "\n",
    "                tar_stream.seek(0)  # Reset stream position for extraction\n",
    "                extract_tar_to_local(tar_stream, dest_path)\n",
    "                resp.close()\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error copying file or directory: {e}\")\n",
    "\n",
    "    def minio_setup(minio_url, minio_access_key, minio_secret_key):\n",
    "        # Initialize Minio client with just the base URL (without path)\n",
    "        client = Minio(\n",
    "            minio_url,  # Ensure minio_url does not include a path, only the base URL (e.g., http://localhost:9000)\n",
    "            access_key=minio_access_key,\n",
    "            secret_key=minio_secret_key,\n",
    "            secure=False  # Minio is using HTTP on localhost:9000\n",
    "        )\n",
    "        return client\n",
    "\n",
    "    # minio_url = MINIO_URL\n",
    "    # minio_access_key = MINIO_ACCESS_KEY\n",
    "    # minio_secret_key = MINIO_SECRET_KEY\n",
    "    # bucket_name = MINIO_MODEL_BUCKET_NAME\n",
    "    pt_object_name = 'model-store/youtubegoes5g/model.pt'\n",
    "    model_object_name = 'model-store/youtubegoes5g/model.py'\n",
    "    pt_local_file_path = 'model.pt'\n",
    "    model_local_file_path = 'model.py'\n",
    "\n",
    "    # Initialize the MinIO client\n",
    "    client = minio_setup(minio_url, minio_access_key, minio_secret_key)\n",
    "\n",
    "    try:\n",
    "        # Download the file from MinIO\n",
    "        client.fget_object(bucket_name, pt_object_name, pt_local_file_path)\n",
    "        print(f\"File {pt_object_name} downloaded successfully to {pt_local_file_path}.\")\n",
    "    except S3Error as exc:\n",
    "        print(f\"Error occurred: {exc}\")\n",
    "\n",
    "    try:\n",
    "        # Download the file from MinIO\n",
    "        client.fget_object(bucket_name, model_object_name, model_local_file_path)\n",
    "        print(f\"File {model_object_name} downloaded successfully to {model_local_file_path}.\")\n",
    "    except S3Error as exc:\n",
    "        print(f\"Error occurred: {exc}\")\n",
    "\n",
    "    model_pt_source_path = 'model.pt'\n",
    "    model_store_dest_path = \"/pv/model-store/youtubegoes5g/\"\n",
    "\n",
    "    cp_pt_result = copy_file_or_dir(core_v1, \n",
    "                                    kserve_namespace, \n",
    "                                    model_store_pod_name, \n",
    "                                    model_store_pod_container_name, \n",
    "                                    model_pt_source_path, \n",
    "                                    model_store_dest_path, \n",
    "                                    to_pod=True)\n",
    "\n",
    "    model_py_source_path = 'model.py'\n",
    "\n",
    "    cp_py_result = copy_file_or_dir(core_v1, \n",
    "                                    kserve_namespace, \n",
    "                                    model_store_pod_name, \n",
    "                                    model_store_pod_container_name, \n",
    "                                    model_py_source_path, \n",
    "                                    model_store_dest_path, \n",
    "                                    to_pod=True)\n",
    "\n",
    "    prop_source_path = f'{github_cloned_dir}/model-archiver/model-store/properties.json'\n",
    "    model_prop_dest_path = \"/pv/model-store/\"\n",
    "\n",
    "    cp_prop_result = copy_file_or_dir(core_v1, \n",
    "                                      kserve_namespace, \n",
    "                                      model_store_pod_name, \n",
    "                                      model_store_pod_container_name, \n",
    "                                      prop_source_path, \n",
    "                                      model_prop_dest_path, \n",
    "                                      to_pod=True)\n",
    "\n",
    "    config_source_path = f'{github_cloned_dir}/model-archiver/config/config.properties'\n",
    "    config_dest_path = \"/pv/config/\"\n",
    "\n",
    "    cp_conf_result = copy_file_or_dir(core_v1, \n",
    "                                      kserve_namespace, \n",
    "                                      model_store_pod_name, \n",
    "                                      model_store_pod_container_name, \n",
    "                                      config_source_path, \n",
    "                                      config_dest_path, \n",
    "                                      to_pod=True)\n",
    "\n",
    "    scripts_source_path = f'{github_cloned_dir}/model-archiver/scripts/margen.sh'\n",
    "    scripts_dest_path = \"/pv/scripts/\"\n",
    "\n",
    "    cp_scripts_result = copy_file_or_dir(core_v1, \n",
    "                                      kserve_namespace, \n",
    "                                      model_store_pod_name, \n",
    "                                      model_store_pod_container_name, \n",
    "                                      scripts_source_path, \n",
    "                                      scripts_dest_path, \n",
    "                                      to_pod=True)\n",
    "\n",
    "    # Delete model_store_pod\n",
    "    try:\n",
    "        api_response = core_v1.delete_namespaced_pod(model_store_pod_name, kserve_namespace)\n",
    "        print(api_response)\n",
    "    except ApiException as e:\n",
    "        print(\"Exception when calling CoreV1Api->delete_namespaced_pod: %s\\n\" % e)\n",
    "\n",
    "    # Create model archiver pod\n",
    "    mar_yaml_dir = f'{github_cloned_dir}/model-archiver/manifests/'\n",
    "    mar_pod_name = \"margen-pod\"\n",
    "    mar_pod_container_name = \"margen-container\"\n",
    "    mar_pod_label = \"service.istio.io/canonical-name=margen-pod\"\n",
    "\n",
    "    try:\n",
    "        margen_result = utils.create_from_directory(k8s_client, mar_yaml_dir, verbose=True)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "    # Wait for pods to run before exec\n",
    "    wait_pod(core_v1, kserve_namespace, mar_pod_label, mar_pod_name, 120)\n",
    "\n",
    "    # Exec mar gen in a script\n",
    "    mar_gen_command = \"bash /home/model-server/scripts/margen.sh\"\n",
    "    mar_gen_result = exec_commands(core_v1, \n",
    "                                   kserve_namespace, \n",
    "                                   mar_pod_name, \n",
    "                                   mar_pod_container_name, \n",
    "                                   mar_gen_command)\n",
    "\n",
    "    # Copy mar file to local\n",
    "    mar_source_path = \"youtubegoes5g.mar\"\n",
    "    mar_dest_path = \"./\"\n",
    "\n",
    "    mar_cp_result = copy_file_or_dir(core_v1, \n",
    "                                     kserve_namespace, \n",
    "                                     mar_pod_name, \n",
    "                                     mar_pod_container_name, \n",
    "                                     mar_source_path, \n",
    "                                     mar_dest_path, \n",
    "                                     to_pod=False)\n",
    "\n",
    "    # Upload mar file to minio\n",
    "\n",
    "    def upload_file(client, bucket_name, object_name, filepath):\n",
    "        # Create the bucket if it does not exist\n",
    "        if not client.bucket_exists(bucket_name):\n",
    "            client.make_bucket(bucket_name)\n",
    "            create_bucket_result = f\"Successfully created bucket: {bucket_name}\"\n",
    "        else:\n",
    "            create_bucket_result = f\"Bucket {bucket_name} already exists\"\n",
    "\n",
    "        try:\n",
    "            # Upload the file to the specified path in the bucket\n",
    "            client.fput_object(bucket_name, object_name, filepath)\n",
    "            return (f'Successfully uploaded {filepath} to {bucket_name}/{object_name}')\n",
    "\n",
    "        except Exception as e:\n",
    "            # Log and raise any upload errors\n",
    "            raise Exception(f'Failed to upload model to Minio: {e}')\n",
    "\n",
    "    mar_object_name = \"model-store/youtubegoes5g.mar\"\n",
    "    mar_filepath = './youtubegoes5g.mar'\n",
    "\n",
    "    up_mar_result = upload_file(client, bucket_name, mar_object_name, mar_filepath)\n",
    "\n",
    "    # Delete margen pod\n",
    "    try:\n",
    "        api_response = core_v1.delete_namespaced_pod(mar_pod_name, kserve_namespace)\n",
    "        print(api_response)\n",
    "    except ApiException as e:\n",
    "        print(\"Exception when calling CoreV1Api->delete_namespaced_pod: %s\\n\" % e)\n",
    "        \n",
    "@pipeline\n",
    "def my_pipeline(\n",
    "    github_repo_url: str,\n",
    "    github_cloned_dir: str,\n",
    "    github_main_branch: str,\n",
    "    github_username: str,\n",
    "    github_token: str,\n",
    "    minio_url: str,\n",
    "    minio_access_key: str,\n",
    "    minio_secret_key: str,\n",
    "    kserve_namespace: str,\n",
    "    bucket_name: str,\n",
    "    k8s_api_token: str\n",
    "):\n",
    "    margen_task = mar_gen(github_repo_url=github_repo_url,\n",
    "                          github_cloned_dir=github_cloned_dir,\n",
    "                          github_main_branch=github_main_branch,\n",
    "                          github_username=github_username,\n",
    "                          github_token=github_token,\n",
    "                          minio_url=minio_url,\n",
    "                          minio_access_key=minio_access_key,\n",
    "                          minio_secret_key=minio_secret_key,\n",
    "                          kserve_namespace=kserve_namespace,\n",
    "                          bucket_name=bucket_name,\n",
    "                          k8s_api_token=k8s_api_token)\n",
    "\n",
    "# Compile the pipeline\n",
    "pipeline_filename = \"margen_pipe.yaml\"\n",
    "kfp.compiler.Compiler().compile(\n",
    "    pipeline_func=my_pipeline,\n",
    "    package_path=pipeline_filename)\n",
    "\n",
    "# Submit the pipeline to the KFP cluster\n",
    "client = kfp.Client(\n",
    "    host=KUBEFLOW_HOST_URL,\n",
    "    existing_token=KUBEFLOW_TOKEN)  \n",
    "\n",
    "client.create_run_from_pipeline_func(\n",
    "    my_pipeline,\n",
    "    enable_caching=False,\n",
    "    arguments={\n",
    "        'github_repo_url': GITHUB_REPO_URL,\n",
    "        'github_cloned_dir': GITHUB_CLONED_DIR,\n",
    "        'github_main_branch': GITHUB_MAIN_BRANCH,\n",
    "        'github_username': GITHUB_USERNAME,\n",
    "        'github_token': GITHUB_TOKEN,\n",
    "        'minio_url': MINIO_URL,\n",
    "        'minio_access_key': MINIO_ACCESS_KEY,\n",
    "        'minio_secret_key': MINIO_SECRET_KEY,\n",
    "        'kserve_namespace': KSERVE_NAMESPACE,\n",
    "        'bucket_name': MINIO_MODEL_BUCKET_NAME,\n",
    "        'k8s_api_token': K8S_API_TOKEN\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78cf08b0-8d7b-4b91-919b-6b433388bf45",
   "metadata": {},
   "source": [
    "# Data Ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "f91437e7-ae9e-4c96-b691-83e49f048def",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from git import Repo\n",
    "from subprocess import run, CalledProcessError\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "github_repo_url = GITHUB_REPO_URL\n",
    "github_cloned_dir = GITHUB_CLONED_DIR\n",
    "github_dvc_branch = GITHUB_DVC_BRANCH\n",
    "github_username = GITHUB_USERNAME\n",
    "github_token = GITHUB_TOKEN\n",
    "dvc_remote_name = DVC_REMOTE_DB\n",
    "dvc_remote_db_url = DVC_REMOTE_DB_URL\n",
    "minio_url = MINIO_URL\n",
    "minio_access_key = MINIO_ACCESS_KEY\n",
    "minio_secret_key = MINIO_SECRET_KEY\n",
    "dvc_file_dir = DVC_FILE_DIR\n",
    "dvc_file_name = DVC_FILE_NAME\n",
    "\n",
    "def clone_repository_with_token(github_repo_url, github_cloned_dir, github_dvc_branch, github_username, github_token):\n",
    "    \"\"\"Clone a Git repository using a GitHub token in the URL and specifying the branch.\"\"\"\n",
    "    try:\n",
    "        # Construct the URL with the GitHub username and token\n",
    "        url_with_token = f\"https://{github_username}:{github_token}@{github_repo_url.split('//')[1]}\"\n",
    "\n",
    "        # Clone the repository from the specified branch\n",
    "        repo = Repo.clone_from(url_with_token, github_cloned_dir, branch=github_dvc_branch)\n",
    "        return \"Repository cloned successfully\"\n",
    "    except Exception as e:\n",
    "        return f\"Error occurred during repository cloning: {e}\"\n",
    "\n",
    "def configure_dvc_remote(github_cloned_dir, dvc_remote_name, dvc_remote_db_url, minio_url, minio_access_key, minio_secret_key):\n",
    "    http_minio = f'http://{minio_url}'\n",
    "    \"\"\"Configure the Minio bucket as the DVC remote repository using the `dvc remote` commands.\"\"\"\n",
    "    try:\n",
    "        # Add the remote\n",
    "        run(\n",
    "            ['dvc', 'remote', 'add', '-d', dvc_remote_name, dvc_remote_db_url],\n",
    "            cwd=github_cloned_dir,\n",
    "            capture_output=True,\n",
    "            text=True,\n",
    "            check=True\n",
    "        )\n",
    "\n",
    "        # Configure the endpoint URL\n",
    "        run(\n",
    "            ['dvc', 'remote', 'modify', dvc_remote_name, 'endpointurl', http_minio],\n",
    "            cwd=github_cloned_dir,\n",
    "            capture_output=True,\n",
    "            text=True,\n",
    "            check=True\n",
    "        )\n",
    "\n",
    "        # Configure access key ID\n",
    "        run(\n",
    "            ['dvc', 'remote', 'modify', dvc_remote_name, 'access_key_id', minio_access_key],\n",
    "            cwd=github_cloned_dir,\n",
    "            capture_output=True,\n",
    "            text=True,\n",
    "            check=True\n",
    "        )\n",
    "\n",
    "        # Configure secret access key\n",
    "        run(\n",
    "            ['dvc', 'remote', 'modify', dvc_remote_name, 'secret_access_key', minio_secret_key],\n",
    "            cwd=github_cloned_dir,\n",
    "            capture_output=True,\n",
    "            text=True,\n",
    "            check=True\n",
    "        )\n",
    "\n",
    "        return f'Successfully configured Minio bucket as DVC remote repository: {dvc_remote_name}'\n",
    "    except CalledProcessError as e:\n",
    "        # Log and raise any errors\n",
    "        return f'Failed to configure DVC remote: {e.stderr}'\n",
    "\n",
    "def perform_dvc_pull(github_cloned_dir, dvc_remote_name):\n",
    "    \"\"\"Perform a DVC pull to synchronize local data with the remote repository.\"\"\"\n",
    "    try:\n",
    "        # Run the `dvc pull` command\n",
    "        result = run(['dvc', 'pull', '-r', dvc_remote_name], cwd=github_cloned_dir, capture_output=True, text=True)\n",
    "\n",
    "        # Check if the command executed successfully\n",
    "        if result.returncode != 0:\n",
    "            # Log and raise an error if the command failed\n",
    "            error_message = f\"dvc pull failed with error: {result.stderr}\"\n",
    "            raise Exception(error_message)\n",
    "\n",
    "        # Log successful operation\n",
    "        return \"Successfully pulled data from remote DVC repository\"\n",
    "\n",
    "    except Exception as e:\n",
    "        # Log and handle the error\n",
    "        return f\"Error occurred during dvc pull: {e}\"\n",
    "\n",
    "# Call the functions\n",
    "clone_result = clone_repository_with_token(github_repo_url, github_cloned_dir, github_dvc_branch, github_username, github_token)\n",
    "configure_result = configure_dvc_remote(github_cloned_dir, dvc_remote_name, dvc_remote_db_url, minio_url, minio_access_key, minio_secret_key)\n",
    "dvc_pull_result = perform_dvc_pull(github_cloned_dir, dvc_remote_name)\n",
    "\n",
    "# Save dataset with pandas in Dataset artifact\n",
    "pulled_dataset_path = os.path.join(github_cloned_dir, dvc_file_dir, dvc_file_name)\n",
    "tmp_dataset_path = \"/tmp/\" + dvc_file_name\n",
    "dataset = pd.read_csv(pulled_dataset_path)\n",
    "dataset.to_pickle(tmp_dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d46215ee-6416-4bfd-b1b5-82359506d9df",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size 2693\n"
     ]
    }
   ],
   "source": [
    "print(\"Dataset size\", dataset.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a6c0f4-4da4-432f-8e4f-aaf49a90e939",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac5ebab9-6074-4cdc-b2df-5ffd12ae0e96",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_size = 0.2\n",
    "random_state = 42\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch\n",
    "import os\n",
    "\n",
    "# Load dataset from Dataset artifact\n",
    "df = pd.read_pickle(tmp_dataset_path)\n",
    "\n",
    "# Handle null values and replace specific characters\n",
    "#df = df.replace([' ', '-',np.nan], 0) # There are null values\n",
    "df = df.replace([' ', '-', np.nan], np.nan)\n",
    "\n",
    "# Selective columns for mean calculation\n",
    "columns_to_convert = [\n",
    "    'CQI1', 'CQI2', 'CQI3', 'cSTD CQI', 'cMajority', 'c25 P', 'c50 P', 'c75 P', \n",
    "    'RSRP1', 'RSRP2', 'RSRP3', 'pMajority', 'p25 P', 'p50 P', 'p75 P', \n",
    "    'RSRQ1', 'RSRQ2', 'RSRQ3', 'qMajority', 'q25 P', 'q50 P', 'q75 P', \n",
    "    'SNR1', 'SNR2', 'SNR3', 'sMajority', 's25 P', 's50 P', 's75 P'\n",
    "]\n",
    "df[columns_to_convert] = df[columns_to_convert].astype(float)\n",
    "\n",
    "# Replace np.nan with mean values for selective columns\n",
    "df[columns_to_convert] = df[columns_to_convert].fillna(df[columns_to_convert].mean())\n",
    "\n",
    "# Convert 'Stall' column to numerical values\n",
    "df['Stall'].replace({'Yes': 1, 'No': 0}, inplace=True)\n",
    "\n",
    "X = df[columns_to_convert].values\n",
    "y = df['Stall'].values\n",
    "\n",
    "# Apply SMOTE for balancing the dataset\n",
    "# oversample = SMOTE(random_state=random_state)\n",
    "oversample = SMOTE()\n",
    "X, y = oversample.fit_resample(X, y)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Convert to torch tensors\n",
    "X = torch.tensor(X, dtype=torch.float32)\n",
    "y = torch.tensor(y, dtype=torch.float32)\n",
    "\n",
    "# Split the dataset into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee319604",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Data Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bbcf5608-25a5-4fd6-b663-4e2552c17e85",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | Loss: 0.69019, Accuracy: 51.72% | Test Loss: 0.68449, Test Accuracy: 55.18%\n",
      "Epoch: 500 | Loss: 0.47132, Accuracy: 78.29% | Test Loss: 0.48062, Test Accuracy: 77.87%\n",
      "Epoch: 1000 | Loss: 0.36650, Accuracy: 84.04% | Test Loss: 0.42489, Test Accuracy: 81.99%\n",
      "Epoch: 1500 | Loss: 0.26057, Accuracy: 89.68% | Test Loss: 0.39684, Test Accuracy: 82.41%\n",
      "Epoch: 2000 | Loss: 0.17468, Accuracy: 94.36% | Test Loss: 0.40738, Test Accuracy: 84.96%\n",
      "Epoch: 2500 | Loss: 0.11994, Accuracy: 96.70% | Test Loss: 0.43905, Test Accuracy: 86.24%\n",
      "Epoch: 3000 | Loss: 0.08511, Accuracy: 97.91% | Test Loss: 0.48346, Test Accuracy: 86.38%\n",
      "<class 'numpy.float64'>\n",
      "Precision: 0.859740\n",
      "Recall: 0.856738\n",
      "Micro F1 score: 0.856738\n",
      "Macro F1 score: 0.856727\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    No-Stall       0.89      0.82      0.86       370\n",
      "       Stall       0.82      0.89      0.86       335\n",
      "\n",
      "    accuracy                           0.86       705\n",
      "   macro avg       0.86      0.86      0.86       705\n",
      "weighted avg       0.86      0.86      0.86       705\n",
      "\n",
      "Error occurred: S3 operation failed; code: NoSuchKey, message: The specified key does not exist., resource: /model-files/accuracy-score/last_acc.txt, request_id: 17F7F5C0EB978A81, host_id: 04364467-0bee-474e-8dba-2559e675bfee, bucket_name: model-files, object_name: accuracy-score/last_acc.txt\n",
      "0.8567375886524823\n",
      "0.0\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score, classification_report\n",
    "from minio import Minio\n",
    "\n",
    "model_lr = MODEL_LR\n",
    "model_epochs = MODEL_EPOCHS\n",
    "model_print_frequency_per_n_epochs = MODEL_PRINT_FREQUENCY_PER_N_EPOCHS\n",
    "bucket_name = MINIO_MODEL_BUCKET_NAME\n",
    "minio_model_object_name = MINIO_MODEL_OBJECT_NAME\n",
    "trigger_type = TRIGGER_TYPE\n",
    "performance_factor = PERFORMANCE_FACTOR\n",
    "last_accuracy_object_name = LAST_ACC_OBJECT_NAME\n",
    "tmp_dir = TEMP_DIR\n",
    "tmp_file_last_acc = TEMP_FILE_ACC_IN_LAST_RUN\n",
    "\n",
    "# Build model with non-linear activation function\n",
    "class InterruptionModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer_1 = nn.Linear(in_features=29, out_features=200)\n",
    "        self.layer_2 = nn.Linear(in_features=200, out_features=100)\n",
    "        self.layer_3 = nn.Linear(in_features=100, out_features=1)\n",
    "        self.relu = nn.ReLU() # <- add in ReLU activation function\n",
    "        # Can also put sigmoid in the model\n",
    "        # This would mean you don't need to use it on the predictions\n",
    "        # self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Intersperse the ReLU activation function between layers\n",
    "        return self.layer_3(self.relu(self.layer_2(self.relu(self.layer_1(x)))))\n",
    "\n",
    "# Helper functions\n",
    "def accuracy_fn(y_true, y_pred):\n",
    "    correct = torch.eq(y_true, y_pred).sum().item() # torch.eq() calculates where two tensors are equal\n",
    "    acc = (correct / len(y_pred)) * 100\n",
    "    return acc\n",
    "\n",
    "def minio_setup(minio_url, minio_access_key, minio_secret_key):\n",
    "    # Initialize Minio client with just the base URL (without path)\n",
    "    client = Minio(\n",
    "        minio_url,  # Ensure minio_url does not include a path, only the base URL (e.g., http://localhost:9000)\n",
    "        access_key=minio_access_key,\n",
    "        secret_key=minio_secret_key,\n",
    "        secure=False  # Minio is using HTTP on localhost:9000\n",
    "    )\n",
    "    return client\n",
    "\n",
    "def upload_file(client, bucket_name, object_name, filepath):\n",
    "    # Create the bucket if it does not exist\n",
    "    if not client.bucket_exists(bucket_name):\n",
    "        client.make_bucket(bucket_name)\n",
    "        create_bucket_result = f\"Successfully created bucket: {bucket_name}\"\n",
    "    else:\n",
    "        create_bucket_result = f\"Bucket {bucket_name} already exists\"\n",
    "\n",
    "    try:\n",
    "        # Upload the file to the specified path in the bucket\n",
    "        client.fput_object(bucket_name, object_name, filepath)\n",
    "        return (f'Successfully uploaded {filepath} to {bucket_name}/{object_name}')\n",
    "\n",
    "    except Exception as e:\n",
    "        # Log and raise any upload errors\n",
    "        raise Exception(f'Failed to upload model to Minio: {e}')\n",
    "\n",
    "def read_from_minio(client, bucket_name, object_name):\n",
    "    \"\"\"\n",
    "    Function to read a file from a MinIO bucket and convert its single content to a float.\n",
    "    If the file is not found or is empty, it returns 0.0.\n",
    "\n",
    "    Args:\n",
    "        client: minio client\n",
    "        bucket_name (str): The name of the bucket in MinIO.\n",
    "        object_name (str): The name of the object (file) in the bucket.\n",
    "\n",
    "    Returns:\n",
    "        float: The float value converted from the file content, or 0.0 if the file is not found or empty.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Get the file from the MinIO bucket\n",
    "        response = client.get_object(bucket_name, object_name)\n",
    "\n",
    "        # Read the file content into a buffer\n",
    "        file_data = response.read()\n",
    "\n",
    "        # Decode file content and strip whitespace\n",
    "        content = file_data.decode('utf-8').strip()\n",
    "\n",
    "        # If the content is empty, return 0.0\n",
    "        if not content:\n",
    "            print(f\"File {object_name} is empty.\")\n",
    "            return 0.0\n",
    "\n",
    "        # Convert the content to a float\n",
    "        float_value = float(content)\n",
    "        return float_value\n",
    "\n",
    "    except Exception as e:\n",
    "        # Handle file not found or any other errors\n",
    "        print(f\"Error occurred: {e}\")\n",
    "        return 0.0\n",
    "\n",
    "def save_float_to_tempfile(float_value, dir_name, file_name):\n",
    "    \"\"\"\n",
    "    Saves a float value to a specified directory and file name.\n",
    "\n",
    "    Args:\n",
    "        float_value (float): The float value to save.\n",
    "        dir_name (str): The name of the directory to save the file in.\n",
    "        file_name (str): The name of the file.\n",
    "\n",
    "    Returns:\n",
    "        str: The path to the file.\n",
    "    \"\"\"\n",
    "    # Ensure the directory exists\n",
    "    os.makedirs(dir_name, exist_ok=True)\n",
    "    temp_file_path = os.path.join(dir_name, file_name)\n",
    "\n",
    "    with open(temp_file_path, 'w') as temp_file:\n",
    "        # Convert the float to a string, then write to file\n",
    "        temp_file.write(str(float_value))\n",
    "\n",
    "    return temp_file_path\n",
    "\n",
    "def get_accuracy_in_last_run(client, bucket_name, object_name):\n",
    "    accuracy_in_last_run = read_from_minio(client, bucket_name, object_name)\n",
    "    return accuracy_in_last_run\n",
    "\n",
    "def update_accuracy_in_last_run(client, bucket_name, object_name, new_value, tmp_dir, tmp_file):\n",
    "    filepath = save_float_to_tempfile(new_value, tmp_dir, tmp_file)\n",
    "    upload_file(client, bucket_name, object_name, filepath)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = InterruptionModel().to(device)\n",
    "\n",
    "# Setup loss and optimizer\n",
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=model_lr)\n",
    "\n",
    "# Fit the model\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Put all data on target device\n",
    "# X_train = torch.load(X_train_artifact.path)\n",
    "# X_test = torch.load(X_test_artifact.path)\n",
    "# y_train = torch.load(y_train_artifact.path)\n",
    "# y_test = torch.load(y_test_artifact.path)\n",
    "X_train, y_train = X_train.to(device), y_train.to(device)\n",
    "X_test, y_test = X_test.to(device), y_test.to(device)\n",
    "\n",
    "for epoch in range(model_epochs):\n",
    "    # 1. Forward pass\n",
    "    y_logits = model(X_train).squeeze()\n",
    "\n",
    "    y_pred = torch.round(torch.sigmoid(y_logits)) # logits -> prediction probabilities -> prediction labels\n",
    "\n",
    "    # 2. Calculate loss and accuracy\n",
    "    loss = loss_fn(y_logits, y_train) # BCEWithLogitsLoss calculates loss using logits\n",
    "    acc = accuracy_fn(y_true=y_train,\n",
    "                    y_pred=y_pred)\n",
    "\n",
    "    # 3. Optimizer zero grad\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # 4. Loss backward\n",
    "    loss.backward()\n",
    "\n",
    "    # 5. Optimizer step\n",
    "    optimizer.step()\n",
    "\n",
    "    ### Testing\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "    # 1. Forward pass\n",
    "        test_logits = model(X_test).squeeze()\n",
    "        #print(test_logits.shape)\n",
    "        test_pred = torch.round(torch.sigmoid(test_logits)) # logits -> prediction probabilities -> prediction labels\n",
    "        # 2. Calcuate loss and accuracy\n",
    "        test_loss = loss_fn(test_logits, y_test)\n",
    "        test_acc = accuracy_fn(y_true=y_test,\n",
    "                            y_pred=test_pred)\n",
    "\n",
    "\n",
    "    # Print out what's happening\n",
    "    if epoch % model_print_frequency_per_n_epochs == 0:\n",
    "        print(f\"Epoch: {epoch} | Loss: {loss:.5f}, Accuracy: {acc:.2f}% | Test Loss: {test_loss:.5f}, Test Accuracy: {test_acc:.2f}%\")\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_preds = torch.round(torch.sigmoid(model(X_test))).squeeze()\n",
    "\n",
    "if device == \"cuda\":\n",
    "    predictions = y_preds.cpu().numpy() #if it is cuda, then this, otherwise y_pred.numpy()\n",
    "    true_labels = y_test.cpu().numpy()\n",
    "else:\n",
    "    predictions = y_preds.numpy()\n",
    "    true_labels = y_test.numpy()\n",
    "\n",
    "# Confusion Matrix\n",
    "cmatrix = confusion_matrix(true_labels, predictions)\n",
    "#print(\"Confusion Matrix:\", cmatrix)\n",
    "\n",
    "# Metrics\n",
    "accuracy = accuracy_score(true_labels, predictions)\n",
    "# metrics.log_metric(\"Accuracy\", accuracy)\n",
    "#print('Accuracy: %f' % accuracy)\n",
    "\n",
    "# test accuracy\n",
    "print(type(accuracy))\n",
    "\n",
    "precision = precision_score(true_labels,  predictions, average='weighted')\n",
    "# metrics.log_metric(\"Precision\", precision)\n",
    "print('Precision: %f' % precision)\n",
    "\n",
    "recall = recall_score(true_labels, predictions, average='weighted')\n",
    "# metrics.log_metric(\"Recall\", recall)\n",
    "print('Recall: %f' % recall)\n",
    "\n",
    "microf1 = f1_score(true_labels, predictions, average='micro')\n",
    "# metrics.log_metric(\"Micro F1 score\", microf1)\n",
    "print('Micro F1 score: %f' % microf1)\n",
    "\n",
    "macrof1 = f1_score(true_labels, predictions, average='macro')\n",
    "# metrics.log_metric(\"Macro F1 score\", macrof1)\n",
    "print('Macro F1 score: %f' % macrof1)\n",
    "\n",
    "target_names = ['No-Stall', 'Stall']\n",
    "# Print precision-recall report\n",
    "print(classification_report(true_labels, predictions, target_names=target_names))\n",
    "\n",
    "# Classification Metrics artifact\n",
    "cmatrix = cmatrix.tolist()\n",
    "target_names = ['No-Stall', 'Stall']\n",
    "# classification_metrics.log_confusion_matrix(target_names, cmatrix)\n",
    "\n",
    "# Save model\n",
    "# model_path = \"/tmp/model.pt\"\n",
    "# torch.save(model.state_dict(), model_path)\n",
    "# os.rename(model_path, model_trained_artifact.path)\n",
    "\n",
    "# Setup minio client to upload and read files\n",
    "client = minio_setup(minio_url, minio_access_key, minio_secret_key)\n",
    "\n",
    "previous_accuracy = get_accuracy_in_last_run(client, bucket_name, last_accuracy_object_name)\n",
    "\n",
    "#metrics.log_metric(\"current-previous accuracy\", accuracy-previous_accuracy)\n",
    "# metrics.log_metric(\"current accuracy\", accuracy)\n",
    "# metrics.log_metric(\"previous accuracy\", previous_accuracy)\n",
    "print(accuracy)\n",
    "print(previous_accuracy)\n",
    "\n",
    "if trigger_type == '1' or trigger_type == '2':\n",
    "    up_model = True\n",
    "elif trigger_type == '3':\n",
    "    if accuracy - previous_accuracy > performance_factor:\n",
    "        up_model = True\n",
    "        # update_accuracy_in_last_run(client, bucket_name, last_accuracy_object_name, accuracy, tmp_dir, tmp_file_last_acc)\n",
    "else:\n",
    "    up_model = False\n",
    "    print('0')\n",
    "    # metrics.log_metric(\"up model\", '0')\n",
    "    # with open(up_model_cond.path, 'w') as f:\n",
    "        # f.write('0')\n",
    "\n",
    "if up_model:\n",
    "    print('1')\n",
    "    # metrics.log_metric(\"up model\", '1')\n",
    "    # with open(up_model_cond.path, 'w') as f:\n",
    "        # f.write('1')\n",
    "    # upload_model_result = upload_file(client, bucket_name, minio_model_object_name, model_trained_artifact.path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ea7145-99c8-4234-b80d-cfa1c20961f8",
   "metadata": {},
   "source": [
    "# Compile Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ba3585-0b4f-4e8d-9b1c-6d8872d59b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @pipeline\n",
    "# def my_pipeline(\n",
    "#     github_repo_url: str,\n",
    "#     github_cloned_dir: str,\n",
    "#     github_dvc_branch: str,\n",
    "#     github_username: str,\n",
    "#     github_token: str,\n",
    "#     dvc_remote_name: str,\n",
    "#     dvc_remote_db_url: str,\n",
    "#     minio_url: str,\n",
    "#     minio_access_key: str,\n",
    "#     minio_secret_key: str,\n",
    "#     dvc_file_dir: str,\n",
    "#     dvc_file_name: str,\n",
    "#     model_name: str,\n",
    "#     kserve_namespae: str,\n",
    "#     model_lr: float,\n",
    "#     model_epochs: int,\n",
    "#     model_print_frequency_per_n_epochs: int,\n",
    "#     bucket_name: str,\n",
    "#     minio_model_object_name: str,\n",
    "#     kserve_svc_acc: str,\n",
    "#     trigger_type: str,\n",
    "#     performance_factor: float,\n",
    "#     last_accuracy_object_name: str,\n",
    "#     tmp_dir: str,\n",
    "#     tmp_file_last_acc: str\n",
    "# ):\n",
    "#     data_ingestion_task = data_ingestion(\n",
    "#         github_repo_url=github_repo_url,\n",
    "#         github_cloned_dir=github_cloned_dir,\n",
    "#         github_dvc_branch=github_dvc_branch,\n",
    "#         github_username=github_username,\n",
    "#         github_token=github_token,\n",
    "#         dvc_remote_name=dvc_remote_name,\n",
    "#         dvc_remote_db_url=dvc_remote_db_url,\n",
    "#         minio_url=minio_url,\n",
    "#         minio_access_key=minio_access_key,\n",
    "#         minio_secret_key=minio_secret_key,\n",
    "#         dvc_file_dir=dvc_file_dir,\n",
    "#         dvc_file_name=dvc_file_name)\n",
    "#     dataset_artifact = data_ingestion_task.outputs[\"dataset_artifact\"]\n",
    "#     data_preparation_task = data_preparation(dataset_artifact=dataset_artifact)\n",
    "#     X_train_artifact = data_preparation_task.outputs[\"X_train_artifact\"]\n",
    "#     X_test_artifact = data_preparation_task.outputs[\"X_test_artifact\"]\n",
    "#     y_train_artifact = data_preparation_task.outputs[\"y_train_artifact\"]\n",
    "#     y_test_artifact = data_preparation_task.outputs[\"y_test_artifact\"]\n",
    "#     model_training_task = model_training(X_train_artifact=X_train_artifact, \n",
    "#                                          X_test_artifact=X_test_artifact, \n",
    "#                                          y_train_artifact=y_train_artifact, \n",
    "#                                          y_test_artifact=y_test_artifact,\n",
    "#                                          model_lr=model_lr,\n",
    "#                                          model_epochs=model_epochs,\n",
    "#                                          model_print_frequency_per_n_epochs=model_print_frequency_per_n_epochs,\n",
    "#                                          minio_url=minio_url,\n",
    "#                                          minio_access_key=minio_access_key,\n",
    "#                                          minio_secret_key=minio_secret_key,\n",
    "#                                          bucket_name=bucket_name,\n",
    "#                                          minio_model_object_name=minio_model_object_name,\n",
    "#                                          trigger_type=trigger_type,\n",
    "#                                          performance_factor=performance_factor,\n",
    "#                                          last_accuracy_object_name=last_accuracy_object_name,\n",
    "#                                          tmp_dir=tmp_dir,\n",
    "#                                          tmp_file_last_acc=tmp_file_last_acc)\n",
    "#     up_model_cond = model_training_task.outputs[\"up_model_cond\"]\n",
    "#     model_serving_task = model_serving(up_model_cond=up_model_cond,\n",
    "#                                        bucket_name=bucket_name,\n",
    "#                                        model_name=model_name, \n",
    "#                                        kserve_namespae=kserve_namespae,\n",
    "#                                        kserve_svc_acc=kserve_svc_acc)\n",
    "\n",
    "# # Compile the pipeline\n",
    "# pipeline_filename = f\"{KUBEFLOW_PIPELINE_NAME}.yaml\"\n",
    "# kfp.compiler.Compiler().compile(\n",
    "#     pipeline_func=my_pipeline,\n",
    "#     package_path=pipeline_filename)\n",
    "\n",
    "# # Submit the pipeline to the KFP cluster\n",
    "# client = kfp.Client(\n",
    "#     host=KUBEFLOW_HOST_URL,\n",
    "#     existing_token=KUBEFLOW_TOKEN)  \n",
    "\n",
    "# client.create_run_from_pipeline_func(\n",
    "#     my_pipeline,\n",
    "#     enable_caching=False,\n",
    "#     arguments={\n",
    "#         'github_repo_url': GITHUB_REPO_URL,\n",
    "#         'github_cloned_dir': GITHUB_CLONED_DIR,\n",
    "#         'github_dvc_branch': GITHUB_DVC_BRANCH,\n",
    "#         'github_username': GITHUB_USERNAME,\n",
    "#         'github_token': GITHUB_TOKEN,\n",
    "#         'dvc_remote_name': DVC_REMOTE_DB,\n",
    "#         'dvc_remote_db_url': DVC_REMOTE_DB_URL,\n",
    "#         'minio_url': MINIO_URL,\n",
    "#         'minio_access_key': MINIO_ACCESS_KEY,\n",
    "#         'minio_secret_key': MINIO_SECRET_KEY,\n",
    "#         'dvc_file_dir': DVC_FILE_DIR,\n",
    "#         'dvc_file_name': DVC_FILE_NAME,\n",
    "#         'model_name': MODEL_NAME,\n",
    "#         'kserve_namespae': KSERVE_NAMESPACE,\n",
    "#         'model_lr': MODEL_LR,\n",
    "#         'model_epochs': MODEL_EPOCHS,\n",
    "#         'model_print_frequency_per_n_epochs': MODEL_PRINT_FREQUENCY_PER_N_EPOCHS,\n",
    "#         'bucket_name': MINIO_MODEL_BUCKET_NAME,\n",
    "#         'minio_model_object_name': MINIO_MODEL_OBJECT_NAME,\n",
    "#         'kserve_svc_acc': KSERVE_SVC_ACC,\n",
    "#         'trigger_type': TRIGGER_TYPE,\n",
    "#         'performance_factor': PERFORMANCE_FACTOR,\n",
    "#         'last_accuracy_object_name': LAST_ACC_OBJECT_NAME,\n",
    "#         'tmp_dir': TEMP_DIR,\n",
    "#         'tmp_file_last_acc': TEMP_FILE_ACC_IN_LAST_RUN\n",
    "#     })\n",
    "\n",
    "# #upload to Kubeflow \n",
    "# client.upload_pipeline(pipeline_package_path=pipeline_filename,\n",
    "#                        pipeline_name=KUBEFLOW_PIPELINE_NAME,\n",
    "#                        namespace = KSERVE_NAMESPACE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "toc-autonumbering": true,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

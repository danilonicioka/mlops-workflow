{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install -r requirements-components-test.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "4kQGfDn2_KVc"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "Ke6FQ2ew35ix",
    "outputId": "315dff67-1161-4d51-e023-23901df285a7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.24.3'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "t1pgBT1Y_Nz8"
   },
   "outputs": [],
   "source": [
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "W--LAXED_Pd5",
    "outputId": "a8354054-8150-4922-b6ff-d5201ecd9f67"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.3.0+cu121'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "CDbxWNPh_RfR"
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "l-UFhEi_3TDi",
    "outputId": "367219b1-6271-47ad-e1f1-16e6bb1713be"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.3'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "g7LyEYDtClsr",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Successfully downloaded file from https://raw.githubusercontent.com/razaulmustafa852/youtubegoes5g/main/Models/Stall-Windows%20-%20Stall-3s.csv to init_dataset.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "import logging\n",
    "# Setup logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Configuration variables\n",
    "config = {\n",
    "    \"REPO_URL\": os.environ.get('REPO_URL', 'https://github.com/danilonicioka/mlops-workflow.git'),\n",
    "    \"CLONED_DIR\": os.environ.get('CLONED_DIR', 'mlops-workflow'),\n",
    "    \"FILE_URL\": os.environ.get('FILE_URL', 'https://raw.githubusercontent.com/razaulmustafa852/youtubegoes5g/main/Models/Stall-Windows%20-%20Stall-3s.csv'),\n",
    "    \"DVC_FILE_DIR\": os.environ.get('DVC_FILE_DIR', 'data/external'),\n",
    "    \"DVC_FILE_NAME\": os.environ.get('DVC_FILE_NAME', 'init_dataset.csv'),\n",
    "    \"BRANCH_NAME\": os.environ.get('BRANCH_NAME', 'tests'),\n",
    "    \"BUCKET_NAME\": os.environ.get('BUCKET_NAME', 'dvc-data'),\n",
    "    \"MINIO_URL\": os.environ.get('MINIO_URL', 'localhost:9000'),\n",
    "    \"ACCESS_KEY\": os.environ.get('ACCESS_KEY'),\n",
    "    \"SECRET_KEY\": os.environ.get('SECRET_KEY'),\n",
    "    \"REMOTE_NAME\": os.environ.get('REMOTE_NAME', 'minio_remote'),\n",
    "    \"GITHUB_USERNAME\": os.environ.get('GITHUB_USERNAME'),\n",
    "    \"GITHUB_TOKEN\": os.environ.get('GITHUB_TOKEN')\n",
    "}\n",
    "\n",
    "file_url = config[\"FILE_URL\"]\n",
    "local_file_path = config[\"DVC_FILE_NAME\"]\n",
    "\n",
    "try:\n",
    "    # Request the file content\n",
    "    response = requests.get(file_url)\n",
    "    response.raise_for_status()\n",
    "\n",
    "    # Save the file content locally\n",
    "    with open(local_file_path, 'wb') as local_file:\n",
    "        local_file.write(response.content)\n",
    "    logger.info(f\"Successfully downloaded file from {file_url} to {local_file_path}\")\n",
    "except requests.RequestException as e:\n",
    "    # Log and raise any download errors\n",
    "    logger.error(f\"Failed to download file: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "Eu-ccO37l04V"
   },
   "outputs": [],
   "source": [
    "#colab_path = os.path.join('/content', local_file_path)\n",
    "df = pd.read_csv(local_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JeNMPwS4BvrG",
    "outputId": "e3e4f8ef-4084-4406-c008-d0e20b01c344"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ID', 'Stall', 'Quality', 'Time', 'CQI1', 'CQI2', 'CQI3', 'cSTD CQI',\n",
       "       'cMajority', 'c25 P', 'c50 P', 'c75 P', 'RSRP1', 'RSRP2', 'RSRP3',\n",
       "       'pMajority', 'p25 P', 'p50 P', 'p75 P', 'RSRQ1', 'RSRQ2', 'RSRQ3',\n",
       "       'qMajority', 'q25 P', 'q50 P', 'q75 P', 'SNR1', 'SNR2', 'SNR3',\n",
       "       'sMajority', 's25 P', 's50 P', 's75 P'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "92TIYC4GcELK"
   },
   "outputs": [],
   "source": [
    "df = df.replace([' ', '-',np.nan], 0) # There are null values\n",
    "#df = df.replace([' ', '-',np.nan], np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z-A7wn3iex59",
    "outputId": "bc1005fe-da7d-4903-f601-588f7db1d379"
   },
   "outputs": [],
   "source": [
    "# Selective columns for mean calculation\n",
    "columns_to_convert = ['CQI1', 'CQI2', 'CQI3', 'cSTD CQI',\n",
    "       'cMajority', 'c25 P', 'c50 P', 'c75 P', 'RSRP1', 'RSRP2', 'RSRP3',\n",
    "       'pMajority', 'p25 P', 'p50 P', 'p75 P', 'RSRQ1', 'RSRQ2', 'RSRQ3',\n",
    "       'qMajority', 'q25 P', 'q50 P', 'q75 P', 'SNR1', 'SNR2', 'SNR3',\n",
    "       'sMajority', 's25 P', 's50 P', 's75 P']\n",
    "df[columns_to_convert] = df[columns_to_convert].astype(float)\n",
    "\n",
    "# Replace np.nan with mean values for selective columns\n",
    "df[columns_to_convert] = df[columns_to_convert].fillna(df[columns_to_convert].mean())\n",
    "\n",
    "# Display the modified DataFrame\n",
    "#print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iwMle4VXvOar",
    "outputId": "f15235be-9474-4a9d-ce6e-8930553102dd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID           False\n",
      "Stall        False\n",
      "Quality      False\n",
      "Time         False\n",
      "CQI1         False\n",
      "CQI2         False\n",
      "CQI3         False\n",
      "cSTD CQI     False\n",
      "cMajority    False\n",
      "c25 P        False\n",
      "c50 P        False\n",
      "c75 P        False\n",
      "RSRP1        False\n",
      "RSRP2        False\n",
      "RSRP3        False\n",
      "pMajority    False\n",
      "p25 P        False\n",
      "p50 P        False\n",
      "p75 P        False\n",
      "RSRQ1        False\n",
      "RSRQ2        False\n",
      "RSRQ3        False\n",
      "qMajority    False\n",
      "q25 P        False\n",
      "q50 P        False\n",
      "q75 P        False\n",
      "SNR1         False\n",
      "SNR2         False\n",
      "SNR3         False\n",
      "sMajority    False\n",
      "s25 P        False\n",
      "s50 P        False\n",
      "s75 P        False\n",
      "dtype: bool\n"
     ]
    }
   ],
   "source": [
    "# Check which columns contain np.nan values\n",
    "columns_with_nan = df.isna().any()\n",
    "# Display the columns with np.nan values\n",
    "print(columns_with_nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "jsFpaDR4c0GH"
   },
   "outputs": [],
   "source": [
    "df['Stall'].replace('Yes', 1, inplace=True)\n",
    "df['Stall'].replace('No', 0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DmoiwXGtEuoM",
    "outputId": "02a876de-5a96-4636-ff0a-6bba4db6d3d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          ID  Stall   Quality      Time  CQI1  CQI2  CQI3  cSTD CQI  \\\n",
      "0      4P7s2      0    hd2160  16:14:29  13.0  13.0  13.0  0.000000   \n",
      "1      4P7s2      0    hd2160  16:14:30  13.0  13.0  13.0  0.000000   \n",
      "2      4P7s2      0    hd2160  16:14:31  13.0  13.0  13.0  0.000000   \n",
      "3      4P7s2      0    hd2160  16:14:32  13.0  13.0  12.0  0.471405   \n",
      "4      4P7s2      0    hd2160  16:14:33  12.0  14.0  12.0  0.942809   \n",
      "...      ...    ...       ...       ...   ...   ...   ...       ...   \n",
      "2688  5Po26s      1  unknown,  17:43:18  14.0  14.0  14.0  0.000000   \n",
      "2689  4Po26s      1  unknown,  17:43:23   0.0   0.0   0.0  0.000000   \n",
      "2690  4Po26s      1   hd1440,  17:43:33   0.0   0.0   0.0  0.000000   \n",
      "2691   4I27s      1  unknown,  10:52:04   9.0   9.0   9.0  0.000000   \n",
      "2692   4I27s      1   hd1440,  10:52:16   9.0   9.0   9.0  0.000000   \n",
      "\n",
      "      cMajority  c25 P  ...  q25 P  q50 P  q75 P  SNR1  SNR2  SNR3  sMajority  \\\n",
      "0          13.0   13.0  ...   -9.5   -7.0   -7.0  12.0  12.0   7.0       12.0   \n",
      "1          13.0   13.0  ...   -9.5   -7.0   -7.0  12.0  12.0   7.0       12.0   \n",
      "2          13.0   13.0  ...  -12.0  -12.0   -9.5  12.0   7.0   7.0        7.0   \n",
      "3          13.0   12.5  ...  -12.0  -12.0  -11.5   7.0   7.0   2.0        7.0   \n",
      "4          12.0   12.0  ...  -11.0  -11.0   -9.0   2.0   2.0   9.0        2.0   \n",
      "...         ...    ...  ...    ...    ...    ...   ...   ...   ...        ...   \n",
      "2688       14.0   14.0  ...   -3.0   -3.0   -3.0   6.0   6.0   6.0        6.0   \n",
      "2689        0.0    0.0  ...    0.0    0.0    0.0   0.0   0.0   0.0        0.0   \n",
      "2690        0.0    0.0  ...    0.0    0.0    0.0   0.0   0.0   0.0        0.0   \n",
      "2691        9.0    9.0  ...  -12.0  -12.0  -11.5   7.0   7.0  10.0        7.0   \n",
      "2692        9.0    9.0  ...  -12.0  -12.0  -12.0   8.0   9.0   9.0        9.0   \n",
      "\n",
      "      s25 P  s50 P  s75 P  \n",
      "0       9.5   12.0   12.0  \n",
      "1       9.5   12.0   12.0  \n",
      "2       7.0    7.0    9.5  \n",
      "3       4.5    7.0    7.0  \n",
      "4       2.0    2.0    5.5  \n",
      "...     ...    ...    ...  \n",
      "2688    6.0    6.0    6.0  \n",
      "2689    0.0    0.0    0.0  \n",
      "2690    0.0    0.0    0.0  \n",
      "2691    7.0    7.0    8.5  \n",
      "2692    8.5    9.0    9.0  \n",
      "\n",
      "[2693 rows x 33 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JMZvSleecToT",
    "outputId": "1ffa6aca-15ad-47b1-c81e-d2d1130671b7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ID', 'Stall', 'Quality', 'Time', 'CQI1', 'CQI2', 'CQI3', 'cSTD CQI',\n",
       "       'cMajority', 'c25 P', 'c50 P', 'c75 P', 'RSRP1', 'RSRP2', 'RSRP3',\n",
       "       'pMajority', 'p25 P', 'p50 P', 'p75 P', 'RSRQ1', 'RSRQ2', 'RSRQ3',\n",
       "       'qMajority', 'q25 P', 'q50 P', 'q75 P', 'SNR1', 'SNR2', 'SNR3',\n",
       "       'sMajority', 's25 P', 's50 P', 's75 P'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "id": "KqZiOAnEcFNy"
   },
   "outputs": [],
   "source": [
    "X = df[['CQI1', 'CQI2', 'CQI3', 'cSTD CQI',\n",
    "       'cMajority', 'c25 P', 'c50 P', 'c75 P', 'RSRP1', 'RSRP2', 'RSRP3',\n",
    "       'pMajority', 'p25 P', 'p50 P', 'p75 P', 'RSRQ1', 'RSRQ2', 'RSRQ3',\n",
    "       'qMajority', 'q25 P', 'q50 P', 'q75 P', 'SNR1', 'SNR2', 'SNR3',\n",
    "       'sMajority', 's25 P', 's50 P', 's75 P']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "id": "0Uz-Lf3ycYcM"
   },
   "outputs": [],
   "source": [
    "y = df['Stall'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NPGxzwbi1dSF",
    "outputId": "42b701ec-e5ce-4074-a213-3f1b84a1f9b6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2693, 29), (2693,))"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "id": "Fbj2trSTd_61"
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "id": "iCFjyyRnc4e-"
   },
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "Nk_tQrGR4DYU",
    "outputId": "1af102da-f096-4482-a431-58dafc101322"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.2.2'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "id": "89vPLfwEM_PP"
   },
   "outputs": [],
   "source": [
    "import imblearn\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "5xTKs75t4NtI",
    "outputId": "3360078e-e744-4381-96f0-004216e61245"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.11.0'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imblearn.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "id": "Uukc_gID4R2E"
   },
   "outputs": [],
   "source": [
    "oversample = SMOTE()\n",
    "X, y = oversample.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 13. ,  13. ,  13. ,   0. ,  13. ,  13. ,  13. ,  13. , -76. ,\n",
       "       -76. , -81. , -76. , -78.5, -76. , -76. ,  -7. ,  -7. , -12. ,\n",
       "        -7. ,  -9.5,  -7. ,  -7. ,  12. ,  12. ,   7. ,  12. ,   9.5,\n",
       "        12. ,  12. ])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bvaCa6r3BvrK",
    "outputId": "af374082-6ebf-4c99-e7ae-0d7dd0cc6f7d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3524, 29)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import joblib\n",
    "\n",
    "scaler = StandardScaler()\n",
    "fit_scaler = scaler.fit(X)\n",
    "joblib.dump(fit_scaler, 'scaler.save')\n",
    "X = fit_scaler.transform(X)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "id": "gkOL3bMlNdOP"
   },
   "outputs": [],
   "source": [
    "X = torch.from_numpy(X).type(torch.float32)\n",
    "y = torch.from_numpy(y).type(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pxNRza7idOxY",
    "outputId": "14177788-6c9c-49f9-d372-ded4ea053a5d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3524, 29])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RlTO_K6NBvrL",
    "outputId": "63f3caca-e374-43e8-a2d8-26c3ece7dbc3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.2869,  1.2773,  1.2949, -0.8119,  1.2809,  1.5356,  1.3002,  1.1853,\n",
       "         1.3699,  1.3685,  1.0438,  1.3697,  1.2404,  1.3689,  1.3431,  0.5627,\n",
       "         0.5623, -0.5295,  0.5599,  0.0665,  0.5606,  0.5251,  0.4544,  0.4446,\n",
       "        -0.1923,  0.4467,  0.1804,  0.4452,  0.4011])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rCvEQdyuliPn",
    "outputId": "da4545c0-0145-4d3c-9d68-5e4989df62a1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3524])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a8gv73lHloJ_",
    "outputId": "349b7ad9-de75-4174-e723-386e4f97c887"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: tensor([[ 0.3118,  1.2773, -0.3338,  1.4247,  0.3141,  0.1325,  0.3219,  0.6873,\n",
      "          0.7814,  0.7799,  0.7831,  0.7811,  0.8137,  0.7802,  0.7539,  0.3437,\n",
      "          0.3440, -0.0923,  0.3417,  0.1749,  0.3423,  0.3006,  1.0899,  1.0798,\n",
      "          0.9498,  1.0833,  1.0753,  1.0811,  1.0443]]) \n",
      "X_train_shape: torch.Size([1, 29]) \n",
      "X_test: tensor([[ 1.9369,  1.5987,  1.6206, -0.2988,  1.6032,  1.8864,  1.6263,  1.6832,\n",
      "          1.3046,  1.4338,  1.3046,  1.3043,  1.3389,  1.3035,  1.3431,  1.4389,\n",
      "          1.4352,  1.4379,  1.4324,  1.4750,  1.4336,  1.4233,  1.7255,  1.7150,\n",
      "          1.7112,  1.7198,  1.7785,  1.7170,  1.6875]]) \n",
      "X_test_shape: torch.Size([1, 29]) \n",
      "y_train: tensor([0.]) \n",
      "y_test: tensor([0.])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=42\n",
    ")\n",
    "\n",
    "print(\"X_train:\", X_train[:1],\"\\nX_train_shape:\", X_train[:1].shape,\"\\nX_test:\", X_test[:1],\"\\nX_test_shape:\",X_test[:1].shape, \"\\ny_train:\", y_train[:1],\"\\ny_test:\", y_test[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QDTLbnHC4LSo",
    "outputId": "9b37bbd8-08f4-4d51-e3cd-adb882b91cfa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: tensor([[ 0.3118,  1.2773, -0.3338,  1.4247,  0.3141,  0.1325,  0.3219,  0.6873,\n",
      "          0.7814,  0.7799,  0.7831,  0.7811,  0.8137,  0.7802,  0.7539,  0.3437,\n",
      "          0.3440, -0.0923,  0.3417,  0.1749,  0.3423,  0.3006,  1.0899,  1.0798,\n",
      "          0.9498,  1.0833,  1.0753,  1.0811,  1.0443]])\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train:\", X_train[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "id": "zi5yZmFQGWjH"
   },
   "outputs": [],
   "source": [
    "torch.save(X_train, \"/tmp/X_train.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D8YilSYm4HMk",
    "outputId": "de0e51aa-2da6-4322-d634-f2da9eb33d5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: tensor([[ 0.3118,  1.2773, -0.3338,  1.4247,  0.3141,  0.1325,  0.3219,  0.6873,\n",
      "          0.7814,  0.7799,  0.7831,  0.7811,  0.8137,  0.7802,  0.7539,  0.3437,\n",
      "          0.3440, -0.0923,  0.3417,  0.1749,  0.3423,  0.3006,  1.0899,  1.0798,\n",
      "          0.9498,  1.0833,  1.0753,  1.0811,  1.0443]])\n"
     ]
    }
   ],
   "source": [
    "X_train_loaded = torch.load(\"/tmp/X_train.pt\")\n",
    "print(\"X_train:\", X_train_loaded[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WZfSubyMpcAH",
    "outputId": "04ce14c4-e30c-433e-f447-c74c3a2da7df"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "-RX--XqwmgWm",
    "outputId": "6769a4d0-e488-4542-cae9-3dbd4751fc66"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a4mOVimKl1Te",
    "outputId": "946a66ec-717d-4e37-9803-5f943de157f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "InteruptionModel(\n",
      "  (layer_1): Linear(in_features=29, out_features=200, bias=True)\n",
      "  (layer_2): Linear(in_features=200, out_features=100, bias=True)\n",
      "  (layer_3): Linear(in_features=100, out_features=1, bias=True)\n",
      "  (relu): ReLU()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Build model with non-linear activation function\n",
    "from torch import nn\n",
    "class InteruptionModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer_1 = nn.Linear(in_features=29, out_features=200)\n",
    "        self.layer_2 = nn.Linear(in_features=200, out_features=100)\n",
    "        self.layer_3 = nn.Linear(in_features=100, out_features=1)\n",
    "        self.relu = nn.ReLU() # <- add in ReLU activation function\n",
    "        # Can also put sigmoid in the model\n",
    "        # This would mean you don't need to use it on the predictions\n",
    "        # self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "      # Intersperse the ReLU activation function between layers\n",
    "       return self.layer_3(self.relu(self.layer_2(self.relu(self.layer_1(x)))))\n",
    "\n",
    "model_3 = InteruptionModel().to(device)\n",
    "print(model_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4LdQs1yMHyTC",
    "outputId": "d0b4c727-4d2e-40ed-aaeb-43e703ca2656"
   },
   "outputs": [],
   "source": [
    "#model_3.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "id": "Klsrww6wmhnp"
   },
   "outputs": [],
   "source": [
    "# Setup loss and optimizer\n",
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model_3.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "id": "LQsS4A83m2_j"
   },
   "outputs": [],
   "source": [
    "def accuracy_fn(y_true, y_pred):\n",
    "    correct = torch.eq(y_true, y_pred).sum().item() # torch.eq() calculates where two tensors are equal\n",
    "    acc = (correct / len(y_pred)) * 100\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XmgM-bVvmpqO",
    "outputId": "5d9adfdd-de8e-4533-d543-634a95d21a61"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | Loss: 0.69271, Accuracy: 50.69% | Test Loss: 0.68669, Test Accuracy: 55.04%\n",
      "Epoch: 500 | Loss: 0.47577, Accuracy: 76.98% | Test Loss: 0.49363, Test Accuracy: 75.46%\n",
      "Epoch: 1000 | Loss: 0.36996, Accuracy: 83.54% | Test Loss: 0.43959, Test Accuracy: 80.28%\n",
      "Epoch: 1500 | Loss: 0.26551, Accuracy: 89.68% | Test Loss: 0.41142, Test Accuracy: 83.26%\n",
      "Epoch: 2000 | Loss: 0.17830, Accuracy: 94.40% | Test Loss: 0.40736, Test Accuracy: 85.39%\n",
      "Epoch: 2500 | Loss: 0.12169, Accuracy: 96.59% | Test Loss: 0.43225, Test Accuracy: 86.24%\n",
      "Epoch: 3000 | Loss: 0.08707, Accuracy: 97.69% | Test Loss: 0.46989, Test Accuracy: 85.96%\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "torch.manual_seed(42)\n",
    "epochs = 3500\n",
    "\n",
    "# Put all data on target device\n",
    "X_train, y_train = X_train.to(device), y_train.to(device)\n",
    "X_test, y_test = X_test.to(device), y_test.to(device)\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # 1. Forward pass\n",
    "    y_logits = model_3(X_train).squeeze()\n",
    "\n",
    "    y_pred = torch.round(torch.sigmoid(y_logits)) # logits -> prediction probabilities -> prediction labels\n",
    "\n",
    "    # 2. Calculate loss and accuracy\n",
    "    loss = loss_fn(y_logits, y_train) # BCEWithLogitsLoss calculates loss using logits\n",
    "    acc = accuracy_fn(y_true=y_train,\n",
    "                      y_pred=y_pred)\n",
    "\n",
    "    # 3. Optimizer zero grad\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # 4. Loss backward\n",
    "    loss.backward()\n",
    "\n",
    "    # 5. Optimizer step\n",
    "    optimizer.step()\n",
    "\n",
    "    ### Testing\n",
    "    model_3.eval()\n",
    "    with torch.no_grad():\n",
    "      # 1. Forward pass\n",
    "        test_logits = model_3(X_test).squeeze()\n",
    "        #print(test_logits.shape)\n",
    "        test_pred = torch.round(torch.sigmoid(test_logits)) # logits -> prediction probabilities -> prediction labels\n",
    "        # 2. Calcuate loss and accuracy\n",
    "        test_loss = loss_fn(test_logits, y_test)\n",
    "        test_acc = accuracy_fn(y_true=y_test,\n",
    "                             y_pred=test_pred)\n",
    "\n",
    "\n",
    "    # Print out what's happening\n",
    "    if epoch % 500 == 0:\n",
    "        print(f\"Epoch: {epoch} | Loss: {loss:.5f}, Accuracy: {acc:.2f}% | Test Loss: {test_loss:.5f}, Test Accuracy: {test_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "id": "f0ajvarorOFf"
   },
   "outputs": [],
   "source": [
    "model_3.eval()\n",
    "with torch.no_grad():\n",
    "     y_preds = torch.round(torch.sigmoid(model_3(X_test))).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eoflm9NgrrrZ",
    "outputId": "b1b7c1fe-7358-4c1a-8a60-4a6d0cee6c5f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([705]), torch.Size([705]))"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_preds.shape,y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "id": "COMEFsAjrs7g"
   },
   "outputs": [],
   "source": [
    "if device == \"cuda\":\n",
    "  predictions = y_preds.cpu().numpy() #if it is cuda, then this, otherwise y_pred.numpy()\n",
    "  true_labels = y_test.cpu().numpy()\n",
    "else:\n",
    "  predictions = y_preds.numpy()\n",
    "  true_labels = y_test.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fxDeucCxs6U8",
    "outputId": "5d94445d-cb33-4cdb-fd47-8824d5d25dba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Confusion Matrix ===\n",
      "[[318  52]\n",
      " [ 43 292]]\n",
      "\n",
      "\n",
      "=== Score ===\n",
      "Accuracy: 0.865248\n",
      "Precision: 0.865657\n",
      "Recall: 0.865248\n",
      "Micro F1 score: 0.865248\n",
      "Macro F1 score: 0.865065\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score,fbeta_score\n",
    "\n",
    "print(\"=== Confusion Matrix ===\")\n",
    "print(confusion_matrix(true_labels, predictions))\n",
    "print('\\n')\n",
    "\n",
    "\n",
    "print(\"=== Score ===\")\n",
    "accuracy = accuracy_score(true_labels, predictions)\n",
    "print('Accuracy: %f' % accuracy)\n",
    "\n",
    "precision = precision_score(true_labels,  predictions, average='weighted')\n",
    "print('Precision: %f' % precision)\n",
    "recall = recall_score(true_labels, predictions, average='weighted')\n",
    "print('Recall: %f' % recall)\n",
    "\n",
    "microf1 = f1_score(true_labels, predictions, average='micro')\n",
    "print('Micro F1 score: %f' % microf1)\n",
    "macrof1 = f1_score(true_labels, predictions, average='macro')\n",
    "print('Macro F1 score: %f' % macrof1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ACAmFpC-tJ0o",
    "outputId": "a15d74c6-aa9f-4fb4-cfb8-2e777781a127"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    No-Stall       0.88      0.86      0.87       370\n",
      "       Stall       0.85      0.87      0.86       335\n",
      "\n",
      "    accuracy                           0.87       705\n",
      "   macro avg       0.86      0.87      0.87       705\n",
      "weighted avg       0.87      0.87      0.87       705\n",
      "\n"
     ]
    }
   ],
   "source": [
    "target_names = ['No-Stall', 'Stall']\n",
    "# Print precision-recall report\n",
    "print(classification_report(true_labels, predictions, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "id": "XNsSYjD2tSlO"
   },
   "outputs": [],
   "source": [
    "#Done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "from torch import nn\n",
    "import joblib\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def preprocess(data):\n",
    "    \"\"\"\n",
    "    Transform raw input into model input data.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Log the incoming data for debugging\n",
    "        logger.info(f\"Received data: {data}\")\n",
    "\n",
    "        # Load scaler\n",
    "        scaler = StandardScaler()\n",
    "        scaler = joblib.load('scaler.save')\n",
    "\n",
    "        tensor_list = []\n",
    "        for item in data:\n",
    "            item = scaler.transform([item['data']])\n",
    "            tensor_data = torch.tensor(item, dtype=torch.float32)  # Each instance as a tensor\n",
    "            tensor_list.append(tensor_data)\n",
    "        # Stack all tensors along a new dimension to create a single tensor\n",
    "        combined_tensor = torch.cat(tensor_list, dim=0)\n",
    "        logger.info(\"Input data preprocessed successfully\")\n",
    "        return combined_tensor\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error during preprocessing: {str(e)}\")\n",
    "        raise ValueError(\"Failed to preprocess input data\")\n",
    "\n",
    "def inference(model_input):\n",
    "    \"\"\"\n",
    "    Perform model inference.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        inference_list = []\n",
    "        for tensor_data in model_input:\n",
    "            with torch.no_grad():\n",
    "                output = torch.round(torch.sigmoid(model_3(tensor_data))).squeeze()\n",
    "            inference = output.cpu().numpy().tolist()\n",
    "            inference_list.append(output)\n",
    "        logger.info(\"Inference performed successfully\")\n",
    "        return inference_list\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error during inference: {str(e)}\")\n",
    "        raise RuntimeError(\"Inference failed\")\n",
    "\n",
    "def postprocess(inference_output):\n",
    "    \"\"\"\n",
    "    Convert model output to a list of predictions.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Process each item in the batch\n",
    "        result_list = []\n",
    "        for result in inference_output:\n",
    "            if result > 0:\n",
    "                result_list.append(\"Stall\")\n",
    "            else:\n",
    "                result_list.append(\"No Stall\")\n",
    "        logger.info(\"Output postprocessed successfully\")\n",
    "        return result_list\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error during postprocessing: {str(e)}\")\n",
    "        raise ValueError(\"Failed to postprocess output data\")\n",
    "\n",
    "def handle(data):\n",
    "    \"\"\"\n",
    "    Handle a prediction request.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        model_input = preprocess(data)\n",
    "        model_output = inference(model_input)\n",
    "        return postprocess(model_output)\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error during handle: {str(e)}\")\n",
    "        return [str(e)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Received data: [{'data': [13, 13, 13, 0, 13, 13, 13, 13, -76, -76, -81, -76, -78.5, -76, -76, -7, -7, -12, -7, -9.5, -7, -7, 12, 12, 7, 12, 9.5, 12, 12]}, {'data': [14, 14, 14, 0, 14, 14, 14, 14, -99, -99, -99, -99, -99, -99, -99, -5, -10, -10, -10, -10, -10, -7.5, 17, 17, 17, 17, 17, 17, 17]}]\n",
      "INFO:__main__:Input data preprocessed successfully\n",
      "INFO:__main__:Inference performed successfully\n",
      "INFO:__main__:Output postprocessed successfully\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['No Stall', 'Stall']"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_data = [{'data': [13,13,13,0,13,13,13,13,-76,-76,-81,-76,-78.5,-76,-76,-7,-7,-12,-7,-9.5,-7,-7,12,12,7,12,9.5,12,12]}]\n",
    "stall_data = [{'data': [14,14,14,0,14,14,14,14,-99,-99,-99,-99,-99,-99,-99,-5,-10,-10,-10,-10,-10,-7.5,17,17,17,17,17,17,17]}]\n",
    "m_data = [{'data': [13,13,13,0,13,13,13,13,-76,-76,-81,-76,-78.5,-76,-76,-7,-7,-12,-7,-9.5,-7,-7,12,12,7,12,9.5,12,12]}, {'data': [14,14,14,0,14,14,14,14,-99,-99,-99,-99,-99,-99,-99,-5,-10,-10,-10,-10,-10,-7.5,17,17,17,17,17,17,17]}]\n",
    "\n",
    "handle(m_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

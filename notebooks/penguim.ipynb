{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b779a572-9f7a-4582-9abc-7b5d51bb8104",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href=\"/pipeline/#/experiments/details/19833df7-7ce5-4e91-b099-c9dc7f8b93cc\" target=\"_blank\" >Experiment details</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<a href=\"/pipeline/#/runs/details/e73d8917-73ef-4ff0-87f9-59255f9eddd3\" target=\"_blank\" >Run details</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "RunPipelineResult(run_id=e73d8917-73ef-4ff0-87f9-59255f9eddd3)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import kfp\n",
    "from kfp.v2 import dsl\n",
    "from kfp.v2.dsl import (Dataset, Input, Model, Output)\n",
    "from kfp.v2.compiler import Compiler\n",
    "\n",
    "@dsl.component(\n",
    "    base_image='python:3.8',\n",
    "    packages_to_install=['pandas', 'minio']\n",
    ")\n",
    "def load_data_from_minio(output_data: Output[Dataset]):\n",
    "    from minio import Minio\n",
    "    import pandas as pd\n",
    "    \n",
    "    client = Minio(\n",
    "        \"10.96.204.210:9000\",\n",
    "        access_key=\"minio\",\n",
    "        secret_key=\"minio123\",\n",
    "        secure=False\n",
    "    )\n",
    "    \n",
    "    # Download the dataset\n",
    "    client.fget_object(\"penguin-dataset\", \"penguins_size.csv\", \"/tmp/penguins_size.csv\")\n",
    "    \n",
    "    data = pd.read_csv('/tmp/penguins_size.csv')\n",
    "    data.to_csv(output_data.path, index=False)\n",
    "\n",
    "@dsl.component(\n",
    "    base_image='python:3.8',\n",
    "    packages_to_install=['pandas', 'scikit-learn']\n",
    ")\n",
    "def preprocess_data(input_data: Input[Dataset], output_train_data: Output[Dataset], output_test_data: Output[Dataset]):\n",
    "    import pandas as pd\n",
    "    from sklearn.impute import SimpleImputer\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    \n",
    "    data = pd.read_csv(input_data.path)\n",
    "    \n",
    "    # Handling missing values\n",
    "    imputer = SimpleImputer(strategy='most_frequent')\n",
    "    data.iloc[:, :] = imputer.fit_transform(data)\n",
    "    \n",
    "    # Encoding categorical data\n",
    "    lb = LabelEncoder()\n",
    "    data[\"sex\"] = lb.fit_transform(data[\"sex\"])\n",
    "    \n",
    "    # Split the data into training and test sets\n",
    "    train_data, test_data = train_test_split(data, test_size=0.9, random_state=42)\n",
    "    \n",
    "    train_data.to_csv(output_train_data.path, index=False)\n",
    "    test_data.to_csv(output_test_data.path, index=False)\n",
    "\n",
    "@dsl.component(\n",
    "    base_image='python:3.8',\n",
    "    packages_to_install=['pandas', 'tensorflow', 'scikit-learn', 'joblib', 'minio']\n",
    ")\n",
    "def train_model(input_train_data: Input[Dataset], model: Output[Model], model_path: str):\n",
    "    import pandas as pd\n",
    "    from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "    from sklearn.compose import ColumnTransformer\n",
    "    import tensorflow as tf\n",
    "    from minio import Minio\n",
    "    import os\n",
    "\n",
    "    # Initialize MinIO client\n",
    "    client = Minio(\n",
    "        \"10.96.204.210:9000\",\n",
    "        access_key=\"minio\",\n",
    "        secret_key=\"minio123\",\n",
    "        secure=False\n",
    "    )\n",
    "\n",
    "    bucket_name = \"mlpipeline\"\n",
    "    found = client.bucket_exists(bucket_name)\n",
    "    if not found:\n",
    "        client.make_bucket(bucket_name)\n",
    "\n",
    "    train_data = pd.read_csv(input_train_data.path)\n",
    "    X_train = train_data.drop('species', axis=1)  # Assuming 'species' is the target\n",
    "    y_train = train_data['species']\n",
    "    \n",
    "    # Define which columns are categorical and which are numerical\n",
    "    categorical_features = X_train.select_dtypes(include=['object']).columns\n",
    "    numerical_features = X_train.select_dtypes(include=['number']).columns\n",
    "    \n",
    "    # Create a column transformer that will apply OneHotEncoder to categorical columns\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', StandardScaler(), numerical_features),\n",
    "            ('cat', OneHotEncoder(), categorical_features)\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    # Preprocess the features\n",
    "    X_train = preprocessor.fit_transform(X_train)\n",
    "    \n",
    "    # Encode the labels\n",
    "    label_encoder = LabelEncoder()\n",
    "    y_train = label_encoder.fit_transform(y_train)\n",
    "    \n",
    "    # Define a simple neural network model\n",
    "    model_keras = tf.keras.Sequential([\n",
    "        tf.keras.layers.InputLayer(input_shape=(X_train.shape[1],)),\n",
    "        tf.keras.layers.Dense(128, activation='relu'),\n",
    "        tf.keras.layers.Dense(64, activation='relu'),\n",
    "        tf.keras.layers.Dense(3, activation='softmax')  # Assuming 3 classes for species\n",
    "    ])\n",
    "    \n",
    "    model_keras.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    # Train the model\n",
    "    model_keras.fit(X_train, y_train, epochs=1)\n",
    "    \n",
    "    # Save the model locally\n",
    "    #local_model_path = \"/tmp/saved_model\"\n",
    "    model_keras.save(model.path)\n",
    "    # Upload the model to MinIO\n",
    "    #for root, _, files in os.walk(local_model_path):\n",
    "        #for file in files:\n",
    "            #local_file_path = os.path.join(root, file)\n",
    "            #remote_file_path = os.path.relpath(local_file_path, local_model_path)\n",
    "            #client.fput_object(bucket_name, f\"{model_path}/{remote_file_path}\", local_file_path)\n",
    "    model.uri = model.uri+\"/1/\"\n",
    "    print(\"MAtni: \" + model.uri)\n",
    "    \n",
    "@dsl.component(\n",
    "    base_image='python:3.8',\n",
    "    packages_to_install=['kserve', 'kubernetes', 'tensorflow']\n",
    ")\n",
    "def model_serving(model_trained: Input[Model]):\n",
    "    \"\"\"\n",
    "    Create kserve instance\n",
    "    \"\"\"\n",
    "    from kubernetes import client\n",
    "    from kserve import KServeClient\n",
    "    from kserve import constants\n",
    "    from kserve import utils\n",
    "    from kserve import V1beta1InferenceService\n",
    "    from kserve import V1beta1InferenceServiceSpec\n",
    "    from kserve import V1beta1PredictorSpec\n",
    "    from kserve import V1beta1TFServingSpec\n",
    "    from datetime import datetime\n",
    "    import time\n",
    "    \n",
    "    # Get model uri\n",
    "    uri = model_trained.uri\n",
    "    # Replace minio with s3\n",
    "    print(f\"matni: {uri}\")\n",
    "    uri = uri.replace(\"minio\", \"s3\")\n",
    "    # Removing last subfolder /1/\n",
    "    uri = uri.rsplit(\"/\", 2)[0]\n",
    "    print(uri)\n",
    "    \n",
    "    # Inference server config\n",
    "    namespace = utils.get_default_target_namespace()\n",
    "    name = \"penguin-classifier\"\n",
    "    kserve_version = 'v1beta1'\n",
    "    api_version = constants.KSERVE_GROUP + '/' + kserve_version\n",
    "\n",
    "    isvc = V1beta1InferenceService(api_version=api_version,\n",
    "                                   kind=constants.KSERVE_KIND,\n",
    "                                   metadata=client.V1ObjectMeta(\n",
    "                                       name=name, namespace=namespace, annotations={'sidecar.istio.io/inject': 'false'}),\n",
    "                                   spec=V1beta1InferenceServiceSpec(\n",
    "                                   predictor=V1beta1PredictorSpec(\n",
    "                                       service_account_name=\"sa-minio-kserve\",\n",
    "                                       tensorflow=V1beta1TFServingSpec(\n",
    "                                           storage_uri=uri)\n",
    "                                   )\n",
    "                               )\n",
    "    )\n",
    "\n",
    "    kserve = KServeClient()\n",
    "    \n",
    "    # Replace old inference service with a new one\n",
    "    try:\n",
    "        kserve.delete(name=name, namespace=namespace)\n",
    "        print(\"Previous model deleted\")\n",
    "    except:\n",
    "        print(\"Cannot delete previous model\")\n",
    "    time.sleep(10)\n",
    "    \n",
    "    kserve.create(isvc)\n",
    "\n",
    "@dsl.pipeline(\n",
    "    name='penguin_classification_pipeline',\n",
    "    description='A pipeline to classify penguins using a TensorFlow model and KServe'\n",
    ")\n",
    "def penguin_pipeline():\n",
    "    load_data_task = load_data_from_minio()\n",
    "    preprocess_task = preprocess_data(input_data=load_data_task.outputs['output_data'])\n",
    "    train_task = train_model(\n",
    "        input_train_data=preprocess_task.outputs['output_train_data'],\n",
    "        model_path='penguin-model'\n",
    "    )\n",
    "    serve_task = model_serving(model_trained=train_task.outputs['model'])\n",
    "    \n",
    "    # Ensure serve_task runs after train_task\n",
    "    serve_task.after(train_task)\n",
    "\n",
    "# Compile the pipeline\n",
    "Compiler().compile(pipeline_func=penguin_pipeline, package_path='penguin_pipeline.yaml')\n",
    "\n",
    "# Run the pipeline\n",
    "client = kfp.Client()\n",
    "\n",
    "client.create_run_from_pipeline_package(\n",
    "    pipeline_file='penguin_pipeline.yaml',\n",
    "    arguments={}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db47a84a-aceb-45ec-bb46-d4ec673beb1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aedc9b61-cb5f-4fb7-a697-f97e17e1f7d1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matni: minio://mlpipeline/v2/artifacts/penguin-classification-pipeline/716929e6-4592-4377-b7e2-e5e4b94e1edb/train-model/model\n",
      "s3://mlpipeline/v2/artifacts/penguin-classification-pipeline/716929e6-4592-4377-b7e2-e5e4b94e1edb/train-model/model\n",
      "Previous model deleted\n"
     ]
    }
   ],
   "source": [
    "def model_serving():\n",
    "    \"\"\"\n",
    "    Create kserve instance\n",
    "    \"\"\"\n",
    "    from kubernetes import client\n",
    "    from kserve import KServeClient\n",
    "    from kserve import constants\n",
    "    from kserve import utils\n",
    "    from kserve import V1beta1InferenceService\n",
    "    from kserve import V1beta1InferenceServiceSpec\n",
    "    from kserve import V1beta1PredictorSpec\n",
    "    from kserve import V1beta1TFServingSpec\n",
    "    from datetime import datetime\n",
    "    import time\n",
    "    \n",
    "    # Get model uri\n",
    "    uri = \"minio://mlpipeline/v2/artifacts/penguin-classification-pipeline/716929e6-4592-4377-b7e2-e5e4b94e1edb/train-model/model\"\n",
    "    # Replace minio with s3\n",
    "    print(f\"matni: {uri}\")\n",
    "    uri = uri.replace(\"minio\", \"s3\")\n",
    "    # Removing last subfolder /1/\n",
    "    # uri = uri.rsplit(\"/\", 2)[0]\n",
    "    print(uri)\n",
    "    \n",
    "    # Inference server config\n",
    "    namespace = utils.get_default_target_namespace()\n",
    "    name = \"penguin-classifier\"\n",
    "    kserve_version = 'v1beta1'\n",
    "    api_version = constants.KSERVE_GROUP + '/' + kserve_version\n",
    "\n",
    "    isvc = V1beta1InferenceService(api_version=api_version,\n",
    "                                   kind=constants.KSERVE_KIND,\n",
    "                                   metadata=client.V1ObjectMeta(\n",
    "                                       name=name, namespace=namespace, annotations={'sidecar.istio.io/inject': 'false'}),\n",
    "                                   spec=V1beta1InferenceServiceSpec(\n",
    "                                   predictor=V1beta1PredictorSpec(\n",
    "                                       service_account_name=\"sa-minio-kserve\",\n",
    "                                       tensorflow=V1beta1TFServingSpec(\n",
    "                                           storage_uri=uri)\n",
    "                                   )\n",
    "                               )\n",
    "    )\n",
    "\n",
    "    kserve = KServeClient()\n",
    "    \n",
    "    # Replace old inference service with a new one\n",
    "    try:\n",
    "        kserve.delete(name=name, namespace=namespace)\n",
    "        print(\"Previous model deleted\")\n",
    "    except:\n",
    "        print(\"Cannot delete previous model\")\n",
    "    time.sleep(10)\n",
    "    \n",
    "    kserve.create(isvc)\n",
    "    \n",
    "model_serving()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e98027d-0bf5-402e-9999-0330c497479f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

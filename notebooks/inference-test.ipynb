{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f35f373-8b9a-4f0f-9439-210b77138e28",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7bb6e51c-ee4b-4416-8cdb-c9024b6851c3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Successfully downloaded file from https://raw.githubusercontent.com/razaulmustafa852/youtubegoes5g/main/Models/Stall-Windows%20-%20Stall-3s.csv to dataset.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stall Value: No\n",
      "First Sample Tensor: tensor([ 13.0000,  13.0000,  13.0000,   0.0000,  13.0000,  13.0000,  13.0000,\n",
      "         13.0000, -76.0000, -76.0000, -81.0000, -76.0000, -78.5000, -76.0000,\n",
      "        -76.0000,  -7.0000,  -7.0000, -12.0000,  -7.0000,  -9.5000,  -7.0000,\n",
      "         -7.0000,  12.0000,  12.0000,   7.0000,  12.0000,   9.5000,  12.0000,\n",
      "         12.0000])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import requests\n",
    "import logging\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from torch import nn\n",
    "\n",
    "# Load environment variables from env file\n",
    "load_dotenv('env')\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# Github variables\n",
    "GITHUB_USERNAME = os.getenv(\"GITHUB_USERNAME\")\n",
    "GITHUB_TOKEN = os.getenv(\"GITHUB_TOKEN\")\n",
    "GITHUB_REPO_URL = \"https://github.com/danilonicioka/mlops-workflow.git\"\n",
    "GITHUB_CLONED_DIR = \"mlops-workflow\"\n",
    "GITHUB_DVC_BRANCH = \"dvc\"\n",
    "GITHUB_MAIN_BRANCH = \"main\"\n",
    "\n",
    "# Kubeflow variables\n",
    "# KUBEFLOW_PIPELINE_NAME = \"mlops\"\n",
    "# KUBEFLOW_HOST_URL = \"http://ml-pipeline.kubeflow:8888\"  # KFP host URL\n",
    "# KUBEFLOW_PIPELINE_ID=\"7451916e-eee8-4c14-ad5f-8dee5aa61e3b\"\n",
    "# with open(os.environ['KF_PIPELINES_SA_TOKEN_PATH'], \"r\") as f:\n",
    "#     KUBEFLOW_TOKEN = f.read()\n",
    "\n",
    "# DVC variables\n",
    "DVC_REMOTE_DB = \"minio_remote\"\n",
    "DVC_REMOTE_DB_URL = \"s3://dvc-data\"\n",
    "DVC_FILE_DIR = 'data/external'\n",
    "DVC_FILE_NAME = 'dataset.csv'\n",
    "\n",
    "# MinIO variables\n",
    "MINIO_URL = \"minio-service.kubeflow:9000\"\n",
    "MINIO_ACCESS_KEY = os.getenv(\"MINIO_ACCESS_KEY\")\n",
    "MINIO_SECRET_KEY = os.getenv(\"MINIO_SECRET_KEY\")\n",
    "MINIO_MODEL_BUCKET_NAME = \"model-files\"\n",
    "MINIO_MODEL_OBJECT_NAME = \"model-store/youtubegoes5g/model.pt\"\n",
    "\n",
    "# Triggers variables\n",
    "TRIGGER_TYPE = '1'\n",
    "PERFORMANCE_FACTOR = 0.05\n",
    "# Temp dir and files to save accuracy for trigger 3\n",
    "TEMP_DIR = \"tmp\"\n",
    "TEMP_FILE_ACC_IN_LAST_RUN = \"accuracy_in_last_run.txt\"\n",
    "LAST_ACC_OBJECT_NAME = \"accuracy-score/last_acc.txt\"\n",
    "\n",
    "# Model variables\n",
    "MODEL_LR = 0.0001\n",
    "MODEL_EPOCHS = 3500\n",
    "MODEL_PRINT_FREQUENCY_PER_N_EPOCHS = 500\n",
    "MODEL_NAME = \"youtubegoes5g\"\n",
    "\n",
    "# Kserve variables\n",
    "#MODEL_FRAMEWORK = \"pytorch\"\n",
    "KSERVE_NAMESPACE = \"kubeflow-user-example-com\"\n",
    "KSERVE_SVC_ACC = \"sa-minio-kserve\"\n",
    "#MODEL_URI = \"pvc://model-store-claim\"\n",
    "#MODEL_URI = \"minio-service.kubeflow:9000/model-files\"\n",
    "\n",
    "# Model archiver gen vars\n",
    "MODEL_STORE_POD_NAME = \"model-store-pod\"\n",
    "MODEL_STORE_POD_CONTAINER_NAME = \"model-store\"\n",
    "MAR_POD_NAME = \"margen-pod\"\n",
    "MAR_POD_CONTAINER_NAME = \"margen-container\"\n",
    "MAR_OBJECT_NAME = \"model-store/youtubegoes5g.mar\"\n",
    "K8S_API_TOKEN = os.getenv(\"K8S_API_TOKEN\")\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "MODEL_INIT_DATASET_URL = 'https://raw.githubusercontent.com/razaulmustafa852/youtubegoes5g/main/Models/Stall-Windows%20-%20Stall-3s.csv'\n",
    "\n",
    "file_url = MODEL_INIT_DATASET_URL\n",
    "local_file_path = DVC_FILE_NAME\n",
    "\n",
    "# Build model with non-linear activation function\n",
    "class InterruptionModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer_1 = nn.Linear(in_features=29, out_features=200)\n",
    "        self.layer_2 = nn.Linear(in_features=200, out_features=100)\n",
    "        self.layer_3 = nn.Linear(in_features=100, out_features=1)\n",
    "        self.relu = nn.ReLU() # <- add in ReLU activation function\n",
    "        # Can also put sigmoid in the model\n",
    "        # This would mean you don't need to use it on the predictions\n",
    "        # self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "      # Intersperse the ReLU activation function between layers\n",
    "       return self.layer_3(self.relu(self.layer_2(self.relu(self.layer_1(x)))))\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "path_to_pt = \"../model-archiver/model-store/youtubegoes5g/model.pt\"\n",
    "\n",
    "model = InterruptionModel()\n",
    "model.load_state_dict(torch.load(path_to_pt, weights_only=True))\n",
    "model.eval()\n",
    "\n",
    "try:\n",
    "    # Request the file content\n",
    "    response = requests.get(file_url)\n",
    "    response.raise_for_status()\n",
    "\n",
    "    # Save the file content locally\n",
    "    with open(local_file_path, 'wb') as local_file:\n",
    "        local_file.write(response.content)\n",
    "    logger.info(f\"Successfully downloaded file from {file_url} to {local_file_path}\")\n",
    "except requests.RequestException as e:\n",
    "    # Log and raise any download errors\n",
    "    logger.error(f\"Failed to download file: {e}\")\n",
    "    raise\n",
    "\n",
    "# get sample\n",
    "# Step 1: Read the first row of the CSV file\n",
    "sample = pd.read_csv('dataset.csv', nrows=1)\n",
    "\n",
    "# Capture the value of the 'Stall' column before dropping it\n",
    "stall_value = sample['Stall'].values[0] if 'Stall' in sample.columns else None\n",
    "print(\"Stall Value:\", stall_value)\n",
    "\n",
    "# Step 2: Drop the 'Stall', 'ID', 'Quality', and 'Time' columns\n",
    "sample = sample.drop(columns=['Stall', 'ID', 'Quality', 'Time'], errors='ignore')\n",
    "\n",
    "# Step 3: Replace ' ', '-', and np.nan with 0\n",
    "sample = sample.replace([' ', '-', np.nan], 0)\n",
    "\n",
    "# Convert all columns to float\n",
    "sample = sample.astype(float)\n",
    "\n",
    "# Step 4: Extract the first sample as a NumPy array without the column names\n",
    "first_sample = sample.values.flatten()  # Use flatten() to get a 1D array\n",
    "\n",
    "# Step 5: Convert the first sample to a PyTorch tensor\n",
    "first_sample_tensor = torch.tensor(first_sample, dtype=torch.float32)\n",
    "\n",
    "# Display the tensor\n",
    "print(\"First Sample Tensor:\", first_sample_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9b31797-8e03-46b3-b2a5-7c21eeef1fdd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.2961,  1.2947,  1.3103, -0.8068,  1.2950,  1.5510,  1.3164,  1.2005,\n",
      "          1.3405,  1.3391,  1.0186,  1.3402,  1.2126,  1.3393,  1.3140,  0.5796,\n",
      "          0.5772, -0.5194,  0.5746,  0.0798,  0.5754,  0.5401,  0.4581,  0.4473,\n",
      "         -0.1917,  0.4490,  0.1823,  0.4479,  0.4039],\n",
      "        [ 1.6234,  1.6197,  1.6393, -0.8068,  1.6199,  1.9051,  1.6455,  1.5355,\n",
      "         -0.1424, -0.1427, -0.1381, -0.1419, -0.1135, -0.1427, -0.1703,  1.0207,\n",
      "         -0.0817, -0.0798, -0.0839, -0.0292, -0.0835,  0.4271,  1.1001,  1.0871,\n",
      "          1.0830,  1.0899,  1.1467,  1.0884,  1.0531]])\n",
      "[tensor(0.), tensor(1.)]\n",
      "['No Stall', 'Stall']\n",
      "4.89 ms ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -r 1 -n 1\n",
    "    \n",
    "from sklearn.preprocessing import StandardScaler   \n",
    "import joblib\n",
    "    \n",
    "def preprocess(data):\n",
    "    # Load scaler\n",
    "    scaler = StandardScaler()\n",
    "    scaler = joblib.load('scaler.save')\n",
    "    tensor_list = []\n",
    "    for item in data:\n",
    "        item = scaler.transform([item['data']])\n",
    "        tensor_data = torch.tensor(item, dtype=torch.float32)  # Each instance as a tensor\n",
    "        tensor_list.append(tensor_data)\n",
    "    # Stack all tensors along a new dimension to create a single tensor\n",
    "    combined_tensor = torch.cat(tensor_list, dim=0)\n",
    "    return combined_tensor\n",
    "\n",
    "def inference(model_input):\n",
    "    inference_list = []\n",
    "    for tensor_data in model_input:\n",
    "        with torch.no_grad():\n",
    "            output = torch.round(torch.sigmoid(model(tensor_data))).squeeze()\n",
    "        inference = output.cpu().numpy().tolist()\n",
    "        inference_list.append(output)\n",
    "    return inference_list\n",
    "\n",
    "def postprocess(inference_output):\n",
    "    result_list = []\n",
    "    for result in inference_output:\n",
    "        \n",
    "        if result > 0:\n",
    "            result_list.append(\"Stall\")\n",
    "        else:\n",
    "            result_list.append(\"No Stall\")\n",
    "    return result_list\n",
    "    \n",
    "no_data = [{'data': [13,13,13,0,13,13,13,13,-76,-76,-81,-76,-78.5,-76,-76,-7,-7,-12,-7,-9.5,-7,-7,12,12,7,12,9.5,12,12]}]\n",
    "stall_data = [{'data': [14,14,14,0,14,14,14,14,-99,-99,-99,-99,-99,-99,-99,-5,-10,-10,-10,-10,-10,-7.5,17,17,17,17,17,17,17]}]\n",
    "m_data = [{'data': [13,13,13,0,13,13,13,13,-76,-76,-81,-76,-78.5,-76,-76,-7,-7,-12,-7,-9.5,-7,-7,12,12,7,12,9.5,12,12]}, {'data': [14,14,14,0,14,14,14,14,-99,-99,-99,-99,-99,-99,-99,-5,-10,-10,-10,-10,-10,-7.5,17,17,17,17,17,17,17]}]\n",
    "\n",
    "tensor_list = preprocess(m_data)\n",
    "inference_list = inference(tensor_list)\n",
    "result_list = postprocess(inference_list)\n",
    "\n",
    "print(tensor_list)\n",
    "print(inference_list)\n",
    "print(result_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "627d25e2-a892-4111-9b21-6f575680f5b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

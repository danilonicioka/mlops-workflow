{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f35f373-8b9a-4f0f-9439-210b77138e28",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install -r ../model-archiver/model-store/youtubegoes5g/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "627d25e2-a892-4111-9b21-6f575680f5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch\n",
    "\n",
    "# Build model with non-linear activation function\n",
    "class InterruptionModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer_1 = nn.Linear(in_features=29, out_features=200)\n",
    "        self.layer_2 = nn.Linear(in_features=200, out_features=100)\n",
    "        self.layer_3 = nn.Linear(in_features=100, out_features=1)\n",
    "        self.relu = nn.ReLU() # <- add in ReLU activation function\n",
    "        # Can also put sigmoid in the model\n",
    "        # This would mean you don't need to use it on the predictions\n",
    "        # self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Intersperse the ReLU activation function between layers\n",
    "        return self.layer_3(self.relu(self.layer_2(self.relu(self.layer_1(x)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62f9f54b-ab26-4f48-97a7-b15e44cd4bfe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from pickle import load\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "model = None\n",
    "\n",
    "class MyHandler():\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "\n",
    "    def preprocess(self, data):\n",
    "        \"\"\"\n",
    "        Transform raw input into model input data.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Load scaler\n",
    "            scaler = StandardScaler()\n",
    "            scaler = load(open('../model-archiver/model-store/youtubegoes5g/scaler.pkl', 'rb'))\n",
    "\n",
    "            tensor_list = []\n",
    "            for item in data:\n",
    "                item = scaler.transform([item['data']])\n",
    "                tensor_data = torch.tensor(item, dtype=torch.float32)  # Each instance as a tensor\n",
    "                tensor_list.append(tensor_data)\n",
    "            # Stack all tensors along a new dimension to create a single tensor\n",
    "            combined_tensor = torch.cat(tensor_list, dim=0)\n",
    "            return combined_tensor\n",
    "        except Exception as e:\n",
    "            raise ValueError(\"Failed to preprocess input data: \", e, \"data received: \", data)\n",
    "\n",
    "    def inference(self, model_input):\n",
    "        \"\"\"\n",
    "        Perform model inference.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            inference_list = []\n",
    "            for tensor_data in model_input:\n",
    "                with torch.no_grad():\n",
    "                    output = torch.round(torch.sigmoid(self.model(tensor_data))).squeeze()\n",
    "                #inference = output.cpu().numpy().tolist()\n",
    "                inference_list.append(output)\n",
    "            return inference_list\n",
    "        except Exception as e:\n",
    "            raise RuntimeError(\"Inference failed:\", e)\n",
    "\n",
    "    def postprocess(self, inference_output):\n",
    "        \"\"\"\n",
    "        Convert model output to a list of predictions.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Process each item in the batch\n",
    "            result_list = []\n",
    "            for result in inference_output:\n",
    "                if result > 0:\n",
    "                    result_list.append(\"Stall\")\n",
    "                else:\n",
    "                    result_list.append(\"No Stall\")\n",
    "            return result_list\n",
    "        except Exception as e:\n",
    "            raise ValueError(\"Failed to postprocess output data: \", e)\n",
    "\n",
    "    def handle(self, data):\n",
    "        \"\"\"\n",
    "        Handle a prediction request.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            model_input = self.preprocess(data)\n",
    "            model_output = self.inference(model_input)\n",
    "            return self.postprocess(model_output)\n",
    "        except Exception as e:\n",
    "            return [str(e)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "989a17c6-c900-4130-819f-7b58d3cd78a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Instantiate model and handler\n",
    "serialized_file = \"../model-archiver/model-store/youtubegoes5g/model.pt\"\n",
    "    \n",
    "model = InterruptionModel()\n",
    "model.load_state_dict(torch.load(serialized_file, weights_only=True))\n",
    "model.eval()\n",
    "handler = MyHandler(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "07e7f337-c862-443b-ab7a-f48a5374731c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "# Load the CSV file\n",
    "csv_file = \"dataset.csv\"  # Replace with your file path\n",
    "df = pd.read_csv(csv_file)\n",
    "\n",
    "# Drop the first 4 columns\n",
    "df = df.iloc[:, 4:]\n",
    "\n",
    "# Shuffle the DataFrame to randomize row order\n",
    "df_shuffled = df.sample(frac=1, random_state=None).reset_index(drop=True)\n",
    "\n",
    "# Number of rows to extract (should not exceed total rows)\n",
    "num_iterations = min(512, len(df_shuffled))  # Adjust as needed\n",
    "\n",
    "# Loop to get unique rows and store them in separate variables\n",
    "for i in range(1, num_iterations + 1):\n",
    "    # Select row i (guaranteed to be unique due to shuffling)\n",
    "    row_values = df_shuffled.iloc[i - 1].values.tolist()\n",
    "    \n",
    "    # Dynamically create a variable name and assign the values\n",
    "    globals()[f\"sample_{i}\"] = row_values\n",
    "    \n",
    "    # Print the selected sample\n",
    "    print(f\"Sample {i}: {globals()[f'sample_{i}']}\")\n",
    "    \n",
    "# Select a random variable\n",
    "#random_variable_name = random.choice([f\"sample_{i}\" for i in range(1, num_iterations + 1)])\n",
    "#random_variable_value = globals()[random_variable_name]\n",
    "#data = [{\"data\": random_variable_value}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ce6eea02-e6a6-474a-a2aa-ae864cad11dd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.5 ms ± 451 µs per loop (mean ± std. dev. of 10 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -r 10 -n 100\n",
    "# Single input test\n",
    "data = [{\"data\": [13,13,13,0,13,13,13,13,-76,-76,-81,-76,-78.5,-76,-76,-7,-7,-12,-7,-9.5,-7,-7,12,12,7,12,9.5,12,12]}]\n",
    "#data = [{\"data\": globals()['sample_1']}]\n",
    "\n",
    "result = handler.handle(data)\n",
    "\n",
    "#print(\"result: \" ,result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "5ea01f09-ec0b-465f-bd59-f23f57f281bf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15.9 ms ± 2.63 ms per loop (mean ± std. dev. of 10 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -r 10 -n 100\n",
    "num_iterations = 4\n",
    "for i in range(1, num_iterations + 1):\n",
    "    # Select row i (guaranteed to be unique due to shuffling)\n",
    "    #data = [{\"data\": globals()[f'sample_{i}']}]\n",
    "    data = [{\"data\": [13,13,13,0,13,13,13,13,-76,-76,-81,-76,-78.5,-76,-76,-7,-7,-12,-7,-9.5,-7,-7,12,12,7,12,9.5,12,12]}]\n",
    "    result = handler.handle(data)\n",
    "    #print(\"result: \" ,result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "fc30ce66-9d3e-452f-a284-2935bdf3667a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30.4 ms ± 4.03 ms per loop (mean ± std. dev. of 10 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -r 10 -n 100\n",
    "num_iterations = 8\n",
    "for i in range(1, num_iterations + 1):\n",
    "    # Select row i (guaranteed to be unique due to shuffling)\n",
    "    #data = [{\"data\": globals()[f'sample_{i}']}]\n",
    "    data = [{\"data\": [13,13,13,0,13,13,13,13,-76,-76,-81,-76,-78.5,-76,-76,-7,-7,-12,-7,-9.5,-7,-7,12,12,7,12,9.5,12,12]}]\n",
    "    result = handler.handle(data)\n",
    "    #print(\"result: \" ,result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "6c3c9c8b-dc7c-46f9-8b3c-5c348b08b4fa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59.5 ms ± 4.07 ms per loop (mean ± std. dev. of 10 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -r 10 -n 100\n",
    "num_iterations = 16\n",
    "for i in range(1, num_iterations + 1):\n",
    "    # Select row i (guaranteed to be unique due to shuffling)\n",
    "    #data = [{\"data\": globals()[f'sample_{i}']}]\n",
    "    data = [{\"data\": [13,13,13,0,13,13,13,13,-76,-76,-81,-76,-78.5,-76,-76,-7,-7,-12,-7,-9.5,-7,-7,12,12,7,12,9.5,12,12]}]\n",
    "    result = handler.handle(data)\n",
    "    #print(\"result: \" ,result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "bfde7393-7125-4f5a-bd9e-79564c49d7b1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118 ms ± 5.2 ms per loop (mean ± std. dev. of 10 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -r 10 -n 100\n",
    "num_iterations = 32\n",
    "for i in range(1, num_iterations + 1):\n",
    "    # Select row i (guaranteed to be unique due to shuffling)\n",
    "    #data = [{\"data\": globals()[f'sample_{i}']}]\n",
    "    data = [{\"data\": [13,13,13,0,13,13,13,13,-76,-76,-81,-76,-78.5,-76,-76,-7,-7,-12,-7,-9.5,-7,-7,12,12,7,12,9.5,12,12]}]\n",
    "    result = handler.handle(data)\n",
    "    #print(\"result: \" ,result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "4c7fd481-689d-45b3-b4a7-a6bac4450e3a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "373 ms ± 5.35 ms per loop (mean ± std. dev. of 10 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -r 10 -n 100\n",
    "num_iterations = 100\n",
    "for i in range(1, num_iterations + 1):\n",
    "    # Select row i (guaranteed to be unique due to shuffling)\n",
    "    #data = [{\"data\": globals()[f'sample_{i}']}]\n",
    "    data = [{\"data\": [13,13,13,0,13,13,13,13,-76,-76,-81,-76,-78.5,-76,-76,-7,-7,-12,-7,-9.5,-7,-7,12,12,7,12,9.5,12,12]}]\n",
    "    result = handler.handle(data)\n",
    "    #print(\"result: \" ,result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "80df69a4-fd5a-460a-953d-0885e9c35f5d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "478 ms ± 8.02 ms per loop (mean ± std. dev. of 10 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -r 10 -n 100\n",
    "num_iterations = 128\n",
    "for i in range(1, num_iterations + 1):\n",
    "    # Select row i (guaranteed to be unique due to shuffling)\n",
    "    #data = [{\"data\": globals()[f'sample_{i}']}]\n",
    "    data = [{\"data\": [13,13,13,0,13,13,13,13,-76,-76,-81,-76,-78.5,-76,-76,-7,-7,-12,-7,-9.5,-7,-7,12,12,7,12,9.5,12,12]}]\n",
    "    result = handler.handle(data)\n",
    "    #print(\"result: \" ,result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "d7e86374-242a-421a-ab85-1ec1f3efb692",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "949 ms ± 9.27 ms per loop (mean ± std. dev. of 10 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -r 10 -n 100\n",
    "num_iterations = 256\n",
    "for i in range(1, num_iterations + 1):\n",
    "    # Select row i (guaranteed to be unique due to shuffling)\n",
    "    #data = [{\"data\": globals()[f'sample_{i}']}]\n",
    "    data = [{\"data\": [13,13,13,0,13,13,13,13,-76,-76,-81,-76,-78.5,-76,-76,-7,-7,-12,-7,-9.5,-7,-7,12,12,7,12,9.5,12,12]}]\n",
    "    result = handler.handle(data)\n",
    "    #print(\"result: \" ,result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "f4469728-1532-47f5-909a-5be52c1efe71",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.08 s ± 13 ms per loop (mean ± std. dev. of 10 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -r 10 -n 100\n",
    "num_iterations = 512\n",
    "for i in range(1, num_iterations + 1):\n",
    "    # Select row i (guaranteed to be unique due to shuffling)\n",
    "    data = [{\"data\": globals()[f'sample_{i}']}]\n",
    "    #data = [{\"data\": [13,13,13,0,13,13,13,13,-76,-76,-81,-76,-78.5,-76,-76,-7,-7,-12,-7,-9.5,-7,-7,12,12,7,12,9.5,12,12]}]\n",
    "    result = handler.handle(data)\n",
    "    #print(\"result: \" ,result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c318feb1-3092-4d66-aa79-47d68c66e9cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result:  ['No Stall', 'No Stall', 'Stall', 'Stall']\n",
      "2.85 ms ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -r 1 -n 1\n",
    "data = [\n",
    "      {\"data\": [13,13,13,0,13,13,13,13,-76,-76,-81,-76,-78.5,-76,-76,-7,-7,-12,-7,-9.5,-7,-7,12,12,7,12,9.5,12,12]},\n",
    "      {\"data\": [13,13,12,0.4714045208,13,12.5,13,13,-81,-81,-82,-81,-81.5,-81,-81,-12,-12,-11,-12,-12,-12,-11.5,7,7,2,7,4.5,7,7]},\n",
    "      {\"data\": [6,7,7,0.4714045208,7,6.5,7,7,-107,-106,-106,-106,-106.5,-106,-106,-13,-14,-14,-14,-14,-14,-13.5,2,2,2,2,2,2,2]},\n",
    "      {\"data\": [8,8,8,0,8,8,8,8,-108,-108,-108,-108,-108,-108,-108,-13,-13,-13,-13,-13,-13,-13,2,2,2,2,2,2,2]}\n",
    "]\n",
    "\n",
    "result = handler.handle(data)\n",
    "\n",
    "print(\"result: \", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ca2dcb54-1304-4200-85cc-4f5544710cff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result 1: ['No Stall']\n",
      "result 2: ['No Stall']\n",
      "result 3: ['Stall']\n",
      "result 4: ['Stall']\n",
      "30.1 ms ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -r 1 -n 1\n",
    "\n",
    "data1 = [{\"data\": [13,13,13,0,13,13,13,13,-76,-76,-81,-76,-78.5,-76,-76,-7,-7,-12,-7,-9.5,-7,-7,12,12,7,12,9.5,12,12]}]\n",
    "data2 = [{\"data\": [13,13,12,0.4714045208,13,12.5,13,13,-81,-81,-82,-81,-81.5,-81,-81,-12,-12,-11,-12,-12,-12,-11.5,7,7,2,7,4.5,7,7]}]\n",
    "data3 = [{\"data\": [6,7,7,0.4714045208,7,6.5,7,7,-107,-106,-106,-106,-106.5,-106,-106,-13,-14,-14,-14,-14,-14,-13.5,2,2,2,2,2,2,2]}]\n",
    "data4 = [{\"data\": [8,8,8,0,8,8,8,8,-108,-108,-108,-108,-108,-108,-108,-13,-13,-13,-13,-13,-13,-13,2,2,2,2,2,2,2]}]\n",
    "\n",
    "result1 = handler.handle(data1)\n",
    "print(\"result 1:\", result1)\n",
    "\n",
    "result2 = handler.handle(data2)\n",
    "print(\"result 2:\", result2)\n",
    "\n",
    "result3 = handler.handle(data3)\n",
    "print(\"result 3:\", result3)\n",
    "\n",
    "result4 = handler.handle(data4)\n",
    "print(\"result 4:\", result4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d4635fa2-e140-4c0b-995a-b6fc0a343b1d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task Data1 finished with result: ['No Stall']\n",
      "Task Data2 finished with result: ['No Stall']\n",
      "Task Data3 finished with result: ['Stall']\n",
      "Task Data4 finished with result: ['Stall']\n",
      "7.56 ms ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -r 1 -n 1\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "# Define a task function to handle data\n",
    "def handle_data(data, identifier):\n",
    "    handler = MyHandler(model)\n",
    "    result = handler.handle(data)\n",
    "    return f\"Task {identifier} finished with result: {result}\"\n",
    "\n",
    "\n",
    "# Example datasets\n",
    "datasets = [\n",
    "    ([{\"data\": [13, 13, 13, 0, 13, 13, 13, 13, -76, -76, -81, -76, -78.5, -76, -76, -7, -7, -12, -7, -9.5, -7, -7, 12, 12, 7, 12, 9.5, 12, 12]}], \"Data1\"),\n",
    "    ([{\"data\": [13, 13, 12, 0.4714045208, 13, 12.5, 13, 13, -81, -81, -82, -81, -81.5, -81, -81, -12, -12, -11, -12, -12, -12, -11.5, 7, 7, 2, 7, 4.5, 7, 7]}], \"Data2\"),\n",
    "    ([{\"data\": [6, 7, 7, 0.4714045208, 7, 6.5, 7, 7, -107, -106, -106, -106, -106.5, -106, -106, -13, -14, -14, -14, -14, -14, -13.5, 2, 2, 2, 2, 2, 2, 2]}], \"Data3\"),\n",
    "    ([{\"data\": [8, 8, 8, 0, 8, 8, 8, 8, -108, -108, -108, -108, -108, -108, -108, -13, -13, -13, -13, -13, -13, -13, 2, 2, 2, 2, 2, 2, 2]}], \"Data4\"),\n",
    "]\n",
    "\n",
    "# Run tasks concurrently\n",
    "with ThreadPoolExecutor() as executor:\n",
    "    futures = [executor.submit(handle_data, dataset[0], dataset[1]) for dataset in datasets]\n",
    "\n",
    "    # Collect and print results as they complete\n",
    "    for future in futures:\n",
    "        print(future.result())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccda57a3-1b78-4e53-95cc-a0ce243c749b",
   "metadata": {},
   "source": [
    "# Kserve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "1f508306-d2f4-486a-9959-030c998f4466",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "# Define KServe Inference Service details\n",
    "INGRESS_HOST = \"youtubegoes5g.kubeflow-user-example-com.svc.cluster.local\"\n",
    "INGRESS_PORT = \"80\"  \n",
    "SERVICE_HOSTNAME = \"youtubegoes5g.kubeflow-user-example-com.svc.cluster.local\"\n",
    "MODEL_NAME = \"youtubegoes5g\"\n",
    "\n",
    "# Construct the inference URL and headers\n",
    "URL = f\"http://{INGRESS_HOST}:{INGRESS_PORT}/v1/models/{MODEL_NAME}:predict\"\n",
    "HEADERS = {\n",
    "    \"Host\": SERVICE_HOSTNAME,\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "\n",
    "# Define the sample data payload\n",
    "def get_data():\n",
    "    return {\n",
    "        \"instances\": [\n",
    "            {\"data\": [13, 13, 13, 0, 13, 13, 13, 13, -76, -76, -81, -76, -78.5, -76, -76, -7, -7, -12, -7, -9.5, -7, -7, 12, 12, 7, 12, 9.5, 12, 12]}\n",
    "        ]\n",
    "    }\n",
    "\n",
    "# Function to handle the inference request\n",
    "def handle_request():\n",
    "    payload = json.dumps(get_data())\n",
    "    response = requests.post(URL, headers=HEADERS, data=payload)\n",
    "    return response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad7565a-ff06-4b03-888a-7022399f10c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit -r 10 -n 100 \n",
    "num_iterations = 1\n",
    "for i in range(1, num_iterations + 1):\n",
    "    data = get_data()  # Dynamically retrieve data for each iteration\n",
    "    result = handle_request()\n",
    "    # Optionally print or process result\n",
    "    #print(f\"Result for iteration {i}: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb8f8a8a-8247-496c-95b8-bdc9436ba0b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit -r 10 -n 100 \n",
    "num_iterations = 4\n",
    "for i in range(1, num_iterations + 1):\n",
    "    data = get_data()  # Dynamically retrieve data for each iteration\n",
    "    result = handle_request()\n",
    "    # Optionally print or process result\n",
    "    #print(f\"Result for iteration {i}: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "a5fe2e07-7de2-479e-b290-94f75c840b13",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "158 ms ± 3.24 ms per loop (mean ± std. dev. of 10 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -r 10 -n 100 \n",
    "num_iterations = 8\n",
    "for i in range(1, num_iterations + 1):\n",
    "    data = get_data()  # Dynamically retrieve data for each iteration\n",
    "    result = handle_request()\n",
    "    # Optionally print or process result\n",
    "    #print(f\"Result for iteration {i}: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "c11c8e9d-5ceb-488d-819c-c3359db35a7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "316 ms ± 4.09 ms per loop (mean ± std. dev. of 10 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -r 10 -n 100 \n",
    "num_iterations = 16\n",
    "for i in range(1, num_iterations + 1):\n",
    "    data = get_data()  # Dynamically retrieve data for each iteration\n",
    "    result = handle_request()\n",
    "    # Optionally print or process result\n",
    "    #print(f\"Result for iteration {i}: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "f617b611-cee4-4c56-bbe3-2994a953ce0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "630 ms ± 5.55 ms per loop (mean ± std. dev. of 10 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -r 10 -n 100 \n",
    "num_iterations = 32\n",
    "for i in range(1, num_iterations + 1):\n",
    "    data = get_data()  # Dynamically retrieve data for each iteration\n",
    "    result = handle_request()\n",
    "    # Optionally print or process result\n",
    "    #print(f\"Result for iteration {i}: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "b18b1eba-24d5-4855-a912-126253899dbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.97 s ± 6.59 ms per loop (mean ± std. dev. of 10 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -r 10 -n 100 \n",
    "num_iterations = 100\n",
    "for i in range(1, num_iterations + 1):\n",
    "    data = get_data()  # Dynamically retrieve data for each iteration\n",
    "    result = handle_request()\n",
    "    # Optionally print or process result\n",
    "    #print(f\"Result for iteration {i}: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "b948d5ab-1f18-4abf-a6ef-617205a75782",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.52 s ± 9.88 ms per loop (mean ± std. dev. of 10 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -r 10 -n 100 \n",
    "num_iterations = 128\n",
    "for i in range(1, num_iterations + 1):\n",
    "    data = get_data()  # Dynamically retrieve data for each iteration\n",
    "    result = handle_request()\n",
    "    # Optionally print or process result\n",
    "    #print(f\"Result for iteration {i}: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "9479dc45-f9bf-4660-aba8-5972b5997f72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.05 s ± 12.8 ms per loop (mean ± std. dev. of 10 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -r 10 -n 100 \n",
    "num_iterations = 256\n",
    "for i in range(1, num_iterations + 1):\n",
    "    data = get_data()  # Dynamically retrieve data for each iteration\n",
    "    result = handle_request()\n",
    "    # Optionally print or process result\n",
    "    #print(f\"Result for iteration {i}: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "2c1644ef-d19e-458a-a9a8-9e188b5db012",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.1 s ± 17.4 ms per loop (mean ± std. dev. of 10 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -r 10 -n 100 \n",
    "num_iterations = 512\n",
    "for i in range(1, num_iterations + 1):\n",
    "    data = get_data()  # Dynamically retrieve data for each iteration\n",
    "    result = handle_request()\n",
    "    # Optionally print or process result\n",
    "    #print(f\"Result for iteration {i}: {result}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

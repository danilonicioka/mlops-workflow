# PIPELINE DEFINITION
# Name: my-pipeline
# Inputs:
#    model_name: str
#    model_uri: str
#    namespace: str
components:
  comp-model-serving:
    executorLabel: exec-model-serving
    inputDefinitions:
      parameters:
        model_name:
          parameterType: STRING
        model_uri:
          parameterType: STRING
        namespace:
          parameterType: STRING
deploymentSpec:
  executors:
    exec-model-serving:
      container:
        args:
        - --executor_input
        - '{{$}}'
        - --function_to_execute
        - model_serving
        command:
        - sh
        - -c
        - "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip ||\
          \ python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1\
          \ python3 -m pip install --quiet --no-warn-script-location 'kfp==2.4.0'\
          \ '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"3.9\"'  &&\
          \  python3 -m pip install --quiet --no-warn-script-location 'kserve==0.13.0'\
          \ 'kubernetes==30.1.0' && \"$0\" \"$@\"\n"
        - sh
        - -ec
        - 'program_path=$(mktemp -d)


          printf "%s" "$0" > "$program_path/ephemeral_component.py"

          _KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"

          '
        - "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import\
          \ *\n\ndef model_serving(\n    model_name: str,\n    namespace: str,\n \
          \   model_uri: str\n):\n    # Create kserve instance\n    from kubernetes\
          \ import client \n    from kserve import KServeClient, constants, V1beta1InferenceService,\
          \ V1beta1InferenceServiceSpec, V1beta1PredictorSpec, V1beta1TorchServeSpec\n\
          \    from datetime import datetime\n    import time\n    from subprocess\
          \ import run\n\n    #TFServing wants this type of structure ./models/1/model\n\
          \    # the number represent the model version\n    # in this example we\
          \ use only 1 version\n\n    #Inference server config\n    now = datetime.now()\n\
          \    kserve_version='v1beta1'\n    api_version = constants.KSERVE_GROUP\
          \ + '/' + kserve_version\n\n    isvc = V1beta1InferenceService(api_version=api_version,\n\
          \                                   kind=constants.KSERVE_KIND,\n      \
          \                             metadata=client.V1ObjectMeta(\n          \
          \                             name=model_name, namespace=namespace, annotations={'sidecar.istio.io/inject':'false'}),\n\
          \                                   spec=V1beta1InferenceServiceSpec(\n\
          \                                   predictor=V1beta1PredictorSpec(\n  \
          \                                     service_account_name=\"default-editor\"\
          ,\n                                       pytorch=(V1beta1TorchServeSpec(\n\
          \                                           storage_uri=model_uri))))\n\
          \    )\n\n    KServe = KServeClient()\n\n    #replace old inference service\
          \ with a new one\n    try:\n        KServe.delete(name=model_name, namespace=namespace)\n\
          \        print(\"Old model deleted\")\n    except:\n        print(\"Couldn't\
          \ delete old model\")\n    time.sleep(10)\n\n    KServe.create(isvc)\n\n"
        image: python:3.11.9
pipelineInfo:
  name: my-pipeline
root:
  dag:
    tasks:
      model-serving:
        cachingOptions:
          enableCache: true
        componentRef:
          name: comp-model-serving
        inputs:
          parameters:
            model_name:
              componentInputParameter: model_name
            model_uri:
              componentInputParameter: model_uri
            namespace:
              componentInputParameter: namespace
        taskInfo:
          name: model-serving
  inputDefinitions:
    parameters:
      model_name:
        parameterType: STRING
      model_uri:
        parameterType: STRING
      namespace:
        parameterType: STRING
schemaVersion: 2.1.0
sdkVersion: kfp-2.4.0

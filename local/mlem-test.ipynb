{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9f35f373-8b9a-4f0f-9439-210b77138e28",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d37d4ade-1d71-4fdc-8c93-e835a95873d8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Sample Tensor: tensor([[ 13.0000,  13.0000,  13.0000,   0.0000,  13.0000,  13.0000,  13.0000,\n",
      "          13.0000, -76.0000, -76.0000, -81.0000, -76.0000, -78.5000, -76.0000,\n",
      "         -76.0000,  -7.0000,  -7.0000, -12.0000,  -7.0000,  -9.5000,  -7.0000,\n",
      "          -7.0000,  12.0000,  12.0000,   7.0000,  12.0000,   9.5000,  12.0000,\n",
      "          12.0000]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MlemModel(location=Location(path='/home/jovyan/mlops-workflow/local/models/youtubegoes5g.mlem', project=None, rev=None, uri='file:///home/jovyan/mlops-workflow/local/models/youtubegoes5g.mlem', project_uri=None, fs=<fsspec.implementations.local.LocalFileSystem object at 0x7f22afe91590>), params={}, artifacts={'data': LocalArtifact(uri='youtubegoes5g', size=110792, hash='74ba0722cab958b5bc4f9661ce0c851d')}, requirements=Requirements(__root__=[InstallableRequirement(module='torch', version='2.3.0', package_name=None, extra_index='https://download.pytorch.org/whl/cpu', source_url=None, vcs=None, vcs_commit=None)]), processors_cache={'model': TorchModel(model=InterruptionModel(\n",
       "  (layer_1): Linear(in_features=29, out_features=200, bias=True)\n",
       "  (layer_2): Linear(in_features=200, out_features=100, bias=True)\n",
       "  (layer_3): Linear(in_features=100, out_features=1, bias=True)\n",
       "  (relu): ReLU()\n",
       "), io=TorchModelIO(is_jit=False), methods={'__call__': Signature(name='__call__', args=[], returns=TorchTensorDataType(value=None, shape=(None, 1), dtype='float32'), varargs='args', varargs_type=TorchTensorDataType(value=None, shape=(None, 29), dtype='float32'), varkw='kwargs', varkw_type=None)})}, call_orders={'__call__': [('model', '__call__')]})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mlem.api import import_object, save\n",
    "import torch\n",
    "from torch import nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# Build model with non-linear activation function\n",
    "class InterruptionModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer_1 = nn.Linear(in_features=29, out_features=200)\n",
    "        self.layer_2 = nn.Linear(in_features=200, out_features=100)\n",
    "        self.layer_3 = nn.Linear(in_features=100, out_features=1)\n",
    "        self.relu = nn.ReLU() # <- add in ReLU activation function\n",
    "        # Can also put sigmoid in the model\n",
    "        # This would mean you don't need to use it on the predictions\n",
    "        # self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Intersperse the ReLU activation function between layers\n",
    "        return self.layer_3(self.relu(self.layer_2(self.relu(self.layer_1(x)))))\n",
    "        \n",
    "path_to_pt = \"../model-archiver/model-store/youtubegoes5g/model.pt\"\n",
    "\n",
    "model = InterruptionModel()\n",
    "model.load_state_dict(torch.load(path_to_pt, weights_only=True))\n",
    "model.eval()\n",
    "\n",
    "# Step 1: Read the CSV file and drop the specified columns\n",
    "sample = pd.read_csv('../data/external/dataset.csv', nrows=1).drop(columns=['Stall', 'ID', 'Quality', 'Time'], errors='ignore')\n",
    "\n",
    "# Step 2: Replace ' ', '-', and np.nan with 0\n",
    "sample = sample.replace([' ', '-', np.nan], 0)\n",
    "\n",
    "# Convert all columns to float \n",
    "sample = sample.astype(float)\n",
    "\n",
    "# Step 3: Extract the first sample as a NumPy array without the column names\n",
    "first_sample = sample.values#.flatten()  # Use flatten() to get a 1D array\n",
    "\n",
    "# Step 4: Convert the first sample to a PyTorch tensor\n",
    "first_sample_tensor = torch.tensor(first_sample, dtype=torch.float32)\n",
    "\n",
    "# Display the tensor\n",
    "print(\"First Sample Tensor:\", first_sample_tensor)\n",
    "\n",
    "save(model, \"models/youtubegoes5g\", sample_data=first_sample_tensor)\n",
    "\n",
    "#model = import_object(path=\"../model-archiver/model-store/youtubegoes5g/model.pt\", target=\"models/youtubegoes5g.mlem\", type_=\"pickle\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7bb6e51c-ee4b-4416-8cdb-c9024b6851c3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stall Value: No\n",
      "First Sample Tensor: tensor([ 13.0000,  13.0000,  13.0000,   0.0000,  13.0000,  13.0000,  13.0000,\n",
      "         13.0000, -76.0000, -76.0000, -81.0000, -76.0000, -78.5000, -76.0000,\n",
      "        -76.0000,  -7.0000,  -7.0000, -12.0000,  -7.0000,  -9.5000,  -7.0000,\n",
      "         -7.0000,  12.0000,  12.0000,   7.0000,  12.0000,   9.5000,  12.0000,\n",
      "         12.0000])\n"
     ]
    }
   ],
   "source": [
    "from mlem.api import load\n",
    "\n",
    "model = load(\"models/youtubegoes5g\")  # RandomForestClassifier\n",
    "\n",
    "# Step 1: Read the first row of the CSV file\n",
    "sample = pd.read_csv('../data/external/dataset.csv', nrows=1)\n",
    "\n",
    "# Capture the value of the 'Stall' column before dropping it\n",
    "stall_value = sample['Stall'].values[0] if 'Stall' in sample.columns else None\n",
    "print(\"Stall Value:\", stall_value)\n",
    "\n",
    "# Step 2: Drop the 'Stall', 'ID', 'Quality', and 'Time' columns\n",
    "sample = sample.drop(columns=['Stall', 'ID', 'Quality', 'Time'], errors='ignore')\n",
    "\n",
    "# Step 3: Replace ' ', '-', and np.nan with 0\n",
    "sample = sample.replace([' ', '-', np.nan], 0)\n",
    "\n",
    "# Convert all columns to float\n",
    "sample = sample.astype(float)\n",
    "\n",
    "# Step 4: Extract the first sample as a NumPy array without the column names\n",
    "first_sample = sample.values.flatten()  # Use flatten() to get a 1D array\n",
    "\n",
    "# Step 5: Convert the first sample to a PyTorch tensor\n",
    "first_sample_tensor = torch.tensor(first_sample, dtype=torch.float32)\n",
    "\n",
    "# Display the tensor\n",
    "print(\"First Sample Tensor:\", first_sample_tensor)\n",
    "\n",
    "#y_pred = model.forward(first_sample_tensor)\n",
    "\n",
    "#y_logits = model(first_sample_tensor).squeeze()\n",
    "\n",
    "#y_pred = torch.round(torch.sigmoid(y_logits))\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0db1a51d-0bda-4bc5-906f-bfff90ca0f8b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Stall\n",
      "1.45 ms ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -r 1 -n 1\n",
    "with torch.no_grad():\n",
    "    y_pred = torch.round(torch.sigmoid(model(first_sample_tensor))).squeeze()\n",
    "\n",
    "if device == \"cuda\":\n",
    "    prediction = y_pred.cpu().numpy() #if it is cuda, then this, otherwise y_pred.numpy()\n",
    "else:\n",
    "    prediction = y_pred.numpy()\n",
    "\n",
    "if prediction == 0:\n",
    "    result = \"No Stall\"\n",
    "elif prediction == 1:\n",
    "    result = \"Stall\"\n",
    "    \n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aca4329-b6b5-4b25-8491-f95128cd63ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from env file\n",
    "load_dotenv('env')\n",
    "\n",
    "# Github variables\n",
    "GITHUB_USERNAME = os.getenv(\"GITHUB_USERNAME\")\n",
    "GITHUB_TOKEN = os.getenv(\"GITHUB_TOKEN\")\n",
    "GITHUB_REPO_URL = \"https://github.com/danilonicioka/mlops-workflow.git\"\n",
    "GITHUB_CLONED_DIR = \"mlops-workflow\"\n",
    "GITHUB_DVC_BRANCH = \"dvc\"\n",
    "GITHUB_MAIN_BRANCH = \"main\"\n",
    "\n",
    "# Kubeflow variables\n",
    "# KUBEFLOW_PIPELINE_NAME = \"mlops\"\n",
    "# KUBEFLOW_HOST_URL = \"http://ml-pipeline.kubeflow:8888\"  # KFP host URL\n",
    "# KUBEFLOW_PIPELINE_ID=\"7451916e-eee8-4c14-ad5f-8dee5aa61e3b\"\n",
    "# with open(os.environ['KF_PIPELINES_SA_TOKEN_PATH'], \"r\") as f:\n",
    "#     KUBEFLOW_TOKEN = f.read()\n",
    "\n",
    "# DVC variables\n",
    "DVC_REMOTE_DB = \"minio_remote\"\n",
    "DVC_REMOTE_DB_URL = \"s3://dvc-data\"\n",
    "DVC_FILE_DIR = 'data/external'\n",
    "DVC_FILE_NAME = 'dataset.csv'\n",
    "\n",
    "# MinIO variables\n",
    "MINIO_URL = \"minio-service.kubeflow:9000\"\n",
    "MINIO_ACCESS_KEY = os.getenv(\"MINIO_ACCESS_KEY\")\n",
    "MINIO_SECRET_KEY = os.getenv(\"MINIO_SECRET_KEY\")\n",
    "MINIO_MODEL_BUCKET_NAME = \"model-files\"\n",
    "MINIO_MODEL_OBJECT_NAME = \"model-store/youtubegoes5g/model.pt\"\n",
    "\n",
    "# Triggers variables\n",
    "TRIGGER_TYPE = '1'\n",
    "PERFORMANCE_FACTOR = 0.05\n",
    "# Temp dir and files to save accuracy for trigger 3\n",
    "TEMP_DIR = \"tmp\"\n",
    "TEMP_FILE_ACC_IN_LAST_RUN = \"accuracy_in_last_run.txt\"\n",
    "LAST_ACC_OBJECT_NAME = \"accuracy-score/last_acc.txt\"\n",
    "\n",
    "# Model variables\n",
    "MODEL_LR = 0.0001\n",
    "MODEL_EPOCHS = 3500\n",
    "MODEL_PRINT_FREQUENCY_PER_N_EPOCHS = 500\n",
    "MODEL_NAME = \"youtubegoes5g\"\n",
    "\n",
    "# Kserve variables\n",
    "#MODEL_FRAMEWORK = \"pytorch\"\n",
    "KSERVE_NAMESPACE = \"kubeflow-user-example-com\"\n",
    "KSERVE_SVC_ACC = \"sa-minio-kserve\"\n",
    "#MODEL_URI = \"pvc://model-store-claim\"\n",
    "#MODEL_URI = \"minio-service.kubeflow:9000/model-files\"\n",
    "\n",
    "# Model archiver gen vars\n",
    "MODEL_STORE_POD_NAME = \"model-store-pod\"\n",
    "MODEL_STORE_POD_CONTAINER_NAME = \"model-store\"\n",
    "MAR_POD_NAME = \"margen-pod\"\n",
    "MAR_POD_CONTAINER_NAME = \"margen-container\"\n",
    "MAR_OBJECT_NAME = \"model-store/youtubegoes5g.mar\"\n",
    "K8S_API_TOKEN = os.getenv(\"K8S_API_TOKEN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Successfully downloaded file from https://raw.githubusercontent.com/razaulmustafa852/youtubegoes5g/main/Models/Stall-Windows%20-%20Stall-3s.csv to dataset.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "import logging\n",
    "# Setup logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "MODEL_INIT_DATASET_URL = 'https://raw.githubusercontent.com/razaulmustafa852/youtubegoes5g/main/Models/Stall-Windows%20-%20Stall-3s.csv'\n",
    "\n",
    "file_url = MODEL_INIT_DATASET_URL\n",
    "local_file_path = DVC_FILE_NAME\n",
    "\n",
    "try:\n",
    "    # Request the file content\n",
    "    response = requests.get(file_url)\n",
    "    response.raise_for_status()\n",
    "\n",
    "    # Save the file content locally\n",
    "    with open(local_file_path, 'wb') as local_file:\n",
    "        local_file.write(response.content)\n",
    "    logger.info(f\"Successfully downloaded file from {file_url} to {local_file_path}\")\n",
    "except requests.RequestException as e:\n",
    "    # Log and raise any download errors\n",
    "    logger.error(f\"Failed to download file: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | Loss: 0.69065, Accuracy: 49.38% | Test Loss: 0.68069, Test Accuracy: 52.48%\n",
      "Epoch: 500 | Loss: 0.47073, Accuracy: 77.33% | Test Loss: 0.49445, Test Accuracy: 75.89%\n",
      "Epoch: 1000 | Loss: 0.35729, Accuracy: 84.21% | Test Loss: 0.43325, Test Accuracy: 80.71%\n",
      "Epoch: 1500 | Loss: 0.24109, Accuracy: 91.17% | Test Loss: 0.40143, Test Accuracy: 84.11%\n",
      "Epoch: 2000 | Loss: 0.16294, Accuracy: 95.28% | Test Loss: 0.41717, Test Accuracy: 84.96%\n",
      "Epoch: 2500 | Loss: 0.11604, Accuracy: 96.81% | Test Loss: 0.45718, Test Accuracy: 84.40%\n",
      "Epoch: 3000 | Loss: 0.08478, Accuracy: 97.87% | Test Loss: 0.50607, Test Accuracy: 84.68%\n",
      "=== Confusion Matrix ===\n",
      "[[308  62]\n",
      " [ 36 299]]\n",
      "\n",
      "\n",
      "=== Score ===\n",
      "Accuracy: 0.860993\n",
      "Precision: 0.863467\n",
      "Recall: 0.860993\n",
      "Micro F1 score: 0.860993\n",
      "Macro F1 score: 0.860970\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    No-Stall       0.90      0.83      0.86       370\n",
      "       Stall       0.83      0.89      0.86       335\n",
      "\n",
      "    accuracy                           0.86       705\n",
      "   macro avg       0.86      0.86      0.86       705\n",
      "weighted avg       0.86      0.86      0.86       705\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from mlem.api import save\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "\n",
    "# load data\n",
    "df = pd.read_csv(local_file_path)\n",
    "\n",
    "df = df.replace([' ', '-',np.nan], np.nan)\n",
    "\n",
    "# Selective columns for mean calculation\n",
    "columns_to_convert = ['CQI1', 'CQI2', 'CQI3', 'cSTD CQI',\n",
    "       'cMajority', 'c25 P', 'c50 P', 'c75 P', 'RSRP1', 'RSRP2', 'RSRP3',\n",
    "       'pMajority', 'p25 P', 'p50 P', 'p75 P', 'RSRQ1', 'RSRQ2', 'RSRQ3',\n",
    "       'qMajority', 'q25 P', 'q50 P', 'q75 P', 'SNR1', 'SNR2', 'SNR3',\n",
    "       'sMajority', 's25 P', 's50 P', 's75 P']\n",
    "df[columns_to_convert] = df[columns_to_convert].astype(float)\n",
    "\n",
    "# Replace np.nan with mean values for selective columns\n",
    "df[columns_to_convert] = df[columns_to_convert].fillna(df[columns_to_convert].mean())\n",
    "\n",
    "df['Stall'].replace('Yes', 1, inplace=True)\n",
    "df['Stall'].replace('No', 0, inplace=True)\n",
    "\n",
    "X = df[['CQI1', 'CQI2', 'CQI3', 'cSTD CQI',\n",
    "       'cMajority', 'c25 P', 'c50 P', 'c75 P', 'RSRP1', 'RSRP2', 'RSRP3',\n",
    "       'pMajority', 'p25 P', 'p50 P', 'p75 P', 'RSRQ1', 'RSRQ2', 'RSRQ3',\n",
    "       'qMajority', 'q25 P', 'q50 P', 'q75 P', 'SNR1', 'SNR2', 'SNR3',\n",
    "       'sMajority', 's25 P', 's50 P', 's75 P']].values\n",
    "\n",
    "y = df['Stall'].values\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "oversample = SMOTE()\n",
    "X, y = oversample.fit_resample(X, y)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "X = torch.from_numpy(X).type(torch.float32)\n",
    "y = torch.from_numpy(y).type(torch.float32)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=42\n",
    ")\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Build model with non-linear activation function\n",
    "from torch import nn\n",
    "class InteruptionModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer_1 = nn.Linear(in_features=29, out_features=200)\n",
    "        self.layer_2 = nn.Linear(in_features=200, out_features=100)\n",
    "        self.layer_3 = nn.Linear(in_features=100, out_features=1)\n",
    "        self.relu = nn.ReLU() # <- add in ReLU activation function\n",
    "        # Can also put sigmoid in the model\n",
    "        # This would mean you don't need to use it on the predictions\n",
    "        # self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "      # Intersperse the ReLU activation function between layers\n",
    "       return self.layer_3(self.relu(self.layer_2(self.relu(self.layer_1(x)))))\n",
    "\n",
    "model = InteruptionModel().to(device)\n",
    "\n",
    "# Setup loss and optimizer\n",
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "def accuracy_fn(y_true, y_pred):\n",
    "    correct = torch.eq(y_true, y_pred).sum().item() # torch.eq() calculates where two tensors are equal\n",
    "    acc = (correct / len(y_pred)) * 100\n",
    "    return acc\n",
    "\n",
    "# Fit the model\n",
    "torch.manual_seed(42)\n",
    "epochs = 3500\n",
    "\n",
    "# Put all data on target device\n",
    "X_train, y_train = X_train.to(device), y_train.to(device)\n",
    "X_test, y_test = X_test.to(device), y_test.to(device)\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # 1. Forward pass\n",
    "    y_logits = model(X_train).squeeze()\n",
    "\n",
    "    y_pred = torch.round(torch.sigmoid(y_logits)) # logits -> prediction probabilities -> prediction labels\n",
    "\n",
    "    # 2. Calculate loss and accuracy\n",
    "    loss = loss_fn(y_logits, y_train) # BCEWithLogitsLoss calculates loss using logits\n",
    "    acc = accuracy_fn(y_true=y_train,\n",
    "                      y_pred=y_pred)\n",
    "\n",
    "    # 3. Optimizer zero grad\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # 4. Loss backward\n",
    "    loss.backward()\n",
    "\n",
    "    # 5. Optimizer step\n",
    "    optimizer.step()\n",
    "\n",
    "    ### Testing\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "      # 1. Forward pass\n",
    "        test_logits = model(X_test).squeeze()\n",
    "        #print(test_logits.shape)\n",
    "        test_pred = torch.round(torch.sigmoid(test_logits)) # logits -> prediction probabilities -> prediction labels\n",
    "        # 2. Calcuate loss and accuracy\n",
    "        test_loss = loss_fn(test_logits, y_test)\n",
    "        test_acc = accuracy_fn(y_true=y_test,\n",
    "                             y_pred=test_pred)\n",
    "\n",
    "\n",
    "    # Print out what's happening\n",
    "    if epoch % 500 == 0:\n",
    "        print(f\"Epoch: {epoch} | Loss: {loss:.5f}, Accuracy: {acc:.2f}% | Test Loss: {test_loss:.5f}, Test Accuracy: {test_acc:.2f}%\")\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "     y_preds = torch.round(torch.sigmoid(model(X_test))).squeeze()\n",
    "\n",
    "if device == \"cuda\":\n",
    "  predictions = y_preds.cpu().numpy() #if it is cuda, then this, otherwise y_pred.numpy()\n",
    "  true_labels = y_test.cpu().numpy()\n",
    "else:\n",
    "  predictions = y_preds.numpy()\n",
    "  true_labels = y_test.numpy()\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score,fbeta_score\n",
    "\n",
    "print(\"=== Confusion Matrix ===\")\n",
    "print(confusion_matrix(true_labels, predictions))\n",
    "print('\\n')\n",
    "\n",
    "\n",
    "print(\"=== Score ===\")\n",
    "accuracy = accuracy_score(true_labels, predictions)\n",
    "print('Accuracy: %f' % accuracy)\n",
    "\n",
    "precision = precision_score(true_labels,  predictions, average='weighted')\n",
    "print('Precision: %f' % precision)\n",
    "recall = recall_score(true_labels, predictions, average='weighted')\n",
    "print('Recall: %f' % recall)\n",
    "\n",
    "microf1 = f1_score(true_labels, predictions, average='micro')\n",
    "print('Micro F1 score: %f' % microf1)\n",
    "macrof1 = f1_score(true_labels, predictions, average='macro')\n",
    "print('Macro F1 score: %f' % macrof1)\n",
    "\n",
    "target_names = ['No-Stall', 'Stall']\n",
    "# Print precision-recall report\n",
    "print(classification_report(true_labels, predictions, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save model\n",
    "model_path = \"model.pt\"\n",
    "torch.save(model.state_dict(), model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

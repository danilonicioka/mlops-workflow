2024-12-14T17:29:45,214 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Received data: [{'data': [13, 13, 13, 0, 13, 13, 13, 13, -76, -76, -81, -76, -78.5, -76, -76, -7, -7, -12, -7, -9.5, -7, -7, 12, 12, 7, 12, 9.5, 12, 12]}]
2024-12-14T17:29:45,215 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Input data preprocessed successfully
2024-12-14T17:29:45,219 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Inference performed successfully
2024-12-14T17:29:45,220 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Output postprocessed successfully
2024-12-14T17:29:45,220 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:5.5|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,1734197385,382be552-5475-4caf-8046-d904af31797a, pattern=[METRICS]
2024-12-14T17:29:45,220 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_METRICS - PredictionTime.ms:5.5|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,requestID:382be552-5475-4caf-8046-d904af31797a,timestamp:1734197385
2024-12-14T17:29:45,220 [INFO ] W-9000-youtubegoes5g_1.0 ACCESS_LOG - /127.0.0.1:40190 "POST /v1/models/youtubegoes5g:predict HTTP/1.1" 200 8
2024-12-14T17:29:45,221 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1734197385
2024-12-14T17:29:45,221 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:7764.01|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1734197385
2024-12-14T17:29:45,221 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:200.329|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1734197385
2024-12-14T17:29:45,221 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.job.Job - Waiting time ns: 200329, Backend time ns: 8373683
2024-12-14T17:29:45,221 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1734197385
2024-12-14T17:29:45,221 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2024-12-14T17:29:45,221 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 7
2024-12-14T17:29:45,221 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1734197385
2024-12-14T17:29:45,254 [INFO ] epollEventLoopGroup-3-1 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1734197385
2024-12-14T17:29:45,255 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1734197385255
2024-12-14T17:29:45,255 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Backend received inference at: 1734197385
2024-12-14T17:29:45,256 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Received data: [{'data': [13, 13, 12, 0.4714045208, 13, 12.5, 13, 13, -81, -81, -82, -81, -81.5, -81, -81, -12, -12, -11, -12, -12, -12, -11.5, 7, 7, 2, 7, 4.5, 7, 7]}]
2024-12-14T17:29:45,256 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Input data preprocessed successfully
2024-12-14T17:29:45,257 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Inference performed successfully
2024-12-14T17:29:45,257 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Output postprocessed successfully
2024-12-14T17:29:45,257 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:1.85|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,1734197385,d00cea78-3712-4ff8-80e9-806aa028f6ea, pattern=[METRICS]
2024-12-14T17:29:45,258 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_METRICS - PredictionTime.ms:1.85|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,requestID:d00cea78-3712-4ff8-80e9-806aa028f6ea,timestamp:1734197385
2024-12-14T17:29:45,258 [INFO ] W-9000-youtubegoes5g_1.0 ACCESS_LOG - /127.0.0.1:40194 "POST /v1/models/youtubegoes5g:predict HTTP/1.1" 200 4
2024-12-14T17:29:45,258 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1734197385
2024-12-14T17:29:45,258 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:3546.518|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1734197385
2024-12-14T17:29:45,258 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:116.621|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1734197385
2024-12-14T17:29:45,259 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.job.Job - Waiting time ns: 116621, Backend time ns: 4025642
2024-12-14T17:29:45,259 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1734197385
2024-12-14T17:29:45,259 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2024-12-14T17:29:45,259 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3
2024-12-14T17:29:45,259 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1734197385
2024-12-14T17:29:45,284 [INFO ] epollEventLoopGroup-3-2 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1734197385
2024-12-14T17:29:45,284 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1734197385284
2024-12-14T17:29:45,285 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Backend received inference at: 1734197385
2024-12-14T17:29:45,285 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Received data: [{'data': [6, 7, 7, 0.4714045208, 7, 6.5, 7, 7, -107, -106, -106, -106, -106.5, -106, -106, -13, -14, -14, -14, -14, -14, -13.5, 2, 2, 2, 2, 2, 2, 2]}]
2024-12-14T17:29:45,286 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Input data preprocessed successfully
2024-12-14T17:29:45,286 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Inference performed successfully
2024-12-14T17:29:45,287 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Output postprocessed successfully
2024-12-14T17:29:45,287 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:1.29|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,1734197385,d9621895-e6f7-4dd2-b4d7-00af839024be, pattern=[METRICS]
2024-12-14T17:29:45,287 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_METRICS - PredictionTime.ms:1.29|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,requestID:d9621895-e6f7-4dd2-b4d7-00af839024be,timestamp:1734197385
2024-12-14T17:29:45,287 [INFO ] W-9000-youtubegoes5g_1.0 ACCESS_LOG - /127.0.0.1:40202 "POST /v1/models/youtubegoes5g:predict HTTP/1.1" 200 3
2024-12-14T17:29:45,287 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1734197385
2024-12-14T17:29:45,287 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:2817.969|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1734197385
2024-12-14T17:29:45,288 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:159.266|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1734197385
2024-12-14T17:29:45,288 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.job.Job - Waiting time ns: 159266, Backend time ns: 3362380
2024-12-14T17:29:45,288 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1734197385
2024-12-14T17:29:45,288 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2024-12-14T17:29:45,288 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2
2024-12-14T17:29:45,288 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:2.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1734197385
2024-12-14T17:29:45,311 [INFO ] epollEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1734197385
2024-12-14T17:29:45,311 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT to backend at: 1734197385311
2024-12-14T17:29:45,312 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Backend received inference at: 1734197385
2024-12-14T17:29:45,312 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Received data: [{'data': [8, 8, 8, 0, 8, 8, 8, 8, -108, -108, -108, -108, -108, -108, -108, -13, -13, -13, -13, -13, -13, -13, 2, 2, 2, 2, 2, 2, 2]}]
2024-12-14T17:29:45,313 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Input data preprocessed successfully
2024-12-14T17:29:45,313 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Inference performed successfully
2024-12-14T17:29:45,313 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Output postprocessed successfully
2024-12-14T17:29:45,313 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:1.14|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,1734197385,4bb43d83-0fd2-452b-8635-e3b57751cdbc, pattern=[METRICS]
2024-12-14T17:29:45,314 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_METRICS - PredictionTime.ms:1.14|#ModelName:youtubegoes5g,Level:Model|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,requestID:4bb43d83-0fd2-452b-8635-e3b57751cdbc,timestamp:1734197385
2024-12-14T17:29:45,314 [INFO ] W-9000-youtubegoes5g_1.0 ACCESS_LOG - /127.0.0.1:40208 "POST /v1/models/youtubegoes5g:predict HTTP/1.1" 200 3
2024-12-14T17:29:45,314 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1734197385
2024-12-14T17:29:45,314 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:2550.871|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1734197385
2024-12-14T17:29:45,314 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:137.431|#model_name:youtubegoes5g,model_version:default|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1734197385
2024-12-14T17:29:45,314 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.job.Job - Waiting time ns: 137431, Backend time ns: 3171374
2024-12-14T17:29:45,314 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1734197385
2024-12-14T17:29:45,314 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - sent a reply, jobdone: true
2024-12-14T17:29:45,314 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1
2024-12-14T17:29:45,315 [INFO ] W-9000-youtubegoes5g_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:3.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-79494b89b5-6qkqc,timestamp:1734197385

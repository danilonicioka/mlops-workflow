WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.
2024-11-08T01:12:42,697 [WARN ] main org.pytorch.serve.util.ConfigManager - Your torchserve instance can access any URL to load models. When deploying to production, make sure to limit the set of allowed_urls in config.properties
2024-11-08T01:12:42,700 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2024-11-08T01:12:42,968 [INFO ] main org.pytorch.serve.metrics.configuration.MetricConfiguration - Successfully loaded metrics configuration from /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml
2024-11-08T01:12:43,192 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.8.2
TS Home: /home/venv/lib/python3.9/site-packages
Current directory: /home/model-server
Temp directory: /home/model-server/tmp
Metrics config path: /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml
Number of GPUs: 0
Number of CPUs: 1
Max heap size: 494 M
Python executable: /home/venv/bin/python
Config file: /mnt/models/config/config.properties
Inference address: http://0.0.0.0:8085
Management address: http://0.0.0.0:8085
Metrics address: http://0.0.0.0:8082
Model Store: /mnt/models/model-store
Initial Models: N/A
Log dir: /home/model-server/logs
Metrics dir: /home/model-server/logs
Netty threads: 4
Netty client threads: 0
Default workers per model: 1
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: true
Enable metrics API: true
Metrics mode: log
Disable system metrics: false
Workflow Store: /mnt/models/model-store
Model config: N/A
2024-11-08T01:12:43,267 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2024-11-08T01:12:43,291 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Started restoring models from snapshot {"name":"startup.cfg","modelCount":1,"models":{"youtubegoes5g":{"1.0":{"defaultVersion":true,"marName":"youtubegoes5g.mar","minWorkers":1,"maxWorkers":5,"batchSize":1,"maxBatchDelay":10,"responseTimeout":120}}}}
2024-11-08T01:12:43,300 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Validating snapshot startup.cfg
2024-11-08T01:12:43,301 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Snapshot startup.cfg validated successfully
2024-11-08T01:12:43,481 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model youtubegoes5g
2024-11-08T01:12:43,482 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model youtubegoes5g
2024-11-08T01:12:43,482 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model youtubegoes5g
2024-11-08T01:12:43,482 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model youtubegoes5g loaded.
2024-11-08T01:12:43,483 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: youtubegoes5g, count: 1
2024-11-08T01:12:43,624 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9000, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2024-11-08T01:12:43,625 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.
2024-11-08T01:12:44,084 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://0.0.0.0:8085
2024-11-08T01:12:44,085 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.
2024-11-08T01:12:44,086 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://0.0.0.0:8082
Model server started.
2024-11-08T01:12:45,365 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
INFO:root:Wrapper : Model names ['youtubegoes5g'], inference address http://0.0.0.0:8085, management address http://0.0.0.0:8085, grpc_inference_address, 0.0.0.0:7070, model store /mnt/models/model-store
INFO:root:Predict URL set to 0.0.0.0:8085
INFO:root:Explain URL set to 0.0.0.0:8085
INFO:root:Protocol version is v1
INFO:root:Copying contents of /mnt/models/model-store to local
INFO:root:TSModelRepo is initialized
INFO:kserve:Registering model: youtubegoes5g
INFO:kserve:Setting max asyncio worker threads as 10
2024-11-08T01:12:45,565 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-f7df47f88-rkzmm,timestamp:1731028365
INFO:kserve:Starting uvicorn with 1 workers
2024-11-08T01:12:45,567 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:326.0216484069824|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-f7df47f88-rkzmm,timestamp:1731028365
2024-11-08T01:12:45,567 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:145.98161697387695|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-f7df47f88-rkzmm,timestamp:1731028365
2024-11-08T01:12:45,567 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:30.9|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-f7df47f88-rkzmm,timestamp:1731028365
2024-11-08T01:12:45,568 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:13336.77734375|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-f7df47f88-rkzmm,timestamp:1731028365
2024-11-08T01:12:45,568 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:6283.1640625|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-f7df47f88-rkzmm,timestamp:1731028365
2024-11-08T01:12:45,568 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:33.2|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-f7df47f88-rkzmm,timestamp:1731028365
2024-11-08 01:12:45.910 uvicorn.error INFO:     Started server process [10]
2024-11-08 01:12:45.910 uvicorn.error INFO:     Waiting for application startup.
2024-11-08 01:12:46.069 10 kserve INFO [start():62] Starting gRPC server on [::]:8081
2024-11-08 01:12:46.070 uvicorn.error INFO:     Application startup complete.
2024-11-08 01:12:46.071 uvicorn.error INFO:     Uvicorn running on http://0.0.0.0:8080 (Press CTRL+C to quit)
2024-11-08T01:12:52,335 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9000, pid=31
2024-11-08T01:12:52,336 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9000
2024-11-08T01:12:52,352 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Successfully loaded /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2024-11-08T01:12:52,352 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - [PID]31
2024-11-08T01:12:52,353 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Torch worker started.
2024-11-08T01:12:52,358 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Python runtime: 3.9.18
2024-11-08T01:12:52,358 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-youtubegoes5g_1.0 State change null -> WORKER_STARTED
2024-11-08T01:12:52,374 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9000
2024-11-08T01:12:52,387 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9000.
2024-11-08T01:12:52,390 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD to backend at: 1731028372390
2024-11-08T01:12:52,501 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - model_name: youtubegoes5g, batchSize: 1
2024-11-08T01:12:53,901 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Backend worker process died.
2024-11-08T01:12:53,901 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2024-11-08T01:12:53,901 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG -   File "/home/venv/lib/python3.9/site-packages/ts/model_service_worker.py", line 253, in <module>
2024-11-08T01:12:53,902 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG -     worker.run_server()
2024-11-08T01:12:53,902 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG -   File "/home/venv/lib/python3.9/site-packages/ts/model_service_worker.py", line 221, in run_server
2024-11-08T01:12:53,902 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2024-11-08T01:12:53,902 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG -   File "/home/venv/lib/python3.9/site-packages/ts/model_service_worker.py", line 184, in handle_connection
2024-11-08T01:12:53,903 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2024-11-08T01:12:53,903 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG -   File "/home/venv/lib/python3.9/site-packages/ts/model_service_worker.py", line 131, in load_model
2024-11-08T01:12:53,903 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG -     service = model_loader.load(
2024-11-08T01:12:53,904 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG -   File "/home/venv/lib/python3.9/site-packages/ts/model_loader.py", line 117, in load
2024-11-08T01:12:53,904 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG -     entry_point, initialize_fn = self._get_class_entry_point(module)
2024-11-08T01:12:53,904 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG -   File "/home/venv/lib/python3.9/site-packages/ts/model_loader.py", line 170, in _get_class_entry_point
2024-11-08T01:12:53,905 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG -     raise ValueError(
2024-11-08T01:12:53,905 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - ValueError: Expected only one class in custom service code or a function entry point [<class 'custom_handler.InterruptionModel'>, <class 'custom_handler.KServeModelHandler'>]
2024-11-08T01:12:53,907 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2024-11-08T01:12:53,909 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2024-11-08T01:12:53,909 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:435) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:213) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2024-11-08T01:12:53,976 [WARN ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: youtubegoes5g, error: Worker died.
2024-11-08T01:12:53,976 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-youtubegoes5g_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2024-11-08T01:12:53,977 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery start timestamp: 1731028373977
2024-11-08T01:12:53,978 [WARN ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-youtubegoes5g_1.0-stderr
2024-11-08T01:12:53,978 [WARN ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-youtubegoes5g_1.0-stdout
2024-11-08T01:12:53,979 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2024-11-08T01:12:53,997 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-youtubegoes5g_1.0-stdout
2024-11-08T01:12:53,997 [INFO ] W-9000-youtubegoes5g_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-youtubegoes5g_1.0-stderr
2024-11-08T01:12:54,980 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9000, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2024-11-08T01:12:56,727 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9000, pid=60
2024-11-08T01:12:56,729 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9000
2024-11-08T01:12:56,740 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Successfully loaded /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2024-11-08T01:12:56,741 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - [PID]60
2024-11-08T01:12:56,741 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Torch worker started.
2024-11-08T01:12:56,741 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Python runtime: 3.9.18
2024-11-08T01:12:56,741 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-youtubegoes5g_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2024-11-08T01:12:56,741 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9000
2024-11-08T01:12:56,743 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2024-11-08T01:12:56,743 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2024-11-08T01:12:56,743 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer.tryAcquireSharedNanos(AbstractQueuedSynchronizer.java:1081) ~[?:?]
	at java.util.concurrent.CountDownLatch.await(CountDownLatch.java:276) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.connect(WorkerThread.java:415) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:183) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2024-11-08T01:12:56,744 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-youtubegoes5g_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2024-11-08T01:12:56,744 [WARN ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2024-11-08T01:12:56,745 [WARN ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-youtubegoes5g_1.0-stderr
2024-11-08T01:12:56,745 [WARN ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-youtubegoes5g_1.0-stdout
2024-11-08T01:12:56,745 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2024-11-08T01:12:56,767 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-youtubegoes5g_1.0-stdout
2024-11-08T01:12:56,767 [INFO ] W-9000-youtubegoes5g_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-youtubegoes5g_1.0-stderr
2024-11-08T01:12:56,776 [ERROR] epollEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - Unknown exception
io.netty.channel.unix.Errors$NativeIoException: readAddress(..) failed: Connection reset by peer
2024-11-08T01:12:57,746 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9000, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2024-11-08T01:12:59,493 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9000, pid=69
2024-11-08T01:12:59,495 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9000
2024-11-08T01:12:59,505 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Successfully loaded /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2024-11-08T01:12:59,505 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - [PID]69
2024-11-08T01:12:59,505 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Torch worker started.
2024-11-08T01:12:59,506 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Python runtime: 3.9.18
2024-11-08T01:12:59,506 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-youtubegoes5g_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2024-11-08T01:12:59,506 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9000
2024-11-08T01:12:59,507 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2024-11-08T01:12:59,507 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9000.
2024-11-08T01:12:59,507 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2024-11-08T01:12:59,508 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer.tryAcquireSharedNanos(AbstractQueuedSynchronizer.java:1081) ~[?:?]
	at java.util.concurrent.CountDownLatch.await(CountDownLatch.java:276) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.connect(WorkerThread.java:415) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:183) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2024-11-08T01:12:59,508 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-youtubegoes5g_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2024-11-08T01:12:59,509 [WARN ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2024-11-08T01:12:59,509 [WARN ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-youtubegoes5g_1.0-stderr
2024-11-08T01:12:59,509 [WARN ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-youtubegoes5g_1.0-stdout
2024-11-08T01:12:59,509 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 2 seconds.
2024-11-08T01:12:59,522 [INFO ] W-9000-youtubegoes5g_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-youtubegoes5g_1.0-stderr
2024-11-08T01:12:59,523 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-youtubegoes5g_1.0-stdout
2024-11-08T01:13:01,510 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9000, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2024-11-08T01:13:03,274 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9000, pid=77
2024-11-08T01:13:03,275 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9000
2024-11-08T01:13:03,291 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Successfully loaded /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2024-11-08T01:13:03,292 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - [PID]77
2024-11-08T01:13:03,292 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Torch worker started.
2024-11-08T01:13:03,293 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Python runtime: 3.9.18
2024-11-08T01:13:03,293 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-youtubegoes5g_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2024-11-08T01:13:03,293 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9000
2024-11-08T01:13:03,294 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2024-11-08T01:13:03,294 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9000.
2024-11-08T01:13:03,294 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2024-11-08T01:13:03,295 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.LinkedBlockingDeque.pollFirst(LinkedBlockingDeque.java:515) ~[?:?]
	at java.util.concurrent.LinkedBlockingDeque.poll(LinkedBlockingDeque.java:677) ~[?:?]
	at org.pytorch.serve.wlm.Model.pollBatch(Model.java:276) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.BatchAggregator.getRequest(BatchAggregator.java:34) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:186) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2024-11-08T01:13:03,295 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-youtubegoes5g_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2024-11-08T01:13:03,295 [WARN ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2024-11-08T01:13:03,295 [WARN ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-youtubegoes5g_1.0-stderr
2024-11-08T01:13:03,296 [WARN ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-youtubegoes5g_1.0-stdout
2024-11-08T01:13:03,296 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 3 seconds.
2024-11-08T01:13:03,311 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-youtubegoes5g_1.0-stdout
2024-11-08T01:13:03,311 [INFO ] W-9000-youtubegoes5g_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-youtubegoes5g_1.0-stderr
2024-11-08T01:13:06,296 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9000, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2024-11-08T01:13:07,979 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9000, pid=85
2024-11-08T01:13:07,980 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9000
2024-11-08T01:13:07,991 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Successfully loaded /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2024-11-08T01:13:07,992 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - [PID]85
2024-11-08T01:13:07,992 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Torch worker started.
2024-11-08T01:13:07,992 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-youtubegoes5g_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2024-11-08T01:13:07,992 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9000
2024-11-08T01:13:07,993 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2024-11-08T01:13:07,993 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2024-11-08T01:13:07,992 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Python runtime: 3.9.18
2024-11-08T01:13:07,993 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.LinkedBlockingDeque.pollFirst(LinkedBlockingDeque.java:515) ~[?:?]
	at java.util.concurrent.LinkedBlockingDeque.poll(LinkedBlockingDeque.java:677) ~[?:?]
	at org.pytorch.serve.wlm.Model.pollBatch(Model.java:276) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.BatchAggregator.getRequest(BatchAggregator.java:34) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:186) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2024-11-08T01:13:07,994 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9000.
2024-11-08T01:13:07,994 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-youtubegoes5g_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2024-11-08T01:13:07,994 [WARN ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2024-11-08T01:13:07,994 [WARN ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-youtubegoes5g_1.0-stderr
2024-11-08T01:13:07,994 [WARN ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-youtubegoes5g_1.0-stdout
2024-11-08T01:13:07,995 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 5 seconds.
2024-11-08T01:13:08,009 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-youtubegoes5g_1.0-stdout
2024-11-08T01:13:08,009 [INFO ] W-9000-youtubegoes5g_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-youtubegoes5g_1.0-stderr
2024-11-08T01:13:12,995 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9000, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2024-11-08T01:13:14,652 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9000, pid=93
2024-11-08T01:13:14,653 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9000
2024-11-08T01:13:14,663 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Successfully loaded /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2024-11-08T01:13:14,663 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - [PID]93
2024-11-08T01:13:14,663 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Torch worker started.
2024-11-08T01:13:14,664 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Python runtime: 3.9.18
2024-11-08T01:13:14,664 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-youtubegoes5g_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2024-11-08T01:13:14,664 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9000
2024-11-08T01:13:14,665 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2024-11-08T01:13:14,665 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9000.
2024-11-08T01:13:14,665 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2024-11-08T01:13:14,665 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.LinkedBlockingDeque.pollFirst(LinkedBlockingDeque.java:515) ~[?:?]
	at java.util.concurrent.LinkedBlockingDeque.poll(LinkedBlockingDeque.java:677) ~[?:?]
	at org.pytorch.serve.wlm.Model.pollBatch(Model.java:276) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.BatchAggregator.getRequest(BatchAggregator.java:34) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:186) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2024-11-08T01:13:14,666 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-youtubegoes5g_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2024-11-08T01:13:14,666 [WARN ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2024-11-08T01:13:14,666 [WARN ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-youtubegoes5g_1.0-stderr
2024-11-08T01:13:14,666 [WARN ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-youtubegoes5g_1.0-stdout
2024-11-08T01:13:14,666 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 8 seconds.
2024-11-08T01:13:14,680 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-youtubegoes5g_1.0-stdout
2024-11-08T01:13:14,681 [INFO ] W-9000-youtubegoes5g_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-youtubegoes5g_1.0-stderr
2024-11-08T01:13:22,667 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9000, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2024-11-08T01:13:24,380 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9000, pid=101
2024-11-08T01:13:24,381 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9000
2024-11-08T01:13:24,391 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Successfully loaded /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2024-11-08T01:13:24,391 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - [PID]101
2024-11-08T01:13:24,391 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Torch worker started.
2024-11-08T01:13:24,391 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-youtubegoes5g_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2024-11-08T01:13:24,392 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Python runtime: 3.9.18
2024-11-08T01:13:24,392 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9000
2024-11-08T01:13:24,393 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2024-11-08T01:13:24,393 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2024-11-08T01:13:24,393 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9000.
2024-11-08T01:13:24,393 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.LinkedBlockingDeque.pollFirst(LinkedBlockingDeque.java:515) ~[?:?]
	at java.util.concurrent.LinkedBlockingDeque.poll(LinkedBlockingDeque.java:677) ~[?:?]
	at org.pytorch.serve.wlm.Model.pollBatch(Model.java:276) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.BatchAggregator.getRequest(BatchAggregator.java:34) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:186) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2024-11-08T01:13:24,394 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-youtubegoes5g_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2024-11-08T01:13:24,394 [WARN ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2024-11-08T01:13:24,394 [WARN ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-youtubegoes5g_1.0-stderr
2024-11-08T01:13:24,394 [WARN ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-youtubegoes5g_1.0-stdout
2024-11-08T01:13:24,394 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 13 seconds.
2024-11-08T01:13:24,410 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-youtubegoes5g_1.0-stdout
2024-11-08T01:13:24,410 [INFO ] W-9000-youtubegoes5g_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-youtubegoes5g_1.0-stderr
2024-11-08T01:13:37,395 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9000, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2024-11-08T01:13:39,051 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9000, pid=109
2024-11-08T01:13:39,052 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9000
2024-11-08T01:13:39,062 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Successfully loaded /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2024-11-08T01:13:39,062 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - [PID]109
2024-11-08T01:13:39,063 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Torch worker started.
2024-11-08T01:13:39,063 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Python runtime: 3.9.18
2024-11-08T01:13:39,065 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-youtubegoes5g_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2024-11-08T01:13:39,065 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9000
2024-11-08T01:13:39,066 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2024-11-08T01:13:39,066 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9000.
2024-11-08T01:13:39,066 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2024-11-08T01:13:39,066 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.LinkedBlockingDeque.pollFirst(LinkedBlockingDeque.java:515) ~[?:?]
	at java.util.concurrent.LinkedBlockingDeque.poll(LinkedBlockingDeque.java:677) ~[?:?]
	at org.pytorch.serve.wlm.Model.pollBatch(Model.java:276) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.BatchAggregator.getRequest(BatchAggregator.java:34) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:186) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2024-11-08T01:13:39,067 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-youtubegoes5g_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2024-11-08T01:13:39,067 [WARN ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2024-11-08T01:13:39,067 [WARN ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-youtubegoes5g_1.0-stderr
2024-11-08T01:13:39,067 [WARN ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-youtubegoes5g_1.0-stdout
2024-11-08T01:13:39,068 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 21 seconds.
2024-11-08T01:13:39,081 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-youtubegoes5g_1.0-stdout
2024-11-08T01:13:39,082 [INFO ] W-9000-youtubegoes5g_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-youtubegoes5g_1.0-stderr
2024-11-08T01:13:45,371 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-f7df47f88-rkzmm,timestamp:1731028425
2024-11-08T01:13:45,372 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:326.0181427001953|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-f7df47f88-rkzmm,timestamp:1731028425
2024-11-08T01:13:45,372 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:145.98512268066406|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-f7df47f88-rkzmm,timestamp:1731028425
2024-11-08T01:13:45,372 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:30.9|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-f7df47f88-rkzmm,timestamp:1731028425
2024-11-08T01:13:45,372 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:13288.8125|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-f7df47f88-rkzmm,timestamp:1731028425
2024-11-08T01:13:45,373 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:6331.13671875|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-f7df47f88-rkzmm,timestamp:1731028425
2024-11-08T01:13:45,373 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:33.5|#Level:Host|#hostname:youtubegoes5g-predictor-00001-deployment-f7df47f88-rkzmm,timestamp:1731028425
2024-11-08T01:14:00,068 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9000, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2024-11-08T01:14:01,748 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9000, pid=119
2024-11-08T01:14:01,748 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9000
2024-11-08T01:14:01,759 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Successfully loaded /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2024-11-08T01:14:01,760 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - [PID]119
2024-11-08T01:14:01,760 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Torch worker started.
2024-11-08T01:14:01,760 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-youtubegoes5g_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2024-11-08T01:14:01,761 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Python runtime: 3.9.18
2024-11-08T01:14:01,761 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9000
2024-11-08T01:14:01,765 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2024-11-08T01:14:01,765 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2024-11-08T01:14:01,765 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9000.
2024-11-08T01:14:01,766 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.LinkedBlockingDeque.pollFirst(LinkedBlockingDeque.java:515) ~[?:?]
	at java.util.concurrent.LinkedBlockingDeque.poll(LinkedBlockingDeque.java:677) ~[?:?]
	at org.pytorch.serve.wlm.Model.pollBatch(Model.java:276) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.BatchAggregator.getRequest(BatchAggregator.java:34) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:186) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2024-11-08T01:14:01,766 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-youtubegoes5g_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2024-11-08T01:14:01,766 [WARN ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2024-11-08T01:14:01,766 [WARN ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-youtubegoes5g_1.0-stderr
2024-11-08T01:14:01,767 [WARN ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-youtubegoes5g_1.0-stdout
2024-11-08T01:14:01,767 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 34 seconds.
2024-11-08T01:14:01,784 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-youtubegoes5g_1.0-stdout
2024-11-08T01:14:01,784 [INFO ] W-9000-youtubegoes5g_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-youtubegoes5g_1.0-stderr
2024-11-08T01:14:35,767 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9000, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2024-11-08T01:14:37,468 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9000, pid=127
2024-11-08T01:14:37,469 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9000
2024-11-08T01:14:37,479 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Successfully loaded /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2024-11-08T01:14:37,479 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - [PID]127
2024-11-08T01:14:37,479 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Torch worker started.
2024-11-08T01:14:37,479 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-youtubegoes5g_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2024-11-08T01:14:37,480 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9000
2024-11-08T01:14:37,480 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Python runtime: 3.9.18
2024-11-08T01:14:37,481 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2024-11-08T01:14:37,481 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2024-11-08T01:14:37,482 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.LinkedBlockingDeque.pollFirst(LinkedBlockingDeque.java:515) ~[?:?]
	at java.util.concurrent.LinkedBlockingDeque.poll(LinkedBlockingDeque.java:677) ~[?:?]
	at org.pytorch.serve.wlm.Model.pollBatch(Model.java:276) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.BatchAggregator.getRequest(BatchAggregator.java:34) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:186) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2024-11-08T01:14:37,482 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-youtubegoes5g_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2024-11-08T01:14:37,482 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9000.
2024-11-08T01:14:37,482 [WARN ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2024-11-08T01:14:37,483 [WARN ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-youtubegoes5g_1.0-stderr
2024-11-08T01:14:37,483 [WARN ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-youtubegoes5g_1.0-stdout
2024-11-08T01:14:37,483 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 55 seconds.
2024-11-08T01:14:37,496 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-youtubegoes5g_1.0-stdout
2024-11-08T01:14:37,496 [INFO ] W-9000-youtubegoes5g_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-youtubegoes5g_1.0-stderr
2024-11-08T01:15:32,484 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9000, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2024-11-08T01:15:34,166 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9000, pid=135
2024-11-08T01:15:34,166 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9000
2024-11-08T01:15:34,177 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Successfully loaded /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2024-11-08T01:15:34,177 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - [PID]135
2024-11-08T01:15:34,177 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Torch worker started.
2024-11-08T01:15:34,177 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-youtubegoes5g_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2024-11-08T01:15:34,178 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Python runtime: 3.9.18
2024-11-08T01:15:34,178 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9000
2024-11-08T01:15:34,183 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2024-11-08T01:15:34,183 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9000.
2024-11-08T01:15:34,183 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2024-11-08T01:15:34,184 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.LinkedBlockingDeque.pollFirst(LinkedBlockingDeque.java:515) ~[?:?]
	at java.util.concurrent.LinkedBlockingDeque.poll(LinkedBlockingDeque.java:677) ~[?:?]
	at org.pytorch.serve.wlm.Model.pollBatch(Model.java:276) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.BatchAggregator.getRequest(BatchAggregator.java:34) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:186) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2024-11-08T01:15:34,184 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-youtubegoes5g_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2024-11-08T01:15:34,184 [WARN ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2024-11-08T01:15:34,185 [WARN ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-youtubegoes5g_1.0-stderr
2024-11-08T01:15:34,185 [WARN ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-youtubegoes5g_1.0-stdout
2024-11-08T01:15:34,185 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 89 seconds.
2024-11-08T01:15:34,198 [INFO ] W-9000-youtubegoes5g_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-youtubegoes5g_1.0-stderr
2024-11-08T01:15:34,199 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-youtubegoes5g_1.0-stdout
2024-11-08T01:17:03,189 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9000, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2024-11-08T01:17:04,909 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9000, pid=144
2024-11-08T01:17:04,910 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9000
2024-11-08T01:17:04,922 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Successfully loaded /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2024-11-08T01:17:04,923 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - [PID]144
2024-11-08T01:17:04,923 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Torch worker started.
2024-11-08T01:17:04,924 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-youtubegoes5g_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2024-11-08T01:17:04,924 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Python runtime: 3.9.18
2024-11-08T01:17:04,924 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9000
2024-11-08T01:17:04,926 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9000.
2024-11-08T01:17:04,926 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2024-11-08T01:17:04,926 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2024-11-08T01:17:04,926 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.LinkedBlockingDeque.pollFirst(LinkedBlockingDeque.java:515) ~[?:?]
	at java.util.concurrent.LinkedBlockingDeque.poll(LinkedBlockingDeque.java:677) ~[?:?]
	at org.pytorch.serve.wlm.Model.pollBatch(Model.java:276) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.BatchAggregator.getRequest(BatchAggregator.java:34) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:186) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2024-11-08T01:17:04,927 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-youtubegoes5g_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2024-11-08T01:17:04,927 [WARN ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2024-11-08T01:17:04,927 [WARN ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-youtubegoes5g_1.0-stderr
2024-11-08T01:17:04,927 [WARN ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-youtubegoes5g_1.0-stdout
2024-11-08T01:17:04,928 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 144 seconds.
2024-11-08T01:17:04,943 [INFO ] W-9000-youtubegoes5g_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-youtubegoes5g_1.0-stderr
2024-11-08T01:17:04,943 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-youtubegoes5g_1.0-stdout
2024-11-08T01:19:28,929 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/home/venv/bin/python, /home/venv/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /home/model-server/tmp/.ts.sock.9000, --metrics-config, /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml]
2024-11-08T01:19:30,589 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - s_name_part0=/home/model-server/tmp/.ts.sock, s_name_part1=9000, pid=154
2024-11-08T01:19:30,590 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Listening on port: /home/model-server/tmp/.ts.sock.9000
2024-11-08T01:19:30,600 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Successfully loaded /home/venv/lib/python3.9/site-packages/ts/configs/metrics.yaml.
2024-11-08T01:19:30,600 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - [PID]154
2024-11-08T01:19:30,601 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Torch worker started.
2024-11-08T01:19:30,601 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Python runtime: 3.9.18
2024-11-08T01:19:30,601 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-youtubegoes5g_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2024-11-08T01:19:30,601 [INFO ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9000
2024-11-08T01:19:30,602 [INFO ] W-9000-youtubegoes5g_1.0-stdout MODEL_LOG - Connection accepted: /home/model-server/tmp/.ts.sock.9000.
2024-11-08T01:19:30,603 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2024-11-08T01:19:30,603 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2024-11-08T01:19:30,603 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1679) ~[?:?]
	at java.util.concurrent.LinkedBlockingDeque.pollFirst(LinkedBlockingDeque.java:515) ~[?:?]
	at java.util.concurrent.LinkedBlockingDeque.poll(LinkedBlockingDeque.java:677) ~[?:?]
	at org.pytorch.serve.wlm.Model.pollBatch(Model.java:276) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.BatchAggregator.getRequest(BatchAggregator.java:34) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:186) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?]
	at java.lang.Thread.run(Thread.java:833) [?:?]
2024-11-08T01:19:30,604 [DEBUG] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-youtubegoes5g_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2024-11-08T01:19:30,604 [WARN ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerThread - Auto recovery failed again
2024-11-08T01:19:30,604 [WARN ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-youtubegoes5g_1.0-stderr
2024-11-08T01:19:30,604 [WARN ] W-9000-youtubegoes5g_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-youtubegoes5g_1.0-stdout
2024-11-08T01:19:30,628 [INFO ] W-9000-youtubegoes5g_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-youtubegoes5g_1.0-stderr
2024-11-08T01:19:30,629 [INFO ] W-9000-youtubegoes5g_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-youtubegoes5g_1.0-stdout
